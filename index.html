<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"szhowardhuang.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="嵌入式老兵博客">
<meta property="og:url" content="https://szhowardhuang.github.io/index.html">
<meta property="og:site_name" content="嵌入式老兵博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Howard Huang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://szhowardhuang.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>嵌入式老兵博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">嵌入式老兵博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Howard Huang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/04/11/pytorch-file-info/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/11/pytorch-file-info/" class="post-title-link" itemprop="url">Pytorch格式 .pt .pth .bin .onnx 解释</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-04-11 14:11:27 / 修改时间：15:41:27" itemprop="dateCreated datePublished" datetime="2024-04-11T14:11:27+08:00">2024-04-11</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>9 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Pytorch是深度学习领域中非常流行的框架之一，支持的模型保存格式包括.pt和.pth .bin .onnx。这几种格式的文件都可以保存Pytorch训练出的模型，但是它们的区别是什么呢？</p>
<h3 id="格式汇总"><a href="#格式汇总" class="headerlink" title="格式汇总"></a>格式汇总</h3><p>下面是一个整理了 .pt、.pth、.bin、ONNX 和 TorchScript 等 PyTorch 模型文件格式的表格：</p>
<table>
<thead>
<tr>
<th>格式</th>
<th>解释</th>
<th>适用场景</th>
<th>可对应的后缀</th>
</tr>
</thead>
<tbody><tr>
<td>.pt 或 .pth</td>
<td>PyTorch 的默认模型文件格式，用于保存和加载完整的 PyTorch 模型，包含模型的结构和参数等信息。</td>
<td>需要保存和加载完整的 PyTorch 模型的场景，例如在训练中保存最佳的模型或在部署中加载训练好的模型。</td>
<td>.pt 或 .pth</td>
</tr>
<tr>
<td>.bin</td>
<td>一种通用的二进制格式，可以用于保存和加载各种类型的模型和数据。</td>
<td>需要将 PyTorch 模型转换为通用的二进制格式的场景。</td>
<td>.bin</td>
</tr>
<tr>
<td>ONNX</td>
<td>一种通用的模型交换格式，可以用于将模型从一个深度学习框架转换到另一个深度学习框架或硬件平台。在 PyTorch 中，可以使用 torch.onnx.export 函数将 PyTorch 模型转换为 ONNX 格式。</td>
<td>需要将 PyTorch 模型转换为其他深度学习框架或硬件平台可用的格式的场景。</td>
<td>.onnx</td>
</tr>
<tr>
<td>TorchScript</td>
<td>PyTorch 提供的一种序列化和优化模型的方法，可以将 PyTorch 模型转换为一个序列化的程序，并使用 JIT 编译器对模型进行优化。在 PyTorch 中，可以使用 torch.jit.trace 或 torch.jit.script 函数将 PyTorch 模型转换为 TorchScript 格式。</td>
<td>需要将 PyTorch 模型序列化和优化，并在没有 Python 环境的情况下运行模型的场景。</td>
<td>.pt 或 .pth</td>
</tr>
</tbody></table>
<p>不同的后缀只是用于提示我们文件可能包含的内容，但是具体的内容需要看模型提供者编写的README.md才知道。而在使用torch.load()方法加载模型信息的时候，并不是根据文件的后缀进行的读取，而是根据文件的实际内容自动识别的，因此对于torch.load()方法而言，不管你把后缀改成是什么，只要文件是对的都可以读取。</p>
<h3 id="模型的保存与加载到底在做什么？"><a href="#模型的保存与加载到底在做什么？" class="headerlink" title="模型的保存与加载到底在做什么？"></a>模型的保存与加载到底在做什么？</h3><p>我们在使用pytorch构建模型并且训练完成后，下一步要做的就是把这个模型放到实际场景中应用，或者是分享给其他人学习、研究、使用。因此，我们开始思考一个问题，提供哪些模型信息，能够让对方能够完全复现我们的模型？</p>
<p>模型代码：</p>
<ul>
<li>包含了我们如何定义模型的结构，包括模型有多少层&#x2F;每层有多少神经元等等信息；</li>
<li>包含了我们如何定义的训练过程，包括epoch batch_size等参数；</li>
<li>包含了我们如何加载数据和使用；</li>
<li>包含了我们如何测试评估模型。</li>
</ul>
<p>模型参数：提供了模型代码之后，对方确实能够复现模型，但是运行的参数需要重新训练才能得到，而没有办法在我们的模型参数基础上继续训练，因此对方还希望我们能够把模型的参数也保存下来给对方。</p>
<ul>
<li>包含model.state_dict()，这是模型每一层可学习的节点的参数，比如weight&#x2F;bias；</li>
<li>包含optimizer.state_dict()，这是模型的优化器中的参数；</li>
<li>包含我们其他参数信息，如epoch&#x2F;batch_size&#x2F;loss等。</li>
</ul>
<p>数据集：</p>
<ul>
<li>包含了我们训练模型使用的所有数据；</li>
<li>可以提示对方如何去准备同样格式的数据来训练模型。</li>
</ul>
<p>使用文档：</p>
<ul>
<li>根据使用文档的步骤，每个人都可以重现模型；</li>
<li>包含了模型的使用细节和我们相关参数的设置依据等信息。</li>
</ul>
<p>可以看到，根据我们提供的模型代码&#x2F;模型参数&#x2F;数据集&#x2F;使用文档，我们就可以有理由相信对方是有手就会了，那么目的就达到了。</p>
<h3 id="pt-pth格式"><a href="#pt-pth格式" class="headerlink" title=".pt .pth格式"></a>.pt .pth格式</h3><p>一个完整的Pytorch模型文件，包含了如下参数：</p>
<ul>
<li>model_state_dict：模型参数</li>
<li>optimizer_state_dict：优化器的状态</li>
<li>epoch：当前的训练轮数</li>
<li>loss：当前的损失值</li>
</ul>
<p>下面是一个.pt文件的保存和加载示例（注意，后缀也可以是 .pth ）：</p>
<ul>
<li>.state_dict()：包含所有的参数和持久化缓存的字典，model和optimizer都有这个方法</li>
<li>torch.save()：将所有的组件保存到文件中</li>
</ul>
<h4 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h4><pre><code>import torch
import torch.nn as nn

# 定义一个简单的模型
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 5)
        self.fc2 = nn.Linear(5, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        return x

model = Net()

# 保存模型
torch.save(&#123;
            &#39;epoch&#39;: 10,
            &#39;model_state_dict&#39;: model.state_dict(),
            &#39;optimizer_state_dict&#39;: optimizer.state_dict(),
            &#39;loss&#39;: loss,
            &#125;, PATH)
</code></pre>
<h4 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h4><pre><code>import torch
import torch.nn as nn

# 定义同样的模型结构
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 5)
        self.fc2 = nn.Linear(5, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        return x

# 加载模型
model = Net()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint[&#39;model_state_dict&#39;])
optimizer.load_state_dict(checkpoint[&#39;optimizer_state_dict&#39;])
epoch = checkpoint[&#39;epoch&#39;]
loss = checkpoint[&#39;loss&#39;]
model.eval()
</code></pre>
<h3 id="bin格式"><a href="#bin格式" class="headerlink" title=".bin格式"></a>.bin格式</h3><p>.bin文件是一个二进制文件，可以保存Pytorch模型的参数和持久化缓存。.bin文件的大小较小，加载速度较快，因此在生产环境中使用较多。</p>
<p>下面是一个.bin文件的保存和加载示例（注意：也可以使用 .pt .pth 后缀）：</p>
<h4 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h4><pre><code>import torch
import torch.nn as nn

# 定义一个简单的模型
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 5)
        self.fc2 = nn.Linear(5, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        return x

model = Net()
# 保存参数到.bin文件
torch.save(model.state_dict(), PATH)
</code></pre>
<h4 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h4><pre><code>import torch
import torch.nn as nn

# 定义相同的模型结构
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 5)
        self.fc2 = nn.Linear(5, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        return x

# 加载.bin文件
model = Net()
model.load_state_dict(torch.load(PATH))
model.eval()
</code></pre>
<h3 id="onnx格式"><a href="#onnx格式" class="headerlink" title=".onnx格式"></a>.onnx格式</h3><p>上述保存的文件可以通过PyTorch提供的torch.onnx.export函数转化为ONNX格式，这样可以在其他深度学习框架中使用PyTorch训练的模型。转化方法如下：</p>
<pre><code>import torch
import torch.onnx

# 将模型保存为.bin文件
model = torch.nn.Linear(3, 1)
torch.save(model.state_dict(), &quot;model.bin&quot;)
# torch.save(model.state_dict(), &quot;model.pt&quot;)
# torch.save(model.state_dict(), &quot;model.pth&quot;)

# 将.bin文件转化为ONNX格式
model = torch.nn.Linear(3, 1)
model.load_state_dict(torch.load(&quot;model.bin&quot;))
# model.load_state_dict(torch.load(&quot;model.pt&quot;))
# model.load_state_dict(torch.load(&quot;model.pth&quot;))
example_input = torch.randn(1, 3)
torch.onnx.export(model, example_input, &quot;model.onnx&quot;, input_names=[&quot;input&quot;], output_names=[&quot;output&quot;])
</code></pre>
<p>加载ONNX格式的代码可以参考以下示例代码：</p>
<pre><code>import onnx
import onnxruntime

# 加载ONNX文件
onnx_model = onnx.load(&quot;model.onnx&quot;)

# 将ONNX文件转化为ORT格式
ort_session = onnxruntime.InferenceSession(&quot;model.onnx&quot;)

# 输入数据
input_data = np.random.random(size=(1, 3)).astype(np.float32)

# 运行模型
outputs = ort_session.run(None, &#123;&quot;input&quot;: input_data&#125;)

# 输出结果
print(outputs)
</code></pre>
<p>注意，需要安装onnx和onnxruntime两个Python包。此外，还需要使用numpy等其他常用的科学计算库。</p>
<h3 id="直接保存完整模型"><a href="#直接保存完整模型" class="headerlink" title="直接保存完整模型"></a>直接保存完整模型</h3><p>可以看出来，我们在之前的报错方式中，都是保存了.state_dict()，但是没有保存模型的结构，在其他地方使用的时候，必须先重新定义相同结构的模型（或兼容模型），才能够加载模型参数进行使用，如果我们想直接把整个模型都保存下来，避免重新定义模型，可以按如下操作：</p>
<h4 id="保存模型-1"><a href="#保存模型-1" class="headerlink" title="保存模型"></a>保存模型</h4><pre><code>PATH = &quot;entire_model.pt&quot;
# PATH = &quot;entire_model.pth&quot;
# PATH = &quot;entire_model.bin&quot;
model = Net()
torch.save(model, PATH)
</code></pre>
<h4 id="加载模型-1"><a href="#加载模型-1" class="headerlink" title="加载模型"></a>加载模型</h4><pre><code>model = torch.load(&quot;entire_model.pt&quot;)
model.eval()
</code></pre>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>本文介绍了pytorch可以导出的模型的几种后缀格式，但是模型导出的关键并不是后缀，而是到处时候提供的信息到底是什么，只要知道了模型的model.state_dict()和optimizer.state_dict()，以及相应的epoch batch_size loss等信息，我们就能够重建出模型，至于要导出哪些信息，就取决于你了，务必在readme.md中写清楚，你导出了哪些信息。</p>
<p>之所以写了本文，是因为上一篇“通过游戏深入了解强化学习” 训练完模型后，怎么把模型应用到实际场景中，就写了这篇，理解如何加载模型。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/620688513">https://zhuanlan.zhihu.com/p/620688513</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/04/09/reinforce-learing-game/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/09/reinforce-learing-game/" class="post-title-link" itemprop="url">通过游戏深入了解强化学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-04-09 21:11:59" itemprop="dateCreated datePublished" datetime="2024-04-09T21:11:59+08:00">2024-04-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-04-11 16:04:42" itemprop="dateModified" datetime="2024-04-11T16:04:42+08:00">2024-04-11</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文将分为两部分。在这一部分中，我们将探讨一些强化学习的基本理论，同时使用 PyTorch 的 REINFORCE 方法玩 <a target="_blank" rel="noopener" href="https://flappybird.io/">Flappy Bird</a> 游戏。</p>
<p>在下一部分中，我们将研究更复杂的 RL 算法，例如 Advantage Actor Critic （A2C） 和当前最先进的算法 PPO</p>
<h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>强化学习是一种机器学习方法，专注于通过与环境的交互来学习行为策略，旨在实现特定目标或最大化绩效指标。它由三个主要元素组成：环境、代理和奖励。</p>
<p><img src="/../asset_reinforcelearinggame/01.webp"></p>
<ul>
<li>代理从环境接收状态 （s_t）</li>
<li>根据该状态，代理向环境提供操作 （a_t）</li>
<li>环境进入新状态 （s_t+1），并向代理提供一些奖励 （r_t+1）</li>
</ul>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>环境是与代理交互的系统。它定义了代理可能遇到的所有可能状态、在这些状态下可以采取的操作以及这些操作的结果。</p>
<p>环境通过提供新的状态和奖励信息来响应智能体的行为，这些信息用于指导智能体的学习过程。环境定义以下信息：</p>
<ul>
<li>操作空间：定义代理可能执行的一组操作</li>
<li>观察空间：定义代理可以观察的所有可能状态。这些状态提供代理决定其下一步操作所需的信息。状态空间可以是有限的，也可以是无限的，可以是连续的，也可以是离散的</li>
<li>奖励功能： 奖励功能提供对代理行为的即时评估（奖励），指导代理学习如何调整其策略以获得更高的总奖励。</li>
<li>转换动态： 转换动态描述了在给定的当前状态和采取特定操作后环境移动到新状态的概率。</li>
</ul>
<h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>在强化学习中，代理是指可以观察环境、做出决策和执行操作的实体。代理的目标是学习一种策略，这是一种在给定环境状态下选择最佳行动的方法，以便最大化获得的长期回报。</p>
<h2 id="奖励"><a href="#奖励" class="headerlink" title="奖励"></a>奖励</h2><p>奖励是指导代理学习过程的关键信号，提供有关其行为的反馈。这些奖励，无论是积极的还是消极的，都有助于代理了解其行为在实现目标方面的后果。</p>
<p>代理的主要目标是通过学习策略来选择各种状态下的最佳行动，从而随着时间的推移最大化其总回报。</p>
<p><img src="/../asset_reinforcelearinggame/02.webp"></p>
<p>Gt 是时间步长 t 的总奖励（也称为回报）。它被定义为从时间步长 t 到过程结束 （T） 的奖励总和。此外，我们对每个奖励都应用折扣率 γ。该因素决定了未来奖励在时间步长 t 处对总奖励的贡献程度。</p>
<p>贴现率γ是介于 0 和 1 之间的值。以 0.95 为例，预计在更遥远的将来获得的奖励 Rt 乘以一个较小的数字 0.95^（t-1）。</p>
<p>这是因为达到未来某个状态的概率相对较低，因此，它提供的奖励应该较小才能被认为是合理的。</p>
<p><img src="/../asset_reinforcelearinggame/03.webp"></p>
<p>这是一个计算奖励的简单示例。“蛇”和“目标”的图像分别代表初始状态和最终状态。我们现在有两条可能实现目标的途径：</p>
<p>路径1：直上，然后向右走到目标</p>
<p>路径 2：向右走，然后向上走到果阿l</p>
<p>当贴现率 γ &#x3D; 1 时</p>
<ul>
<li>R（路径 1） &#x3D; 2 + γ（-3） + γ²（0） + γ³（1） &#x3D; 0</li>
<li>R（路径 2） &#x3D; 1+ γ（0） + γ²（3） + γ³（0） &#x3D; 4</li>
</ul>
<p>我们可以看到有不同的轨迹（路径）可以达到目标，但每个轨迹都可能导致非常不同的回报（0 和 4）。因此，找到最大化总奖励的最佳轨迹是强化学习 （RL） 的目标。</p>
<p>轨迹： 轨迹（通常表示为 τ）描述了代理所经历的特定状态、操作和奖励序列。例如：τ &#x3D; （s₀， a₀， r₁， s₁， a₁， r₂， s₂， a₂， …， s_T， a_T， r_T+1， s_T+1）</p>
<h2 id="值函数"><a href="#值函数" class="headerlink" title="值函数"></a>值函数</h2><p>为了定义我们的状态有多好，我们必须有一个函数来确定它，这就是值函数。</p>
<p>从本质上讲，此函数估计处于该状态的预期回报。它让人感受到在特定状态下，遵循特定策略（代理遵循的一种策略）所能带来的长期效益。</p>
<p><img src="/../asset_reinforcelearinggame/04.webp"></p>
<p>上面定义的值函数可以重新表述为<a target="_blank" rel="noopener" href="https://huggingface.co/learn/deep-rl-course/unit2/bellman-equation">贝尔曼方程</a>的形式，以提高我们计算其值的能力。这允许我们以递归方式计算状态值。</p>
<p><img src="/../asset_reinforcelearinggame/05.webp"></p>
<p>在值函数中，转移概率 P（a ，s→s′） 的期望值用于解释在相同状态 （s） 下采取相同操作 （a） 的结果（状态 s′）可能会变化的实际场景。</p>
<p>符号 π 表示代理的策略，其中 π（a | s） 表示代理在状态 s 中选择操作 a 的概率。</p>
<p>看一个例子：<br><img src="/../asset_reinforcelearinggame/06.webp"></p>
<p>（r 表示从一种状态过渡到另一种状态获得的即时奖励，例如 s1 -&gt; s3，奖励 &#x3D; 3）</p>
<p>在此场景中，我们有四种状态：s1 作为起始状态，s2、s3 和 s4 作为结束状态。可以选择两个动作，“左”或“右”，每个动作在这些状态之间都有自己的一组转换概率。</p>
<p>不同的策略下状态 1 的值：</p>
<ul>
<li>V（π &#x3D; 始终向左） &#x3D; 0.5 * 2 + 0.5 * 4 &#x3D; 3</li>
<li>V（π &#x3D; 始终向右） &#x3D; 0.33 * 3 + 0.67 * 4 &#x3D; 3.67</li>
<li>V（π &#x3D; 50% 左，50% 右） &#x3D; 0.5 * V（左） + 0.5 * V（右） &#x3D; 3.335<br>此示例考虑了转换概率（例如，action &#x3D; right：33% 到 s3,67% 到 s4），突出了转换的随机性，即相同的操作并不能保证每次都获得相同的结果。</li>
</ul>
<p>一个更复杂的例子：<br><img src="/../asset_reinforcelearinggame/07.webp"></p>
<p>为简单起见，在此示例中，我们将忽略转换概率，代理只能选择在开始时执行“向上”或“向下”操作。对于后续状态，代理始终向右。</p>
<p>（S1 为起始状态，S6 为终末状态，终末状态值 &#x3D; 0）</p>
<p>对于 π &#x3D; 始终向上，γ &#x3D; 1</p>
<ul>
<li>V（s6） &#x3D; 0</li>
<li>V（s3） &#x3D; V（s5） &#x3D; 10 + γV（s6） &#x3D; 10</li>
<li>V（s2） &#x3D; 2+ γV（s3） &#x3D; 12</li>
<li>V（s4） &#x3D; 4+ γV（s5） &#x3D; 14</li>
<li>V（s1） &#x3D; 1 + γV（s2） &#x3D; 13</li>
</ul>
<p>对于π &#x3D;（50% 上升，50% 下降），γ &#x3D; 1</p>
<ul>
<li>V（s6） &#x3D; 0</li>
<li>V（s3） &#x3D; V（s5） &#x3D; 10 + γV（s6） &#x3D; 10</li>
<li>V（s2） &#x3D; 2+ γV（s3） &#x3D; 12</li>
<li>V（s4） &#x3D; 4+ γV（s5） &#x3D; 14</li>
<li>V（s1） &#x3D; （1 + γV（s2）） * 0.5 + （2 + γV（s4）） * 0.5 &#x3D; 9.5</li>
</ul>
<h2 id="Q-函数"><a href="#Q-函数" class="headerlink" title="Q 函数"></a>Q 函数</h2><p>在实践中，如果所有状态的值都是已知的，我们可以通过确保代理在每个时间片移动到具有最高值的状态来最大化累积奖励。</p>
<p>但是，由于计算状态值需要了解转移概率，而转移概率通常是未知的。因此，使用状态-动作函数（Q 函数）成为更好的选择。</p>
<p>由于 Q 值可以直接从经验中学习，因此无需知道环境的转换概率。</p>
<p><img src="/../asset_reinforcelearinggame/08.webp"></p>
<p>Q 函数或 action-value 函数，定义了在策略 π 下的状态 s 中执行操作 a 的值。Q 函数和值函数之间的区别在于，Q 函数指定确定性动作的值，因此无需计算给定策略 π（a∣s） 的动作概率。</p>
<p><img src="/../asset_reinforcelearinggame/09.webp"></p>
<p>值函数也可以看作是所有可能操作 a 的 Q 函数的总和。</p>
<p><img src="/../asset_reinforcelearinggame/10.webp"><br>上式中的Q*（s， a）是最优Q函数</p>
<p>在像 Q-learning 这样基于价值的方法中，始终为每个状态选择具有最高 Q 值的行动的策略确保了总奖励的自动最大化。</p>
<p>但是，当动作空间非常大或连续时，计算所有可能的 Q 值以确定每个状态的最佳动作变得不切实际。</p>
<h2 id="基于策略的方法"><a href="#基于策略的方法" class="headerlink" title="基于策略的方法"></a>基于策略的方法</h2><p><img src="/../asset_reinforcelearinggame/11.webp"><br>强化学习中基于策略的方法，直接参数化和优化代理选择行动所遵循的策略，而无需明确计算作为中间函数的价值函数（基于价值的方法）。</p>
<p>该策略，用 π（a∣s;θ），是一个将状态映射到动作概率分布的函数，其中 θ 表示策略的参数（例如，神经网络的权重）。</p>
<h2 id="强化"><a href="#强化" class="headerlink" title="强化"></a>强化</h2><p>REINFORCETE是一种优化策略的策略梯度方法。它通过估计相对于策略参数的预期回报梯度，然后使用梯度下降来调整这些参数来做到这一点。<br><img src="/../asset_reinforcelearinggame/12.webp"></p>
<p>梯度刻度与回报 （R（τ）） 成正比，回报表示所采取的行动的质量。同时，梯度本身由采取该行动的概率的对数表示。</p>
<p>这种方法旨在增加产生高回报的行动的概率，并降低导致低回报的行动的概率。</p>
<h2 id="强化步骤"><a href="#强化步骤" class="headerlink" title="强化步骤"></a>强化步骤</h2><p>在 REINFORCE 方法中，有必要使用真实样本计算回报。此外，实施还需要通过<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Monte_Carlo_method">蒙特卡洛方法</a>获得的完整轨迹。</p>
<ul>
<li>使用随机权重初始化网络。</li>
<li>执行 N 次完整过程，收集它们的轨迹（s、a、r、s’）</li>
<li>计算每个时间步长的返回值。</li>
<li>计算损失函数 L &#x3D; -R（τ）logπ（a|s）</li>
<li>更新模型权重</li>
</ul>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>在我们的第一个实现中，我们使用 Gym 环境来玩 FlappyBird 游戏。</p>
<p><img src="/../asset_reinforcelearinggame/13.webp"></p>
<p>在开始之前，了解环境的细节非常重要。在实施之前，请确保每次都通读<a target="_blank" rel="noopener" href="https://github.com/markub3327/flappy-bird-gymnasium">文档</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;]=&quot;TRUE&quot;  # 如果遇到KMP_DUPLICATE_LIB 就服用此行</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import gymnasium as gym</span><br><span class="line">import flappy_bird_gymnasium</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def make_env(env_id):</span><br><span class="line">    def wrapped_env():</span><br><span class="line">        env = gym.make(env_id, render_mode=&#x27;rgb_array&#x27;)</span><br><span class="line">        # could add some environment wrapper</span><br><span class="line">        return env</span><br><span class="line">    return wrapped_env</span><br><span class="line"></span><br><span class="line">env_id = &#x27;FlappyBird-v0&#x27;</span><br><span class="line">env = make_env(env_id)()</span><br><span class="line">obs, _ = env.reset()</span><br><span class="line">image = env.render()</span><br><span class="line"></span><br><span class="line">plt.imshow(image)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/../asset_reinforcelearinggame/14.webp"></p>
<p>观测由一个 1D 阵列组成，该阵列由 LIDAR 传感器收集 180 个数据点。代理可以采取两种可能的操作：0 表示不执行任何操作，1 表示拍打。</p>
<p><img src="/../asset_reinforcelearinggame/15.webp"></p>
<h2 id="BirdAgent-训练"><a href="#BirdAgent-训练" class="headerlink" title="BirdAgent &amp; 训练"></a>BirdAgent &amp; 训练</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class BirdPolicy(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(BirdPolicy, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(180, 128)  </span><br><span class="line">        self.relu = nn.ReLU()  </span><br><span class="line">        self.fc2 = nn.Linear(128, 2)  </span><br><span class="line">        self.softmax = nn.Softmax(dim=-1) </span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        return self.softmax(x)</span><br></pre></td></tr></table></figure>

<p>代理主要负责根据环境提供的状态做出决策。它返回一个概率分布，表示选择每个可能操作的可能性。</p>
<p>因此，动作数（表示为 n_action）等于环境的动作空间，即 2。</p>
<p>最后，这里是训练循环~~ </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">def REINFORCE(env, episodes, policy, device, optimizer):</span><br><span class="line">    for episode in range(episodes):</span><br><span class="line">        obs, _ = env.reset()</span><br><span class="line">        log_probs = []</span><br><span class="line">        rewards = []</span><br><span class="line">        done = False</span><br><span class="line">        </span><br><span class="line">        while not done:</span><br><span class="line">            # Add batch dimension</span><br><span class="line">            obs = torch.FloatTensor(obs).unsqueeze(0).to(device) </span><br><span class="line">            probs = policy(obs)</span><br><span class="line">            action = torch.distributions.Categorical(probs).sample()</span><br><span class="line">            log_prob = torch.log(probs.squeeze(0)[action])</span><br><span class="line">            obs, reward, done, _, info = env.step(action.item())</span><br><span class="line">            log_probs.append(log_prob)</span><br><span class="line">            rewards.append(reward)</span><br><span class="line">        Return = []</span><br><span class="line">        Gt = 0</span><br><span class="line"></span><br><span class="line">        for reward in rewards[::-1]:</span><br><span class="line">            # bellman equation</span><br><span class="line">            # computed from back to front</span><br><span class="line">            Gt = reward + 0.99 * Gt</span><br><span class="line">            Return.insert(0, Gt)</span><br><span class="line">        </span><br><span class="line">        Return = torch.tensor(Return).to(device)</span><br><span class="line">        policy_loss = []</span><br><span class="line">        for log_prob, Q in zip(log_probs, Return):</span><br><span class="line">            # compute policy gradient</span><br><span class="line">            policy_loss.append(-log_prob * Q)</span><br><span class="line">            </span><br><span class="line">        policy_loss = torch.cat(policy_loss).mean()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        policy_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">            </span><br><span class="line">        if episode % 200 == 0:</span><br><span class="line">            print(f&#x27;Episode &#123;episode+1&#125;, Total Reward: &#123;sum(rewards)&#125;&#x27;)</span><br><span class="line">            torch.save(policy.state_dict(), f&quot;./weight_epoch.pt&quot;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;</span><br><span class="line">policy = BirdPolicy().to(device) </span><br><span class="line">optimizer = optim.Adam(policy.parameters(), lr=1e-4)</span><br><span class="line"></span><br><span class="line"># train for 20000 iterations</span><br><span class="line">REINFORCE(env, 20000, policy, device, optimizer)</span><br></pre></td></tr></table></figure>

<p>训练完了以后，可以推理一下训练出来的模型。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def INFERENCE(env, policy, device):</span><br><span class="line"></span><br><span class="line">    obs, _ = env.reset()</span><br><span class="line"></span><br><span class="line">    done = False</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    policy.load_state_dict(torch.load(f&quot;./weight_epoch.pt&quot;, map_location=torch.device(&#x27;cpu&#x27;)))</span><br><span class="line">    # 如果模型是CUDA训练出来的，推理用CPU，需要添加 map_location=torch.device(&#x27;cpu&#x27;) 来适配</span><br><span class="line">    policy.eval()</span><br><span class="line">    while not done:</span><br><span class="line">        obs = torch.FloatTensor(obs).unsqueeze(0).to(device)</span><br><span class="line">        probs = policy(obs)</span><br><span class="line">        action = torch.distributions.Categorical(probs).sample()</span><br><span class="line">        obs, reward, done, _, info = env.step(action.item())</span><br></pre></td></tr></table></figure>

<p>修改以下代码就可以看到图像：</p>
<pre><code># env = gym.make(env_id, render_mode=&#39;rgb_array&#39;)
env = gym.make(env_id, render_mode=&#39;human&#39;)
</code></pre>
<p>修改以下代码就可以推理：</p>
<pre><code># REINFORCE(env, 20000, policy, device, optimizer)
INFERENCE(env, policy, device)
</code></pre>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在本文中，我简要介绍了强化学习的基本原理，包括值函数、Q 函数等。我还从策略梯度方法中引入了 REINFORCE 算法，并用它来玩 Flappy Bird 游戏。</p>
<p>在下一部分中，我将介绍另外两种策略梯度方法，A2C 和 PPO，并在两个游戏中实现它们：<a target="_blank" rel="noopener" href="https://gymnasium.farama.org/environments/box2d/car_racing/">赛车</a>和<a target="_blank" rel="noopener" href="https://github.com/linyiLYi/snake-ai">贪吃蛇游戏</a>。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://levelup.gitconnected.com/mastering-game-worlds-a-deep-dive-into-reinforcement-learning-5acccad89a18">https://levelup.gitconnected.com/mastering-game-worlds-a-deep-dive-into-reinforcement-learning-5acccad89a18</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/04/04/langchain-chess/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/04/langchain-chess/" class="post-title-link" itemprop="url">使用LangChain最新的结构化输出功能构建国际象棋代理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-04-04 17:16:15" itemprop="dateCreated datePublished" datetime="2024-04-04T17:16:15+08:00">2024-04-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-04-06 23:50:32" itemprop="dateModified" datetime="2024-04-06T23:50:32+08:00">2024-04-06</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>LangChain最近添加了一个API来返回结构化输出。它使用每个 LLM 提供商的函数调用功能。要使用它，您只需为所需的输出定义一个 pydantic 模型。</p>
<p>结构化输出是构建大型系统的关键，其中各个部分使用 JSON 相互通信。有点类似于 Web 应用程序的后端 API 和前端如何进行通信。</p>
<p>使用 LangChain 的结构化输出功能来构建一个国际象棋代理并使其与 Stockfish 下棋。方法如下。</p>
<p>pip install -U python-dotenv langchain-openai chess</p>
<p>首先，我需要定义我的国际象棋代理将输出什么。在与 Stockfish 的比赛中，我的代理应该至少输出其下一步行动，给定的输入包含棋盘状态、游戏中的行动历史记录以及对计划下一步行动有用的其他数据。</p>
<p>我决定将国际象棋代理的下一步棋定义为包含该棋步的 pydantic 类，以及解释该棋步的推理。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">import chess</span><br><span class="line">import chess.engine</span><br><span class="line">from langchain_core.pydantic_v1 import BaseModel, Field</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class NextMove(BaseModel):</span><br><span class="line">    move: str = Field(..., description=&quot;Best next move to win the chess game. It should be in Standard Algebraic Notation. Always plan 5 moves ahead before deciding the best next move.&quot;)</span><br><span class="line">    reasoning: str = Field(..., description=&quot;Reasoning explaining why the move is the best&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ChatOpenAI(model=&quot;gpt-4&quot;)</span><br><span class="line">chess_agent = model.with_structured_output(NextMove)</span><br></pre></td></tr></table></figure>
<p>接下来，我需要定义我将使用的 Stockfish 引擎的版本。<br>我还在 play_game() 函数中定义了游戏的逻辑。<br>我添加了短期记忆，以便国际象棋代理可以记住过去的比赛，并有可能利用这些知识来提高水平。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"># Initialize a chess board and the chess engine</span><br><span class="line">engine = chess.engine.SimpleEngine.popen_uci(r&quot;F:\stockfish\stockfish\stockfish-windows-x86-64-avx2.exe&quot;)</span><br><span class="line"></span><br><span class="line"># Configure Stockfish to a specific skill level, e.g., 10</span><br><span class="line">engine.configure(&#123;&quot;Skill Level&quot;: 0&#125;)</span><br><span class="line"></span><br><span class="line">file_path = os.path.expanduser(&#x27;~\\learning_chess.txt&#x27;)</span><br><span class="line">try:</span><br><span class="line">    with open(file_path, &#x27;r&#x27;) as file:</span><br><span class="line">        past_game_performance = file.read()</span><br><span class="line">except FileNotFoundError:</span><br><span class="line">    print(f&quot;The file &#123;file_path&#125; does not exist. Creating a new one.&quot;)</span><br><span class="line">    with open(file_path, &#x27;w&#x27;) as file:</span><br><span class="line">        file.write(&quot;Initial content\n&quot;)</span><br><span class="line">        past_game_performance = &quot;Initial content\n&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def play_game():</span><br><span class="line">    moves = []  # Variable to store the list of moves</span><br><span class="line">    board = chess.Board()</span><br><span class="line"></span><br><span class="line">    def get_agent_move(board):</span><br><span class="line">        feedback = &quot;&quot;</span><br><span class="line">        while True:</span><br><span class="line"></span><br><span class="line">            prompt = f&quot;&quot;&quot;Current board: &#123;board&#125;\nMove history: &#123;moves&#125;</span><br><span class="line">            Choose the next move for black in UCI format. The available legal moves are &#123;list(board.legal_moves)&#125;.</span><br><span class="line">            The move you select should be among the legal moves in UCI format like this:&#x27;Move.from_uci(&#x27;g7g5&#x27;)&#x27; &#123;feedback&#125; Only reply with the move and nothing else.</span><br><span class="line">            Take into your past performance against stockfish: &#123;past_game_performance&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">            # No streaming</span><br><span class="line">            response = chess_agent.invoke(prompt)</span><br><span class="line"></span><br><span class="line">            next_move = response.move</span><br><span class="line"></span><br><span class="line">            try:</span><br><span class="line">                move = chess.Move.from_uci(next_move)</span><br><span class="line"></span><br><span class="line">                if move in board.legal_moves:</span><br><span class="line">                    return move</span><br><span class="line">                else:</span><br><span class="line">                    feedback = f&quot;Agent&#x27;s generated move &#123;move&#125; is not valid currently.&quot;</span><br><span class="line">            except:</span><br><span class="line">                feedback = &quot;Failed to parse the Agent&#x27;s generated move. Retrying...&quot;</span><br><span class="line"></span><br><span class="line">    while not board.is_game_over():</span><br><span class="line">        if board.turn:  # True for white&#x27;s turn, False for black&#x27;s turn</span><br><span class="line">            result = engine.play(board, chess.engine.Limit(time=2.0))</span><br><span class="line">            board.push(result.move)</span><br><span class="line">            moves.append(result.move.uci())  # Store UCI move in the list</span><br><span class="line">        else:</span><br><span class="line">            move = get_agent_move(board)</span><br><span class="line">            board.push(move)</span><br><span class="line">            moves.append(move.uci())  # Store UCI move in the list</span><br><span class="line">        print(board)</span><br><span class="line">        print(&quot;\n\n&quot;)</span><br><span class="line"></span><br><span class="line">    # Check the result of the game</span><br><span class="line">    winner = &quot;&quot;</span><br><span class="line">    if board.is_checkmate():</span><br><span class="line">        if board.turn:</span><br><span class="line">            winner = &quot;Black&quot;</span><br><span class="line">        else:</span><br><span class="line">            winner = &quot;White&quot;</span><br><span class="line">    elif board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition() or board.is_variant_draw():</span><br><span class="line">        winner = &quot;Draw&quot;</span><br><span class="line"></span><br><span class="line">    # Write the result in the short term memory</span><br><span class="line">    with open(file_path, &#x27;a&#x27;) as file:</span><br><span class="line">        file.write(f&quot;\n&#123;&#x27; &#x27;.join(moves)&#125; =&gt; Winner: &#123;&#x27;AI Agent&#x27; if winner == &#x27;Black&#x27; else &#x27;Stockfish&#x27;&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    if winner == &quot;Black&quot;:</span><br><span class="line">        return &quot;Agent wins by checkmate.&quot;</span><br><span class="line">    elif winner == &quot;White&quot;:</span><br><span class="line">        return &quot;Stockfish wins by checkmate.&quot;</span><br><span class="line">    else:</span><br><span class="line">        return &quot;The game is a draw.&quot;</span><br></pre></td></tr></table></figure>
<p>在提供的代码片段中，我概述了基于 GPT-4 的自定义 AI 代理与 Stockfish 国际象棋引擎之间国际象棋游戏的设置和执行。以下是代码各段中发生的情况的细分：</p>
<ul>
<li><p>初始化国际象棋引擎：使用该chess.engine.SimpleEngine方法初始化 Stockfish 国际象棋引擎，指定系统上安装的 Stockfish 可执行文件的路径。</p>
</li>
<li><p>配置Stockfish技能等级：通过该 engine.configure 方法将Stockfish引擎的技能等级设置为0 。这部分有一个错误；要将技能等级设置为 10，则应{“Skill Level”: 10}改为{“Skill Level”: 0}。</p>
</li>
<li><p>读取过去的游戏表现：过去游戏的表现是从learning_chess.txt文本文件加载。该信息用于告知人工智能代理在游戏过程中的决策。</p>
</li>
<li><p>玩游戏函数：该函数封装了AI代理和Stockfish引擎之间下棋的逻辑。它在一个名为 moves 的列表中跟踪游戏期间所做的动作moves，并利用一个chess.Board()对象来管理游戏状态。</p>
</li>
<li><p>获取代理移动函数：在该play_game函数中，有一个嵌套函数get_agent_move，旨在确定 AI 代理的下一步移动。它生成一个提示，包括当前棋盘状态、走棋历史和合法走棋，然后等待国际象棋代理（假设是 LLM 或类似的 AI 模型）的响应。该响应被解析并验证为合法的国际象棋棋步。</p>
</li>
<li><p>游戏循环：游戏以循环方式进行，其中 Stockfish 在其回合中进行移动（白色），而 AI 代理在其回合中进行移动（黑色）。由于将死、平局或其他平局情况，将进行移动直至游戏结束。</p>
</li>
<li><p>确定并记录游戏结果：游戏结束时，根据游戏的最终状态确定结果。此结果将附加到learning_chess.txt文件中，用最新的游戏动作和结果更新人工智能代理的“短期记忆”。</p>
</li>
<li><p>返回游戏结果：最后，该函数返回一条字符串消息，指示 AI 代理是否获胜、Stockfish 获胜，或者游戏是否以平局结束。</p>
</li>
</ul>
<p>然后我决定比赛 3 次，看看 GPT-4 能否在国际象棋方面有所改进并击败 Stockfish 16。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># Number of games to play</span><br><span class="line">n_games = 3</span><br><span class="line"></span><br><span class="line"># Initialize a dictionary to store the results</span><br><span class="line">results = &#123;&quot;Agent wins&quot;: 0, &quot;Stockfish wins&quot;: 0, &quot;Draw&quot;: 0&#125;</span><br><span class="line"></span><br><span class="line"># Run the game n times</span><br><span class="line">for i in range(n_games):</span><br><span class="line">    # print(f&quot;Starting game &#123;i+1&#125;...&quot;)</span><br><span class="line">    result = play_game()</span><br><span class="line">    print(result)</span><br><span class="line"></span><br><span class="line">    # Update the results dictionary based on the outcome of the game</span><br><span class="line">    if &quot;Agent wins&quot; in result:</span><br><span class="line">        results[&quot;Agent wins&quot;] += 1</span><br><span class="line">    elif &quot;Stockfish wins&quot; in result:</span><br><span class="line">        results[&quot;Stockfish wins&quot;] += 1</span><br><span class="line">    else:</span><br><span class="line">        results[&quot;Draw&quot;] += 1</span><br><span class="line"></span><br><span class="line">    # print(f&quot;Game &#123;i+1&#125; finished.\n\n&quot;)</span><br><span class="line"></span><br><span class="line"># Print the final results</span><br><span class="line">print(&quot;Final results after playing&quot;, n_games, &quot;games:&quot;)</span><br><span class="line">print(&quot;Agent won:&quot;, results[&quot;Agent wins&quot;], &quot;games&quot;)</span><br><span class="line">print(&quot;Stockfish won:&quot;, results[&quot;Stockfish wins&quot;], &quot;games&quot;)</span><br><span class="line">print(&quot;Draw:&quot;, results[&quot;Draw&quot;], &quot;games&quot;)</span><br></pre></td></tr></table></figure>
<p>开始比赛：</p>
<p><img src="/../asset_chessopenai/01.png"></p>
<p><a href="/../asset_chessopenai/chess_record.txt">比赛记录文本</a></p>
<p>g1f3 e7e5 d2d4 e5d4 d1d4 g8f6 e2e4 b8c6 d4d3 d7d5 e4e5 f6e4 c1e3 f8e7 b1c3 e4c3 d3c3 c6e5 c3e5 f7f6 e5d4 e8g8 d4d2 c8f5 a1d1 f5e4 f3d4 e4g6 f1d3 f8f7 d3e2 d8d7 d4f3 d7e6 f3d4 e6e5 c2c4 e5e4 f2f3 e4f3 e2f3 e7d6 f3d5 d6f4 e3f4 g6d3 d2d3 g8h8 h1f1 f7f8 f4c7 f8g8 f1f3 g7g6 d4e6 g8g7 f3f6 g7g8 d3d4 g8g7 e1d2 g7f7 f6f7 h8g8 e6c5 a8f8 d4g7 &#x3D;&gt; Winner: Stockfish</p>
<p>在尝试了几种策略之后，我得出的结论是 GPT-4 不可能成为国际象棋中的 Stockfish 引擎。</p>
<p>该实验揭示了几个关键点：</p>
<ul>
<li><p>专业化与泛化： Stockfish 在国际象棋方面的专业化使其比 GPT-4 等更通用的 AI 模型更具优势，这强调了特定于任务的编程在某些领域仍然具有显着优势。</p>
</li>
<li><p>人工智能学习和适应：利用过去的游戏表现来指导未来的决策是迈向更具适应性的人工智能系统的一步。尽管 GPT-4 没有超越 Stockfish，但结合过去结果的学习方法对于能够随着时间的推移学习和进化的 AI 的发展至关重要。</p>
</li>
<li><p>AI模型之间的协作： GPT-4和LangChain的结构化输出的实验预示着不同AI技术协同工作以解决复杂问题的未来。将专用引擎与通用模型集成可以产生利用两种方法优势的创新解决方案。</p>
</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://medium.com/ai-advances/can-gpt-4-beat-the-stockfish-engine-lets-use-langchain-to-find-out-0b25133ed563">https://medium.com/ai-advances/can-gpt-4-beat-the-stockfish-engine-lets-use-langchain-to-find-out-0b25133ed563</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/04/03/AirLLM-on-4G/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/03/AirLLM-on-4G/" class="post-title-link" itemprop="url">如何在单个 4GB GPU 上运行 70B LLM</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-04-03 11:26:28 / 修改时间：21:26:28" itemprop="dateCreated datePublished" datetime="2024-04-03T11:26:28+08:00">2024-04-03</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>您是否曾经梦想过使用最先进的大型语言模型 （LLM） 来完成您的自然语言处理 （NLP） 任务，但对高内存要求感到沮丧？如果是这样，您可能会对 AirLLM 感兴趣，这是一个优化推理内存使用的 Python 包，允许 70B LLM 在单个 4GB GPU 卡上运行推理。不需要量化、蒸馏、修剪或其他会导致模型性能下降的模型压缩技术。</p>
<h2 id="什么是-AirLLM"><a href="#什么是-AirLLM" class="headerlink" title="什么是 AirLLM"></a>什么是 AirLLM</h2><p>大型语言模型 （LLM） 的计算成本很高，并且需要大量内存来训练和运行。这样做的原因是 LLM 有大量的层——一个 70B 模型可以有 80 多个层。但是，在推理过程中，语言模型中的每一层都是独立的，并且仅依赖于前一层的输出。因此，没有必要将所有层都保留在 GPU 内存中。相反，我们可以在执行该层时仅从磁盘加载必要的层，执行所有计算，然后完全释放内存。这样，单层所需的 GPU 内存仅与该transformer 层的参数大小差不多，即完整型号的 1&#x2F;80，即 ~2GB。</p>
<p>AirLLM 背后的主要思想确实是将原始 LLM 拆分为更小的子模型，每个子模型包含一个或几个层，并在推理过程中按需加载它们。这样，在任何给定时间，只有必要的子模型保存在内存中，其余的都存储在磁盘上。它还应用块式量化来进一步压缩子模型，从而减少磁盘加载时间和内存使用量。</p>
<p>AirLLM 支持 Hugging Face open LLM 排行榜中的大多数顶级型号，例如 Platypus2、LLaMa2、Mistral、Mixtral、SOLAR、StellarBright 等。</p>
<h2 id="如何使用AirLLM"><a href="#如何使用AirLLM" class="headerlink" title="如何使用AirLLM"></a>如何使用AirLLM</h2><p>使用 AirLLM 非常简单直观。你只需要安装 airllm pip 包，然后使用 AutoModel 类从 Hugging Face 中心或本地路径加载你选择的 LLM。然后，您可以使用 generate 方法执行类似于常规 transformer 模型的推理。例如，以下代码片段演示如何使用 AirLLM 加载和使用 Platypus2–70B-instruct 模型，该模型可以回答自然语言问题并遵循说明。</p>
<p>pip install airllm</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from airllm import AutoModel</span><br><span class="line"></span><br><span class="line">MAX_LENGTH = 128</span><br><span class="line"></span><br><span class="line"># load the model from the Hugging Face hub</span><br><span class="line">model = AutoModel.from_pretrained(&quot;garage-bAInd/Platypus2-70B-instruct&quot;)</span><br><span class="line"></span><br><span class="line"># or load the model from a local path</span><br><span class="line"># model = AutoModel.from_pretrained(&quot;/home/ubuntu/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/b585e74bcaae02e52665d9ac6d23f4d0dbc81a0f&quot;)</span><br><span class="line"></span><br><span class="line"># prepare the input text</span><br><span class="line">input_text = [</span><br><span class="line">    &#x27;What is the capital of United States?&#x27;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"># tokenize the input text</span><br><span class="line">input_tokens = model.tokenizer(input_text,</span><br><span class="line">    return_tensors=&quot;pt&quot;,</span><br><span class="line">    return_attention_mask=False,</span><br><span class="line">    truncation=True,</span><br><span class="line">    max_length=MAX_LENGTH,</span><br><span class="line">    padding=False)</span><br><span class="line"></span><br><span class="line"># generate the output text</span><br><span class="line">generation_output = model.generate(</span><br><span class="line">    input_tokens[&#x27;input_ids&#x27;].cuda(),</span><br><span class="line">    max_new_tokens=20,</span><br><span class="line">    use_cache=True,</span><br><span class="line">    return_dict_in_generate=True)</span><br><span class="line"></span><br><span class="line"># decode the output text</span><br><span class="line">output = model.tokenizer.decode(generation_output.sequences[0])</span><br><span class="line"></span><br><span class="line"># print the output text</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>
<p>此代码片段的输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">What is the capital of United States?</span><br><span class="line">The capital of the United States is Washington, D.C.</span><br></pre></td></tr></table></figure>
<p>请注意，在第一次推理中，AirLLM 将逐层分解并保存原始 LLM，因此请确保您有足够的磁盘空间。之后，AirLLM 将按需加载子模型，并以更快的速度和更少的内存执行推理。</p>
<h2 id="使用-AirLLM-有什么好处？"><a href="#使用-AirLLM-有什么好处？" class="headerlink" title="使用 AirLLM 有什么好处？"></a>使用 AirLLM 有什么好处？</h2><p>通过使用 AirLLM，您具有以下优势：</p>
<ul>
<li>访问最先进的 LLM：您可以将最先进的 LLM 用于您的 NLP 任务，例如问答、文本生成、文本摘要、文本分类等。您可以从各种适合您的需求和偏好的模型中进行选择，例如特定于域的模型、多语言模型或指令优化模型。</li>
<li>低内存要求：无需担心内存不足错误或昂贵的云计算资源。您可以在单个 4GB GPU 卡上运行推理，甚至可以在 CPU 或 Mac 设备上运行推理。</li>
<li>简单直观的使用：您可以使用 AirLLM 作为常规 transformer 型号的直接替代品，只需最少的代码更改。</li>
</ul>
<h2 id="使用-AirLLM-的缺点是什么？"><a href="#使用-AirLLM-的缺点是什么？" class="headerlink" title="使用 AirLLM 的缺点是什么？"></a>使用 AirLLM 的缺点是什么？</h2><p>如前所述，AirLLM 在执行该层时仅从磁盘加载必要的层，然后完全释放内存。但是，从速度较慢的存储（如磁盘 I&#x2F;O）按顺序加载数据会增加推理过程的延迟。如果 SSD 的读数为 4GB&#x2F;s，而型号的读数为 80Gb，则您将等待 20 秒才能生成一个令牌，并且对于每个令牌，您需要完全通过。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://generativeai.pub/how-to-run-70b-llms-on-a-single-4gb-gpu-d1c61ed5258c">https://generativeai.pub/how-to-run-70b-llms-on-a-single-4gb-gpu-d1c61ed5258c</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/04/02/scratch-ai-agent-openai/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/02/scratch-ai-agent-openai/" class="post-title-link" itemprop="url">利用 OpenAI 工具：从零开始构建可靠的 AI 代理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-04-02 20:26:28" itemprop="dateCreated datePublished" datetime="2024-04-02T20:26:28+08:00">2024-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-04-03 21:26:28" itemprop="dateModified" datetime="2024-04-03T21:26:28+08:00">2024-04-03</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>18k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>32 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>思考人工智能的未来，我脑海中浮现出《钢铁侠》中的贾维斯和《命运》（游戏）中的拉斯普京。在这两个例子中，人工智能充当了一个通过语音控制的接口，提供高级抽象的复杂系统。例如，托尼·斯塔克使用它来管理他的研究、进行计算和运行模拟。甚至 R2D2 也可以响应语音命令，与陌生的计算机系统进行交互，提取数据或与建筑系统进行交互。</p>
<p>在这些场景中，人工智能使得用户可以与复杂系统进行交互，而无需对其有深入的理解。这可以类比今天大型公司中的企业资源计划（ERP）系统。在大型公司中很少有人完全了解和理解内部 ERP 系统的每个方面。不难想象，在不久的将来，人工智能可能几乎会在与 ERP 系统的每个交互中提供帮助。从最终用户管理客户数据或记录订单，到软件开发人员修复错误或实施新功能，这些交互可能很快就会由熟悉 ERP 系统的人工智能助手来完成。这样的人工智能助手将知道将客户数据输入哪个数据库，以及哪些流程和代码可能与错误相关。</p>
<p>为了实现这一目标，我们面临着几个挑战和创新。我们需要重新思考流程及其文档化。如今的企业资源计划（ERP）流程是为人类使用而设计的，不同用户有不同的角色，文档是给人类看的，输入掩码是为人类设计的，用户交互旨在直观且无误。对于人工智能（AI）交互，这些方面的设计将会有所不同。我们需要为 AI 交互设定特定的角色，并设计不同的流程，以实现直观且无误的 AI 交互。这在我们与提示信息的工作中已经显现出来。我们认为的明确任务往往并不那么简单明了。</p>
<h2 id="从概念到现实：构建-AI-代理的基础"><a href="#从概念到现实：构建-AI-代理的基础" class="headerlink" title="从概念到现实：构建 AI 代理的基础"></a>从概念到现实：构建 AI 代理的基础</h2><p>让我们回到代理的概念。代理是能够使用提供的工具执行任务并决策如何使用这些工具的人工智能助手，它们是最终可能实现这样一个系统的构建模块。它们是我们希望将其整合到复杂系统的各个方面的过程组件。但是它们很难可靠地部署（之前在internlm实践lagent就不成功）。在本文中，我将演示如何设计和优化一个能够可靠地与数据库进行交互的代理。</p>
<p>AI 的未来宏伟愿景令人鼓舞，但实现这一愿景需要采取切实可行的步骤。为了展示我们如何开始构建这种先进 AI 系统的基础，让我们专注于创建一个常见任务的原型代理：“费用跟踪”。这个原型将作为一个具体的例子，展示 AI 如何在高效管理财务交易方面提供帮助，展示 AI 在自动化例行任务方面的潜力，并突出设计与数据库无缝交互的 AI 系统所涉及的挑战和考虑因素。通过从一个具体而易于理解的用例开始，我们可以获得宝贵的见解，为未来更复杂的 AI 代理的开发提供指导。</p>
<h2 id="本文目的"><a href="#本文目的" class="headerlink" title="本文目的"></a>本文目的</h2><p>本文将为一系列文章奠定基础，旨在开发一个聊天机器人，它可以作为小型企业支持和执行业务流程的唯一交互点，或者作为你个人生活中组织一切需要跟踪的东西的聊天机器人。从数据、例行事务、文件到图片，我们希望能够简单地与我们的助手聊天，让它找出存储和检索数据的位置。</p>
<p>从 AI 未来的宏伟愿景过渡到实际应用，让我们聚焦于创建一个原型代理。这个代理将作为实现之前讨论的雄心勃勃的目标的基础步骤。我们将着手开发一个“费用跟踪”代理，这是一个简单但至关重要的任务，展示了 AI 如何能够有效地协助管理财务交易。</p>
<p>这个“费用跟踪”原型不仅展示了人工智能在自动化例行任务方面的潜力，还阐明了设计与数据库无缝交互的人工智能系统所涉及的挑战和考虑因素。通过专注于这个例子，我们可以探索代理设计、输入验证以及将人工智能与现有系统整合的复杂性，为未来更复杂的应用奠定坚实基础。</p>
<h2 id="实践：测试-OpenAI-工具调用"><a href="#实践：测试-OpenAI-工具调用" class="headerlink" title="实践：测试 OpenAI 工具调用"></a>实践：测试 OpenAI 工具调用</h2><p>为了让我们的原型代理程序运行起来并找出潜在的瓶颈，我们尝试测试 OpenAI 的工具调用功能。从一个基本的费用跟踪示例开始，我们正在构建一个模拟真实应用程序的基础部分。这个阶段涉及创建一个基本模型，并使用 langchain 库的convert_to_openai_tool函数将其转换为 OpenAI 工具模式。此外，我们制作一个 report_tool ，以便我们未来的代理程序可以与结果进行通信，或者突出显示缺失的信息或问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from pydantic.v1 import BaseModel, validator  </span><br><span class="line">from datetime import datetime</span><br><span class="line">from langchain_core.utils.function_calling import convert_to_openai_tool</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">class Expense(BaseModel):    </span><br><span class="line">   description: str    </span><br><span class="line">   net_amount: float    </span><br><span class="line">   gross_amount: float    </span><br><span class="line">   tax_rate: float    </span><br><span class="line">   date: datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Report(BaseModel):</span><br><span class="line">   report: str</span><br><span class="line"></span><br><span class="line">add_expense_tool = convert_to_openai_tool(Expense)</span><br><span class="line">report_tool = convert_to_openai_tool(Report)</span><br></pre></td></tr></table></figure>

<p>数据模型和工具设置好之后，下一步是使用 OpenAI 客户端 SDK 发起一个简单的工具调用。在这个初始测试中，我们故意提供不足的信息给模型，以查看它是否能正确地指示缺失的内容。这种方法不仅测试了代理的功能能力，还测试了它的交互和错误处理能力。</p>
<h3 id="调用-OpenAI-API"><a href="#调用-OpenAI-API" class="headerlink" title="调用 OpenAI API"></a>调用 OpenAI API</h3><p>现在，我们将使用 OpenAI 客户端 SDK 来发起一个简单的工具调用。在我们的第一个测试中，我们故意提供了不足的信息给模型，以查看它是否能够通知我们缺失的细节。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">from openai import OpenAI  </span><br><span class="line">from langchain_core.utils.function_calling import convert_to_openai_tool  </span><br><span class="line">  </span><br><span class="line">SYSTEM_MESSAGE = &quot;&quot;&quot;You are tasked with completing specific objectives and </span><br><span class="line">must report the outcomes. At your disposal, you have a variety of tools, </span><br><span class="line">each specialized in performing a distinct type of task.  </span><br><span class="line">  </span><br><span class="line">For successful task completion:  </span><br><span class="line">Thought: Consider the task at hand and determine which tool is best suited </span><br><span class="line">based on its capabilities and the nature of the work.  </span><br><span class="line">  </span><br><span class="line">Use the report_tool with an instruction detailing the results of your work.  </span><br><span class="line">If you encounter an issue and cannot complete the task:  </span><br><span class="line">  </span><br><span class="line">Use the report_tool to communicate the challenge or reason for the </span><br><span class="line">task&#x27;s incompletion.  </span><br><span class="line">You will receive feedback based on the outcomes of </span><br><span class="line">each tool&#x27;s task execution or explanations for any tasks that </span><br><span class="line">couldn&#x27;t be completed. This feedback loop is crucial for addressing </span><br><span class="line">and resolving any issues by strategically deploying the available tools.  </span><br><span class="line">&quot;&quot;&quot;  </span><br><span class="line">user_message = &quot;I have spend 5$ on a coffee today please track my expense. The tax rate is 0.2.&quot;</span><br><span class="line">  </span><br><span class="line">client = OpenAI()  </span><br><span class="line">model_name = &quot;gpt-3.5-turbo-0125&quot;  </span><br><span class="line">  </span><br><span class="line">messages = [  </span><br><span class="line">    &#123;&quot;role&quot;:&quot;system&quot;, &quot;content&quot;: SYSTEM_MESSAGE&#125;,  </span><br><span class="line">    &#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: user_message&#125;  </span><br><span class="line">]  </span><br><span class="line">  </span><br><span class="line">response = client.chat.completions.create(  </span><br><span class="line">            model=model_name,  </span><br><span class="line">            messages=messages,  </span><br><span class="line">            tools=[  </span><br><span class="line">                convert_to_openai_tool(Expense),  </span><br><span class="line">                convert_to_openai_tool(ReportTool)]  </span><br><span class="line">        )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>接下来，我们需要一个新的函数来从响应中读取函数调用的参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def parse_function_args(response):</span><br><span class="line">    message = response.choices[0].message</span><br><span class="line">    return json.loads(message.tool_calls[0].function.arguments)</span><br><span class="line"></span><br><span class="line">print(parse_function_args(response))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;description&#x27;: &#x27;Coffee&#x27;,</span><br><span class="line"> &#x27;net_amount&#x27;: 5,</span><br><span class="line"> &#x27;gross_amount&#x27;: None,</span><br><span class="line"> &#x27;tax_rate&#x27;: 0.2,</span><br><span class="line"> &#x27;date&#x27;: &#x27;2023-10-06T12:00:00Z&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p> 正如我们所观察到的，我们在执行过程中遇到了几个问题</p>
<ul>
<li><p>The gross_amount is not calculated.  总金额未计算。</p>
</li>
<li><p>The date is hallucinated.  日期是幻觉。</p>
</li>
</ul>
<p>考虑到这一点，让我们尝试解决这些问题并优化我们的代理工作流程。</p>
<h2 id="优化：工具处理流程"><a href="#优化：工具处理流程" class="headerlink" title="优化：工具处理流程"></a>优化：工具处理流程</h2><p>为了优化代理工作流程，我发现将工作流程置于提示工程之上至关重要。虽然微调提示以使代理学会完美使用提供的工具并避免错误可能很诱人，但更明智的做法是首先调整工具和流程。当发生典型错误时，最初的考虑应该是如何基于代码修复它。</p>
<h3 id="处理缺失信息"><a href="#处理缺失信息" class="headerlink" title="处理缺失信息"></a>处理缺失信息</h3><p>处理缺失信息对于创建强大可靠的代理程序来说是一个重要的课题。在前面的例子中，为代理程序提供像“get_current_date”这样的工具是特定场景下的一种解决方法。然而，我们必须假设在各种情境中都会出现缺失信息，并且不能仅仅依靠提示工程和添加更多工具来防止模型产生缺失信息的幻觉。</p>
<p>对于这种情况，一个简单的解决方法是修改工具模式，将所有参数视为可选。这种方法确保代理只提交它知道的参数，避免不必要的幻觉。</p>
<p>因此，让我们来看一下 OpenAI 工具模式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">add_expense_tool = convert_to_openai_tool(Expense)</span><br><span class="line">print(add_expense_tool)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;type&#x27;: &#x27;function&#x27;,</span><br><span class="line"> &#x27;function&#x27;: &#123;&#x27;name&#x27;: &#x27;Expense&#x27;,</span><br><span class="line">  &#x27;description&#x27;: &#x27;&#x27;,</span><br><span class="line">  &#x27;parameters&#x27;: &#123;&#x27;type&#x27;: &#x27;object&#x27;,</span><br><span class="line">   &#x27;properties&#x27;: &#123;&#x27;description&#x27;: &#123;&#x27;type&#x27;: &#x27;string&#x27;&#125;,</span><br><span class="line">    &#x27;net_amount&#x27;: &#123;&#x27;type&#x27;: &#x27;number&#x27;&#125;,</span><br><span class="line">    &#x27;gross_amount&#x27;: &#123;&#x27;type&#x27;: &#x27;number&#x27;&#125;,</span><br><span class="line">    &#x27;tax_rate&#x27;: &#123;&#x27;type&#x27;: &#x27;number&#x27;&#125;,</span><br><span class="line">    &#x27;date&#x27;: &#123;&#x27;type&#x27;: &#x27;string&#x27;, &#x27;format&#x27;: &#x27;date-time&#x27;&#125;&#125;,</span><br><span class="line">   &#x27;required&#x27;: [&#x27;description&#x27;,</span><br><span class="line">    &#x27;net_amount&#x27;,</span><br><span class="line">    &#x27;gross_amount&#x27;,</span><br><span class="line">    &#x27;tax_rate&#x27;,</span><br><span class="line">    &#x27;date&#x27;]&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>正如我们所看到的，我们有一个特殊的键required，我们需要将其移除。以下是您可以通过移除该required键来调整add_expense_tool模式以使参数变为可选的方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">del add_expense_tool[&quot;function&quot;][&quot;parameters&quot;][&quot;required&quot;]</span><br></pre></td></tr></table></figure>

<h3 id="设计工具类"><a href="#设计工具类" class="headerlink" title="设计工具类"></a>设计工具类</h3><p>接下来，我们可以设计一个工具类，最初检查输入参数是否缺失。我们创建这个Tool类有两个方法：.run()，.validate_input()，和一个openai_tool_schema属性，通过删除必需的参数来操作工具模式。此外，我们定义了ToolResult BaseModel，其中包含content字段和success字段，用于每次工具运行的输出对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">from pydantic import BaseModel</span><br><span class="line">from typing import Type, Callable, Dict, Any, List</span><br><span class="line"></span><br><span class="line">class ToolResult(BaseModel):  </span><br><span class="line">    content: str  </span><br><span class="line">    success: bool  </span><br><span class="line">  </span><br><span class="line">class Tool(BaseModel):  </span><br><span class="line">    name: str  </span><br><span class="line">    model: Type[BaseModel]  </span><br><span class="line">    function: Callable  </span><br><span class="line">    validate_missing: bool = False  </span><br><span class="line">  </span><br><span class="line">    class Config:  </span><br><span class="line">        arbitrary_types_allowed = True  </span><br><span class="line">  </span><br><span class="line">    def run(self, **kwargs) -&gt; ToolResult:</span><br><span class="line">        if self.validate_missing:</span><br><span class="line">            missing_values = self.validate_input(**kwargs)  </span><br><span class="line">            if missing_values:  </span><br><span class="line">                content = f&quot;Missing values: &#123;&#x27;, &#x27;.join(missing_values)&#125;&quot;  </span><br><span class="line">                return ToolResult(content=content, success=False)  </span><br><span class="line">        result = self.function(**kwargs)  </span><br><span class="line">        return ToolResult(content=str(result), success=True)  </span><br><span class="line">      </span><br><span class="line">    def validate_input(self, **kwargs) -&gt; List[str]:  </span><br><span class="line">        missing_values = []  </span><br><span class="line">        for key in self.model.__fields__.keys():  </span><br><span class="line">            if key not in kwargs:  </span><br><span class="line">                missing_values.append(key)  </span><br><span class="line">        return missing_values</span><br><span class="line">    @property</span><br><span class="line">    def openai_tool_schema(self) -&gt; Dict[str, Any]:</span><br><span class="line">        schema = convert_to_openai_tool(self.model)</span><br><span class="line">        if &quot;required&quot; in schema[&quot;function&quot;][&quot;parameters&quot;]:</span><br><span class="line">            del schema[&quot;function&quot;][&quot;parameters&quot;][&quot;required&quot;]</span><br><span class="line">        return schem</span><br></pre></td></tr></table></figure>
<p>该Tool类是 AI 代理工作流程中的关键组成部分，作为一个蓝图来创建和管理各种工具，这些工具由代理来执行特定任务。它被设计用于处理输入验证，执行工具的功能，并以标准化格式返回结果。</p>
<h3 id="Tool-类的关键组成部分："><a href="#Tool-类的关键组成部分：" class="headerlink" title="Tool 类的关键组成部分："></a>Tool 类的关键组成部分：</h3><ul>
<li>name ：工具的名称。</li>
<li>model ：定义工具输入模式的 Pydantic BaseModel。</li>
<li>function ：工具执行的可调用函数。</li>
<li>validate_missing ：一个布尔标志，指示是否validate missing的输入值（默认为 False ）。</li>
</ul>
<h3 id="这个Tool类有两个主要方法："><a href="#这个Tool类有两个主要方法：" class="headerlink" title="这个Tool类有两个主要方法："></a>这个Tool类有两个主要方法：</h3><ul>
<li><p>run(self, **kwargs) -&gt; ToolResult: 该方法负责使用提供的输入参数执行tool的功能。首先检查validate_missing 是否设置为True。如果是，则调用validate_input()方法检查缺少的输入值。如果找到任何缺少的值，则返回一个带有错误消息的ToolResult对象，并设置success 为False。如果所有必需的输入值都存在，则继续使用提供的参数执行tool的function ，并返回一个带有结果的对象ToolResult ，并设置success 为True。</p>
</li>
<li><p>validate_input(self, **kwargs) -&gt; List[str]: 该方法将传递给tool的输入参数与在model中定义的预期输入模式进行比较。它遍历model中定义的字段，并检查每个字段是否存在于输入参数中。如果有任何字段缺失，它将字段名称追加到缺失值列表中。最后，它返回缺失值列表。</p>
</li>
</ul>
<p>该Tool类还有一个名为openai_tool_schema的属性，它返回该工具的 OpenAI 工具模式。它使用convert_to_openai_tool()函数将model转换为 OpenAI 工具模式格式。此外，它从模式中删除”required”键，使所有输入参数都是可选的。这使得代理可以仅提供可用信息，而无需虚构缺失的值。</p>
<p>通过封装工具的功能、输入验证和模式生成，该Tool类为在 AI 代理的工作流中创建和管理工具提供了一个干净且可重用的接口。它抽象了处理缺失值的复杂性，并确保代理能够优雅地处理不完整的信息，同时根据可用的输入执行适当的工具。</p>
<h3 id="测试缺失信息的处理流程"><a href="#测试缺失信息的处理流程" class="headerlink" title="测试缺失信息的处理流程"></a>测试缺失信息的处理流程</h3><p>接下来，我们将扩展我们的 OpenAI API 调用。我们希望客户端能够利用我们的工具，并且我们的响应对象能够直接触发 tool.run()。为此，我们需要在我们新创建的 Tool 类中初始化我们的工具。我们定义了两个虚拟函数，它们返回一个成功消息字符串。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def add_expense_func(**kwargs):  </span><br><span class="line">    return f&quot;Added expense: &#123;kwargs&#125; to the database.&quot;</span><br><span class="line"></span><br><span class="line">add_expense_tool = Tool(  </span><br><span class="line">    name=&quot;add_expense_tool&quot;,  </span><br><span class="line">    model=Expense,  </span><br><span class="line">    function=add_expense_func  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">def report_func(report: str = None):  </span><br><span class="line">    return f&quot;Reported: &#123;report&#125;&quot;  </span><br><span class="line">  </span><br><span class="line">report_tool = Tool(  </span><br><span class="line">    name=&quot;report_tool&quot;,  </span><br><span class="line">    model=ReportTool,  </span><br><span class="line">    function=report_func  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">tools = [add_expense_tool, report_tool]</span><br></pre></td></tr></table></figure>
<p>接下来，我们定义了一个辅助函数，它以客户端的响应作为输入，并帮助与我们的工具进行交互。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def get_tool_from_response(response, tools=tools):  </span><br><span class="line">    tool_name = response.choices[0].message.tool_calls[0].function.name  </span><br><span class="line">    for t in tools:  </span><br><span class="line">        if t.name == tool_name:  </span><br><span class="line">            return t  </span><br><span class="line">    raise ValueError(f&quot;Tool &#123;tool_name&#125; not found in tools list.&quot;)</span><br><span class="line"></span><br><span class="line">def parse_function_args(response):  </span><br><span class="line">    message = response.choices[0].message  </span><br><span class="line">    return json.loads(message.tool_calls[0].function.arguments)</span><br><span class="line"></span><br><span class="line">def run_tool_from_response(response, tools=tools):  </span><br><span class="line">    tool = get_tool_from_response(response, tools)  </span><br><span class="line">    tool_kwargs = parse_function_args(response)  </span><br><span class="line">    return tool.run(**tool_kwargs)</span><br></pre></td></tr></table></figure>

<p>现在，我们可以使用我们的新工具执行客户端并使用该run_tool_from_response 函数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">response = client.chat.completions.create(  </span><br><span class="line">            model=model_name,  </span><br><span class="line">            messages=messages,  </span><br><span class="line">            tools=[tool.openai_tool_schema for tool in tools]  </span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">tool_result = run_tool_from_response(response, tools=tools)</span><br><span class="line">print(tool_result)</span><br></pre></td></tr></table></figure>

<p>运行上述代码后，您应该会看到以下输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">content=&#x27;Missing values: gross_amount, date&#x27; success=False</span><br></pre></td></tr></table></figure>

<p>完美，我们现在看到我们的工具显示存在缺失值。多亏了我们将所有参数都设为可选的技巧，我们现在避免了虚构的参数。</p>
<h2 id="构建代理工作流程"><a href="#构建代理工作流程" class="headerlink" title="构建代理工作流程"></a>构建代理工作流程</h2><p>我们目前的流程还不能代表一个真正的代理。到目前为止，我们只执行了一个 API 工具调用。为了将其转化为代理工作流程，我们需要引入一个迭代过程，将工具执行的结果反馈给客户端。基本流程应该是这样的：<br><img src="/../asset_scratchaiagentopenai/01.webp"></p>
<p>让我们开始创建一个新的 OpenAIAgent 类：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">class StepResult(BaseModel):  </span><br><span class="line">    event: str   </span><br><span class="line">    content: str  </span><br><span class="line">    success: bool</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class OpenAIAgent:  </span><br><span class="line">      </span><br><span class="line">    def __init__(  </span><br><span class="line">            self,   </span><br><span class="line">            tools: list[Tool],   </span><br><span class="line">            client: OpenAI,   </span><br><span class="line">            system_message: str = SYSTEM_MESSAGE,   </span><br><span class="line">            model_name: str = &quot;gpt-3.5-turbo-0125&quot;,  </span><br><span class="line">            max_steps: int = 5,  </span><br><span class="line">            verbose: bool = True  </span><br><span class="line">    ):  </span><br><span class="line">        self.tools = tools  </span><br><span class="line">        self.client = client  </span><br><span class="line">        self.model_name = model_name  </span><br><span class="line">        self.system_message = system_message  </span><br><span class="line">        self.step_history = []  </span><br><span class="line">        self.max_steps = max_steps  </span><br><span class="line">        self.verbose = verbose  </span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">    def to_console(self, tag: str, message: str, color: str = &quot;green&quot;):  </span><br><span class="line">        if self.verbose:  </span><br><span class="line">            color_prefix = Fore.__dict__[color.upper()]  </span><br><span class="line">            print(color_prefix + f&quot;&#123;tag&#125;: &#123;message&#125;&#123;Style.RESET_ALL&#125;&quot;)</span><br></pre></td></tr></table></figure>

<p>像我们的ToolResult对象一样，我们将一个StepResult  定义为每个代理步骤的对象。然后，我们定义了 OpenAIAgent 类的__init__ 方法和一个 to_console() 方法，用于将我们的中间步骤和工具调用打印到控制台，使用 colorama 进行彩色打印。接下来，我们定义了代理的核心，run() 和run_step() 方法。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">class OpenAIAgent:</span><br><span class="line"></span><br><span class="line">    # ... __init__...</span><br><span class="line">    </span><br><span class="line">    # ... to_console ...</span><br><span class="line">    </span><br><span class="line">    def run(self, user_input: str):  </span><br><span class="line">        </span><br><span class="line">        openai_tools = [tool.openai_tool_schema for tool in self.tools]    </span><br><span class="line">        self.step_history = [    </span><br><span class="line">            &#123;&quot;role&quot;:&quot;system&quot;, &quot;content&quot;:self.system_message&#125;,    </span><br><span class="line">            &#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;:user_input&#125;    </span><br><span class="line">        ]    </span><br><span class="line">          </span><br><span class="line">        step_result = None    </span><br><span class="line">        i = 0</span><br><span class="line">        </span><br><span class="line">        self.to_console(&quot;START&quot;, f&quot;Starting Agent with Input: &#123;user_input&#125;&quot;)</span><br><span class="line">          </span><br><span class="line">        while i &lt; self.max_steps:  </span><br><span class="line">            step_result = self.run_step(self.step_history, openai_tools)    </span><br><span class="line">            </span><br><span class="line">            if step_result.event == &quot;finish&quot;:    </span><br><span class="line">                break  </span><br><span class="line">            elif step_result.event == &quot;error&quot;:  </span><br><span class="line">                self.to_console(step_result.event, step_result.content, &quot;red&quot;)  </span><br><span class="line">            else:  </span><br><span class="line">                self.to_console(step_result.event, step_result.content, &quot;yellow&quot;)  </span><br><span class="line">            i += 1   </span><br><span class="line">              </span><br><span class="line">        self.to_console(&quot;Final Result&quot;, step_result.content, &quot;green&quot;)  </span><br><span class="line">        return step_result.content</span><br></pre></td></tr></table></figure>

<p>在该run() 方法中，我们首先通过使用预定义的 system_message 和 user_input 来初始化step_history，它们将作为我们的消息存储器。然后我们开始我们的 while 循环，在每次迭代中调用 run_step  函数，它将返回一个 StepResult 对象。我们判断代理是否完成了任务或是否发生了错误，并将其传递给控制台。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">class OpenAIAgent:</span><br><span class="line"></span><br><span class="line">    # ... __init__...</span><br><span class="line">    </span><br><span class="line">    # ... to_console ...</span><br><span class="line">    # ... run ...</span><br><span class="line">    def run_step(self, messages: list[dict], tools):  </span><br><span class="line">          </span><br><span class="line">        # plan the next step  </span><br><span class="line">        response = self.client.chat.completions.create(  </span><br><span class="line">            model=self.model_name,  </span><br><span class="line">            messages=messages,  </span><br><span class="line">            tools=tools  </span><br><span class="line">        )  </span><br><span class="line">          </span><br><span class="line">        # add message to history  </span><br><span class="line">        self.step_history.append(response.choices[0].message)  </span><br><span class="line">        </span><br><span class="line">        # check if tool call is present  </span><br><span class="line">        if not response.choices[0].message.tool_calls:  </span><br><span class="line">            return StepResult(</span><br><span class="line">                event=&quot;Error&quot;,</span><br><span class="line">                content=&quot;No tool calls were returned.&quot;, </span><br><span class="line">                success=False</span><br><span class="line">                )  </span><br><span class="line">          </span><br><span class="line">        tool_name = response.choices[0].message.tool_calls[0].function.name  </span><br><span class="line">        tool_kwargs = parse_function_args(response)  </span><br><span class="line">          </span><br><span class="line">        # execute the tool call  </span><br><span class="line">        self.to_console(</span><br><span class="line">        &quot;Tool Call&quot;, f&quot;Name: &#123;tool_name&#125;\nArgs: &#123;tool_kwargs&#125;&quot;, &quot;magenta&quot;</span><br><span class="line">        )  </span><br><span class="line">        tool_result = run_tool_from_response(response, tools=self.tools)  </span><br><span class="line">        tool_result_msg = self.tool_call_message(response, tool_result)  </span><br><span class="line">        self.step_history.append(tool_result_msg)  </span><br><span class="line">          </span><br><span class="line">        if tool_result.success:  </span><br><span class="line">            step_result = StepResult(  </span><br><span class="line">                event=&quot;tool_result&quot;,   </span><br><span class="line">                content=tool_result.content,   </span><br><span class="line">                success=True)  </span><br><span class="line">        else:  </span><br><span class="line">            step_result = StepResult(  </span><br><span class="line">                event=&quot;error&quot;,   </span><br><span class="line">                content=tool_result.content,   </span><br><span class="line">                success=False  </span><br><span class="line">            )   </span><br><span class="line">          </span><br><span class="line">        return step_result  </span><br><span class="line">          </span><br><span class="line">      </span><br><span class="line">    def tool_call_message(self, response, tool_result: ToolResult):  </span><br><span class="line">        tool_call = response.choices[0].message.tool_calls[0]  </span><br><span class="line">        return &#123;  </span><br><span class="line">            &quot;tool_call_id&quot;: tool_call.id,  </span><br><span class="line">            &quot;role&quot;: &quot;tool&quot;,  </span><br><span class="line">            &quot;name&quot;: tool_call.function.name,  </span><br><span class="line">            &quot;content&quot;: tool_result.content,  </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<p>现在我们已经为每个步骤定义了逻辑。我们首先通过之前测试过的客户端 API 调用工具来获取一个响应对象。我们将响应消息对象附加到我们的 step_history 中。然后我们验证是否在响应对象中包含了一个工具调用，否则我们在 StepResult 中返回一个错误。然后我们将工具调用记录到控制台，并使用之前定义的run_tool_from_response() 方法运行所选的工具。我们还需要将工具结果附加到我们的消息历史中。OpenAI 已经为此定义了一个特定的格式，以便模型知道哪个工具调用与哪个输出相关联，通过将 tool_call_id 传递给我们的消息字典。这是通过我们的方法 tool_call_message() 完成的，该方法接受响应对象和工具结果作为输入参数。在每个步骤结束时，我们将工具结果分配给一个 StepResult 对象，该对象还指示步骤是否成功，并将其返回给我们的循环 run() 中。</p>
<h2 id="运行代理"><a href="#运行代理" class="headerlink" title="运行代理"></a>运行代理</h2><p>现在我们可以使用之前的示例来测试我们的代理，直接将其配备为一个get_current_date_tool 。在这里，我们可以将之前定义的validate_missing 属性设置为False ，因为该工具不需要任何输入参数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class DateTool(BaseModel):  </span><br><span class="line">    x: str = None  </span><br><span class="line"></span><br><span class="line">get_date_tool = Tool(  </span><br><span class="line">    name=&quot;get_current_date&quot;,  </span><br><span class="line">    model=DateTool,  </span><br><span class="line">    function=lambda: datetime.now().strftime(&quot;%Y-%m-%d&quot;),  </span><br><span class="line">    validate_missing=False  </span><br><span class="line">)  </span><br><span class="line">      </span><br><span class="line">tools = [  </span><br><span class="line">    add_expense_tool,   </span><br><span class="line">    report_tool,  </span><br><span class="line">    get_date_tool  </span><br><span class="line">]  </span><br><span class="line">  </span><br><span class="line">agent = OpenAIAgent(tools, client)</span><br><span class="line">agent.run(&quot;I have spent 5$ on a coffee today please track my expense. The tax rate is 0.2.&quot;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">START: Starting Agent with Input: </span><br><span class="line">&quot;I have spend 5$ on a coffee today please track my expense. The tax rate is 0.2.&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tool Call: get_current_date</span><br><span class="line">Args: &#123;&#125;</span><br><span class="line">tool_result: 2024-03-15</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tool Call: add_expense_tool</span><br><span class="line">Args: &#123;&#x27;description&#x27;: &#x27;Coffee expense&#x27;, &#x27;net_amount&#x27;: 5, &#x27;tax_rate&#x27;: 0.2, &#x27;date&#x27;: &#x27;2024-03-15&#x27;&#125;</span><br><span class="line">error: Missing values: gross_amount</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tool Call: add_expense_tool</span><br><span class="line">Args: &#123;&#x27;description&#x27;: &#x27;Coffee expense&#x27;, &#x27;net_amount&#x27;: 5, &#x27;tax_rate&#x27;: 0.2, &#x27;date&#x27;: &#x27;2024-03-15&#x27;, &#x27;gross_amount&#x27;: 6&#125;</span><br><span class="line">tool_result: Added expense: &#123;&#x27;description&#x27;: &#x27;Coffee expense&#x27;, &#x27;net_amount&#x27;: 5, &#x27;tax_rate&#x27;: 0.2, &#x27;date&#x27;: &#x27;2024-03-15&#x27;, &#x27;gross_amount&#x27;: 6&#125; to the database.</span><br><span class="line">Error: No tool calls were returned.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tool Call: Name: report_tool</span><br><span class="line">Args: &#123;&#x27;report&#x27;: &#x27;Expense successfully tracked for coffee purchase.&#x27;&#125;</span><br><span class="line">tool_result: Reported: Expense successfully tracked for coffee purchase.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Final Result: Reported: Expense successfully tracked for coffee purchase.</span><br></pre></td></tr></table></figure>

<p>在成功执行我们的原型代理之后，值得强调的是代理根据计划有效地利用了指定的工具。最初，它调用了get_current_date_tool，为费用记录建立了基础时间戳。随后，在尝试通过add_expense_tool 进行费用记录时，我们智能设计的工具类发现了一个缺失的gross_amount——这是准确财务跟踪所必需的关键信息。令人印象深刻的是，代理通过使用提供的tax_rate自动解决了这个gross_amount 计算问题。</p>
<p>调试发现AI Agent不会成功，不成功log如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">START: Starting Agent with Input: I have spend 5$ on a coffee today please track my expense. The tax rate is 0.2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tool Call: Name: get_current_date</span><br><span class="line">Args: &#123;&#125;</span><br><span class="line">tool_result: 2024-04-03</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tool Call: Name: add_expense_tool</span><br><span class="line">Args: &#123;&#x27;description&#x27;: &#x27;Coffee&#x27;, &#x27;net_amount&#x27;: 5, &#x27;tax_rate&#x27;: 0.2, &#x27;date&#x27;: &#x27;2024-04-03&#x27;&#125;</span><br><span class="line">error: Missing values: gross_amount</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tool Call: Name: add_expense_tool</span><br><span class="line">Args: &#123;&#x27;description&#x27;: &#x27;Coffee&#x27;, &#x27;net_amount&#x27;: 5, &#x27;tax_rate&#x27;: 0.2, &#x27;date&#x27;: &#x27;2024-04-03&#x27;, &#x27;gross_amount&#x27;: 6&#125;</span><br><span class="line">tool_result: Added expense: &#123;&#x27;description&#x27;: &#x27;Coffee&#x27;, &#x27;net_amount&#x27;: 5, &#x27;tax_rate&#x27;: 0.2, &#x27;date&#x27;: &#x27;2024-04-03&#x27;, &#x27;gross_amount&#x27;: 6&#125; to the database.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tool Call: Name: report_tool</span><br><span class="line">Args: &#123;&#x27;report&#x27;: &#x27;Expense of $5 for coffee today has been successfully tracked with a tax rate of 0.2.&#x27;&#125;</span><br><span class="line">tool_result: Reported: Expense of $5 for coffee today has been successfully tracked with a tax rate of 0.2.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Error: No tool calls were returned.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Final Result: No tool calls were returned.</span><br></pre></td></tr></table></figure>
<p>这是因为openai的模型判断工具调用完成就会停止工具调用，返回response.choices[0].message.tool_calls 为空，需要改一下源代码。<br>如下：在agent.py中添加check if task is completed如下代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># add message to history</span><br><span class="line">self.step_history.append(response.choices[0].message)</span><br><span class="line"># check if task is completed</span><br><span class="line">if response.choices[0].finish_reason == &quot;stop&quot;:</span><br><span class="line">    step_result = StepResult(event=&quot;finish&quot;, content=&quot;Task completed.&quot;, success=True)</span><br><span class="line">    return step_result</span><br></pre></td></tr></table></figure>


<p>在我们的测试中，需要提到的是，输入费用的性质——无论是花在咖啡上的 5 美元是净额还是毛额——并没有明确指定。在这个阶段，为了使代理能够成功完成任务，这种明确性并不是必需的。然而，这为我们改进代理的理解和交互能力提供了有价值的见解：将这些详细信息纳入我们的初始系统提示中，可以显著提高代理在处理费用记录方面的准确性和效率。这个调整将确保从一开始就更全面地掌握财务数据。</p>
<h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><ul>
<li>迭代开发：该项目强调了迭代开发周期的关键性，通过反馈促进持续改进。在人工智能领域，这种方法至关重要，因为变化是常态，需要一种适应性强、响应迅速的开发策略。</li>
<li>处理不确定性：我们的过程突显了优雅地管理模糊和错误的重要性。创新，如可选参数和严格的输入验证，已被证明对提高代理的可靠性和用户体验至关重要。</li>
<li>特定任务的定制代理工作流程：这项工作的一个关键洞察是定制代理工作流程以适应特定的用例的重要性。除了组装一套工具之外，工具交互和响应的战略设计至关重要。这种定制确保代理有效地应对特定挑战，从而实现更加专注和高效的问题解决方法。</li>
</ul>
<h2 id="展望未来"><a href="#展望未来" class="headerlink" title="展望未来"></a>展望未来</h2><p>接下来的文章将着重扩展我们原型的功能，并将其与现实世界的系统集成。在下一篇文章中，我们将深入探讨设计一个强大的项目结构，使我们的代理能够与 SQL 数据库无缝交互。通过利用本文中开发的代理，我们将展示 AI 如何高效地管理和操作存储在数据库中的数据，为自动化数据相关任务打开了无限可能性。</p>
<p>在此基础上，本系列的第三篇文章将介绍高级查询功能，使我们的代理能够处理更复杂的数据检索和操作任务。我们还将探讨路由代理的概念，它将充当一个中央枢纽，用于管理多个子代理，每个子代理负责与特定的数据库表进行交互。这种分层结构将允许用户用自然语言提出请求，然后路由代理将解释并将其指示给适当的子代理执行。</p>
<p>为了进一步提升我们基于人工智能的系统的实用性和安全性，我们将引入基于角色的访问控制系统。这将确保用户根据其分配的角色拥有适当的权限来访问和修改数据。通过实施这一功能，我们可以展示人工智能代理如何在现实场景中部署，同时保持数据的完整性和安全性。</p>
<p>通过这些即将推出的增强功能，我们旨在展示 AI 代理在简化数据管理流程和为用户提供更直观高效的与数据库交互方式方面的真正潜力。通过结合自然语言处理、数据库管理和基于角色的访问控制的能力，我们将为开发能够彻底改变企业和个人处理数据方式的复杂 AI 助手奠定基础。</p>
<h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><p>所涵盖项目的全部源代码都可以在 GitHub 上找到。您可以在 <a target="_blank" rel="noopener" href="https://github.com/elokus/AgentDemo">https://github.com/elokus/AgentDemo</a> 访问它。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/leverage-openai-tool-calling-building-a-reliable-ai-agent-from-scratch-4e21fcd15b62">https://towardsdatascience.com/leverage-openai-tool-calling-building-a-reliable-ai-agent-from-scratch-4e21fcd15b62</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/03/31/graph-rag/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/31/graph-rag/" class="post-title-link" itemprop="url">从传统的 RAG 到图形 RAG</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-31 23:26:28" itemprop="dateCreated datePublished" datetime="2024-03-31T23:26:28+08:00">2024-03-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-04-08 20:26:56" itemprop="dateModified" datetime="2024-04-08T20:26:56+08:00">2024-04-08</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>When Large Language Models Meet Knowledge Graphs<br>当大语言模型遇上知识图谱</p>
<h2 id="图-RAG：RAG-x-知识图谱"><a href="#图-RAG：RAG-x-知识图谱" class="headerlink" title="图 RAG：RAG x 知识图谱"></a>图 RAG：RAG x 知识图谱</h2><p>图形 RAG 基于 RAG 的概念，利用知识图谱（KGs）。</p>
<p>这种创新的方法是由 NebulaGraph 首创的概念，通过整合图数据库改变了LLMs解释和响应查询的方式。</p>
<p>图形 RAG 通过将知识图谱中的结构化数据整合到LLM的处理中，为模型的响应提供更细致和明智的基础。</p>
<p>KG 是现实世界实体及其之间关系的结构化表示，由节点和边组成。节点代表人、地点、物体或概念等实体。</p>
<p>反过来，这些节点代表着这些实体之间的关系或连接。</p>
<p><img src="/../asset_graphrag/01.png"></p>
<p>这种结构极大地提高了LLMs生成明智回应的能力，使模型能够精确访问与上下文相关的数据。</p>
<p>Graph RAG 的创新在于将图数据库与LLMs集成，以丰富模型在生成响应之前的上下文。</p>
<p>一些受欢迎的图数据库产品包括 Ontotext、NebulaGraph 和 Neo4J。</p>
<h2 id="图形-RAG-演示"><a href="#图形-RAG-演示" class="headerlink" title="图形 RAG 演示"></a>图形 RAG 演示</h2><p>对于这个演示，我们将使用 <a target="_blank" rel="noopener" href="https://www.developer.tech.gov.sg/products/all-products/">Govtech 的开发者门户网站</a>上的产品信息作为我们的知识库。</p>
<h3 id="1-设置"><a href="#1-设置" class="headerlink" title="1. 设置"></a>1. 设置</h3><p>使用 Neo4j 桌面版启动一个本地的 Neo4j 实例,<br><img src="/../asset_graphrag/04.webp"></p>
<p>使用 LangChain 在本地连接到 Neo4j 数据库。好消息是，LangChain 有一个可直接使用的<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/templates/neo4j-advanced-rag">模板</a>，方便快速设置。</p>
<h3 id="2-提取"><a href="#2-提取" class="headerlink" title="2. 提取"></a>2. 提取</h3><p>使用快速工程和LLM来提取信息、节点及其连接。以下是一个提示的示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># Instructions for Creating Knowledge Graphs</span><br><span class="line">## Overview</span><br><span class="line">You are engineered for organising data into knowledge graphs.</span><br><span class="line">- **Nodes**: Represent entities and ideas.</span><br><span class="line">- The objective is to ensure the knowledge graph is straightforward and intelligible for broad use.</span><br><span class="line"></span><br><span class="line">## Node Labeling</span><br><span class="line">- **Uniformity**: Stick to simple labels for nodes. For instance, label any entity that is an organisation as &quot;company&quot;, rather than using terms like &quot;Facebook&quot; or &quot;Amazon&quot;.</span><br><span class="line">- **Identifiers for Nodes**: Opt for textual or comprehensible identifiers over numerical ones.</span><br><span class="line">  - **Permissible Node Labels**: If there are specific allowed node labels, list them here.</span><br><span class="line">  - **Permissible Relationship Types**: If there are specific allowed relationship types, list them here.</span><br><span class="line"></span><br><span class="line">## Managing Numerical Data and Dates</span><br><span class="line">- Integrate numerical information directly as attributes of nodes.</span><br><span class="line">- **Integrated Dates/Numbers**: Refrain from creating distinct nodes for dates or numbers, attaching them instead as attributes.</span><br><span class="line">- **Format for Properties**: Use a key-value pairing format.</span><br><span class="line">- **Avoiding Quotation Marks**: Do not use escaped quotes within property values.</span><br><span class="line">- **Key Naming**: Adopt camelCase for naming keys, such as `dateTime`.</span><br><span class="line"></span><br><span class="line">## Uniformity</span><br><span class="line">- **Entity Uniformity**: Ensure consistent identification for entities across various mentions or references.</span><br><span class="line">  </span><br><span class="line">## Adherence to Guidelines</span><br><span class="line">Strict adherence to these instructions is mandatory. Non-adherence will result in termination.</span><br></pre></td></tr></table></figure>

<h3 id="3-图构建"><a href="#3-图构建" class="headerlink" title="3. 图构建"></a>3. 图构建</h3><ul>
<li><p>使用 CSVLoader 和文档分割来处理我们的文档</p>
</li>
<li><p>将提取的信息映射到图节点和关系</p>
</li>
<li><p>通过我们的提取管道处理文档，并将信息存储在 Neo4j 中</p>
</li>
</ul>
<p><img src="/../asset_graphrag/02.webp"><br>该过程耗时近一个小时，最终得到了提取的节点标签的最终列表</p>
<ul>
<li>不幸的是，不是所有的节点标签都对我们的上下文有用或符合我们的需求。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;identity&quot;: 1040,</span><br><span class="line">  &quot;labels&quot;: [</span><br><span class="line">    &quot;Feedbackstatus&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;id&quot;: &quot;Feedback-Success&quot;,</span><br><span class="line">    &quot;message&quot;: &quot;Sent. Thank you for the feedback!&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;elementId&quot;: &quot;4:81cd2613-0f18-49c1-8134-761643e88b7a:1040&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">  &quot;identity&quot;: 1582,</span><br><span class="line">  &quot;labels&quot;: [</span><br><span class="line">    &quot;Feedbackstatus&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;id&quot;: &quot;Feedbacksuccess&quot;,</span><br><span class="line">    &quot;status&quot;: &quot;Sent. Thank you for the feedback!&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;elementId&quot;: &quot;4:81cd2613-0f18-49c1-8134-761643e88b7a:1582&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">  &quot;identity&quot;: 1405,</span><br><span class="line">  &quot;labels&quot;: [</span><br><span class="line">    &quot;Header&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;id&quot;: &quot;Modalcardhead&quot;,</span><br><span class="line">    &quot;class&quot;: &quot;sgds-modal-card-head&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;elementId&quot;: &quot;4:81cd2613-0f18-49c1-8134-761643e88b7a:1405&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">  &quot;identity&quot;: 1112,</span><br><span class="line">  &quot;labels&quot;: [</span><br><span class="line">    &quot;Feedbackindicator&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;id&quot;: &quot;Feedbacksuccess&quot;,</span><br><span class="line">    &quot;title&quot;: &quot;check&quot;,</span><br><span class="line">    &quot;message&quot;: &quot;Sent. Thank you for the feedback!&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;elementId&quot;: &quot;4:81cd2613-0f18-49c1-8134-761643e88b7a:1112&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="4-评估和改进"><a href="#4-评估和改进" class="headerlink" title="4. 评估和改进"></a>4. 评估和改进</h3><p>我们将指定LLM应该提取哪些节点标签来完善我们的方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">permissible_nodes_to_extract = [</span><br><span class="line">    &quot;Aisubfield&quot;,</span><br><span class="line">    &quot;Application&quot;,</span><br><span class="line">    &quot;Cloudservice&quot;,</span><br><span class="line">    &quot;Concept&quot;,</span><br><span class="line">    &quot;Digitalsolution&quot;,</span><br><span class="line">    &quot;Division&quot;,</span><br><span class="line">    &quot;Entity&quot;,</span><br><span class="line">    &quot;Feature&quot;,</span><br><span class="line">    &quot;Fundinginitiative&quot;,</span><br><span class="line">    &quot;Initiative&quot;,</span><br><span class="line">    &quot;Link&quot;,</span><br><span class="line">    &quot;Location&quot;,</span><br><span class="line">    &quot;Organization&quot;,</span><br><span class="line">    &quot;Person&quot;,</span><br><span class="line">    &quot;Platform&quot;,</span><br><span class="line">    &quot;Policy&quot;,</span><br><span class="line">    &quot;Program&quot;</span><br><span class="line">    &quot;Resource&quot;,</span><br><span class="line">    &quot;Role&quot;,</span><br><span class="line">    &quot;Schema&quot;,</span><br><span class="line">    &quot;Service&quot;,</span><br><span class="line">    &quot;Standard&quot;,</span><br><span class="line">    &quot;Technology&quot;,</span><br><span class="line">    &quot;Technologyplatform&quot;,</span><br><span class="line">    &quot;Technologystack&quot;,</span><br><span class="line">    &quot;Webframework&quot;,</span><br><span class="line">    &quot;Webresource&quot;,</span><br><span class="line">    &quot;Website&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>


<p>使用 Neo4j 浏览器探索我们新构建的知识图谱</p>
<p><img src="/../asset_graphrag/03.webp"></p>
<p>例子如下：</p>
<p>Q: “I need to remove sensitive information from some of my documents. What products does Govtech offer that has these capabilities?”</p>
<p>Base RAG: “Govtech offers the products Cloak and FileSG, which have capabilities to help remove sensitive information from documents.”</p>
<p>Graph RAG: “GovTech offers a product called Cloak, which is a central privacy toolkit for policy-compliant data anonymization. This product helps public officers apply data anonymization techniques to datasets and review re-identification risks in compliance with guidelines.”</p>
<p>与传统的 RAG 方法相比，Graph RAG 在这个例子中的优势是显而易见的。</p>
<p>该回应不仅展示了准确性，还通过上下文和关系的丰富提供了一种在标准的（RAG）方法中缺失的深度水平。</p>
<p>Graph RAG 的秘密在于其分析 “用户的查询” 的能力，从图数据库中找出相关数据，并将这种上下文洞察力融入到LLM的回应中。</p>
<p>这种方法利用了传统方法可能忽视的一系列相互关联的信息，从而得到对查询更加细致入微的理解。</p>
<h2 id="使用-Neo4j-和-Langchain-从-Bhagavad-Gita-Treatise-PDF-开发基本知识图谱"><a href="#使用-Neo4j-和-Langchain-从-Bhagavad-Gita-Treatise-PDF-开发基本知识图谱" class="headerlink" title="使用 Neo4j 和 Langchain 从 Bhagavad Gita Treatise PDF 开发基本知识图谱"></a>使用 Neo4j 和 Langchain 从 Bhagavad Gita Treatise PDF 开发基本知识图谱</h2><p>让我们逐步演示一下如何使用著名的《薄伽梵歌》来创建基本知识图谱。这篇由斯里·斯瓦米·悉瓦南达 （Sri Swami Sivananda） 撰写的文本充满了丰富的信息，我们可以用知识图谱来组织这些信息。我们将使用 Neo4j（帮助我们管理和构建图形）和 Langchain（帮助我们处理文本）。</p>
<p>首先，使用 <a target="_blank" rel="noopener" href="https://neo4j.com/cloud/aura-free/">Neo4j</a> 创建一个免费帐户。在此示例中，我们将使用free版本，它允许创建一个实例。</p>
<p><img src="/../asset_graphrag/05.png"></p>
<p>凭据文件将包含以下详细信息，您需要在后续代码中使用这些详细信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NEO4J_URI=value</span><br><span class="line">NEO4J_USERNAME=neo4j</span><br><span class="line">NEO4J_PASSWORD=创建Neo4j账号时给的密码</span><br><span class="line">AURA_INSTANCEID=value</span><br><span class="line">AURA_INSTANCENAME=Instance01</span><br></pre></td></tr></table></figure>
<p>现在让我们创建知识图谱。</p>
<h3 id="安装库"><a href="#安装库" class="headerlink" title="安装库"></a>安装库</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from dotenv import load_dotenv</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"># Common data processing</span><br><span class="line">import textwrap</span><br><span class="line"></span><br><span class="line"># Langchain</span><br><span class="line">from langchain_community.graphs import Neo4jGraph</span><br><span class="line">from langchain_community.vectorstores import Neo4jVector</span><br><span class="line">from langchain.text_splitter import RecursiveCharacterTextSplitter</span><br><span class="line">from langchain.chains import RetrievalQAWithSourcesChain</span><br><span class="line">from langchain.llms import OpenAI</span><br><span class="line">from langchain.embeddings import OpenAIEmbeddings</span><br><span class="line">from langchain.document_loaders import PyPDFLoader</span><br></pre></td></tr></table></figure>

<h3 id="从-PDF-中提取文本："><a href="#从-PDF-中提取文本：" class="headerlink" title="从 PDF 中提取文本："></a>从 PDF 中提取文本：</h3><p>加载 PDF 文件并将其页面拆分为可管理的文本块。我们利用 langchain 库中的 PyPDFLoader 模块来完成这项任务。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Load PDF file</span><br><span class="line">loader = PyPDFLoader(&quot;path/to/your/pdf/file.pdf&quot;)</span><br><span class="line">pages = loader.load_and_split()</span><br></pre></td></tr></table></figure>
<h3 id="将文本拆分为块："><a href="#将文本拆分为块：" class="headerlink" title="将文本拆分为块："></a>将文本拆分为块：</h3><p>接下来，我们将提取的文本拆分为更小的块，以便于进一步处理。langchain 中的 RecursiveCharacterTextSplitter 类用于此目的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Split pages into chunks</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)</span><br><span class="line">chunks = text_splitter.split_documents(pages)</span><br></pre></td></tr></table></figure>

<h3 id="创建一个向量存储，在-Neo4j-中嵌入和存储："><a href="#创建一个向量存储，在-Neo4j-中嵌入和存储：" class="headerlink" title="创建一个向量存储，在 Neo4j 中嵌入和存储："></a>创建一个向量存储，在 Neo4j 中嵌入和存储：</h3><p>我们创建一个 Neo4jVector 对象来存储文本块的嵌入到 Neo4j 图形数据库中。这使我们能够在以后有效地检索和操作嵌入。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Warning control</span><br><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line"># Load from environment from the credentials file</span><br><span class="line">load_dotenv(&#x27;.env&#x27;, override=True)</span><br><span class="line">NEO4J_URI = os.getenv(&#x27;NEO4J_URI&#x27;) </span><br><span class="line"></span><br><span class="line">NEO4J_USERNAME = os.getenv(&#x27;NEO4J_USERNAME&#x27;)</span><br><span class="line"></span><br><span class="line">NEO4J_PASSWORD = os.getenv(&#x27;NEO4J_PASSWORD&#x27;)</span><br><span class="line"></span><br><span class="line">NEO4J_DATABASE = os.getenv(&#x27;NEO4J_DATABASE&#x27;) or &#x27;neo4j&#x27;</span><br><span class="line">NEO4J_DATABASE = &#x27;neo4j&#x27;</span><br><span class="line"># Global constants</span><br><span class="line">VECTOR_INDEX_NAME = &#x27;pdf_chunks&#x27;</span><br><span class="line">VECTOR_NODE_LABEL = &#x27;Chunk&#x27;</span><br><span class="line">VECTOR_SOURCE_PROPERTY = &#x27;text&#x27;</span><br><span class="line">VECTOR_EMBEDDING_PROPERTY = &#x27;textEmbedding&#x27;</span><br><span class="line"></span><br><span class="line">kg = Neo4jGraph(</span><br><span class="line">    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Create Neo4j vector store</span><br><span class="line">neo4j_vector_store = Neo4jVector.from_documents(</span><br><span class="line">    embedding=OpenAIEmbeddings(),</span><br><span class="line">    documents=chunks,</span><br><span class="line">    url=NEO4J_URI,</span><br><span class="line">    username=NEO4J_USERNAME,</span><br><span class="line">    password=NEO4J_PASSWORD,</span><br><span class="line">    index_name=VECTOR_INDEX_NAME,</span><br><span class="line">    text_node_property=VECTOR_SOURCE_PROPERTY,</span><br><span class="line">    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="构建关系："><a href="#构建关系：" class="headerlink" title="构建关系："></a>构建关系：</h3><p>我们在图形中的块之间建立关系，指示它们的顺序以及它们与父 PDF 文档的关联。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># Create a PDF node</span><br><span class="line">cypher = &quot;&quot;&quot;</span><br><span class="line">MERGE (p:PDF &#123;name: $pdfName&#125;)</span><br><span class="line">RETURN p</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">kg.query(cypher, params=&#123;&#x27;pdfName&#x27;: &quot;path/to/your/pdf/file.pdf&quot;&#125;)</span><br><span class="line"></span><br><span class="line"># Connect chunks to their parent PDF with a PART_OF relationship</span><br><span class="line">cypher = &quot;&quot;&quot;</span><br><span class="line">MATCH (c:Chunk), (p:PDF)</span><br><span class="line">WHERE p.name = $pdfName</span><br><span class="line">MERGE (c)-[newRelationship:PART_OF]-&gt;(p)</span><br><span class="line">RETURN count(newRelationship)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">kg.query(cypher, params=&#123;&#x27;pdfName&#x27;: &quot;path/to/your/pdf/file.pdf&quot;&#125;)</span><br><span class="line"></span><br><span class="line"># Create a NEXT relationship between subsequent chunks</span><br><span class="line">cypher = &quot;&quot;&quot;</span><br><span class="line">MATCH (c1:Chunk), (c2:Chunk)</span><br><span class="line">WHERE c1.chunkSeqId = c2.chunkSeqId - 1</span><br><span class="line">MERGE (c1)-[r:NEXT]-&gt;(c2)</span><br><span class="line">RETURN count(r)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">kg.query(cypher)</span><br></pre></td></tr></table></figure>

<h3 id="问答："><a href="#问答：" class="headerlink" title="问答："></a>问答：</h3><p>最后，我们可以利用构建的知识图谱来执行问答任务。我们从矢量存储中创建一个检索器和一个聊天机器人问答链，以根据 PDF 文档的内容回答问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># Create a retriever from the vector store</span><br><span class="line">retriever = neo4j_vector_store.as_retriever()</span><br><span class="line"></span><br><span class="line"># Create a chatbot Question &amp; Answer chain from the retriever</span><br><span class="line">chain = RetrievalQAWithSourcesChain.from_chain_type(</span><br><span class="line">    OpenAI(temperature=0), </span><br><span class="line">    chain_type=&quot;stuff&quot;,</span><br><span class="line">    retriever=retriever</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># Ask a question</span><br><span class="line">question = &quot;What is the main topic of this PDF document?&quot;</span><br><span class="line">answer = chain(</span><br><span class="line">    &#123;&quot;question&quot;: question&#125;,</span><br><span class="line">    return_only_outputs=True,</span><br><span class="line">)</span><br><span class="line">print(textwrap.fill(answer[&quot;answer&quot;]))</span><br></pre></td></tr></table></figure>

<p>以下是一些查询，用于检查neo4j的数据</p>
<p>节点数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Returns the node count</span><br><span class="line">kg.query(&quot;&quot;&quot;</span><br><span class="line">         MATCH (n)</span><br><span class="line">         RETURN count(n) as nodeCount</span><br><span class="line">         &quot;&quot;&quot;)</span><br></pre></td></tr></table></figure>

<p>打印架构</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kg.refresh_schema()</span><br><span class="line">print(kg.schema)</span><br></pre></td></tr></table></figure>

<p>显示索引</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kg.query(&quot;SHOW INDEXES&quot;)</span><br></pre></td></tr></table></figure>

<p>示例输出</p>
<p>Neo4j 仪表板<br><img src="/../asset_graphrag/06.png"></p>
<p>Q&amp;A 输出</p>
<p><img src="/../asset_graphrag/07.png"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>从传统的检索增强生成（RAG）转向图形 RAG，代表了我们与大型语言模型（LLMs）交互方式的重要进步</p>
<p>这个转变解决了一个根本性的挑战：如何提高LLMs在复杂查询中提供上下文准确答案的能力。</p>
<p>比较这两种方法时，图形 RAG 在处理上下文复杂查询方面的优势变得明显。</p>
<p>Conventional RAG techniques often misses the mark on contextually complex questions.<br>传统的 RAG 技术经常在上下文复杂的问题上失准。</p>
<p>相比之下，图形 RAG 利用更复杂的数据网络，提供能够捕捉查询细微差别更深入理解的响应。</p>
<p>然而，图形 RAG 的有效性并非一刀切的解决方案。</p>
<p>这仍然高度依赖于底层知识图谱的质量、深度和广度。</p>
<p>在知识图谱受限或偏向特定领域的情况下，Graph RAG 的性能可能不会超过传统的 RAG 方法。</p>
<p>话虽如此，这种转变有望带来更好地模拟人类思维和发现的人工智能系统。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/03/26/coding-for-next/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/26/coding-for-next/" class="post-title-link" itemprop="url">编码是一个值得学习的技能吗？</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-03-26 22:42:45 / 修改时间：22:57:25" itemprop="dateCreated datePublished" datetime="2024-03-26T22:42:45+08:00">2024-03-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>许多在 50 年前出现的技术都遵循了两种轨迹之一：要么随着时代的发展而进化，要么消失在人们的视野中。一个例子是 1938 年推出的第一台可编程机械计算机。由于内存限制和庞大的重量，很难想象今天我们的家庭或工作场所会容纳这样的设备。</p>
<p>事实上，有许多科技先驱对计算机的未来及其与人类的互动进行了推测。这种做法并不新鲜 - 它有着悠久的历史，持续至今，并预计将持续到未来。塑造未来的前景总是吸引我们，引发支持者和反对者之间的无休止辩论。</p>
<p>以下是 NVIDIA 首席执行官 Jensen Huang 在题为“谁将塑造人工智能的未来？”的活动上的发言</p>
<p>“It’s going to sound completely opposite of what people feel. You probably recall over the course of the last 10–15 years, almost everybody who sits on a stage like this would tell you it is vital that your children learn computer science … everybody should learn how to program. In fact, it’s almost exactly the opposite. It is our job to create computing technology such that nobody has to program and that the programming language is human. Everybody in the world is now a programmer. This is the miracle of artificial intelligence”</p>
<p>我不完全同意 Jensen（至少最初不同意），因为学习编程本身就是一种揭示基本解决方案的方式，直到我们能够开发专注于解决实际业务场景的代码行。我的意思是，编程就像学习任何其他学科或学科一样，培养了我们在决策中的判断力。仅仅通过指示 ChatGPT 来构建整个移动应用程序是具有挑战性的。它可能能够做到，但是在不知道它应该遵循的逻辑顺序的情况下理解整个代码将会很困难。此外，该过程可能存在偏见，并可能在途中遇到错误。</p>
<p>就像其他科学、技术或学科一样，编程将不可避免地受到人工智能的影响，但仍然需要开发人员继续构建更多和更优秀的模型或软件，比如 NVIDIA 销售的那些。</p>
<p>对于 90%的人来说，由于人工智能工程师和提示工程师的团队在所有这些代码行后面工作，提示将变得越来越用户友好，最终优化我们与之交互的聊天界面，无论我们使用 ChatGPT、Gemini、Claude 3、Copilot等等。重点是，虽然主要角色（人工智能）似乎似乎做了一切，但实际上在我们看到的屏幕后面，有人类开发人员通过代码继续投入时间和知识。</p>
<p>Jensen的言论指出了一个基本观念：从学习过程到实施（可能只需要一个提示），人工智能在编程中的角色正处于转变之中。山姆·奥特曼在多次采访中强调，编程在未来仍将保持其重要性，但形式将与我们今天习惯的不同。这种变化主要是由于人工智能在这个领域中作为进步的催化剂的作用。</p>
<p>另一方面，有人声称，像 Stability AI 的首席执行官兼联合创始人 Emad Mostaque 一样的声音认为，在大约 5 年内，我们所熟知的程序员可能不再存在。</p>
<p>对于那些渴望涉足编程的人来说，这可能是一个令人畏惧和不确定的情况。然而，现实情况是，未来大部分的代码开发可能会由人工智能而不是人类编写的代码驱动。这让我产生了以下的问题：</p>
<pre><code>编程语言的目标之一不就是以更易于理解和使用的方式发展，从而使更多的人能够通过编码来创造解决方案吗？
</code></pre>
<p><img src="/../asset_coding/01.webp"></p>
<p>回顾历史，特别是 20 世纪 50 年代，我们可以看到编程语言复杂且需要广泛的专业知识才能掌握。然而，随着时间的推移，这种进入门槛逐渐变得更加容易接触，使得编码变得更加包容和吸引人。</p>
<p>如今我们通过人工智能助手获取代码。因此，许多非程序员或初学者可能正在以与过去完全不同的方式创建他们的第一行代码。然而，就功能而言，他们有潜力达到相同的解决方案或目标。</p>
<p>我们所熟知的编程在未来 3 到 5 年内不太可能消失，但是我们中的一些人可能会想知道 20 年后会发生什么。我们还会继续编码吗？对此，我会质疑到那时我们是否还会使用计算机。</p>
<h2 id="接下来的抽象层"><a href="#接下来的抽象层" class="headerlink" title="接下来的抽象层"></a>接下来的抽象层</h2><p>在标准计算机中，我们通常会遇到软件层和硬件层。这两个层之间的通信是通过所谓的机器语言来实现的，通常以二进制系统表示，这对人类来说可能很复杂。通过对体系结构的详细研究，可以明显看出，抽象和复杂性的元素与每个抽象层有不同程度的关联。随着时间的推移，这些层积累起来，给我们带来了现代计算机，大大提高了人与机器之间的通信便利性，使我们能够使用更简单的指令执行各种任务。</p>
<p><img src="/../asset_coding/02.webp"></p>
<p>AI 助手的概念将是一个额外的层次，它将被添加到图表的顶部。这代表了人类更容易与计算机进行交流的机会。目前，多模态在捕捉我们想要提供的尽可能多的信息方面发挥着重要作用（音频、图像、文本），这些信息被 AI 用作启动生成接近我们期望的回应的提示。</p>
<p>在这个意义上，现在我们正在经历一波代码 AI 助手的浪潮，比如 GitHub Copilot，CodiumAI，AWS Code Whisperer，Tabnine，它们无疑正在改变人们编写代码的方式。</p>
<p>然而，尽管人工智能似乎会让程序员黯然失色，但现实是许多当前的模型仍然容易出错。此外，对于聊天机器人的回应缺乏控制。一个例子是最近谷歌 Gemini 引起轰动的事件，它拒绝生成白人的图像，并过分强调包容性。</p>
<p>如果您经常使用人工智能来生成代码，您可能已经注意到，由于其复杂性或项目所需的代码量，一次性生成高质量代码自然是一项挑战。</p>
<p>现在，事实是人工智能是一个很棒的编码助手，它将帮助我们更快地编写和调试代码，但如果我们期望它能够自己从零开始构建软件，它的能力仍然有限。不可避免地，它将在未来这样做，也许比我们预期的要早，但这是否意味着我们应该停止学习编程呢？</p>
<p>当然不是。</p>
<p>AI 艺术并没有阻止这个领域的爱好者进行绘画、绘图或创作。同样地，AI 不会使程序员过时，而是代表编码中的接下来的一层抽象，使人与机器之间的交互更加顺畅。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://medium.com/artificial-corner/nvidia-ceo-advises-against-learning-to-code-is-coding-still-a-worthwhile-skill-to-learn-704f091a8078">https://medium.com/artificial-corner/nvidia-ceo-advises-against-learning-to-code-is-coding-still-a-worthwhile-skill-to-learn-704f091a8078</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/03/26/sso/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/26/sso/" class="post-title-link" itemprop="url">单点登录（SSO）工作原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-03-26 22:00:30 / 修改时间：22:56:17" itemprop="dateCreated datePublished" datetime="2024-03-26T22:00:30+08:00">2024-03-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>17 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Single Sign-On (SSO) is an authentication process that allows users to access multiple applications with a single login. This is accomplished using a central authentication server that stores the user’s credentials and verifies them for each application.</p>
<p>单点登录（SSO）是一种身份验证过程，允许用户使用单个登录访问多个应用程序。这是通过使用一个中央身份验证服务器来实现的，该服务器存储用户的凭据并为每个应用程序进行验证。</p>
<p>The idea of SSO is not new in the Cloud era. The on-premises identity solutions that enabled businesses to safely link their PCs, networks, and servers in the middle to late 1990s are the source of SSO technology. Around this time, companies started using specialized systems to handle user IDs, such as Lightweight Directory Access Protocol (LDAP) and Microsoft Active Directory (AD). After that, they used on-premises SSO or Web Access Management (WAM) products to protect access.</p>
<p>SSO 的概念在云时代并不新鲜。在 20 世纪 90 年代中后期，使企业能够安全地将其个人电脑、网络和服务器连接起来的本地身份解决方案是 SSO 技术的来源。在此期间，公司开始使用专门的系统来处理用户 ID，例如轻量级目录访问协议（LDAP）和 Microsoft Active Directory（AD）。之后，他们使用本地 SSO 或 Web 访问管理（WAM）产品来保护访问。</p>
<h2 id="SSO-组成"><a href="#SSO-组成" class="headerlink" title="SSO 组成"></a>SSO 组成</h2><ul>
<li><p>Identity Provider (IdP): This is the central authentication server. It’s where you enter your credentials and get verified. Think of it as a high-security building entrance.<br>身份提供者（IdP）：这是中央认证服务器。这是您输入凭据并进行验证的地方。将其视为高安全性建筑入口。</p>
</li>
<li><p>Service Provider (SP): These individual applications rely on SSO for user login. Your work email, project management tool, and CRM platform can all be SPs. Imagine these as individual offices within the secure building.<br>服务提供商（SP）：这些个别应用程序依赖 SSO 进行用户登录。您的工作电子邮件、项目管理工具和 CRM 平台都可以是 SP。将其想象为安全建筑内的个别办公室。</p>
</li>
<li><p>SSO Server: This is the bridge between the IdP and SPs. It handles the communication and securely transmits authentication tokens between them. Think of it as a secure hallway connecting the entrance to the various offices.<br>SSO 服务器：这是 IdP 和 SP 之间的桥梁。它处理通信并安全地传输身份验证令牌。将其视为连接入口和各个办公室的安全走廊。</p>
</li>
</ul>
<h2 id="SSO-工作流程"><a href="#SSO-工作流程" class="headerlink" title="SSO 工作流程"></a>SSO 工作流程</h2><p>Google and other services are excellent examples of how SSO works. Let’s take the example of trying to access Trello using your Google account. You don’t need to create a new user account on Trello and remember a new set of usernames&#x2F;passwords.<br>谷歌和其他服务是单点登录(SSO)运作的绝佳例子。以使用谷歌账户访问 Trello 为例。您无需在 Trello 上创建新的用户账户并记住一组新的用户名&#x2F;密码。</p>
<p>For example, when you try to log in to Trello with your Google account, it redirects you to the central service hosted on accounts.google.com. Here, you will see a sign-in form to input your credentials. If the authentication process is successful, Google redirects you to Trello, where you can gain access where you are automatically signed in.<br>例如，当您尝试使用 Google 账户登录 Trello 时，它会将您重定向到托管在 accounts.google.com 上的中央服务。在这里，您将看到一个登录表单，输入您的凭据。如果身份验证过程成功，Google 会将您重定向到 Trello，您将自动登录并获得访问权限。</p>
<p>如果您想使用 Google 账户访问 Trello，以下是所需的步骤：</p>
<ul>
<li><p>User requests access: Use the Trello login web page and select Google account as a login method.<br>用户请求访问：使用 Trello 登录网页，并选择 Google 账户作为登录方式。</p>
</li>
<li><p>Redirection to IdP: Trello redirects the user to the Google login page.<br>重定向到 IdP：Trello 将用户重定向到 Google 登录页面。</p>
</li>
<li><p>Login page served: The user is served with the Google login page.<br>登录页面已提供：用户被提供了谷歌登录页面。</p>
</li>
<li><p>Credentials entered: The user enters their Google credentials.<br>输入的凭据：用户输入他们的谷歌凭据。</p>
</li>
<li><p>SSO Server verification: Google sends authentication info to the SSO Authorization server<br>SSO 服务器验证：谷歌将认证信息发送给 SSO 授权服务器</p>
</li>
<li><p>Authentication at IdP: The Authorization server returns the auth token (SAML) if the credentials are valid.<br>在 IdP 上进行身份验证：如果凭证有效，授权服务器将返回授权令牌（SAML）。</p>
</li>
<li><p>Access granted: Google sends the auth token to the Trello<br>授权已授予：Google 将认证令牌发送给 Trello</p>
</li>
<li><p>Validate token: In the last step, Trello sends the token to the Google Authorization server to validate it<br>验证令牌：在最后一步中，Trello 将令牌发送给 Google 授权服务器以进行验证</p>
</li>
<li><p>Token valid: If the token is valid, Trello will allow access to the user and store the session for future interactions<br>令牌有效：如果令牌有效，Trello 将允许用户访问并存储会话以供将来交互使用</p>
</li>
</ul>
<p><img src="/../asset_sso/01.webp"></p>
<h2 id="单点登录的好处"><a href="#单点登录的好处" class="headerlink" title="单点登录的好处"></a>单点登录的好处</h2><p>单点登录有多个好处，即：</p>
<ul>
<li><p>Improved user experience: Users do not need to remember multiple usernames and passwords.<br>改进的用户体验：用户不需要记住多个用户名和密码。</p>
</li>
<li><p>Increased security: Users are less likely to reuse passwords across applications.<br>增加安全性：用户更不太可能在不同应用程序中重复使用密码。</p>
</li>
<li><p>Simplified user access auditing: Ensuring the appropriate individuals have access to resources and sensitive data can be challenging. SSO solutions can configure user access permissions according to their role, department, and seniority level.<br>简化用户访问审计：确保适当的人员可以访问资源和敏感数据可能具有挑战性。SSO 解决方案可以根据用户的角色、部门和资历级别配置用户访问权限。</p>
</li>
</ul>
<h2 id="单点登录的类型"><a href="#单点登录的类型" class="headerlink" title="单点登录的类型"></a>单点登录的类型</h2><p>与 SSO 一起工作，您应该了解不同的标准和协议。一些常见的协议类型包括：</p>
<ul>
<li><p>SAML: This is the most common type of SSO. It uses the SAML protocol to exchange authentication information between the SSO server and applications.<br>SAML：这是最常见的单点登录类型。它使用 SAML 协议在单点登录服务器和应用程序之间交换身份验证信息。</p>
</li>
<li><p>Open Authorization (OAuth) 2.0): It provides delegated access to server resources on behalf of a resource owner. It specifies how tokens are transferred, allowing a user’s identity to be authenticated by an IDP and the credentials to be used to access APIs.<br>开放授权（OAuth）2.0：它代表资源所有者提供对服务器资源的委托访问。它规定了令牌的传输方式，允许用户的身份由 IDP 进行验证，并使用凭据访问 API。</p>
</li>
<li><p>Open ID Connect (OIDC) is a newer type of SSO based on OAuth 2.0. It is a more straightforward protocol than SAML and more accessible to integrate with web applications.<br>Open ID Connect（OIDC）是基于 OAuth 2.0 的一种较新的单点登录（SSO）类型。它是比 SAML 更直接的协议，更容易与 Web 应用程序集成。</p>
</li>
</ul>
<p>要了解更多关于 OAuth 2.0 的信息，请查看以下<a target="_blank" rel="noopener" href="https://newsletter.techworld-with-milan.com/i/138606726/how-does-oauth-work">链接</a>。请注意，您也可以在 <a target="_blank" rel="noopener" href="https://learning.postman.com/docs/sending-requests/authorization/oauth-20/">Postman 中使用 OAuth 2.0</a>。</p>
<p><img src="/../asset_sso/02.webp"></p>
<p>一些其他的 SSO 类型，如 Kerberos 和智能卡认证，使用较少。</p>
<ul>
<li><p>Kerberos allows users to obtain service tickets from the KDC using their credentials. These tickets are then presented to applications for access, eliminating the need for repeated logins. However, Kerberos relies on shared secrets between the KDC and all participants, making it less suitable for internet-facing SSO due to security concerns like compromised servers exposing credentials.<br>Kerberos 允许用户使用他们的凭据从 KDC 获取服务票据。然后将这些票据提供给应用程序以进行访问，从而消除了重复登录的需要。然而，Kerberos 依赖于 KDC 和所有参与者之间的共享密钥，这使得它不太适合面向互联网的 SSO，因为存在安全问题，比如受损的服务器暴露凭据。</p>
</li>
<li><p>A smart card that holds an identity works with the SSO system (like a lock) to grant access to applications (doors) without needing separate logins for each. It adds a physical element to the authentication process, making it more resistant to unauthorized access. Yet, the user must physically carry it.<br>一张持有身份信息的智能卡与 SSO 系统（类似于锁）配合使用，可以在不需要单独登录的情况下，为应用程序（门）提供访问权限。它为认证过程增加了物理元素，使其更加抵抗未经授权的访问。然而，用户必须亲自携带它。</p>
</li>
</ul>
<h2 id="如何选择适当的-SSO-协议"><a href="#如何选择适当的-SSO-协议" class="headerlink" title="如何选择适当的 SSO 协议"></a>如何选择适当的 SSO 协议</h2><p>在选择适当的协议时，应考虑以下因素：</p>
<ul>
<li><p>Enterprise vs. consumer applications: SAML is often preferred for enterprise applications due to its extensive support and integration capabilities with enterprise identity providers and complex authentication scenarios. OAuth 2.0 and OIDC are more suited for consumer-facing applications, offering flexibility and compatibility with mobile and web applications.<br>企业与消费者应用：由于 SAML 在与企业身份提供者和复杂认证场景的支持和集成能力方面非常强大，因此在企业应用中通常更受青睐。而 OAuth 2.0 和 OIDC 更适用于面向消费者的应用，提供了与移动和 Web 应用的灵活性和兼容性。</p>
</li>
<li><p>Authorization vs. authentication: If your primary need is authentication (verifying user identity), SAML or OIDC are your go-to options. OIDC, built on top of OAuth 2.0, provides an additional identity layer over OAuth’s authorization capabilities. Use OAuth 2.0 when your application needs to request access to user resources without exposing user passwords.<br>授权与认证：如果您的主要需求是认证（验证用户身份），SAML 或 OIDC 是您的首选选项。OIDC 是建立在 OAuth 2.0 之上的，为 OAuth 的授权能力提供了额外的身份层。当您的应用程序需要请求访问用户资源而不暴露用户密码时，请使用 OAuth 2.0。</p>
</li>
<li><p>Evaluate application and platform compatibility: Check the SSO protocols’ compatibility with your existing infrastructure and the applications you plan to integrate. Some legacy or enterprise systems might support SAML more broadly, while modern applications often favor OAuth 2.0 and OIDC because they are API-friendly.<br>评估应用程序和平台的兼容性：检查 SSO 协议与您现有基础设施和计划集成的应用程序的兼容性。一些传统或企业系统可能更广泛地支持 SAML，而现代应用程序通常更喜欢 OAuth 2.0 和 OIDC，因为它们对 API 友好。</p>
</li>
<li><p>Consider the user experience: OIDC and OAuth 2.0’s modern, token-based approach can offer a smoother and more integrated user experience, especially for web and mobile applications.<br>考虑用户体验：OIDC 和 OAuth 2.0 的现代、基于令牌的方法可以为 Web 和移动应用提供更流畅、更集成的用户体验。</p>
</li>
<li><p>Future-proofing: Consider the future direction of your application ecosystem. Are you moving towards cloud-based services, APIs, and mobile apps? OAuth 2.0 and OIDC may offer more flexibility and are generally considered more forward-looking in cloud and mobile services.<br>未来保护：考虑您的应用生态系统的未来方向。您是否正在转向基于云的服务、API 和移动应用？OAuth 2.0 和 OIDC 可能提供更多的灵活性，并且在云和移动服务中通常被认为更具前瞻性。</p>
</li>
<li><p>Compliance and regulatory requirements: Ensure the chosen protocol meets any specific regulatory requirements relevant to your industry, such as GDPR, HIPAA, or others that may dictate specific security or privacy standards.<br>合规和监管要求：确保所选择的协议符合与您所在行业相关的任何特定监管要求，例如 GDPR、HIPAA 或其他可能规定特定安全或隐私标准的要求。</p>
</li>
</ul>
<h2 id="SSO-实施"><a href="#SSO-实施" class="headerlink" title="SSO 实施"></a>SSO 实施</h2><p>市场上有许多产品可用于 SSO</p>
<ul>
<li><p>Microsoft Entra ID (formerly known as a Microsoft Active Directory). Ideal for organizations already invested in the Microsoft ecosystem, it offers seamless integration with Office 365, Dynamics CRM, and other Microsoft services. It’s known for its robust security features and comprehensive management capabilities.<br>Microsoft Entra ID（以前称为 Microsoft Active Directory）。适用于已经投资于 Microsoft 生态系统的组织，它与 Office 365、Dynamics CRM 和其他 Microsoft 服务无缝集成。它以其强大的安全功能和全面的管理能力而闻名。</p>
</li>
<li><p>Okta is a popular cloud-based SSO solution known for its ease of use, scalability, and wide range of application integrations. It’s a strong option for organizations seeking a comprehensive identity and access management (IAM) platform.<br>Okta 是一种流行的基于云的单点登录（SSO）解决方案，以其易用性、可扩展性和广泛的应用集成而闻名。对于寻求全面身份和访问管理（IAM）平台的组织来说，它是一个强大的选择。</p>
</li>
<li><p>Ping Identity. Known for its flexibility, Ping Identity caters to enterprises with complex security requirements. It offers strong mobile and API security options, making it suitable for organizations needing high levels of customization and security.<br>Ping Identity。以其灵活性而闻名，适用于具有复杂安全需求的企业。它提供强大的移动和 API 安全选项，适用于需要高度定制和安全性的组织。</p>
</li>
<li><p>OneLogin. With a focus on simplicity and integration, OneLogin offers a straightforward SSO solution that works well for small to medium-sized businesses. It provides real-time threat detection and AI-powered authentication for enhanced security.<br>OneLogin。专注于简单性和集成性，OneLogin 提供了一个适用于中小型企业的直接 SSO 解决方案。它提供实时威胁检测和 AI 驱动的身份验证，以增强安全性。</p>
</li>
<li><p>Auth0 is favored for its developer-friendly approach. It provides powerful customization options, making it a go-to for organizations that must tailor their authentication flows. It supports a wide range of programming languages and frameworks.<br>Auth0 因其开发者友好的方法而备受青睐。它提供强大的定制选项，使其成为那些必须定制其身份验证流程的组织的首选。它支持广泛的编程语言和框架。</p>
</li>
</ul>
<p><img src="/../asset_sso/03.webp"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://medium.com/@techworldwithmilan/how-does-single-sign-on-sso-work-31ffa1afcc63">https://medium.com/@techworldwithmilan/how-does-single-sign-on-sso-work-31ffa1afcc63</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/03/20/electron-vue-chatgpt/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/20/electron-vue-chatgpt/" class="post-title-link" itemprop="url">用chatgpt零基础开发electron+vue桌面应用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-20 20:32:57" itemprop="dateCreated datePublished" datetime="2024-03-20T20:32:57+08:00">2024-03-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-30 21:25:18" itemprop="dateModified" datetime="2024-03-30T21:25:18+08:00">2024-03-30</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最近在想了解前端vue，但是不想学习vue，所以就让chatgpt来写代码。实际例子是找一个python实现的工具来porting，因为涉及到OS，所以使用chatgpt来开发electron+vue桌面应用。</p>
<h2 id="先做一个vue的UI"><a href="#先做一个vue的UI" class="headerlink" title="先做一个vue的UI"></a>先做一个vue的UI</h2><p>把vue的架子搭建好，然后把UI图发给chatgpt。<br><img src="/../asset_electronvuechatgpt/01.png"></p>
<p>把图片传给它，然后chatgpt生成代码<br><img src="/../asset_electronvuechatgpt/02.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">  &lt;div id=&quot;menu-bar&quot;&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">      &lt;li&gt;&lt;a href=&quot;#file&quot;&gt;File&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">      &lt;li&gt;&lt;a href=&quot;#operate&quot;&gt;Operate&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">      &lt;li&gt;&lt;a href=&quot;#config&quot;&gt;Config&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">    &lt;/ul&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">export default &#123;</span><br><span class="line">  name: &#x27;MenuBar&#x27;</span><br><span class="line">  // You can add your JavaScript here</span><br><span class="line">&#125;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line"></span><br><span class="line">&lt;style scoped&gt;</span><br><span class="line">#menu-bar &#123;</span><br><span class="line">  background-color: #8B0000; /* Dark red color */</span><br><span class="line">  color: white;</span><br><span class="line">  padding: 10px 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#menu-bar ul &#123;</span><br><span class="line">  list-style-type: none;</span><br><span class="line">  margin: 0;</span><br><span class="line">  padding: 0;</span><br><span class="line">  overflow: hidden;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#menu-bar li &#123;</span><br><span class="line">  float: left;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#menu-bar li a &#123;</span><br><span class="line">  display: block;</span><br><span class="line">  color: white;</span><br><span class="line">  text-align: center;</span><br><span class="line">  padding: 14px 16px;</span><br><span class="line">  text-decoration: none;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* Change the link color to #9d2b2b on hover */</span><br><span class="line">#menu-bar li a:hover &#123;</span><br><span class="line">  background-color: #9d2b2b;</span><br><span class="line">&#125;</span><br><span class="line">&lt;/style&gt;</span><br></pre></td></tr></table></figure>
<p>发现issue，需要修改一下。问chatgpt</p>
<p><img src="/../asset_electronvuechatgpt/03.png"></p>
<p>不停的询问，调试代码，把chatgpt当作一个编程助手，效率还是不错。UI界面做完后，就该做功能了。</p>
<h2 id="添加功能"><a href="#添加功能" class="headerlink" title="添加功能"></a>添加功能</h2><p>把python功能代码发给chatgpt，然后问chatgpt怎么办，根据他的说法不停的问，同时告诉他我想用的electron框架，chatgpt就会生成代码，然后不停的问，调试。整体工作量大概3~4天就完成整个工具，我记得当初做python工具用了2周。</p>
<h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><p>虽然chatgpt帮忙很多，但是不可避免要调试。 render进程用浏览器developer tools调试，不特别讲。<br>调试electron主进程需要讲一下，</p>
<p>在一个electron 应用中有且只有一个主进程。调试主进程的方式也用浏览器来进行debugger</p>
<ul>
<li><p>使用 –inspect&#x3D;[port] 来设置一个运行端口，比如在vscode package.json中配置如下脚本：</p>
<p>“electron:serve”: “vue-cli-service electron:serve –inspect&#x3D;5858”</p>
</li>
<li><p>在终端输入 npm run electron:serve</p>
</li>
<li><p>浏览器输入： chrome:&#x2F;&#x2F;inspect，配置Discover network targets的端口为上述端口(5858)，点击下方inspect</p>
</li>
<li><p>点击inspect之后就会弹出一个调试主进程的浏览器窗口，就可以在这个窗口中去debugger当前electron应用的主进程了。如下：进入Sources标签，ctrl+p输入main.js或者其它js，输入断点可以debug</p>
</li>
</ul>
<h2 id="体会"><a href="#体会" class="headerlink" title="体会"></a>体会</h2><p>大模型确实改变了软件行业，编程语言已经不成为开发软件的门槛，软件工程师具备软件思想，熟悉编程语言的基本逻辑，基本语法甚至不是太熟悉也可以开发软件。 而且效率还是很高的. 主要节省时间在于不需要 </p>
<ul>
<li>上网大量搜索并挑选答案, </li>
<li>代码组织</li>
</ul>
<p>人在这个过程中主要起到：</p>
<ul>
<li>构想功能,提出具体步骤, </li>
<li>根据代码来调试, </li>
<li>根据调试问题提出新问题给chatgpt解决.</li>
</ul>
<p>整体上来讲chatgpt起到编程手册和代码库的作用.大模型作为软件工程师的助手，大大降低了开发难度，提高效率。以后不使用大模型的软件工程师，被使用大模型的软件工程师淘汰是肯定的。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/03/12/ollama/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/12/ollama/" class="post-title-link" itemprop="url">ollama使用方法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-03-12 11:49:50 / 修改时间：15:41:44" itemprop="dateCreated datePublished" datetime="2024-03-12T11:49:50+08:00">2024-03-12</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>591</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Ollama 终于可以在 Windows 上运行了</p>
<h2 id="下载-Ollma-安装文件"><a href="#下载-Ollma-安装文件" class="headerlink" title="下载 Ollma 安装文件"></a>下载 Ollma 安装文件</h2><p>访问 <a target="_blank" rel="noopener" href="https://ollama.com/download%EF%BC%8C%E9%80%89%E6%8B%A9">https://ollama.com/download，选择</a> Windows，单击 “Download for Windows (Preview)” 进行下载。</p>
<h2 id="安装-Ollama"><a href="#安装-Ollama" class="headerlink" title="安装 Ollama"></a>安装 Ollama</h2><p>双击下载的 “OllamaSetup.exe”，直接安装就可以了。安装完以后，ollama app后台进程会自动运行。</p>
<h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><p>Ollama 下载的模型模型保存在 C 盘，如果想更改默认路径的话，可以通过设置 OLLAMA_MODELS 进行修改。</p>
<p>OLLAMA_MODELS：F:\OllamaCache</p>
<p>Ollama 默认提供 OpenAI 的兼容 API，默认端口是 11434，默认只可以通过 localhost 进行访问，如果想公开访问的话，可以通过设置 OLLAMA_HOST 进行修改。</p>
<p>OLLAMA_HOST：0.0.0.0</p>
<p>修改环境变量后，需要去任务管理器杀掉ollama的各个进程或者重启电脑，然后重新打开cmd，set看下环境变量，再重新启动ollama</p>
<h2 id="使用-Ollama"><a href="#使用-Ollama" class="headerlink" title="使用 Ollama"></a>使用 Ollama</h2><p>访问 <a target="_blank" rel="noopener" href="https://ollama.com/library">https://ollama.com/library</a></p>
<p>搜索你要使用的模型，主流的模型，比如 llama2、qwen1.5、mixtral 等，Ollama都支持。</p>
<p>下面以允许 qwen 为例，我们要运行 7b 的模型，</p>
<p>ollama App在后台已经跑起来的情况下，打开cmd，输入</p>
<p><code>ollama run qwen:7b</code></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Howard Huang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">170k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">5:10</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">
    <!--由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动-->
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
