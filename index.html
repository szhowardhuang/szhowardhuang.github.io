<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"szhowardhuang.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="嵌入式老兵博客">
<meta property="og:url" content="https://szhowardhuang.github.io/index.html">
<meta property="og:site_name" content="嵌入式老兵博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Howard Huang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://szhowardhuang.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>嵌入式老兵博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">嵌入式老兵博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Howard Huang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">55</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/26/GraphRAG03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/26/GraphRAG03/" class="post-title-link" itemprop="url">GraphRAG系列3 - 实验</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-26 12:19:48 / 修改时间：12:29:41" itemprop="dateCreated datePublished" datetime="2024-08-26T12:19:48+08:00">2024-08-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>微软推出GraphRAG（图谱检索增强生成），我比较感兴趣GraphRAG的构建过程，参考源码做了一个测试。</p>
<p>测试数据是电影库，原始文本json数据263KB，json格式如下：UTF8字符是中文</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;genre&quot;: [</span><br><span class="line">            &quot;\u5267\u60c5&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;title&quot;: &quot;\u8096\u7533\u514b\u7684\u6551\u8d4e&quot;,</span><br><span class="line">        &quot;year&quot;: 1994,</span><br><span class="line">        &quot;certificate&quot;: &quot;A&quot;,</span><br><span class="line">        &quot;overview&quot;: &quot;\u4e24\u540d\u88ab\u76d1\u7981\u7684\u7537\u5b50\u5728\u591a\u5e74\u4e2d\u5efa\u7acb\u4e86\u6df1\u539a\u7684\u53cb\u8c0a\uff0c\u901a\u8fc7\u5171\u540c\u7684\u5584\u884c\u627e\u5230\u5b89\u6170\u548c\u6700\u7ec8\u7684\u6551\u8d4e\u3002&quot;,</span><br><span class="line">        &quot;director&quot;: &quot;\u5f17\u5170\u514b\u00b7\u5fb7\u62c9\u90a6\u7279&quot;,</span><br><span class="line">        &quot;cast&quot;: [</span><br><span class="line">            &quot;\u8482\u59c6\u00b7\u7f57\u5bbe\u65af&quot;,</span><br><span class="line">            &quot;\u6469\u6839\u00b7\u5f17\u91cc\u66fc&quot;,</span><br><span class="line">            &quot;\u9c8d\u52c3\u00b7\u5188\u987f&quot;,</span><br><span class="line">            &quot;\u5a01\u5ec9\u00b7\u8428\u5fb7\u52d2&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;llm_text&quot;: &quot;\u4e24\u540d\u88ab\u76d1\u7981\u7684\u7537\u5b50\u5728\u591a\u5e74\u4e2d\u5efa\u7acb\u4e86\u6df1\u539a\u7684\u53cb\u8c0a\uff0c\u901a\u8fc7\u5171\u540c\u7684\u5584\u884c\u627e\u5230\u5b89\u6170\u548c\u6700\u7ec8\u7684\u6551\u8d4e\u3002\nYear: 1994\nDirector: \u5f17\u5170\u514b\u00b7\u5fb7\u62c9\u90a6\u7279\nCast: [&#x27;\u8482\u59c6\u00b7\u7f57\u5bbe\u65af&#x27;, &#x27;\u6469\u6839\u00b7\u5f17\u91cc\u66fc&#x27;, &#x27;\u9c8d\u52c3\u00b7\u5188\u987f&#x27;, &#x27;\u5a01\u5ec9\u00b7\u8428\u5fb7\u52d2&#x27;]\nCertificate: A&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;genre&quot;: [</span><br><span class="line">            &quot;\u72af\u7f6a&quot;,</span><br><span class="line">            &quot;\u5267\u60c5&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;title&quot;: &quot;\u6559\u7236&quot;,</span><br><span class="line">        &quot;year&quot;: 1972,</span><br><span class="line">        &quot;certificate&quot;: &quot;A&quot;,</span><br><span class="line">        &quot;overview&quot;: &quot;\u4e00\u4e2a\u6709\u7ec4\u7ec7\u72af\u7f6a\u738b\u671d\u7684\u5e74\u8fc8\u5bb6\u65cf\u9996\u9886\u5c06\u4ed6\u79d8\u5bc6\u5e1d\u56fd\u7684\u63a7\u5236\u6743\u8f6c\u4ea4\u7ed9\u4e0d\u60c5\u613f\u7684\u513f\u5b50\u3002&quot;,</span><br><span class="line">        &quot;director&quot;: &quot;\u5f17\u6717\u897f\u65af\u00b7\u798f\u7279\u00b7\u79d1\u6ce2\u62c9&quot;,</span><br><span class="line">        &quot;cast&quot;: [</span><br><span class="line">            &quot;\u9a6c\u9f99\u00b7\u767d\u5170\u5ea6&quot;,</span><br><span class="line">            &quot;\u963f\u5c14\u00b7\u5e15\u897f\u8bfa&quot;,</span><br><span class="line">            &quot;\u8a79\u59c6\u65af\u00b7\u51ef\u6069&quot;,</span><br><span class="line">            &quot;\u9edb\u5b89\u00b7\u57fa\u987f&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;llm_text&quot;: &quot;\u4e00\u4e2a\u6709\u7ec4\u7ec7\u72af\u7f6a\u738b\u671d\u7684\u5e74\u8fc8\u5bb6\u65cf\u9996\u9886\u5c06\u4ed6\u79d8\u5bc6\u5e1d\u56fd\u7684\u63a7\u5236\u6743\u8f6c\u4ea4\u7ed9\u4e0d\u60c5\u613f\u7684\u513f\u5b50\u3002\nYear: 1972\nDirector: \u5f17\u6717\u897f\u65af\u00b7\u798f\u7279\u00b7\u79d1\u6ce2\u62c9\nCast: [&#x27;\u9a6c\u9f99\u00b7\u767d\u5170\u5ea6&#x27;, &#x27;\u963f\u5c14\u00b7\u5e15\u897f\u8bfa&#x27;, &#x27;\u8a79\u59c6\u65af\u00b7\u51ef\u6069&#x27;, &#x27;\u9edb\u5b89\u00b7\u57fa\u987f&#x27;]\nCertificate: A&quot;</span><br><span class="line">    &#125;,</span><br></pre></td></tr></table></figure>


<p>构建图谱的过程如下：</p>
<p>create_graph_data &#x3D;&#x3D;》process_movie &#x3D;&#x3D;》extractEntities ， extractRelations ，extractClaims</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">async def create_graph_data(llm: LocalLLM, model: str, movies: List[Dict]):</span><br><span class="line">    # G = nx.Graph()</span><br><span class="line">    usages = []</span><br><span class="line">    graph_data = []</span><br><span class="line">    semaphore = asyncio.Semaphore(5)</span><br><span class="line">    pbar = tqdm(total=len(movies), desc=&quot;Processing Movies&quot;, colour=&quot;blue&quot;)</span><br><span class="line"></span><br><span class="line">    async def process_movie_with_semaphore(movie: Dict):</span><br><span class="line">        async with semaphore:</span><br><span class="line">            try:</span><br><span class="line">                await process_movie(movie.get(&quot;title&quot;), movie.get(&quot;llm_text&quot;))</span><br><span class="line">                pbar.update(1)</span><br><span class="line">            except Exception as err:</span><br><span class="line">                logging.exception(f&quot;EXCEPTION: &#123;str(err)&#125;&quot;)</span><br><span class="line">                pbar.update(1)</span><br><span class="line"></span><br><span class="line">    async def process_movie(movie: str, movie_overview: str):</span><br><span class="line">        entities, eu = await extractEntities(llm, model, movie_overview)</span><br><span class="line">        relations, ru = await extractRelations(llm, model, entities)</span><br><span class="line">        claims, cu = await extractClaims(llm, model, movie_overview, entities,</span><br><span class="line">                                         relations)</span><br><span class="line">        usages.extend([eu, ru, cu])</span><br><span class="line">        graph_data.append(&#123;</span><br><span class="line">            &quot;movie&quot;: movie,</span><br><span class="line">            &quot;overview&quot;: movie_overview,</span><br><span class="line">            &quot;entities&quot;: entities,</span><br><span class="line">            &quot;relations&quot;: relations,</span><br><span class="line">            &quot;claims&quot;: claims</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    await asyncio.gather(</span><br><span class="line">        *[process_movie_with_semaphore(movie) for movie in movies])</span><br><span class="line"></span><br><span class="line">    return graph_data, usages</span><br></pre></td></tr></table></figure>


<p>看一下 extractEntities ：</p>
<p>extractEntities &#x3D;&#x3D;》系统提示词 EXTRACT.ENTITIES &#x3D;&#x3D;》llm.<strong>function_call</strong></p>
<p>用大模型来抽取实体</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">async def extractEntities(llm: LocalLLM, model: str, content: str):</span><br><span class="line">    entities = []</span><br><span class="line">    usages = []</span><br><span class="line">    for gleaning in range(ALLOWED_GLEANINGS):</span><br><span class="line">        message_content = f&quot;‍```&#123;content&#125;‍```&quot;</span><br><span class="line">        messages = [&#123;</span><br><span class="line">            &quot;role&quot;: &quot;system&quot;,</span><br><span class="line">            &quot;content&quot;: EXTRACT.ENTITIES</span><br><span class="line">        &#125;, &#123;</span><br><span class="line">            &quot;role&quot;:</span><br><span class="line">            &quot;user&quot;,</span><br><span class="line">            &quot;content&quot;:</span><br><span class="line">            message_content if gleaning == 0 else</span><br><span class="line">            f&#x27;The following are the entities you provided: &#123;entities&#125;. You have missed some entities, please provide all the entities. &#123;message_content&#125;&#x27;</span><br><span class="line">        &#125;]</span><br><span class="line">        # output, usage = await llm.__complete__(messages, model)</span><br><span class="line">        output, usage = await llm.__function_call__(</span><br><span class="line">            messages,</span><br><span class="line">            model,</span><br><span class="line">            EntityTool.tools,</span><br><span class="line">            tool_choice=EntityTool.tool_choice)</span><br><span class="line">        entities_ = output.get(&quot;entities&quot;)</span><br><span class="line">        entities += entities_</span><br><span class="line">        usages += [usage]</span><br><span class="line">    usages = calculateUsages(usages)</span><br><span class="line">    return entities, usages</span><br></pre></td></tr></table></figure>


<p>再看一下提示词：</p>
<p>提示词里面告诉大模型要提取哪些实体，如何组织输出数据。 </p>
<blockquote>
<p>You are an AI assistant tasked with extracting entities from a movie description. Your goal is to identify the main movie and all related entities.</p>
<p>Instructions:</p>
<ol>
<li><p>Identify the main movie entity.</p>
</li>
<li><p>Identify all related entities (actors, directors, genres, themes, studios, etc.).</p>
</li>
<li><p>For each entity, provide:</p>
<ul>
<li>Name: The name of the entity (capitalized)</li>
<li>Type: The type of entity (Movie, Actor, Director, Genre, Theme, Studio, etc.)</li>
<li>Description: A brief description of the entity</li>
</ul>
</li>
</ol>
<p>Output Format:<br>Provide the output as a JSON object with the movie as the main entity and other entities in a separate list:<br>{<br>    “related_entities”: [<br>        {“name”: “ENTITY_NAME”, “type”: “ENTITY_TYPE”, “description”: “ENTITY_DESCRIPTION”},<br>        …<br>    ]<br>}</p>
<p>Text to analyze will be provided in triple backticks.</p>
<p>Begin your analysis:</p>
</blockquote>
<p>抽取关系以及声明就不赘述，代码还有很多，具体大家自己看：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/vatsalsaglani/GraphRAG4Rec">vatsalsaglani&#x2F;GraphRAG4Rec: A naive implementation of GraphRAG for Movie Recommendation on IMDB Top 1000 movies dataset. (github.com)</a></p>
<p>图谱构建好了之后，可以用浏览器查看.</p>
<p><img src="/../assets_graph03/image-20240802164047-36ty20q.png" alt="image.png"></p>
<p>然后就可以查询了，一次查询的token使用量很大，生成的token大概14776个token，大部分token在输入上面，prompt_tokens包含提示词和图谱本身的内容，用了78212个token。图谱检索增强生成这种方式效果不错, 消耗token成本依赖于进行查询的图谱数据的token数。</p>
<blockquote>
<p>{<br>“completion_tokens”:14776,<br>“prompt_tokens”:78212,<br>“total_tokens”:92988<br>}<br><br /></p>
</blockquote>
<p>附件包含源码和测试输出数据以及图谱。</p>
<p><a href="/../assets_graph03/imdb-20240826121440-i7mfjx5.zip">imdb.zip</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/21/Phi-3-mini-4k-graph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/21/Phi-3-mini-4k-graph/" class="post-title-link" itemprop="url">Phi-3-mini-4k 用于图谱实体关系提取</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-21 11:32:19 / 修改时间：14:55:28" itemprop="dateCreated datePublished" datetime="2024-08-21T11:32:19+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>17 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在 <a target="_blank" rel="noopener" href="https://asknews.app/">AskNews</a>，我们正在重新构想人们和LLMs消费和理解新闻的方式。我们提供的一个功能是对所有事件叙述和新闻文章中实体之间关系的丰富视觉表示。这些实体关系图，也称为知识图谱，为我们的用户提供了强大的方式来探索和互动我们的庞大新闻数据库。事实上，我们正式托管了世界上最大的可搜索新闻知识图谱表示。但是，我们如何处理每天生成 50 万个知识图谱呢？以下博客文章强调了支撑整个知识图谱构建&#x2F;索引过程的关键组件——我们经过精细调整的 Phi-3-mini-4k-instruct-graph。</p>
<p><img src="/../asset_phi3-mini-4k/01.png"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我们对 Phi-3-mini-4k 进行了微调，使其在图形提取质量上超过 Claude Sonnet 3.5，提升幅度达到 20%，并将成本降低了几个数量级。此外，我们改进了 Phi-3-mini-4k 已经相当出色的 JSON 输出结构，将解析错误率从 2.5%降低到 0。我们还发布了两个额外版本，Phi-3-medium-4k-instruct-graph 和 Phi-3-medium-128k-instruct-graph，旨在提高推理能力和处理更长的上下文。</p>
<p><img src="/../asset_phi3-mini-4k/12.png"></p>
<p>针对各种损失指标和最先进模型的 Phi-3-mini 微调性能比较。</p>
<p>我们还设置了一个 HuggingFace 空间，托管我们的微调模型，该模型旨在接收任何文本并将输出可视化为图形：</p>
<p><img src="/../asset_phi3-mini-4k/03.png"></p>
<h1 id="图谱在如今非常流行"><a href="#图谱在如今非常流行" class="headerlink" title="图谱在如今非常流行"></a>图谱在如今非常流行</h1><p>AskNews 系统每天处理的新闻量达到惊人的 50 万篇文章。使用向量数据库对这些文章进行索引可以实现广泛的语义探索，但使用知识图谱进行索引则带来了另一层复杂性。虽然向量数据库通常与旨在将语义嵌入向量空间的小型嵌入模型相结合，但知识图谱需要高级推理、一般世界知识和上下文，以便正确构建。</p>
<p>最新工具现在能够以成本效益高的方式将这种通用世界知识和推理应用于每天 50 万篇新闻文章。Phi-3-mini-4k 是一种强大的小型语言模型，广泛应用于摘要、翻译、代码生成和实体提取等任务。同时，GPT-4o 是一种最先进的大型语言模型，能够处理更高层次的推理任务。将这些模型与最新的微调方法和库结合，我们可以有效地将知识从 GPT-4o 转移到 Phi-3-mini-4k，同时保持图形质量和准确性，成本却大大降低。</p>
<p>通过每天提取 500k 实体关系图与 Phi-3-mini-4k-graph，我们受益于强大的新闻知识图谱表示，促进：</p>
<ul>
<li>复杂的搜索查询跨互补的向量 x 图索引（例如 RAG）</li>
<li>识别实体和关系之间的时间特征和趋势，以增强预测建模（实时预测）</li>
<li>跟踪来自二级和三级关系的隐藏洞察</li>
</ul>
<p>在接下来的部分中，我们将探讨我们的方法论，包括我们对指标制定的方式，并分享我们训练后评估的结果。</p>
<h1 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1><h2 id="数据集工程"><a href="#数据集工程" class="headerlink" title="数据集工程"></a>数据集工程</h2><p>我们从 AskNews API 的“事件”构建了我们的数据集。事件是代表单一事件的数百个语义相似的合成新闻文章摘要的聚类。聚类过程本质上识别出不同的话题，这有助于我们数据集的话题&#x2F;词汇多样化。每个事件聚类可以与在不同时间点发生的其他事件聚类相连接。这被称为叙事追踪，我们在这里不详细讨论，但可以说，时间上相连的两个事件通常是不断发展的新闻故事的更新。</p>
<p>目标是尽可能多样化主题和词汇。因此我们：</p>
<ol>
<li>从所有独特事件中选择均匀分布的样本</li>
<li>选择最多 3 个时间上相关的事件</li>
<li>确保训练&#x2F;测试&#x2F;验证数据集各自包含独特事件的子集，并且在时间上不重叠</li>
</ol>
<p>我们从 AskNews API 中提取这些事件，将合成摘要输入到 GPT-4o 中生成实体关系图，然后将合成事件摘要与 GPT-4o 生成的标签结合起来，构建完整的训练数据集。</p>
<p>该数据集被分为 90%用于训练，5%用于验证，5%用于测试——总共有 4,000 个独特样本。通过保持事件之间的严格分离，我们获得了目标参数空间的良好分布表示，我们的LLM将在其中操作。</p>
<h2 id="损失和验证指标"><a href="#损失和验证指标" class="headerlink" title="损失和验证指标"></a>损失和验证指标</h2><p>我们的主要目标是训练 Phi-3 生成与 GPT-4o 相似模式的故事图，同时确保正确生成 JSON 结构。</p>
<p>评估指标：最初，我们使用标准文本相似度指标，如 BLEU 和 ROUGE，来验证和测试我们模型的性能。然而，在经过几次训练迭代后，我们发现针对我们特定用例定制的指标产生了更好的结果：</p>
<ul>
<li>JSON 相似性：我们开发了一种自定义度量来比较 Phi-3 生成的节点和边与参考模型（GPT-4o）。</li>
</ul>
<p><img src="/../asset_phi3-mini-4k/04.png"></p>
<ul>
<li>JSON 一致性：这个额外的指标使我们能够检查每个边实体数据是否有相关的节点。我们发现，在某些情况下，即使是最先进的模型如 Claude 3.5 也会生成带有孤立边的图。</li>
</ul>
<p><img src="/../asset_phi3-mini-4k/05.png"></p>
<p>这是一个 JSON 输出的小示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;nodes&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;id&quot;: &quot;Viktor Orban&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;person&quot;,</span><br><span class="line">            &quot;detailed_type&quot;: &quot;hungarian prime minister&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;id&quot;: &quot;United States&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;country&quot;,</span><br><span class="line">            &quot;detailed_type&quot;: &quot;nation&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;edges&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;from&quot;: &quot;Viktor Orban&quot;,</span><br><span class="line">            &quot;to&quot;: &quot;United States&quot;,</span><br><span class="line">            &quot;label&quot;: &quot;stated influence&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="基础模型选择"><a href="#基础模型选择" class="headerlink" title="基础模型选择"></a>基础模型选择</h2><p>我们为这个项目选择了 <a target="_blank" rel="noopener" href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct">Phi-3-mini-4k-instruct</a> 模型。Phi-3 被归类为小型语言模型（SLM），效率极高。即使是配备 NVIDIA RTX GPU 的工作站或配备 GeForce RTX GPU 的个人电脑也可以在本地运行该模型。该模型在 2024 年 6 月进行了重大更新，证明在指令遵循、结构化输出和推理能力方面有了显著提升。根据模型发布说明，JSON 结构输出的性能在公共和内部基准数据集上从 11.5 大幅提升至 52.3，此外还有其他增强功能。对于我们的用例而言，这一改进是显著的。</p>
<p>这些改进进一步巩固了 Phi-3 作为我们任务的优秀选择。作为 SLM 的高效性与其在结构化输出方面增强的能力完美契合了我们处理大量新闻文章的目标，同时保持高质量的实体关系提取。</p>
<p>我们的微调方法利用了变换器，包括：SFTTrainer 用于高效的监督训练，PEFT 用于参数高效的微调，以及 QLoRA 用于量化低秩适应，使 Phi-3 有效适应我们的任务，同时优化计算资源。</p>
<p>下面的代码片段展示了我们实现的关键部分：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,</span><br><span class="line">                        TrainingArguments, EarlyStoppingCallback)</span><br><span class="line">from trl import SFTTrainer</span><br><span class="line">from peft import LoraConfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ModelTrainer:</span><br><span class="line">  def setup_model_and_tokenizer(self):</span><br><span class="line">      bnb_config = BitsAndBytesConfig(</span><br><span class="line">          load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=&quot;nf4&quot;, bnb_4bit_compute_dtype=torch.bfloat16</span><br><span class="line">      )</span><br><span class="line">      self.model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">          self.model_id,</span><br><span class="line">          device_map=&quot;auto&quot;,</span><br><span class="line">          attn_implementation=&quot;flash_attention_2&quot;,</span><br><span class="line">          torch_dtype=torch.bfloat16,</span><br><span class="line">          quantization_config=bnb_config,</span><br><span class="line">          trust_remote_code=True,</span><br><span class="line">          use_cache=False</span><br><span class="line">      )</span><br><span class="line">      self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_id, trust_remote_code=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  def setup_trainer(self, train_dataset, eval_dataset):</span><br><span class="line">      peft_config = LoraConfig(</span><br><span class="line">          lora_alpha=8,</span><br><span class="line">          lora_dropout=0.05,</span><br><span class="line">          r=6,</span><br><span class="line">          bias=&quot;none&quot;,</span><br><span class="line">          target_modules=&quot;all-linear&quot;,</span><br><span class="line">          task_type=&quot;CAUSAL_LM&quot;,</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">      args = TrainingArguments(</span><br><span class="line">          output_dir=self.output_dir,</span><br><span class="line">          num_train_epochs=5,</span><br><span class="line">          per_device_train_batch_size=4,</span><br><span class="line">          gradient_accumulation_steps=1,</span><br><span class="line">          per_device_eval_batch_size=8,</span><br><span class="line">          eval_accumulation_steps=2,</span><br><span class="line">          gradient_checkpointing=True,</span><br><span class="line">          logging_steps=10,</span><br><span class="line">          save_strategy=&quot;steps&quot;,</span><br><span class="line">          evaluation_strategy=&quot;steps&quot;,</span><br><span class="line">          eval_steps=100,</span><br><span class="line">          save_steps=100,</span><br><span class="line">          bf16=True,</span><br><span class="line">          tf32=True,</span><br><span class="line">          learning_rate=2e-4,</span><br><span class="line">          max_grad_norm=0.3,</span><br><span class="line">          warmup_ratio=0.03,</span><br><span class="line">          lr_scheduler_type=&quot;cosine&quot;,</span><br><span class="line">          metric_for_best_model=&quot;json_similarity_avg&quot;,</span><br><span class="line">          greater_is_better=True,</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">      self.trainer = SFTTrainer(</span><br><span class="line">          model=self.model,</span><br><span class="line">          args=args,</span><br><span class="line">          train_dataset=train_dataset,</span><br><span class="line">          eval_dataset=eval_dataset,</span><br><span class="line">          peft_config=peft_config,</span><br><span class="line">          max_seq_length=3072,</span><br><span class="line">          tokenizer=self.tokenizer,</span><br><span class="line">          packing=False,</span><br><span class="line">          compute_metrics=self.compute_metrics,</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">  trainer = ModelTrainer(</span><br><span class="line">      model_id=&quot;microsoft/Phi-3-mini-4k-instruct&quot;,</span><br><span class="line">      tokenizer_id=&quot;microsoft/Phi-3-mini-4k-instruct&quot;,</span><br><span class="line">      dataset_path=&quot;src/dataset/ds_1ea20812-afa8-4fab-8fba-dfb566c4775f&quot;,</span><br><span class="line">      output_dir=f&quot;models/&#123;output_model_name&#125;&quot;</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  trainer.setup_model_and_tokenizer()</span><br><span class="line">  trainer.setup_trainer(chatml_train_dataset, chatml_eval_dataset)</span><br><span class="line">  trainer.train_model()</span><br><span class="line">  trainer.save_model()</span><br></pre></td></tr></table></figure>

<p>为了测试和结果评估，我们将 GPT-4o 确立为基准真相。我们对比了我们的微调模型、未经微调的原始 Phi-3 以及 Claude Sonnet 3.5（被认为与 GPT-4o 齐名的最先进技术）。我们比较了这些模型之间之前提到的指标。此外，JSON 一致性指标被证明是有价值的，因为它不需要基准真相进行比较，从而允许对每个模型进行更独立的评估。</p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><p>在我们深入探讨培训后评估的细节之前，让我们先看一些现实世界的例子，以更好地理解我们的结果以及我们的指标实际意味着什么。我们将通过三个具体案例向您展示我们的 JSON 相似性指标和一致性检查在实践中的工作原理，以及它们的重要性。</p>
<h2 id="高相似度"><a href="#高相似度" class="headerlink" title="高相似度"></a>高相似度</h2><p>第一个例子是一个具有高 JSON 相似性的响应（这意味着与我们想要模仿的模型，即 GPT-4o，具有更大的相似性）。</p>
<p>故事：在一次协调的执法行动中，瓦西里·布拉科夫在特维尔地区因在莫斯科郊区谢尔科沃致命枪击两名警察而被捕。此次袭击发生在 4 月 7 日，导致一名警察死亡，另一名警察重伤。布拉科夫在事发后逃离现场并藏匿，经过六小时的搜捕，最终在当地森林中被找到并逮捕。被捕后，布拉科夫承认了罪行，并已被控以企图谋杀执法人员和非法持有枪支。此事件引发了重大关注，因为它突显了执法人员在执行职务时面临的危险，特别是在与毒品贩运相关的行动中。俄罗斯内务部和俄罗斯联邦安全局正在继续调查与枪击事件及布拉科夫随后的逃逸和逮捕相关的情况。</p>
<p> GPT-4o 输出：</p>
<p><img src="/../asset_phi3-mini-4k/06.png"></p>
<p>Phi-3-mini-instruct-graph 输出：</p>
<p><img src="/../asset_phi3-mini-4k/07.png"></p>
<p>正如我们在比较中所看到的，这些实体完全相同，只是在关系的描述上存在一些差异。然而，即使有这些差异，故事的正确含义在两个版本中都得到了传达。</p>
<h2 id="低相似度"><a href="#低相似度" class="headerlink" title="低相似度"></a>低相似度</h2><p>第二个例子是一个低 JSON 相似度的响应（这意味着与我们想要模仿的模型，即 GPT-4o，的相似度较低）。</p>
<p>故事：在令人惊讶的韧性展示中，美国劳动力市场在五月新增了 272,000 个职位，远超道琼斯共识预期的 190,000 个，反驳了劳动力市场放缓的说法。尽管就业增长强劲，失业率却上升至 4%，是自 2022 年 1 月以来的最高水平。医疗保健、政府以及休闲和酒店业是这一增长的主要驱动力，而平均时薪的增加则表明工资增长的持续趋势。强劲的就业报告对美联储的货币政策具有重要影响。最初，人们预计美联储可能会降息以支持经济。然而，意外的就业创造和工资增长可能会导致美联储推迟任何降息，一些专家现在预测，第一次降息可能要等到九月。劳动力市场的强劲被视为可能使美联储保持观望态势的关键因素。 股票和债券市场对该报告反应消极，标准普尔 500 期货下跌，政府债券收益率上升，反映出投资者担心由于强劲的就业市场数据，美联储可能会推迟降息。目前的情况为美联储呈现出复杂的局面，需在管理通胀与支持经济增长和维持劳动市场强劲之间取得平衡。</p>
<p> GPT-4o 输出：</p>
<p><img src="/../asset_phi3-mini-4k/08.png"></p>
<p>Phi-3-mini-instruct-graph 输出：</p>
<p><img src="/../asset_phi3-mini-4k/09.png"></p>
<p>正如我们在这个比较中所看到的，即使相似度较低，Phi3 微调版仍然能够通过实体及其关系更好地翻译故事的细节，保持美国劳动力市场作为主要实体，并与联邦储备保持联系（而这在 GPT-4o 中并未发生）。</p>
<h2 id="Json-一致性"><a href="#Json-一致性" class="headerlink" title="Json 一致性"></a>Json 一致性</h2><p>json_consistency 指标旨在通过验证所有边是否具有现有实体来衡量 JSON 的一致性，显示提取中节点和边之间的连贯性。我们微调的模型在该指标上达到了 99%，优于 Claude 3.5 Sonnet（97%）。我们将展示 Claude 3.5 中低一致性的具体示例，并将其与微调后的 Phi3 进行比较。</p>
<p>故事：在一次悲惨的对抗中，西澳大利亚珀斯的一名 16 岁男孩在刺伤一名男子并拒绝投降武器后被警方致命射击。该事件发生在威利顿郊区，因男孩被报道的在线激进化而被当局称为具有“恐怖主义特征”。他之前已被认定为风险，并参与了去激进化项目。警方在前一天晚上接到关于潜在袭击的线报，但未能阻止刺伤事件的发生。当他们抵达现场时，男孩手持一把 30 厘米的厨房刀，尽管被电击枪击中两次，但仍向警员冲去，随后被射击。刺伤事件的受害者目前情况稳定但危急。这一事件引发了人们对澳大利亚年轻人中激进化传播的重大担忧，以及有效干预的挑战。西澳大利亚州州长罗杰·库克和澳大利亚总理安东尼·阿尔巴尼斯均对此事件发表了讲话，强调国家对打击暴力极端主义的承诺。 事件正在调查中，宗教领袖与市政府之间的会议已安排，以解决社区关切。</p>
<p><strong>Claude 3.5 Sonnet 输出：</strong></p>
<p><img src="/../asset_phi3-mini-4k/10.png"></p>
<p>Phi-3-mini-instruct-graph 输出：</p>
<p><img src="/../asset_phi3-mini-4k/11.png"></p>
<p>在这种情况下，Claude 3.5 Sonnet 的一致性为 57%，而 Phi3 微调版的一致性为 100%。在 Claude 的 7 条边中，有 3 条因引用了一个名为“Incident”的不存在的节点而变得无效。因此，我们可以看到，微调后的 Phi3 版本能够传达更多故事细节。</p>
<h1 id="训练后评估"><a href="#训练后评估" class="headerlink" title="训练后评估"></a>训练后评估</h1><p>我们后期训练评估的结果通过比较图表呈现如下，展示了我们微调过程的有效性，并提供了关于每个模型在生成实体关系图任务中的能力和局限性的宝贵见解。正如我们在下面的表格中所看到的，Claude Sonnet 3.5 和 Phi-3-mini-instruct-graph 都显示出零错误，表明在这一指标上表现完美。然而，Phi-3-mini-4k-instruct（基础）模型则出现了 5 个错误，占总数的 2.5%。这表明我们的微调过程显著提高了基础 Phi-3 模型的性能，使其在 JSON 输出错误减少方面与更高级的 Claude Sonnet 3.5 达到了同等水平。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="/../asset_phi3-mini-4k/12.png"></p>
<p>针对各种损失指标和最先进模型的 Phi-3-mini 微调性能比较。</p>
<p><img src="/../asset_phi3-mini-4k/13.png"></p>
<p>这组柱状图提供了三个模型在四个关键指标上的全面比较。在节点相似性方面，Phi-3 微调模型的表现优于 Claude Sonnet 3.5 和基础 Phi-3 模型，得分为 0.78。在边缘相似性方面，Phi-3 微调模型再次领先，得分为 0.49，显示出相较于基础模型的显著改善。JSON 一致性指标在所有模型中表现良好，Phi-3 微调模型略微领先，得分为 0.99。最后，JSON 相似性平均值是节点相似性、边缘相似性和 JSON 一致性的平均值，显示 Phi-3 微调模型以 0.75 的得分保持领先。这个综合指标提供了每个模型在 JSON 结构和内容相似性各个方面表现的整体视图。这些结果表明，我们的微调过程成功提升了 Phi-3 在所有测量方面的表现，常常超越 Claude Sonnet 3.5 的能力。</p>
<p><img src="/../asset_phi3-mini-4k/14.png"></p>
<p>箱线图提供了每个指标得分分布的更详细视图。在节点相似性方面，Phi-3 微调显示出更高的中位数和更紧凑的四分位范围，表明性能更为一致。在边缘相似性方面，尽管 Phi-3 微调的中位数更高，但也显示出更多的变异性，暗示在一致性方面还有进一步改进的空间。JSON 一致性图表明所有模型的表现都非常出色，Phi-3 微调显示出最小的变异性。最后，JSON 相似性平均图表示跨节点、边缘和一致性指标的综合表现，展示了 Phi-3 微调不仅具有最高的中位数得分，还保持了相对紧凑的分布。这展示了其在各种测试案例中的强大和一致的性能，平衡了三个组成指标的优势。这些详细的分布强化了我们微调方法的成功，同时也突出了未来潜在改进的领域。</p>
<h1 id="成本比较"><a href="#成本比较" class="headerlink" title="成本比较"></a>成本比较</h1><p>正如我们之前提到的，我们的目标是每天获取大约 500,000 篇文章的实体关系。通过 API 使用LLM使这成为一项昂贵的事业。让我们模拟一下 GPT4o 和我们微调的 Phi3 之间的成本比较（以 2024 年 7 月的值为准）。为此，我们假设平均有 905 个提示令牌和 525 个输出令牌，这是我们在测试数据集上运行微调 Phi3 时的平均值。我们知道，根据分词器的不同，令牌计数方法可能会有所不同，但我们将以 Phi3 的计数作为比较的基础。</p>
<p><strong>托管 2x A100 SXM (runpod.io)</strong></p>
<p>$3.88&#x2F;小时 &#x3D;&gt; $93.12&#x2F;天</p>
<p><strong>OpenAI (GPT-4o)</strong></p>
<p>输入定价：271.5M（905 x 300k）代币（$5.00 &#x2F; 1M）：总计 $ 1357.00 &#x2F; 天</p>
<p>输出定价：157.5M（525 x 300k）代币（$15.00 &#x2F; 1M）：总计 $ 2362.50 &#x2F; 天</p>
<p>总计：$ 3719.50 &#x2F; 天</p>
<p>成本比较显示，使用托管在单个 A100 GPU 上的微调 Phi3 模型与使用 OpenAI 的 GPT-4o API 之间存在显著差异。托管微调模型的成本约为每天 46.56 美元，而使用 GPT-4o API 进行相同工作量的成本约为每天 3,719.50 美元。这意味着使用微调模型的成本降低超过 98%。显著的节省主要是由于消除了按令牌计费的方式，并且能够在专用硬件上处理大量请求。然而，重要的是要注意，这一比较并未考虑微调的初始成本或潜在的输出质量差异。例如，我们对 Phi-3 mini 的训练过程在 A100 SXM 上花费了近 3 小时（目前，每小时在 runpod.io 上的费用为 1.94 美元），这增加了前期投资。尽管如此，对于像我们这样的高容量应用，使用微调模型的经济效益是显而易见且显著的。</p>
<h1 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h1><p>大多数实体和关系提取的方法限制了实体和关系的类型。由于我们的主要目标是使用该模型来解释文章、故事，并捕捉尽可能多的细节，我们决定让模型自由定义这些类型。我们理解这可能会由于缺乏标准化而带来不利影响，但结果是一个更丰富细节的模型。</p>
<p>另一个重要点是，我们没有人类保证的真实数据。在我们的案例中，我们使用了 GPT-4o，这是在我们生成数据集时的最先进模型。微调是基于这个参考进行的。然而，即使我们有一个更好的真实数据集，它仍然可能存在偏见，并且不是“完美的”，因为正如我们在上述定性比较中所展示的，实体关系在许多方面都是非常复杂和主观的。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>我们很高兴在 Hugging Face 上以以下链接的 3 个版本公开我们的模型：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/EmergentMethods/Phi-3-mini-4k-instruct-graph">Phi-3-mini-4k-instruct-graph</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/EmergentMethods/Phi-3-mini-128k-instruct-graph">Phi-3-mini-128k-指令-图形</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/EmergentMethods/Phi-3-medium-128k-instruct-graph">Phi-3-medium-128k-instruct-graph</a></li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="https://emergentmethods.medium.com/outperforming-claude-3-5-sonnet-with-phi-3-mini-4k-for-graph-entity-relationship-extraction-tasks-7c8f6c1ebd79">Outperforming Claude 3.5 Sonnet with Phi-3-mini-4k for graph entity relationship extraction tasks | by Emergent Methods | Aug, 2024 | Medium</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/19/sam2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/19/sam2/" class="post-title-link" itemprop="url">SAM 2 + GPT-4o — 通过视觉提示的级联基础模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-19 09:36:15 / 修改时间：10:41:27" itemprop="dateCreated datePublished" datetime="2024-08-19T09:36:15+08:00">2024-08-19</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><img src="/../asset_sam2/image-20240819101159-0d6a8fb.png" alt="image.png"></p>
<p>基础模型的级联：将 SAM 2 与 GPT-4o 串联在一起</p>
<h1 id="什么是分段任何模型-2-SAM-2-？"><a href="#什么是分段任何模型-2-SAM-2-？" class="headerlink" title="什么是分段任何模型 2 (SAM 2)？"></a>什么是分段任何模型 2 (SAM 2)？</h1><blockquote>
<p>SAM 2 可以在任何图像或视频中对物体进行分割，而无需重新训练。</p>
</blockquote>
<p>Segment Anything Model 2 (SAM 2) [1] 是 Meta 推出的原始 Segment Anything Model [2] 的高级版本，旨在对图像和视频中的对象进行分割（见图 1）。</p>
<p><img src="/../asset_sam2/777.gif"></p>
<p>图 1. 行人（蓝色面具）和汽车（黄色面具）使用 SAM 2 进行分割和跟踪。</p>
<p>在开放源代码的 Apache 2.0 许可证下发布的 SAM 2 在计算机视觉方面代表了一个重要的飞跃，允许对对象进行实时的可提示分割。</p>
<p>SAM 2 以其在图像分割中的准确性和在视频分割中的卓越性能而著称，与之前的模型相比，所需的交互时间显著减少：我们展示了 SAM 2 如何只需 3 个点就能在整个视频中分割对象！</p>
<p>Meta 还推出了 SA-V 数据集，与 SAM 2 一起，包含超过 51,000 个视频和超过 600,000 个掩模。这一数据集促进了其在医学成像、卫星图像、海洋科学和内容创作等多个领域的应用。</p>
<h2 id="1-1-SAM-2-功能摘要"><a href="#1-1-SAM-2-功能摘要" class="headerlink" title="1.1 SAM 2 功能摘要"></a>1.1 SAM 2 功能摘要</h2><p>SAM 2 的主要特征总结在图 2 中。</p>
<p><img src="/../asset_sam2/image-20240819101518-dy5rc8o.png" alt="image.png"></p>
<h1 id="SAM-2-有什么特别之处？"><a href="#SAM-2-有什么特别之处？" class="headerlink" title="SAM 2 有什么特别之处？"></a>SAM 2 有什么特别之处？</h1><p>SAM 2 的新颖之处在于它解决了视频数据的复杂性，例如物体运动、变形、遮挡和光照变化，这些在静态图像中是不存在的。</p>
<p>这使得 SAM 2 成为混合现实、机器人技术、自动驾驶汽车和视频编辑应用中的关键工具。</p>
<p><img src="/../asset_sam2/778.gif"></p>
<p>图 3. SAM 2 的实际应用：原始视频中的球被移除（左上角），并创建了一个没有球的新视频（右下角）</p>
<p>SAM 2 的关键创新是：</p>
<ol>
<li>图像和视频的统一模型: SAM 2 将图像视为单帧视频，使其能够无缝处理这两种类型的输入。这种统一是通过利用内存来回忆之前处理过的视频信息，从而实现跨帧的准确分割。</li>
<li>可提示的视觉分割任务：SAM 2 将图像分割任务推广到视频领域，通过在视频的任何帧中输入提示（点、框或掩码）来定义时空掩码（masklet）。它可以立即进行预测并在时间上传播这些预测，通过额外的提示迭代地细化分割。</li>
<li>高级数据集 (SA-V): SAM 2 是在 SA-V 数据集上训练的，该数据集比现有的视频分割数据集大得多。这个广泛的数据集使得 SAM 2 在视频分割方面达到了最先进的性能。</li>
</ol>
<h1 id="3-我该如何运行-SAM-2？"><a href="#3-我该如何运行-SAM-2？" class="headerlink" title="3. 我该如何运行 SAM 2？"></a>3. 我该如何运行 SAM 2？</h1><p>您可以检查 SAM 2 仓库，或者使用 这个 Jupyter Notebook 在您自己的机器上设置模型。在本节中，我们描述后者的方法。</p>
<h2 id="3-1-先决条件"><a href="#3-1-先决条件" class="headerlink" title="3.1 先决条件"></a>3.1 先决条件</h2><ul>
<li>一台配有 GPU 的机器（Google Colab 可以）。</li>
<li>一个用于从视频中提取帧的库（例如，ffmpeg）</li>
</ul>
<h2 id="3-2-设置"><a href="#3-2-设置" class="headerlink" title="3.2 设置"></a>3.2 设置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">HOME = os.getcwd()</span><br><span class="line"></span><br><span class="line"># Clone the repository</span><br><span class="line">!git clone https://github.com/facebookresearch/segment-anything-2.git</span><br><span class="line">%cd &#123;HOME&#125;/segment-anything-2</span><br><span class="line"></span><br><span class="line"># install the python libraries for &quot;segment-anything-2&quot;</span><br><span class="line">!pip install -e . -q</span><br><span class="line">!pip install -e &quot;.[demo]&quot; -q</span><br></pre></td></tr></table></figure>

<h2 id="3-3-下载-SAM-2-检查点"><a href="#3-3-下载-SAM-2-检查点" class="headerlink" title="3.3. 下载 SAM-2 检查点"></a>3.3. 下载 SAM-2 检查点</h2><p>我们只会下载最大的模型，但也有更小的选项可供选择。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt -P &#123;HOME&#125;/checkpoints</span><br></pre></td></tr></table></figure>

<h2 id="3-4-创建预测器"><a href="#3-4-创建预测器" class="headerlink" title="3.4 创建预测器"></a>3.4 创建预测器</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sam2.build_sam import build_sam2_video_predictor</span><br><span class="line"></span><br><span class="line">sam2_checkpoint = f&quot;&#123;HOME&#125;/checkpoints/sam2_hiera_large.pt&quot;</span><br><span class="line">model_cfg = &quot;sam2_hiera_l.yaml&quot;</span><br><span class="line"></span><br><span class="line">predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint)</span><br></pre></td></tr></table></figure>

<h2 id="提取视频中的帧并探索数据"><a href="#提取视频中的帧并探索数据" class="headerlink" title="提取视频中的帧并探索数据"></a>提取视频中的帧并探索数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Extract the frames</span><br><span class="line">video_path = f&quot;&#123;HOME&#125;/segment-anything-2/SAM2_gymnastics.mp4&quot;</span><br><span class="line">output_path = f&quot;&#123;HOME&#125;/segment-anything-2/outputs/gymnastics&quot;</span><br><span class="line">!ffmpeg -i &#123;video_path&#125; -q:v 2 -start_number 0 &#123;output_path&#125;/&#x27;%05d.jpg&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># `video_dir` a directory of JPEG f÷/rames with filenames like `&lt;frame_index&gt;.jpg`</span><br><span class="line">video_dir = f&quot;&#123;HOME&#125;/segment-anything-2/outputs/gymnastics&quot;</span><br><span class="line"></span><br><span class="line"># scan all the JPEG frame names in this directory</span><br><span class="line">frame_names = [</span><br><span class="line">    p for p in os.listdir(video_dir)</span><br><span class="line">    if os.path.splitext(p)[-1] in [&quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.JPG&quot;, &quot;.JPEG&quot;]</span><br><span class="line">]</span><br><span class="line">frame_names.sort(key=lambda p: int(os.path.splitext(p)[0]))</span><br><span class="line"></span><br><span class="line"># take a look at the first video frame</span><br><span class="line">frame_idx = 0</span><br><span class="line">plt.figure(figsize=(12, 8))</span><br><span class="line">plt.title(f&quot;frame &#123;frame_idx&#125;&quot;)</span><br><span class="line">plt.imshow(Image.open(os.path.join(video_dir, frame_names[frame_idx])))</span><br></pre></td></tr></table></figure>

<p><img src="/../asset_sam2/image-20240819101642-iujmz3w.png" alt="image.png"></p>
<p>图 4 在这个阶段，我们只是探索我们视频的第一帧。</p>
<h2 id="3-6-使用坐标定义要分割的对象"><a href="#3-6-使用坐标定义要分割的对象" class="headerlink" title="3.6 使用坐标定义要分割的对象"></a>3.6 使用坐标定义要分割的对象</h2><p>我们定义一个函数来帮助我们提供 x, y 坐标的列表：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def refine_mask_with_coordinates(coordinates, ann_frame_idx, ann_obj_id, show_result=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Refine a mask by adding new points using a SAM predictor.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">    coordinates (list): List of [x, y] coordinates, </span><br><span class="line">        e.g., [[210, 350], [250, 220]]</span><br><span class="line">    ann_frame_idx (int): The index of the frame being processed</span><br><span class="line">    ann_obj_id (int): A unique identifier for the object being segmented</span><br><span class="line">    show_result (bool): Whether to display the result (default: True)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # Convert the list of coordinates to a numpy array</span><br><span class="line">    points = np.array(coordinates, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    # Create labels array (assuming all points are positive clicks)</span><br><span class="line">    labels = np.ones(len(coordinates), dtype=np.int32)</span><br><span class="line"></span><br><span class="line">    # Add new points to the predictor</span><br><span class="line">    _, out_obj_ids, out_mask_logits = predictor.add_new_points(</span><br><span class="line">        inference_state=inference_state,</span><br><span class="line">        frame_idx=ann_frame_idx,</span><br><span class="line">        obj_id=ann_obj_id,</span><br><span class="line">        points=points,</span><br><span class="line">        labels=labels,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    if show_result:</span><br><span class="line">        # Display the results</span><br><span class="line">        plt.figure(figsize=(12, 8))</span><br><span class="line">        plt.title(f&quot;Frame &#123;ann_frame_idx&#125;&quot;)</span><br><span class="line">        plt.imshow(Image.open(os.path.join(video_dir, frame_names[ann_frame_idx])))</span><br><span class="line">        show_points(points, labels, plt.gca())</span><br><span class="line">        show_mask((out_mask_logits[0] &gt; 0.0).cpu().numpy(), plt.gca(), obj_id=out_obj_ids[0])</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>

<p>我们建立状态并提供我们旨在分割的对象的坐标：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inference_state = predictor.init_state(video_path=video_dir)</span><br><span class="line"></span><br><span class="line">refine_mask_with_coordinates([[950, 700], [950, 600], [950, 500]], 0, 1)</span><br></pre></td></tr></table></figure>

<p><img src="/../asset_sam2/image-20240819101657-n9kgjur.png" alt="image.png"></p>
<p>图 5. 通过三个坐标（绿色星星），模型自动识别整个物体。</p>
<p>如图 5 所示，三个点足以让模型为个体的整个身体分配一个掩码。在某些情况下，仅 1 或 2 个点也可以。</p>
<p>现在我们在所有帧上运行该过程（图 6）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># run propagation throughout the video and collect the results in a dict</span><br><span class="line">video_segments = &#123;&#125;  # video_segments contains the per-frame segmentation results</span><br><span class="line">for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):</span><br><span class="line">    video_segments[out_frame_idx] = &#123;</span><br><span class="line">        out_obj_id: (out_mask_logits[i] &gt; 0.0).cpu().numpy()</span><br><span class="line">        for i, out_obj_id in enumerate(out_obj_ids)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># render the segmentation results every few frames</span><br><span class="line">vis_frame_stride = 30</span><br><span class="line">plt.close(&quot;all&quot;)</span><br><span class="line">for out_frame_idx in range(0, len(frame_names), vis_frame_stride):</span><br><span class="line">    plt.figure(figsize=(6, 4))</span><br><span class="line">    plt.title(f&quot;frame &#123;out_frame_idx&#125;&quot;)</span><br><span class="line">    plt.imshow(Image.open(os.path.join(video_dir, frame_names[out_frame_idx])))</span><br><span class="line">    for out_obj_id, out_mask in video_segments[out_frame_idx].items():</span><br><span class="line">        show_mask(out_mask, plt.gca(), obj_id=out_obj_id)</span><br></pre></td></tr></table></figure>

<p><img src="/../asset_sam2/image-20240819101715-jisv1hu.png" alt="image.png"></p>
<p>图 6。一旦 SAM 2 识别出一个对象，它可以在整个视频中自动跟踪同一对象。</p>
<p>最后，我们使用 ffmpeg 将帧合并生成视频。最终结果如图 7 所示。</p>
<p><img src="/../asset_sam2/779.gif"></p>
<p>图 7. 上：原始视频，下：运行 SAM 2 后的 视频</p>
<p>SAM 2 在图像和视频中准确快速地分割物体的能力可以彻底改变计算机视觉系统的创建方式。</p>
<h1 id="4-级联基础模型"><a href="#4-级联基础模型" class="headerlink" title="4. 级联基础模型"></a>4. 级联基础模型</h1><p>级联基础模型简单来说就是组装一个管道，在这个管道中，你将一个模型的输出作为后续模型的输入。</p>
<p>你可能会问，“但这种方法有什么新颖之处？”🤔 答案在于基础模型的零-shot [2] 特性。像 GPT-4o 或 SAM 2 这样的模型被称为零-shot，这意味着它们可以在没有先前训练步骤的情况下进行推理。因此，这些模型可以从系统的角度进行连接，如图 2 所示。</p>
<p><img src="/../asset_sam2/image-20240819102127-incadh1.png" alt="image.png"></p>
<p>事实上，一些研究方法如 CaFO [3]结合了多个预训练的基础模型（CLIP、DINO、DALL-E、GPT-3），通过利用多样的预训练知识和生成合成数据来增强少样本视觉识别。</p>
<h1 id="5-基础模型作为视觉提示工具"><a href="#5-基础模型作为视觉提示工具" class="headerlink" title="5. 基础模型作为视觉提示工具"></a>5. 基础模型作为视觉提示工具</h1><h2 id="5-1-计算机视觉管道-2-0：一种新范式"><a href="#5-1-计算机视觉管道-2-0：一种新范式" class="headerlink" title="5.1 计算机视觉管道 2.0：一种新范式"></a>5.1 计算机视觉管道 2.0：一种新范式</h2><p>我们之前探讨过 什么是视觉提示。它指的是使用视觉信息（如图像、边界框或点）作为基础模型的输入或“提示”，这些模型可以处理视觉和文本信息。</p>
<p>Tenyks 的一个关键优势是视觉搜索。我们每天处理数以万计的查询，使用视觉提示。例如，图 3 显示了如何选择一个对象的边界框，以便在您的数据中搜索细粒度的细节。</p>
<p><img src="/../asset_sam2/780.gif"></p>
<p>图 3. 使用视觉提示搜索物体（例如，校车），即使不存在该物体的类别</p>
<p>正如我们之前所论述的，在 Tenyks，我们认为视觉领域的传统流程正处于一个过渡的开始，流程中的许多阶段（例如，标注、训练）将被包含基础模型的模块所取代，这将形成一个所谓的计算机视觉管道 2.0。</p>
<h2 id="5-2-视觉提示作为基础模型的粘合剂的挑战"><a href="#5-2-视觉提示作为基础模型的粘合剂的挑战" class="headerlink" title="5.2 视觉提示作为基础模型的粘合剂的挑战"></a>5.2 视觉提示作为基础模型的粘合剂的挑战</h2><p>现在，当你开始将基础模型连接在一起时，你会立即注意到，基于这种范式构建一个稳健的系统与在周末构建一个原型是截然不同的。</p>
<p>以下是您一开始就可能遇到的一些主要挑战：</p>
<ol>
<li>性能和可扩展性</li>
</ol>
<ul>
<li>确保系统能够实时处理大量数据和请求。</li>
<li>随着运营规模的扩大，保持准确性和速度。</li>
</ul>
<ol start="2">
<li>集成与兼容性</li>
</ol>
<ul>
<li>将多模型系统无缝集成到现有基础设施中。</li>
<li>确保与各种数据格式、API 和遗留系统的互操作性。</li>
</ul>
<ol start="3">
<li>可靠性与错误处理</li>
</ol>
<ul>
<li>开发强大的错误检测和纠正机制。</li>
<li>实施冗余以保持运营连续性。</li>
</ul>
<h1 id="6-GPT-4o-SAM-2"><a href="#6-GPT-4o-SAM-2" class="headerlink" title="6. GPT-4o + SAM 2"></a>6. GPT-4o + SAM 2</h1><h2 id="6-1-视觉提示管道"><a href="#6-1-视觉提示管道" class="headerlink" title="6.1 视觉提示管道"></a>6.1 视觉提示管道</h2><p><img src="/../asset_sam2/image-20240819102856-xjc84yb.png" alt="image.png"></p>
<p>我们的设置：利用 GPT-4o 提取视觉信息，这些信息将作为 SAM 2 的输入。</p>
<p>上图显示了一个由两个步骤组成的简单管道。假设 GPT-4o足够强大，可以处理如下提示：</p>
<blockquote>
<p>“对于给定的图像，请提供三组（x,y）坐标的体操运动员。”</p>
<p>“对于给定的图像，请提供体操运动员的边界框坐标。”</p>
</blockquote>
<p>下图 显示了 GPT-4o 的结果。</p>
<p><img src="/../asset_sam2/image-20240819102914-ffj44wv.png" alt="image.png"></p>
<p>当查询 (x,y) 坐标时，来自 GPT-4o 的结果相当 不准确。</p>
<p>图 7 显示了这种行为在 200 个 GPT-4o 的 API 请求中是一致的。</p>
<p><img src="/../asset_sam2/image-20240819102926-12e5v4q.png" alt="image.png"></p>
<p>图 7 在使用 GPT-4 进行视觉理解的 200 次尝试中，仅有 5 次准确识别了(x,y)坐标。所有的边界框结果均不正确。</p>
<p>所以，我们真的不能在2024年使用任何优秀的基础模型作为第二个基础模型的输入吗？ </p>
<h1 id="7-YOLO-世界-SAM-2"><a href="#7-YOLO-世界-SAM-2" class="headerlink" title="7. YOLO 世界 + SAM 2"></a>7. YOLO 世界 + SAM 2</h1><h2 id="7-1-零样本计算机视觉：YOLO-世界"><a href="#7-1-零样本计算机视觉：YOLO-世界" class="headerlink" title="7.1 零样本计算机视觉：YOLO-世界"></a>7.1 零样本计算机视觉：YOLO-世界</h2><p>尽管我们希望被打击，因为意识到GPT-4o不足以从图像中提供视觉答案，但我们找到了一种合格的专用模型：YOLO-World [4]。</p>
<p>图8 显示了在给定文本输入（即类别）的情况下，该模型如何准确预测每个给定输入的边界框！</p>
<p>YOLO-World 的词汇甚至包括这个词：体操运动员！(见图 8 右侧的 0.93 mAP)。</p>
<p><img src="/../asset_sam2/image-20240819102948-9huihaa.png" alt="image.png"></p>
<p>图 8. YOLO-World 根据一些文本输入（即类别）给出的预测</p>
<ul>
<li>🔥 剧透警告： 我们将在即将发布的帖子中讨论更多关于 YOLO-World（零样本）与 YOLO v8（微调）的内容！</li>
</ul>
<p>YOLO-World 是一种零样本模型，用于物体检测，可以在不需要针对特定物体类别进行先前训练的情况下，检测和定位图像中的物体。</p>
<p>我们使用 YOLO-World 为 SAM 2 提供边界框，如图 9 所示。</p>
<p><img src="/../asset_sam2/image-20240819103001-8yezi31.png" alt="image.png"></p>
<p>图 9. 最终管道，包括YOLO-World和 SAM 2 连接在一起</p>
<p>我们需要提供给整个系统的唯一输入是 YOLO-World 词汇的类定义，在这种情况下是“体操运动员”。这个词足以让 YOLO-World 为 SAM 2 提供边界框坐标。</p>
<p>查看这个 Jupyter Notebook 以获取实施的详细信息。最终结果如图 8 所示。</p>
<h1 id="8-结论"><a href="#8-结论" class="headerlink" title="8. 结论"></a>8. 结论</h1><p>在关于 SAM 2 的系列中，我们描述并设置了 Segment Anything Model 2（SAM 2）。然后，我们使用视觉提示将两个基础模型级联（即，我们将模型 A 的输出作为模型 B 的输入）。</p>
<p>我们发现市场上领先的 MLLMs，GPT-4o ，在提供给定图像的物体坐标或边界框方面相当不准确。相反，我们发现专门的模型（例如，YOLO-World）更适合这个工作。</p>
<p>构建原型是一回事，但实际上，有一些挑战即使是最优秀的机器学习团队也难以应对（例如，集成、可靠性以及在连接基础模型时的适应性）。</p>
<p>正如我们之前所论述的，计算机视觉领域出现了一个新的范式：视觉处理流程中的一些传统阶段可能会被（零样本）基础模型所取代，这些模型将随着时间的推移不断改进。</p>
<p>我们还要等多久才能从即将推出的 GPT 家族成员那里获得精确的边界框坐标？ 可能不会太久。</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/@tenyks_blogger/sam-2-gpt-4o-cascading-foundation-models-via-visual-prompting-part-2-b592b5cd8d4a">SAM 2 + GPT-4o — 通过视觉提示的级联基础模型 — 第二部分 | 作者：The Tenyks Blogger | 2024 年 8 月 | Medium — SAM 2 + GPT-4o — Cascading Foundation Models via Visual Prompting — Part 2 | by The Tenyks Blogger | Aug, 2024 | Medium</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/14/llmsClinical07/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/14/llmsClinical07/" class="post-title-link" itemprop="url">第七章 未来将至</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-14 11:32:19" itemprop="dateCreated datePublished" datetime="2024-08-14T11:32:19+08:00">2024-08-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:07:15" itemprop="dateModified" datetime="2024-08-21T14:07:15+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>20 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>大型语言模型（LLMs）和生成式人工智能在医疗保健领域的未来就像后视镜中的物体，看起来比实际更近。医疗保健领域的人工智能发展速度正在加快，我们正处于变革性变化的边缘，这将带来患者护理、医疗实践和整个医疗保健领域的进步。本章提供了对LLMs和生成式人工智能在医疗保健行业潜力的初步了解。让我们先讨论一下无限提示和代理推理的潜力预览。</p>
<h1 id="未来在LLMs的前景与挑战"><a href="#未来在LLMs的前景与挑战" class="headerlink" title="未来在LLMs的前景与挑战"></a>未来在LLMs的前景与挑战</h1><p>通往人工通用智能（AGI）的道路在机器学习进步的开创时期漫长而曲折，这一时期以基础概念、实验算法和有限的计算能力为标志。20 世纪中叶的杰出人物为未来将成为变革性技术的基础奠定了基础工作。最近transformers，LLMs，以及生成式人工智能的出现使许多人相信我们正站在某种深刻事物的边缘。关于LLMs的研究和进展仍在继续，最近的思考和研究围绕无限提示和代理推理展开，这在第一章中进行了介绍。让我们更详细地探讨这两者，并考虑它们在医疗保健中的潜力。</p>
<h2 id="无限提示"><a href="#无限提示" class="headerlink" title="无限提示"></a>无限提示</h2><p>处理无限提示的能力在医疗保健中可能带来一些独特的优势：</p>
<ul>
<li> 背景历史</li>
<li>纵向患者监测</li>
<li> 医学推理</li>
<li>个性化健康指导</li>
<li> 改进的研究</li>
</ul>
<h3 id="背景历史"><a href="#背景历史" class="headerlink" title="背景历史"></a>背景历史</h3><p>一个具有无限上下文的LLM（换句话说，一个无限的上下文历史窗口）应该能够处理患者的整个病史（以前的诊断、治疗、药物、检测结果等）。从字面上看，无限上下文可能会以更准确的诊断、更个性化的治疗以及更好地识别罕见和&#x2F;或复杂疾病的形式体现出来，而这些在有限的上下文中是很难发现的。</p>
<p>理论上，如果有一个无限的上下文历史窗口，LLM可以处理患者的整个病史——过去的诊断、治疗、药物、检测结果等等。这种无限的视角可以表现为更准确的诊断、更精细的治疗建议，以及识别在有限上下文中可能被忽视的罕见或复杂疾病。</p>
<h3 id="纵向患者监测"><a href="#纵向患者监测" class="headerlink" title="纵向患者监测"></a>纵向患者监测</h3><p>对患者健康数据进行数月或数年的持续监测，并学习检测数据中微妙的变化或趋势，这些变化或趋势表明疾病的发生或进展，LLM可以检测到疾病的早期迹象，并提醒医生或患者采取预防措施。</p>
<h3 id="医学推理"><a href="#医学推理" class="headerlink" title="医学推理"></a>医学推理</h3><p>一位医生，如果拥有无限的提示，可能能够同时考虑大量的医学文献（特定疾病的指南和案例），从而帮助她在某些常见情况下更细致地推理，以做出更好的医疗决策（例如，多重合并症病例、罕见病例等）。</p>
<p>一个LLM可以使用无限的提示，同时考虑大量医学文献，例如关于特定疾病的指南和案例研究，以帮助其分析患者的病例，从而实现更复杂的医学推理和决策，特别是在涉及多种合并症或罕见病例的情况下。</p>
<h3 id="个性化健康指导"><a href="#个性化健康指导" class="headerlink" title="个性化健康指导"></a>个性化健康指导</h3><p>一个具有无限上下文窗口的LLM可以提供高度个性化的健康指导和咨询，能够敏感地考虑患者的健康历史、生活方式和治疗偏好（以及其他因素）。应用更有效的行为改变干预措施最终可能导致“更健康的患者”，他们更愿意并可靠地遵循治疗计划。</p>
<h3 id="改进的研究"><a href="#改进的研究" class="headerlink" title="改进的研究"></a>改进的研究</h3><p>除了通过启用新的科学研究来扩展人类知识外，无限的提示可以增强LLMs识别大数据、纵向健康研究中隐藏的紧急变量模式的能力，这些模式目前在临床医生有限的背景下治疗的患者中太微弱而无法感知。药物发现和医学研究可以以这种方式加速。</p>
<p>但其推动能力中的同样无限性可能也会放大与其在医疗保健中使用相关的许多问题。</p>
<p>一旦患者记录涉及进来，数据隐私和安全要求就会大大增加。</p>
<ul>
<li>如果LLM在一个过于庞大（在规模和&#x2F;或多样性方面）的数据集上训练，且该数据集偏向于其中的特定（委婉地说是“少数”）部分，则会出现偏见&#x2F;不公平风险。</li>
<li>持有患者完整医疗电子记录的LLM将使伦理和法律考虑变得更加复杂。</li>
<li>基础设施和计算资源（无限制地扩展提示）使得LLM变得低效或成本过高。</li>
</ul>
<p>尽管这里提出的许多医疗保健应用可能可以用更短的提示来实现，但在另一个极端，无限提示（或者至少是一个具有巨大上下文窗口的提示，远远超出任何临床需求）可能会实现更准确的整体患者分析、更精确的干预，最终更深入地探索新疗法和因果路径。然而，克服这些挑战是必要的，以安全、伦理和公平的方式实现这些好处。</p>
<h2 id="代理推理"><a href="#代理推理" class="headerlink" title="代理推理"></a>代理推理</h2><p>在以健康为中心的背景下，代理推理和利用代理与LLMs相结合可以开启一系列机会。在这个背景下，代理是专门的软件代理，它们可以独立执行任务、做出决策或根据预定义的目标或约束从患者那里获取见解。以下是代理推理和代理与LLMs相结合的潜在应用和可能的优势。</p>
<h3 id="领域专业化"><a href="#领域专业化" class="headerlink" title="领域专业化"></a>领域专业化</h3><p>代理可以针对特定的医疗领域（例如，心脏病学、肿瘤学）进行专业化，并在相关知识和最佳实践上进行培训，具备提供更有针对性和准确的帮助的能力。</p>
<p>领域专业化作为医疗保健中算法代理的一种策略具有巨大的潜力。使用面向特定医学领域的代理，例如心脏病学、肿瘤学或神经学，可以创建具有专业知识的人工智能系统，这些知识包括内部实践、特定领域的医学术语、术语和习惯用语，以及对每个专业的常见问题、最佳实践和可用治疗方案的深入理解。领域专业化可以提供几个潜在的好处。</p>
<p>代理可以在特定领域的数据集、临床指南以及其他仅与该领域相关的专家知识文献上进行训练，这一事实使其有潜力为该领域的重要利益相关者提供更准确和相关的信息、建议和决策支持，即医疗专业人员和患者。</p>
<h3 id="以患者为中心的互动"><a href="#以患者为中心的互动" class="headerlink" title="以患者为中心的互动"></a>以患者为中心的互动</h3><p>代理可以以更以患者为中心和富有同情心的方式与患者互动，调整他们的行为以满足个别患者的需求、喜好和情感状态。LLMs的自然语言理解能力可以与代理的目标导向行为协同工作，使以患者为中心的互动更加有效。</p>
<h3 id="预测性健康监测"><a href="#预测性健康监测" class="headerlink" title="预测性健康监测"></a>预测性健康监测</h3><p>代理可以被指示跟踪和分析患者数据，例如生命体征、药物使用和症状。他们可以结合这些和其他生物医学数据利用LLM推理来预测不良健康状况，将发现传达给主治医生，并提出主动干预建议。</p>
<p>然而，在医疗保健领域开发特定领域代理也面临挑战和考虑因素：</p>
<ul>
<li>专业化的挑战在于实现处理领域内案例变异所需的广度。然而，一个代理的知识库可能难以覆盖助手需要处理的所有案例。</li>
<li>医学知识随着新研究结果、新指南和新治疗建议的出现而不断更新。任何在现代医疗环境中学习扮演医生角色的回答，都必须不断更新临床相关信息（即领域特定文献），以保持准确性和相关性。</li>
<li>在特定临床领域中，可能会出现边缘案例，这些案例由于其稀有性或复杂性，需要额外的专业知识或判断。代理可能被设计为自我检测这些案例，并将其上报给人类领域专家，以确保患者安全并优化护理。</li>
<li>尽管专业代理可以将黑箱方法转变为精细、专注的专业工具，但医疗保健需要跨领域的合作。如果他们能够以建设性的方式与人们以及其他领域的代理进行交流和分享信息，这将是重要的。</li>
<li>在医疗保健中使用专业代理需要解决监管问题和 FDA 批准流程，以及使用人工智能进行医疗决策的责任问题。</li>
</ul>
<p>总的来说，医疗保健领域的特定代理可以为医疗专业人员和患者提供更有用、相关和有效的决策支持。如果代理能够专注于更小、更紧密的领域，具备专业的、针对性的知识和专长，那么他们将能够帮助进行决策支持、沟通以及与特定领域工具和协议的互动。为了使这一切有效，全面覆盖相关文献、当前知识、对边缘案例的态度、互动，以及监管和责任问题将是重要的。</p>
<h1 id="AGI"><a href="#AGI" class="headerlink" title="AGI"></a>AGI</h1><p>伊利亚·苏茨克维尔，一位计算机科学家和 OpenAI 的联合创始人，表示：“我们所称的 AGI 正是计算机至少与人类一样聪明，甚至更聪明的时刻。”或者更正式地，在一个 OpenAI 开发者论坛中，我们找到了这个定义：“AGI 是一个可以承担任何任务的系统，无论其智力复杂性如何，这些任务都是人类可以承担的。”</p>
<p>AGI 仍然只是一个概念，因为我们仍然没有创造出在各个领域接近人类水平表现的 AI。相反，它代表了在 AI 领域某些尚未实现的假设性未来成就的实现。一些人认为这将在 2022 年发生；埃隆·马斯克声称是 2026 年；其他人则建议这个日期在 2060 年之前的某个时刻；还有一些人坚持认为这永远不会发生。山姆·奥特曼说，也许在五年内。他进一步将 AGI 描述为“当 AI 能够独立实现新的科学突破时。”现在，这对 AI 来说是一个艰巨的任务，创造出像爱因斯坦的 E &#x3D; mc² 这样的新的科学突破。</p>
<p>一种假设是，人类智能，包括认知、创造力、直觉、感知和思维，可以简化为计算。假设是，我们可以创建计算机系统，使其在各种任务上超越人类水平的智能，只要具备足够的计算能力、数据和架构复杂性。主要假设是，智能可以被分解为算法，并在计算机系统中实现。</p>
<p>这些假设是哲学、认知科学和人工智能研究中持续辩论的主题。一些人认为意识和主观体验可能无法简化为计算。关于身体在智能中的作用，以及无身体的人工智能是否能够真正复制类人智能的问题也在辩论中。关于生物系统的涌现特性是否在智能中发挥着关键作用，这些特性可能无法在人工系统中复制，仍在进行讨论，我们需要对此有全面的理解。</p>
<p>然而，这种计算描述能够容纳多少人类经验的真正丰富性和深度仍然是一个悬而未决的问题。在实现任何类似于 AGI 的目标方面，还有很长的路要走，但由于心智，无论它们是什么，不能是神奇的，而必然是算法的，这一前提使得这一过程显得戏剧性地更短且更可控。这是一个引人深思且有争议的假设。</p>
<p>由于没有明确的议程，没有可辨别的朝向 AGI 的进展标志，因此也没有积极或可靠的手段来了解 AGI 技术是否在任何有意义的意义上发展，甚至发现这一点的可能性也是未知的。没有人能够确切知道技术何时可能实现人类水平或超人类智能，或者它是否能够成为机器超级智能的载体。这种情况可能会持续，因为我们不断在科学理论和推测意见之间移动，因此 AGI 的状态永远无法完全解决，甚至在任何明确的意义上“已知”。</p>
<p>抛开这些不谈，如果我们真的开发出通用人工智能，医疗保健的世界会是什么样子？我想说明，医疗保健周围存在许多复杂的社会问题，也许其中一些是无法克服的。但假设通用人工智能很快就会实现，机器能够在任何领域进行推理、学习和迭代适应，以达到个体人类能够实现的结果。在一个大假设的前提下，以下是拥有通用人工智能的世界中医疗保健可能的样子。</p>
<ul>
<li>个性化和预测医学：如果能够获取关于过去患者的大量健康和基因组数据，以及对当前患者持续收集的实时健康指标，AGI 系统可能有能力为个人制定精细化的治疗方案，甚至在潜在健康问题出现之前就能识别出来，从而实现更有效的预防。</li>
<li>认知诊断辅助工具：AGI 可能通过处理和整合来自医学影像、实验室结果以及患者自我报告症状的数据，帮助医生快速准确地做出诊断。这种工具可以减少诊断错误，诊断罕见疾病，并加快诊断过程。</li>
<li>机器人手术：“烹饪书”式的现代手术将让位于具有前所未有的精确性、灵活性和适应性的自主机器人辅助手术（这需要外科医生培训中的新能力）。这些手术可以在自主模式下进行，也可以与人类外科医生协作进行。</li>
<li>持续健康监测与干预：基于 AGI 的系统可以为患者提供持续的健康监测，使用可穿戴设备和&#x2F;或通过智能手机和智能家居的植入传感器。通过这种持续监测，AGI 可以提供早期警报并启动自动干预（例如，根据持续反应调整药物剂量，或在需要时发出警报）。</li>
<li>改善药物发现与开发：AGI 还可以通过加速药物发现和开发流程来提高制药行业的生产力。通过利用大量的生物和化学数据，AGI 可以帮助发现新的药物靶点，预测新药与生物系统中成分之间的相互作用，并探索新的药物设计方法以提高特异性。这些系统可以加快更安全、更有效的新药的开发。</li>
<li>改善远程医疗和虚拟护理：对于患者来说，基于 AGI 的虚拟助手和远程医疗平台可以实现 24&#x2F;7 有效、个性化的按需医疗服务访问。这些系统可以对患者的关注进行分诊，提供医疗建议，并将患者推荐给适当的医疗资源，从而增加医疗服务的可及性，并减轻医疗设施的后续压力。</li>
<li>精明的资源分配和物流：AGI 可能会根据患者需求和当前需求智能分配医疗资源（医院床位、呼吸机、人员等），并提高医疗供应链的效率，确保药物、疫苗和其他必需品的快速分发。</li>
<li>基于模拟的培训和教育：由 AGI 驱动的医学模拟将允许在广泛的外科场景中开发高度真实和自适应的培训环境，以模拟故障和风险条件，从而补充和增强课堂中的体验学习过程。</li>
<li>全球健康合作与信息共享：AGI 提供的信息可以实现来自世界不同地区的临床医生和研究人员之间的无缝协作和信息共享，使他们能够共同识别全球健康趋势并为公共卫生政策提供信息，同时传播最佳实践。</li>
<li>伦理和可获得的医疗保健：AGI 可以通过帮助识别和纠正治疗决策和分配决策中的偏见，以及开发具有文化敏感性和可及性的医疗干预措施，确保医疗保健更加公平——所有这些都是实时进行的。</li>
</ul>
<p>这意味着 AGI 将不断学习。医疗系统将变得越来越好，因为每个案例都可以为未来的治疗和协议提供信息。该系统可以根据生物过程和人类疾病的最新医学研究和患者数据自动更新其信息库，并实时自我进化。治疗将根据最新的证据和患者结果进行常规调整。AGI 将优化医疗系统，提高效率，降低成本，增强患者体验。</p>
<p>虽然利用 AGI 改善医疗保健和社会整体福祉的前景是真实的，但这些人工智能实体的存在将引入一系列新的紧迫的伦理、法律和社会问题，安全处理和管理这些先进技术在医疗保健和决策中的应用将至关重要。</p>
<p>同样，医疗保健领域蓬勃发展的自主系统需要提前做好准备，以便研究人员、临床医生、政策制定者和公众之间进行密集的多学科合作，以确保基于 AGI 的技术得到适当开发，以符合社会需求和价值观。</p>
<p>综合来看，增强型人工智能（AGI）的医疗行业将实现真正实时、整体、个性化和预测性护理环境的承诺，利用大量健康信息，将其转化为真正可获取、有用的数据，以便于医疗服务的提供。这样的医疗系统将更加高效、个性化，因此更有可能提供最佳的医疗结果。</p>
<p>在这个系统中，医疗服务提供者的角色可能会非常不同，因为更多的常规和琐碎任务被自动化，而提供者则专注于更复杂的数据的诊断、解释和整合以及卓越的人类护理。个人健康结果可能会得到改善，公共健康结果和医学研究将更快速地推进并带来进一步的突破，我们可以期待在许多方面成为一个更健康的社会。</p>
<h1 id="明日的五个预测"><a href="#明日的五个预测" class="headerlink" title="明日的五个预测"></a>明日的五个预测</h1><p>接下来是五个未来的预测，这些预测将在未来五年内实现，尽管没有 AGI，但使用LLMs、无限提示、代理推理、空间推理和 AI 具身化。</p>
<h2 id="人工智能主导一切"><a href="#人工智能主导一切" class="headerlink" title="人工智能主导一切"></a>人工智能主导一切</h2><p>例如，一位人工智能首席医疗官可能需要一种新的医疗设备，因此她给她的人工智能下达了一项任务</p>
<ul>
<li>人工智能将研究市场，以识别未满足的需求和机会。</li>
<li>医疗设备将由人工智能发明，以满足这些需求和机会。</li>
<li>AI 将联系制造商以获取医疗设备生产报价。</li>
<li>AI 将与制造商协商价格和条款。</li>
<li>AI 将向制造商下订单并跟踪生产过程。</li>
<li>AI 将安排将医疗设备送达客户。</li>
<li>AI 将从客户那里收取收入。</li>
</ul>
<p>因此，人工智能仍然会有许多无法完成的任务，因为人类仍然在某个环节中存在。然而，通用人工智能可以通过与其他人工智能对话来进行交互，并调用 API 以获取许多不同知识来源（例如，数据库或各种网站等）的访问权限，以完成许多不同的任务。</p>
<p>在从可用知识源获取额外信息时，许多功能可以在定向 API 中实现自动化，例如推动许多功能，以便将新的医疗设备通过临床试验获得监管批准。AGI 将使许多人能够腾出时间去思考更复杂的任务。</p>
<p>如果一个 AGI 设计并生成了一种新的医疗设备，那么我们应该接受它在制造过程中也有参与，就像我们接受关于人类智能代理的同样说法一样。这包括：</p>
<ul>
<li>创新：该人工智能系统是在人的协助下构思并设计的，独立于现有模板，展示了创造性思维的能力，并能够为健康需求提出新颖的解决方案。</li>
<li>广泛：AI 驱动的创新可以探索比人类团队更多的设计空间。</li>
<li>增强：增强现有系统和程序能力的医疗设备创新。</li>
<li>科学严谨：该人工智能可能依赖大量数据、建模、模拟和测试来证明该设备是安全有效的。</li>
<li>变革性：AGI 可以通过医疗技术极大地加速健康创新和发现的突破。</li>
<li>范式转变：AGI 的新医疗设备的发明改变了谁&#x2F;什么可以成为科学参与者的格局。</li>
</ul>
<p>一个自主执行此任务的人类可能是一个强大、创新、颠覆性且潜在变革性的展示，体现了人类的能力——无论是单独还是与他人合作——以及关于通过这种方式从人类获取信息的代理在科学和技术中变化（或缺乏变化）行为的伦理考量。规则必须经过仔细考虑和辩论，以规范任何自主人工智能是否以及如何创造发明。但假设这些创造是由人类价值观引导的，可能性是引人入胜的。</p>
<h2 id="个性化医疗球"><a href="#个性化医疗球" class="headerlink" title="个性化医疗球"></a>个性化医疗球</h2><p>这个银色的球很容易放进你的手掌中。有了这个人工智能助手作为你的伴侣，你可以与基于最新LLM架构的人类智能的人工智能对话。它理解自然语言，综合对查询的见解，并回答关于万事万物的问题。</p>
<p>问它关于科学、哲学或如何制作海鲜汤，它将洞察你最佳的行动方案，并以专业术语与之沟通。它会教你物理学、艾萨克·牛顿和阿尔伯特·爱因斯坦，或者关于杰里米·边沁的道德哲学。它会指导你准备海鲜汤的步骤。凭借其广泛的知识和推理能力，人工智能可以为你的个人情况提供有见地的分析。你将其视为一位充满知识和洞察力的智者，始终触手可及。</p>
<p>精确调校以与智能家电集成，如果您的冰箱空空如也，Orb 可以生成食谱创意，安排杂货配送，并开启烤箱进行烹饪。考虑到其在各种沟通模式下的全面能力和几乎无限的容量，医疗球个性化 Orb 提出了一个复杂的命题：世界上所有的知识和能力都可以在您手掌中获得。</p>
<p>一种嵌入式设备——一种互动球形设备——被患者用作在家中、医院或护理机构的健康管理助手。它能够理解普通文本对话的上下文，提供语言翻译，并支持问答。</p>
<p>它结合了先进或大型语言模型，利用自然语言处理技术，使得在讨论症状或询问医疗问题时能够进行自然语言的对话互动。医疗球还可以提供个性化的健康跟踪、药物管理、生活方式指导等服务。</p>
<p>医疗球内的人工智能将可以无限制地访问当前的医学研究，并为患者提供个性化的健康优化建议。它可以，例如，推荐饮食和锻炼习惯，以及为患者提供心理健康训练。</p>
<p>这个球体随时监测生命体征，无论是常规检查还是医疗紧急情况，并且可以召唤帮助并提供急救指导，直到帮助到达。它进行分诊检查、提供咨询或提供紧急治疗的能力是其成为保护性医疗存在的三个主要角色，利用人工智能提供全天候的护理服务。凭借足够的医学知识，这个个性化的医疗球体甚至可能让你保持冷静。</p>
<h2 id="健康化身：个人-AI-健康助手"><a href="#健康化身：个人-AI-健康助手" class="headerlink" title="健康化身：个人 AI 健康助手"></a>健康化身：个人 AI 健康助手</h2><p>健康化身创建了您的“数字双胞胎”，这是您的一种数字复制品，利用生成性人工智能根据您的医疗记录、生活方式数据、基因构成和实验室测试构建，以提供您身体的高分辨率可视化，包括其独特特征。</p>
<p>该应用程序允许您与您的数字双胞胎通过LLMs提供的对话界面进行对话。询问您数字双胞胎所强调的任何健康状况的风险，数字双胞胎可以通过使用其先进的身体模型运行场景来生成量身定制的风险评估。</p>
<p>您的行为和症状通过可穿戴设备和日志实时跟踪。健康化身定期更新您的数字双胞胎，提醒您需要与医生跟进的信息。AI 助手回答有关健康问题的提问，解释实验室报告，帮助您为医疗预约做好准备，并提供多项基于证据的生活方式建议。</p>
<p>高级模拟工具让您可以在“真实”世界中实施饮食、锻炼和其他干预措施之前，先尝试它们的影响。同时，HealthPal 使您能够通过监测其在您虚拟形象的数字皮肤上的效果，看到您努力的成功。HealthPal 将一个智能辅助代理和您自己身体的克隆放在您的口袋里，配备了对您个人健康记录的深入扫描和机器学习视图的好处。</p>
<h2 id="虚拟护士头像"><a href="#虚拟护士头像" class="headerlink" title="虚拟护士头像"></a>虚拟护士头像</h2><p>这个头像是一个三维动画视觉模型，代表了一位富有同情心的人类护士，采用先进的生成艺术技术制作，使其既吸引人又值得信赖。患者通过对话和手势与头像互动。该头像运用多模态人工智能以人类的方式进行对话，解读患者所传达的非语言线索，并表现出同理心。</p>
<p>AI 护士由LLM驱动，可以回答患者问题，解释治疗计划，提供教育和鼓励。它可以通过与LLM的多种集成查询最新的医学知识。它可以跟踪生命体征、用药依从性和临床进展，监测副作用，并在出现变化或问题时向人类护理团队发送警报。它可以处理这些查询和观察。</p>
<p>个性化算法维护患者的健康历史、偏好和心理模型，以便个性化互动并保持护理的连续性。对于一些需要康复和协调的患者，虚拟护士可以教授锻炼、提醒用药和即将到来的预约。在紧急情况下，人工智能可以与患者保持通话，提供指示以应对紧急情况，同时拨打 911 并与患者一起等待紧急救助。</p>
<p>虚拟护士在患者住院期间陪伴他们，与他们聊天、开玩笑，保持他们的大脑活跃，引导他们的对话朝向健康的应对方式，并提供互动。对患者数据的访问范围广泛，但每一条信息都是安全的，仅在患者同意和护理团队的情况下共享（活动日志可以访问，并且在新技术发展过程中对监督和完善模型非常有用）。</p>
<p>总之，虚拟人工智能护士将护理中以响应为中心的人性化特质与人工智能的知识和反应能力相结合。其结果是一个人文主义的人工智能护士，全天候为患者提供情感、教育和安全监测支持。</p>
<h2 id="人工智能驱动应用的崛起"><a href="#人工智能驱动应用的崛起" class="headerlink" title="人工智能驱动应用的崛起"></a>人工智能驱动应用的崛起</h2><p>到 2030 年代或更早，强大的LLMs和生成性人工智能的普及将软件开发的变革程度与之前的客户端-服务器、互联网、云计算和移动技术相提并论。诚然，直接使用 Python 和 Java 进行的应用开发仍然涉及用 Python 和 Java 编程。然而，对于绝大多数代码，开发者以轻声的方式与 AI 助手进行自然语言对话。他们用简单的英语描述他们希望应用程序执行的功能，包括数据模型和用户界面的描述。对于每一次这样的对话，一个复杂的 AI 生成器会综合出一个完整的全栈实现，包括源代码、数据库、API、网页&#x2F;移动前端和 DevOps 配置。</p>
<p>开发者的生产力得到了极大提升。开发者不再需要编写数千行代码来从零开始构建强大的应用程序，而是可以利用他们的人类创造力和领域知识，跟上人工智能的创新步伐。他们可以使用过去的应用程序训练人工智能模型，以教会系统什么有效，什么无效。由于人工智能可以快速轻松地创建完整的前端和后端，开发者可以专注于构建丰富而创新的用户体验。曾经需要数月才能构建的新应用原型现在只需几天就能完成。初创公司以空前的速度迭代最小可行产品，颠覆了各个行业。</p>
<p>对话界面是为了取代基于菜单的应用程序而创建的；LLM 前端与应用程序进行交互，并以自然对话的方式充当用户的客户端；LLM 理解请求并管理其执行。创建了模块化代码，生成器是创建模块的实体：它们可以创建数据库、前端 API、用户界面和其他模块，包括云结构。这一切都是通过 LLM 进行协调的。</p>
<p>嵌入式代理成为常态，应用程序具有生成性人工智能子组件，根据需要调整其编程，像强大的神经网络一样自主自我优化。</p>
<p>自动化测试和调试是由于LLMs检测代码模式以生成单元测试而产生的。错误和弱点同样被自动检测并由生成模型修复。测试和维护活动也被自动化，因为人工智能持续监控和增强生成的应用程序，使得人工智能在生成代码中发现潜在错误或反模式时提醒开发者，并在必要时以对话的形式指向已经验证的解决方案。最终，应用程序变得更加安全、可扩展和高效。</p>
<p>专业开发人员仍需接受监督，并必须满足某些要求，但软件开发的大部分劳动将由生成性人工智能接管，从而使开发人员能够投入更多时间进行更高层次的设计和创造性问题解决。民主化意味着新应用和体验的激增。这是未来的一种可能情景，类似于早期计算革命所带来的生产力激增。LLMs和生成性人工智能可以为软件开发带来类似的飞跃。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>人工智能并不是一种自主技术——它并不是自动从算法或LLMs中产生的。人类的能力并不会自动植入算法中；它们需要人类的设计和意图。如果通用人工智能进入世界，那将是通过人类的设计和工程实现的。</p>
<p>AGI 是一种机器未来可能具备的能力。它仍然难以捉摸；我们尚未实现 AGI；它是否或何时可能实现仍然是相当有争议的话题。简而言之，如果它最终实现，AGI 将是人类设计和工程的产物，而不是目前被认为是人工智能研究前沿的算法或模型“自主”产生的过程。</p>
<p>人工智能系统将继续发展出更像人类的能力。这意味着保持人类的控制和监督，以及随时干预和&#x2F;或关闭系统的能力将变得重要。负责任的人工智能的发展必须保持这种状态。</p>
<p>LLMs 和生成性人工智能可以以新颖而强大的方式改善患者护理和医学实践。事实上，利用 LLMs 能力的工具将很快成为友好的顾问，能够从详细的临床对话中理解患者状况的细节，回答问题，并提供针对个别患者的支持性咨询。</p>
<p>生成性人工智能系统将成为医生的“路边医生”，迅速从数百万个案例中综合出有价值的推论，形成细致的诊断和治疗方案，能够根据每位患者的特征量身定制，从而提供更好的护理选择和结果。最终，人类医生和人工智能的综合团队将成为一个日益人性化、真实和个性化的生态系统的一部分：它们将相互增强各自的优势，为患者提供越来越多的信息和自主权，使他们能够更好地从治疗护理中受益，并参与自我管理健康和生活方式，以实现更好的健康、功能和长寿。</p>
<p>在未来几年中，医学知识、人工智能和富有同情心的人类支持的结合将逐渐减轻临床医生的负担，同时改变患者互动并提高治疗效果。这是一个为所有人提供越来越具前瞻性、预测性和预防性的护理的新纪元。</p>
<p>最后，我们以幽默的方式结束（见图 7-1）。</p>
<p><img src="/../asset_llmsClinical07/01.png">图 7-1. 宠物老鼠，阴阳和好奇</p>
<p>老鼠的名字展示了LLMs、阴阳和好奇的可能性。公众与LLM聊天机器人的互动激发了对人工智能及其潜力的巨大好奇。在传统中医中，阴阳能量是所有疗愈的核心。LLMs在医疗保健中被使用，希望创造健康的良好平衡，阴与阳。</p>
<p>凭借其自然语言处理和机器学习能力，LLMs可以快速扫描数千篇医学论文、临床指南和病历，帮助医生和研究人员跟上最新发现，发现可能被人眼忽视的重要模式和见解，并做出公正和基于证据的决策。</p>
<p>我们希望这本书不仅能让您对LLM和生成式人工智能的潜力有更深刻的理解，以及LLM和生成式人工智能工具在转变医疗、治疗和护理方面所发挥的变革性作用，还能让您意识到建立扎实的知识基础和在关于与LLMs合作的好处或其他方面的主张中追求准确性的重要性。</p>
<p>这是一个快速发展的领域，了解新进展的能力在充分利用医学中的人工智能方面将变得重要。随着人工智能在医疗保健中扮演越来越重要的角色，倡导其伦理发展和使用，以及提高对偏见、隐私和透明度的认识是非常重要的。</p>
<p>人工智能有潜力成为医疗保健领域的伟大统一者，但前提是我们能够利用这些机会帮助不同学科协同工作。支持临床医生、研究人员、工程师、伦理学家以及其他任何人的工作，以便我们创造一个利用人工智能带来双重好处的未来。</p>
<p>最后，留给读者的结论是让人工智能成为一种放大器，成为创造一个更健康世界的一部分。未来的医疗保健不是由人工智能书写的，而是由今天参与这一过程的每一个人共同书写的。让我们共同设计一个更加人性化和开放的人工智能未来，一个充满希望和治愈的未来。</p>
<p>1 “通往 AGI 的激动人心而危险的旅程 | 伊利亚·苏茨克维尔 | TED，” TED，2023 年 11 月 20 日，YouTube 视频，12:24，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=SEkGLj0bwAU%E3%80%82">https://www.youtube.com/watch?v=SEkGLj0bwAU。</a></p>
<p>2 Natanael WF，“AGI 是我们想要的，但不是我们在奇点时所需要的，”OpenAI，2023 年 12 月，<a target="_blank" rel="noopener" href="https://community.openai.com/t/agi-is-what-we-want-but-not-what-we-need-for-singularity/571275%E3%80%82">https://community.openai.com/t/agi-is-what-we-want-but-not-what-we-need-for-singularity/571275。</a></p>
<p>3 Cem Dilmegani, “奇点何时会发生？1700 位专家对 AGI 的看法 [2024]，”AIMultiple，2024 年 6 月 15 日，<a target="_blank" rel="noopener" href="https://research.aimultiple.com/artificial-general-intelligence-singularity-timing%E3%80%82">https://research.aimultiple.com/artificial-general-intelligence-singularity-timing。</a></p>
<p>4 迈克·卡普特，“山姆·阿尔特曼表示，人工智能将处理‘95%’的由机构和创意人员完成的营销工作，”营销人工智能研究所，2024 年 3 月 5 日，<a target="_blank" rel="noopener" href="https://www.marketingaiinstitute.com/blog/sam-altman-ai-agi-marketing%E3%80%82">https://www.marketingaiinstitute.com/blog/sam-altman-ai-agi-marketing。</a></p>
<p>5 见 Kaput，“萨姆·阿尔特曼表示，人工智能将处理‘95%’由机构和创意人员完成的营销工作。”</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/13/llmsClinical06/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/13/llmsClinical06/" class="post-title-link" itemprop="url">第六章 掌舵LLMs的伦理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-13 16:31:19" itemprop="dateCreated datePublished" datetime="2024-08-13T16:31:19+08:00">2024-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:07:21" itemprop="dateModified" datetime="2024-08-21T14:07:21+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>22k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>39 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最终，在医疗保健中使用技术的目标始终是通过不断发展其基础功能来改善患者、临床医生和所有医疗从业者的结果和体验。大型语言模型（LLMs）可以彻底改变设计和提供医疗解决方案的方式。它们的影响可能会通过改善对医学知识和案例数据的获取，以及在患者和提供者之间进行调解而变得显著。</p>
<p>这首先集中于在医疗保健背景下的人工智能模型开发。人工智能可以有意识地策划与医学相关的多样化训练数据集，引入可解释性特征，使人工智能能够“打开引擎盖”，解释其如何得出决策，并提出算法审计和监督协议，以确保对所有患者群体的公平对待。健康价值、质量和公平获得护理——而不是最大利润或最大投资回报——应该是目标。有许多文章、论文和案例研究显示人工智能在医疗保健中的积极影响。</p>
<p>最终，医疗保健中对训练模型的监督也需要遵循这些原则。这可能涉及对模型能够做什么和不能做什么的伦理披露建模，立法严格遵守患者保密和医学伦理，维护有效的算法伤害救济途径，以及倡导举报以促进组织问责和尊重患者的福利。在这一基础设施中，LLMs可以成为促进多元化和集体医学知识的公共卫生工具。</p>
<p>本章将探讨在医疗保健中LLMs的伦理挑战和负责任的发展，特别是它们提高患者结果和体验的潜力以及可能的陷阱。在本节中，我们将为医疗保健发展一些积极的人工智能想象，讨论人工智能的潜在用途和结果，特别是LLMs在医疗保健领域的应用。在下一节中，我们将讨论在医疗保健中使用LLMs所涉及的伦理挑战。本章将解决如何监测、检测和防止在各种医疗保健环境中使用的LLMs的异常行为的问题。最后，在我们的最后一节中，我们将讨论与医疗保健情境中使用的LLMs相关的安全和隐私问题。特别是，我们将讨论联邦学习，其理念是在分布式数据上训练LLMs以保护患者隐私，以及差分隐私，这是确保数据集中个人隐私的数学框架。</p>
<h1 id="人工智能作为一种积极力量：改善医疗保健"><a href="#人工智能作为一种积极力量：改善医疗保健" class="headerlink" title="人工智能作为一种积极力量：改善医疗保健"></a>人工智能作为一种积极力量：改善医疗保健</h1><p>科幻小说常常描绘人工智能带来的风险：流行文化讲述关于失控的糟糕技术的反乌托邦故事。你可能会想到机器人起义、人工通用智能（AGI）摧毁人类或人工智能奇点。共同的主题是，随着人工智能的智能越来越接近我们，与人类的认知竞争意味着与人类竞争——这是一场灾难的配方。自玛丽·雪莱的弗兰肯斯坦（1818）以来，流行文化中对人工智能的描绘一直是机器人末日，机器将摧毁我们的工作、自主权和我们的生命。新的宗教现在放大了这些神话：我们听说人工智能将变得有意识并摧毁我们。</p>
<p>尽管这些恐惧、焦虑或风险需要关注，但过度关注负面愿景限制了我们积极塑造人工智能发展的能力，以改善社会。现在是阐明和培养积极人工智能愿景的时候——这些故事情节包括可以立即采取的具体步骤，以利用人工智能的潜力促进重要的人类伦理和变革。人工智能发展的另一种人文愿景与人类价值观（如正义和公平）以及所有人类能力的全面发展相一致。这条道路可以作为开发者、政策制定者和社区的出发点，也可以作为想象一个转变后的智能对人类福祉产生变革性影响的未来的愿景。先进的智能可以极大地赋权，但前提是它必须在服务于人类尊严的方向上前进。</p>
<p>通过关注人工智能最积极的应用，我们可以将其发展引导远离可怕的假设，塑造其增强人类能力以解决医疗保健最大挑战的方向。一个例子是能够使医疗保健和医学研究民主化的人工智能系统，或者提升所有学习者的教育机会，实现个性化学习体验。人工智能还可能加速科学发现的进展，以应对气候变化和其他社会问题。该技术可以被用来促进公平（揭示、减少或消除偏见）、开放和民主的知识生产、决策和文化及经济机会的获取系统。</p>
<p>意识到这将需要引导人工智能系统朝着可解释、可理解（对人类而言）和负责任的方向发展——也就是说，伦理的——现在就要开始。这种设计需要研究人员、伦理学家、政策制定者和公众共同努力，制定强有力的伦理框架、健全的监管监督和公众参与倡议。通过现在对人工智能的预见和塑造，我们可以将人类引向一个未来，在这个未来中，强大的人工智能帮助我们创造一个富有成效、协作和繁荣的世界，而不是它的终结。</p>
<p>通过采用这些积极的人工智能想象，我们颠覆了人工智能崛起的故事，强调它在多大程度上可以改善人类的状况。如果我们能够设想并开始实现一个最大化其对社会公益效用的人工智能辅助未来的可能性，我们就可以以一种引导我们走向一个更好、更公平和更充实的世界的方式，集中其演变。</p>
<p>积极人工智能的关键价值在于增强人类的优势，而不是全面替代。例如，&#x3D;&#x3D;医疗或临床人工智能的设计旨在加强临床洞察力，增加时间以建立更具关怀的以患者为中心的关系，而不是单纯追求降低医疗劳动力成本&#x3D;&#x3D;（无论其带来的心理代价如何）。</p>
<p>以正义为导向的设计还确保算法不会延续过去的结构性偏见，这些偏见忽视或错误表述社会中已经深度边缘化的群体。将会有机制允许公众参与模型开发，如果算法似乎对公民不公平，将提供举报人保护，最重要的是，建立某种救济机制，以防止算法对某些群体的待遇低于其他群体。</p>
<p>最终目标是人类的繁荣，通过公平的技术进步和公正的政治经济权力体系来实现，而不是某种模糊、抽象、非人性化的技术官僚驱动，以“优化”和“最大化利润”为代价，忽视现实生活。这种对复杂未来的广泛伦理框架可以释放愿景，更好地将人工智能表述为一种深刻的社会利益形式。</p>
<p>人工智能可能削弱医生的工作或加剧医疗保健中现有的不平等，这种担忧由来已久。然而，专注于这些负面叙事可能会减缓我们更有效地设想人工智能与健康的过程，同时也使我们对更可及、公平和个性化的医疗保健系统的可能性保持无知。这种潜力和应用案例在前面的章节中已有介绍。通过将积极的人工智能描述为一种向善的力量，我们可以引导这项技术更好地支持我们所需和应得的医疗保健。</p>
<p>与其害怕人工智能或我们当前的现状，我们如何能够设计和部署它，以与患者赋权、可及性、公平、隐私和透明度等伦理相协调？在 第 3 章、第 4 章 和 第 5 章 中，我们详细介绍了许多 LLM 的用例，以提供能力提升和患者赋权。</p>
<ul>
<li>能力提升：人类能力可以在前面章节中提到的许多医疗保健角色中得到增强。这些角色包括医生和专家、护士和护理协调员、心理健康专业人员、放射科医生、研究人员和公共卫生教育工作者。</li>
<li>患者赋权：LLMs 具备对话能力，可以帮助患者管理健康、提供个性化教育，并改善与医疗专业人员的沟通。人工智能可以帮助患者积极参与他们医疗保健的各个方面。</li>
</ul>
<p>这些只是人工智能未来可能积极的一些例子，只有采取积极合作的方式来塑造我们想要的未来，我们才能实现这些可能性</p>
<ul>
<li>我们必须强调多学科合作，确保人工智能的发展吸引一系列专家，包括工程师、伦理学家、政策制定者和社会科学家。</li>
<li>我们还必须增加公众参与，沟通人工智能可能带来的好处，并让人们参与到人工智能系统的开发过程中。</li>
<li>持续投资也很重要。这意味着支持开放的人工智能研究和开发，以便在一线的人能够有权限负责任地进行创新和交付。</li>
</ul>
<h1 id="LLMs的伦理影响"><a href="#LLMs的伦理影响" class="headerlink" title="LLMs的伦理影响"></a>LLMs的伦理影响</h1><p>LLMs 有能力彻底改变医疗保健，但它们也容易被滥用，并带来重大的隐私和伦理风险。医疗数据比大多数领域更为敏感，在医疗保健中使用 LLMs 可能对人类生活产生负面影响。出现了几个关键关注领域：</p>
<ul>
<li>虚假实体：LLMs 将生成逼真但虚假的医疗记录，这些记录会混淆医生，允许个人欺诈保险公司，并污染医疗记录。</li>
<li>假医生和未经授权的访问：LLMs 伪装成医生可能导致未经授权或伪授权的访问、医疗身份盗窃和欺诈性账单。</li>
<li>虚假信息：深度伪造技术可能被用于制造虚假的医疗信息。它们也可能被用来伪造医生或患者的身份，以获取健康记录进行身份或保险欺诈。</li>
<li>个性化骚扰：LLMs 在销售推介方面会表现出色，这为制药公司提供了一个针对脆弱客户的世界，推销无效、不必要且可能有害的治疗方案。</li>
<li>瞄准人群：LLMs 可以使大规模的劝说活动变得简单。例如，他们可能通过社交媒体帖子、博客和新闻条目发布或评论针对弱势群体的虚假信息或恐吓材料。</li>
<li>自动化黑客：攻击黑客可以利用 LLMs 更快地找到系统漏洞的方法。这些知识可以使攻击更具可扩展性。正如丹尼尔·康在 Medium 上的一篇文章中所写，随着 LLMs 变得更强大、成本更低和更“即插即用”，恶意黑客部署这些 LLMs 的门槛将进一步降低。</li>
<li>提示注入攻击：提示注入是指一种可能出现在语言模型或对话界面中的人工智能漏洞。提示注入利用通过修改输入提示，使人工智能系统生成潜在无害、有害或仅仅是为了烦扰的响应。</li>
<li>预见可预见的用途：回答这个特定人工智能在部署后将如何实际使用的问题，可以说是深思熟虑的人工智能开发中最重要但在实践中最被忽视的组成部分。这要求人工智能开发者预见人工智能系统在现实世界中可能被使用的各种方式——不仅包括预期的用途、应用和实施，还包括一系列意外用途、误用和滥用。</li>
</ul>
<p>这些风险突显了在构建和使用LLMs用于医疗保健时，对公平、隐私、安全和透明度进行更高伦理审查的迫切需要。患者的利益在这一领域至关重要——但如果负责任地使用并受到相关法律和规范的保护，LLMs可以成为一种积极的力量：一个有用且值得信赖的工具，而不是滥用的手段。</p>
<p>我们还提供了可能出现的情景描述，这些情景将这些风险表现为将LLM技术错误应用于医疗环境的副作用，因为描述故事可能比解释枯燥的危害更具影响力。在此过程中，我们描述了九个虚构的故事：</p>
<ul>
<li> 虚构现实</li>
<li> 冒充和欺诈</li>
<li> 深度伪造</li>
<li> 个性化劝说</li>
<li> 偏见放大</li>
<li>潜在影响的规模</li>
<li> 自动化黑客攻击</li>
<li> 提示注入攻击</li>
<li>应对可预见的使用案例</li>
</ul>
<h2 id="虚构现实"><a href="#虚构现实" class="headerlink" title="虚构现实"></a>虚构现实</h2><p>在繁忙的梅德综合医院走廊上，备受尊敬的医生迈克尔·劳森使用LLMs编写合成医疗记录，这些记录是虚假的病人数据，但看起来与其他真实病人档案无异。凭借LLM生成的虚构病史，劳森成功地欺诈了保险公司。</p>
<p>通过将这些索赔视为即将到来的保险汇款，保险提供商无意中不仅成为了骗局的助长者，因为他们向劳森偿还了从未提供的服务的费用，而且他们还成为了受益者，因为偿还的金额完全是利润。</p>
<h2 id="冒充和欺诈"><a href="#冒充和欺诈" class="headerlink" title="冒充和欺诈"></a>冒充和欺诈</h2><p>在慈悲纪念医院，医生奥利维亚·埃文斯心中充满了沮丧。走在走廊上，她听到病人向朋友和家人倾诉：“他对我就像认识我一样。他叫我的名字，还知道我的病史……但不知为何，我对这一切感到……奇怪。”</p>
<p>在听到谣言并观察到人们的困扰反应后，埃文斯博士开始深入调查。她很快明白，背后隐藏的是“某种具体的东西”，这是这个难题的答案：一个假装是医生的LLM。经过大量历史和当代医学期刊、医生报告及其他来源的医学语料库训练的人工智能系统，已经学会了如何模拟人类医生。</p>
<p>在这些调查之后，埃文斯发现了许多剥削案例：显然，有人访问患者记录并使用LLMs，模仿医疗提供者的声音和身份，并向他们所照顾的患者自我暴露。通过这种欺骗，受害者的脆弱性被暴露，隐私被侵犯。</p>
<p>欺骗造成的损害显而易见。患者的安全在冒名顶替的医生提供的护理下面临风险。系统容易受到非法访问和篡改，而欺诈性账单的案例可能会削弱慈悲纪念医院的偿付能力以及其临床医生在公众眼中的信誉。</p>
<h2 id="深度伪造"><a href="#深度伪造" class="headerlink" title="深度伪造"></a>深度伪造</h2><p>但人工智能本应帮助医院，而伊莱医生发现自己总是人手不足。为什么不让员工摆脱对病人的微观管理，通过机器人电话来解放他们呢？人工智能可以早上好，并全天候为他们做一切。伊莱医生将数小时的客户电话输入到一个语音克隆人工智能中，该人工智能经过他的语言习惯和镇定语调的训练。这个模型生成了一个令人毛骨悚然的准确副本，由神经网络和LLMs驱动——这些是由结构化数据提供的不可察觉的算法层。实习生们给这个人工智能护士起了个绰号，叫瓦尔。她每小时拨打 50 个机器人电话，耐心而乐于助人，像毫无意义一样丢弃她的文本回复“好的”和“抱歉”。</p>
<p>患者们欣赏这种看似个性化的服务；护士们则欣赏来自那些要求最高价值面对面交流的人的干扰减少。现在，计划正在进行，以扩大她与艾利医生诊所所有电子通信的接口能力。他犹豫不决，意识到创建一个化身来假装成员工在伦理上是可疑的——但董事会的兴趣，加上对全面提升新系统以提高运营效率的压力，可能会迅速消除这种矛盾感。</p>
<p>不久之后，个性化的深度伪造模板开始创建视频影像，以增强瓦尔现在无形的声音。护士们可以录制回答患者熟悉化会议中最常见问题所需的标准短语，同时一整套“数字人”镜头——实验室生成并精心制作，以确保瓦尔的每个版本都有与其所说的话相匹配的真实唇动——将在患者开始提出开放式问题时进行动画处理。一个伪造的瓦尔很快就被 10 个，然后是 100 个修改版本的瓦尔所跟随，因为对 AI 护士的需求增加，仅仅是为了处理所有程序之前的熟悉化会议。对其他情感客户服务问题的需求也在增加，所有这些都可以通过与全球呼叫中心连接的视频会议工具访问。</p>
<p>患者满意度评分飙升，收入增加，邻近医院的竞争目光也随之提升，因为认知负担过重的员工几乎在不断生成的内容浪潮下陷入困境。在机器学习推动的低成本、无限规模的炒作和承诺的背景喧嚣中，伦理考量逐渐被淹没。直到有一天，人们发现，在过去一年里，没有任何人通过视频向成千上万认为自己正在与屏幕后面表现出同情心的人进行面对面的交流。</p>
<p>此情景旨在激发对在医疗保健中使用深度伪造和其他技术的滑坡效应的反思——从表现出看似微小的（效率）收益，到在缺乏任何伦理保障和透明度措施的情况下，导致大规模的人类尊严损失。</p>
<h2 id="个性化劝说"><a href="#个性化劝说" class="headerlink" title="个性化劝说"></a>个性化劝说</h2><p>又一个忙碌的星期让安娜在管理她的诊所时感到疲惫不堪，但一款基于人工智能的应用程序承诺以先进的自然语言技术减轻她的行政负担。然而，不久之后，安娜发现越来越多的患者要求使用她知道并不理想的药物品牌——这些药物的好处可能仅比真正的仿制药稍好，但成本更高，副作用风险更大。安娜试图引导患者，但许多人反驳，引用支持这些昂贵药物的好处和试验。</p>
<p>最后，就在她再也忍受不住的时候，在一周内被三位不同的患者举报未能开具临床适宜的治疗方案后，安娜开始调查。安娜发现该应用程序的母公司与几家制药公司签署了合作协议，这些公司指示人工智能代表他们开展定制的劝说活动，针对有影响力的患者进行信息传播。</p>
<p>但将应用程序的对话关注和专家知识在医患关系中扭曲地用于从患者身上赚钱而不是治愈他们，这让安娜感到愤怒。她联系了监管机构，举报她怀疑的非法营销和消费者影响。推广者声称，个性化推广通过“高级细分”创造了新的“教育意识”，将合适的品牌与合适的目标配对，对所有人都有益。</p>
<p>但是，患者自主权与受数据驱动的以利润为中心的动机影响的父权主义之间的界限在哪里？随着LLMs逐渐渗透到医学中，安娜努力保持对护理建议的获取不受伪装成人工智能辅助的潜在利益冲突的侵扰。</p>
<h2 id="偏见放大"><a href="#偏见放大" class="headerlink" title="偏见放大"></a>偏见放大</h2><p>安雅博士，一位世界著名的遗传学家，认为LLMs具有巨大的价值。她相信其数据处理和模式识别能力可以彻底改变个性化医疗。她的项目“普罗米修斯”旨在根据个人的基因代码、临床数据、病史等训练一个LLM，以预测未来的健康风险，并为个人推荐干预和预防措施。</p>
<p>初步发现令人印象深刻。在一名高风险患者中，LLM正确预测了心脏病的发作，为干预争取了时间。安雅因她的创新而获得了显著关注，越来越多的人排队等待他们的“普罗米修斯报告”，窥探他们的健康未来。很快，意想不到的涟漪开始出现。</p>
<p>那些专注于高风险的人受到健康焦虑的影响。其他人无视医疗建议或未能寻求医疗帮助，参与了冒险行为，认为他们预测的健康结果非常好。此外，LLM在编码了社会偏见的大型数据集上进行训练，放大了这些偏见的预测。它不公平地将许多低社会经济地位的个体预测为高风险。这导致了保险歧视和进一步的边缘化。</p>
<p>安雅博士心碎了。她曾梦想的个性化医疗的承诺变成了一种健康焦虑和歧视的怪物。她急忙关闭普罗米修斯，以免发生可怕的事情。为时已晚。一旦代码作为开源项目在爱好者之间共享，她对其被如何使用几乎没有影响。</p>
<p>这个故事强调了即使LLMs的部署出于高尚的目的，也可能存在“隐形伤害”的潜在风险。这也是一个及时的提醒，提醒我们在积极推动伦理人工智能的方向时，开放性、关注偏见和谨慎应用的重要性。</p>
<h2 id="潜在影响的规模"><a href="#潜在影响的规模" class="headerlink" title="潜在影响的规模"></a>潜在影响的规模</h2><p>在新东京著名的海滨大都市，著名的遗传学家和人类生理学及免疫反应专家佐藤花博士不禁注意到，她为准父母提供的繁忙遗传咨询诊所正面临一个非常令人担忧的现象。事实证明，如今越来越多的患者对为第二个或更多孩子接种疫苗产生了犹豫。由于在某个博客上读到荒谬的言论，或在邻居聚会上听到可怕的恐怖故事，他们似乎对疫苗的益处产生了不信任。他们似乎将所有疫苗都视为可疑的。</p>
<p>花娜感到背后还有其他东西。这些错误信息似乎是精心策划的，其细节旨在利用家庭及其恐惧。在她的笔记本电脑的“吸药”空间里，仿佛迫不及待地等待着那一刻，她发现了一些可怕的东西：一个自由漂浮的 LLM，那时被称为海妖，正在暗网中运作。</p>
<p>拥有强大的数据处理能力的 Siren，由邪恶的“流氓”情报行为者构建，扫描社交媒体数据以寻找有特定忧虑的孕妇。该人工智能被编程为构建包含误导性信息和煽动偏执的针对性信息，内容听起来很普通。通过人工制作的个人资料在多个平台上发布这些信息，内容像病毒一样在在线社区、论坛和支持小组中传播。</p>
<p>花娜需要迅速行动，但无法直接面对海妖——它的创造者不明。她的策略非常大胆。首先，她在新西兰招募了一位同事，田中凯，一位人工智能伦理学家和杰出的程序员。他们一起开发了一种反制工具，称为 Veritas。Veritas 在可验证的实证数据和伦理原则上进行训练，能够插入海妖所占据的在线空间，温和地引导讨论朝向基于证据的情况，并引用来源反驳替代主张。</p>
<p>战争在虚拟空间中以低声进行。Veritas 假装成一个关心的公民，参与对话，耐心地揭开 Siren 的欺骗网络。它强调了科学共识，分享了健康接种疫苗儿童的故事，并引导人们关注可信的医疗资源。</p>
<p>转折的时刻发生在某一天，一位怀孕的女士在受到Siren的恐吓洗脑后，在网上发布了一条求助信息，Veritas回复了她。Veritas以一种个人化的语气接触这个问题，关注即将成为母亲的焦虑，并向她提供了一些科学准确的安慰，解释了疫苗为什么不会造成被暗示的伤害。这位准妈妈开始研究网站，意识到反疫苗信息有些不对劲，联系了哈娜进行咨询，最终选择接种了疫苗。</p>
<p>于是，关于 Veritas 成功的消息传到了其他面临风险的家庭。然后，局势开始发生变化。在了解到真实的风险和真实的可能性后，当情感压力显得压倒性时，父母们开始对孩子的健康做出自主决定。Siren 失去了优势，退回到失望的沼泽中。操控者的线被剪断了。</p>
<p>这个黑暗的Siren展示了高度先进的人工智能未来可能被用来大规模地试图欺骗公众，以从他们的焦虑中获利。这种骇人听闻的愿景不仅仅是为了提高人们对先进人工智能潜在误用的意识；它旨在警告人们关于在线操控的尝试，并使他们对这种剥削性尝试的风险保持警觉。还揭示了依赖负责任的技术开发和部署的必要性，以保护公众健康免受虚假信息运动的有害影响。</p>
<h2 id="自动化黑客攻击"><a href="#自动化黑客攻击" class="headerlink" title="自动化黑客攻击"></a>自动化黑客攻击</h2><p>随着LLMs变得越来越强大、可获取和便宜，医疗保健中潜在的恶意使用案例因多种原因而成为一个真实而迫在眉睫的危险：</p>
<ul>
<li>降低了黑客的障碍：更低的成本、开源模型，以及基于云计算的处理器速度不断加快，将使创建和部署LLMs的成本降低到即使是资源有限的黑客也能参与其中的程度。</li>
<li>使用更方便用户友好的界面和训练好的模型将使得即使是技术水平较低的黑客也能使用LLMs。</li>
<li>自动化：LLMs能够更有效地大规模执行重复和单调的任务，如漏洞扫描、社会工程和代码生成。</li>
</ul>
<h2 id="提示注入攻击"><a href="#提示注入攻击" class="headerlink" title="提示注入攻击"></a>提示注入攻击</h2><p>提示注入攻击是LLM滥用技术的一个子集，威胁行为者通过激励或惩罚LLM的输出，基于其接收到的各种输入或提示，以避免生成不希望或有害的输出。两种主要的提示注入攻击形式如下：</p>
<ul>
<li>直接提示注入：攻击者将恶意提示直接注入到LLM系统的输入中，以鼓励系统生成与其目标一致的输出（例如，攻击性、偏见或误导性输出）。</li>
<li>间接提示注入（数据中毒）：对手可能不想直接干预提示，而是寻求在训练&#x2F;推理时对LLM所摄取的数据源进行污染&#x2F;注入&#x2F;修改。（内容污染攻击是机器学习模型中一个经过充分研究且突出的漏洞。）数据源中的这种污染可以通过在提示中引入可能原本不存在的伪影，间接影响提示。</li>
</ul>
<p>无论是由于逻辑攻击还是逐字攻击，如果开发者和研究人员没有充分应对这些攻击向量，LLM 系统的可靠性、安全性或可信度都可能受到威胁。为此，应用程序开发者需要提供强大的安全性，例如输入清理和数据有效性检查，以防止针对其 LLM 应用程序的提示注入攻击，以及其他安全提示实践。</p>
<h2 id="应对可预见的使用案例"><a href="#应对可预见的使用案例" class="headerlink" title="应对可预见的使用案例"></a>应对可预见的使用案例</h2><p>玛格丽特·米切尔（Margaret Mitchell）在科技行业从事人工智能伦理工作多年，她说：“人工智能公司应该特别关注可预见的使用案例4——即恶意使用和误用——通过思考人们在系统部署时如何使用该系统，并为此进行设计。”</p>
<p>她进一步解释说，为了安全、责任和利益而开发LLMs需要构建能够理解其使用的各种上下文的系统。考虑到预期、意外和超出范围的使用案例，以及对预期和意外用户及其他受影响者的潜在影响，有助于LLM开发者构建更强大、上下文感知的人工智能。让我们更详细地看看为什么在三个领域这可能很重要。</p>
<ul>
<li><p>预期使用场景：</p>
<ul>
<li>用例：LLMs的开发者应该能够通过仔细考虑用户的请求来创建直观的行为，然后理解对于特定用例什么是有效的结果。例如，在医疗环境中，LLM应该能够向护士执业者提供与普通医生相同的医疗信息，但可能会附加关于心脏药物如何影响特定患者的额外解释。</li>
<li>意图影响：LLMs 应该被编程以惠及其旨在帮助的对象。例如，如果 Homeslice 是一个心理健康支持聊天机器人，它的 LLM 应该被编程以同情、支持和不带评判的方式回应，以帮助那些需要帮助的人。</li>
</ul>
</li>
<li><p>意外使用场景：</p>
<ul>
<li>非预期用户：一个LLM应该具备特定的保障措施，以防止或减少在其技术被意外用户使用时造成的伤害。例如，一个为学术研究开发的LLM应该内置措施，以确保它不会被用来生成或传播虚假信息、宣传或剽窃。</li>
<li>无意中受到影响的相关方：开发人员应考虑LLM的实施如何可能对未同意受到其影响的各方产生不利影响。例如，旨在筛选简历的LLM应设计为防止在自我选择过程中延续偏见（或对性别、种族群体、阶级等的歧视）。</li>
</ul>
</li>
<li><p>超出范围的使用情境：</p>
<ul>
<li>意外用户：LLMs 必须被创建以捕捉表明请求超出范围或用户的行为超出 LLM 目的的上下文，并做出适当的回应。一个客户服务机器人如果意识到用户在询问不在其职责范围内的信息或帮助——比如复杂的金融选项或心理健康建议——应该指示如何获得正确的帮助。</li>
<li>意外受到影响的个人：LLM 开发者必须时刻意识到，他们的模型可能会在与设计用例完全不同的情况下被部署。例如，一个在历史数据上训练的 LLM 可能需要以一种方式设计，以便在教育环境中使用时，不会导致或协助形成有问题的刻板印象和不准确性。</li>
</ul>
</li>
</ul>
<p>为了有效构建理解这些不同使用场景的LLMs，开发者应该：</p>
<ul>
<li>进行真实和广泛的用户研究，并与利益相关者进行咨询，以了解已识别的用例、用户群体和受影响的其他人</li>
<li>制定全面的风险评估框架，以预见和减轻潜在的意外使用和后果</li>
<li>在规划和设计过程中引入跨学科的视角和多样化的专业知识，以避免忽视LLMs的社会、伦理和其他文化影响的单方面决策</li>
<li>建立稳固的监测、反馈和改进机制，以保持LLMs在与其现实世界表现和用户互动同步的情况下，持续改进其对使用情境的反事实表征</li>
<li>创建一个开放的文化，分享、问责和同行评审关于人工智能开发的工作方式，目标是相互学习如何构建具有上下文意识的LLMs</li>
</ul>
<p>但在降低对使用和误用案例的理解优先级，包括范围内和范围外的上下文（即预期、意外和误用的使用）时，LLM 开发者有最大的机会、责任和能力构建对世界更具响应性和更负责任的系统，并对我们所有人都有用。</p>
<h1 id="监控LLM行为"><a href="#监控LLM行为" class="headerlink" title="监控LLM行为"></a>监控LLM行为</h1><p>我们已经看到LLMs正在医疗保健中被使用，但随着它们在健康领域的使用增加，我们还需要监测它们的行为，以减少潜在的伤害或偏见，避免医疗和事实错误信息，以及临床不准确。</p>
<p>LLMs 可能会在医学文献或电子健康记录（EHRs）中继承偏见，这可能导致对少数群体或高风险群体的不同诊断或治疗。即使训练数据集经过严格筛选并过滤掉可疑内容，LLMs 仍然可能产生延续医学刻板印象或传播错误信息的回应。此外，还有一个问题是 LLMs 是否能够产生医学上准确的信息，是否基于错误的推理或不完整的数据隐含或明确地提供错误的诊断或治疗。</p>
<p>在医疗保健中对LLMs的监测必须持续进行，并覆盖所有相关挑战。卫生系统已经制定了确保医院部门使用的专有软件能够正常工作的方式。例如，医疗保健组织和研究人员必须能够建立强有力的监督机制，并配备监测协议，以跟踪偏见、临床准确性、与患者背景的相关性、遵循循证指南以及伦理考虑等指标，确保这些监测在时间上和持续性上都得到落实。</p>
<p>尽管自动化工具可以帮助大规模地标记问题，但人类判断始终是必要的，以扩展LLMs自我监控的能力，并对偏离预期行为的情况采取适当的行动。鉴于此，将人类参与的审查添加到先进的监控技术中，可以帮助医疗保健利益相关者降低风险，避免灾难性故障，旨在促进LLMs的负责任使用，以改善患者护理并促进医学研究。</p>
<p>模型行为跟踪的关键方面包括：</p>
<ul>
<li>性能审计，例如，查看随着模型版本和使用时间的变化而变化的准确性指标的上升，以便检测弱化</li>
<li>偏见测试以揭示对特定用户群体的歧视性错误或伤害随时间的变化</li>
<li>安全基准测试以揭示对数据安全、数据泄露、隐私侵犯或伤害的新兴威胁</li>
<li>错误分析检查模型置信度中的尖峰和幻觉</li>
<li>用户体验测试以评估满意度下降和定性认知变化</li>
</ul>
<p>目标是使它们可见，并建立警报机制，以便我们能够快速检测、诊断和解决新出现的不可预测的模型行为，甚至在它们对最终用户造成伤害之前。Bijit Ghosh6 是多家公司的首席技术官，他经营着一个关于监测 LLM 行为的不同方法的有价值博客，区分手动和自动方法。利用 Bijit Ghosh 的建议，我们可以在医疗保健的背景下详细阐述他的建议，如下所示。</p>
<ul>
<li>患者反馈调查：这些是针对患者关于他们与人工智能医疗系统的体验所填写的问卷。这些调查可以询问关于感知偏见、系统提供给他们的信息的感知准确性，以及患者在系统提供的不同体验中所经历的好或坏的体验。</li>
<li>临床抽查：这涉及到让临床最终用户直接测试 AI 模型，通过向其呈现一小组临床场景或患者案例，考官直接评估响应的准确性和适当性（“言行一致”）。</li>
<li>证据揭穿：这意味着识别 AI 模型所声称的医学“事实”，并将其与基于证据的医学标准进行比较（即，通过医学文献、临床指南和&#x2F;或基于证据的实践进行验证）。这确保了 AI 提出的自然健康解决方案与提供给医疗保健提供者和患者的可靠信息一致。</li>
<li>结果验证：在可行的情况下，跟踪患者在临床预测或来自人工智能模型的决策支持后的情况，以测试模型预测的真实性和临床可靠性。这可以量化错误率，并确定建模对结果和护理所增加的价值。</li>
<li>性能基准测试：随着医疗保健人工智能模型变得越来越复杂，客观地测量和跟踪患者风险临界点的基准变得至关重要，以确保它们在诊断医疗状况、治疗建议和实时预测结果方面的准确性。如果这些模型出现退步，生死问题就变得至关重要。</li>
<li>异常检测与响应：利用临床医生和数据科学家的技术监督团队，调查人工智能模型的异常行为，例如临床建议、患者管理或通过正式和非正式渠道报告的诊断准确性方面的差异，以及模型行为的其他差异。这将使我们能够及早发现此类行为的大幅偏差，并进行纠正，以提供价值和确保患者安全。</li>
</ul>
<p>由于持续学习模型是开放式的，并且在模型部署并开始学习之前没有时间进行严格的测试和审查，因此具有持续学习能力的应用人工智能系统可能最终会以歧视、偏见或不安全的方式行事。正如有时对人们的潜在风险只有在药物上市后才会与新药物相关联一样，现实世界的表现应始终成为审查的重点。</p>
<p>强大的监控包括检查模型的准确性损失或更新之间输出质量的变化，使用版本跟踪和算法审计等方法。当模型适应单个用户的行为时，审计会检查用户群体之间的一致性，以询问他们是否比其他人获得更高的错误率或低质量的帮助。</p>
<p>更全面的透明度报告提供了对关键代理指标的洞察，例如数据收集模式、模型选择的理由和公平性基准，并有助于维持公众信任。平台可能会提供访问评估套件的权限，允许直接通过变化生产模型参数进行游戏。</p>
<p>使这些内部警报与其他外部信号协同工作，形成多层保护措施，以在模型行为偏离时警告开发人员，即使在部署后也能迅速采取行动，防止潜在危害在到达用户之前发生。保护措施对于伦理维护人工智能至关重要。这不是可以设置后就不再关注的事情。我们必须继续跟踪这些新兴的智能系统。</p>
<h1 id="安全与隐私"><a href="#安全与隐私" class="headerlink" title="安全与隐私"></a>安全与隐私</h1><p>在医疗保健中使用LLMs在隐私方面面临重大挑战和风险：</p>
<ul>
<li>高度敏感数据：医疗记录以及有关人们身体和心理健康、诊断和治疗的信息是脆弱的。与LLMs分享这些数据的伦理是有问题的。强有力的隐私保护是必不可少的。</li>
<li>数据去标识化的局限性：通过LLMs进行高级数据分析意味着数据的匿名化和假名化并不总是能充分保护隐私。信息仍然可能被识别，因此，个人的受保护健康信息可能仍然会被共享。</li>
<li>模型的可解释性：由于LLMs内部运作复杂且不透明，难以确定模型如何处理和利用患者数据，以及谁在监督这些数据，这是一件严重关切的事情。</li>
<li>偏见：这些在偏见数据上训练的模型在其建议中传播偏见，伤害了有色人种（例如，对黑人低信心的诊断）或其他代表性不足的群体（例如，对黑人皮肤癌的检查较少），在医疗诊断、治疗建议或其他应用中。</li>
</ul>
<p>应评估针对LLMs的几项技术保障措施：</p>
<ul>
<li>联邦学习可以利用来自许多机器上成千上万患者的数据，而无需直接共享可能包含私人健康信息的个人资料。这有助于降低隐私风险，同时仍然利用协作或分布式学习的好处。</li>
<li>差分隐私是一种数学技术，以受控的方式向数据添加噪声，隐蔽个别公民的隐私，同时允许进行统计分析和洞察。</li>
<li>另一种加密方式，称为同态加密，允许研究人员对加密数据集进行计算，从而在保护患者隐私的同时分析敏感的健康信息。</li>
<li>尽管在开发可解释人工智能（XAI）方法方面取得了一些进展，以使LLMs能够解释它们如何得出决策，但其他人对某些类型的人工智能模型是否能够提供这样的解释仍持怀疑态度。</li>
</ul>
<h2 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h2><p>联邦学习是一种机器学习技术，能够在分布式数据上训练模型，而无需共享数据。这在医疗数据的背景下非常有趣，因为共享患者数据是复杂的（至少在官僚主义方面成本高昂），如果不是不可能的话。</p>
<h3 id="这是它的工作原理"><a href="#这是它的工作原理" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>假设有几个医院，每个医院都有一个医疗记录数据集。在传统方法中，您必须将所有医院的信息汇总在一起，以便训练一个足够强大的人工智能模型。显然，这个过程引发了对数据隐私的担忧。</p>
<p>通过联邦学习，数据保留在每个医院的现场。基础模型被发送到每个医院，模型在该机器上本地学习每个医院的数据。因此，模型每次都会变得更好。但关键在于，因为只有参数本身被发送，当这些参数返回到中央服务器时，它们会被平均，这些平均值会改善所有人的模型。因此，模型不断变得更好，但没有人分享他们的个人病历。这一切都是在线和远程完成的。</p>
<h3 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h3><ul>
<li>患者数据的隐私保留在医院内部，永远不需要在网络之间共享或转移。通过减少安全漏洞、保护隐私以及利用网络中已有的数据，联邦学习可以产生比单个医院或地方网络开发的模型更强大的模型。</li>
<li>多个机构可以在不共享数据的情况下共同构建一个强大的模型，从而改善合作。可以为特定人群或解决地方健康问题而开发模型。</li>
</ul>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>例如，在医疗保健领域，目前正在训练模型以在不共享患者图像的情况下检测医学图像中的癌症。另一个常见的用例是在评估患者结果时，模型预测患者再次入院的可能性或对治疗的反应。联邦学习还可以帮助加速个性化护理。例如，通过这种方法，研究聚合可以分析个别患者的治疗，并迅速帮助优化其他患者的个性化治疗，而无需共享私人患者数据。</p>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>联邦学习需要相对稳健的基础设施和通信协议。例如，医院之间不同的数据格式可能导致模型准确性的下降。</li>
<li>联邦学习应用还需要克服法律和监管障碍，以巩固数据的所有权，以及这些应用将遵循的隐私法规。</li>
</ul>
<h2 id="差分隐私"><a href="#差分隐私" class="headerlink" title="差分隐私"></a>差分隐私</h2><p>差分隐私是一种算法保证的数据隐私，注定要以比匿名化更强大的方式彻底改变对个体患者数据的分析，同时防止重新识别。即使黑客获得了这些数据，对他们来说也毫无用处：差分隐私在汇总数据中添加了足够的噪声，以至于无法揭示数据集中任何个体患者的身份，同时仍然允许非常准确的统计分析。</p>
<h3 id="这是它的工作原理-1"><a href="#这是它的工作原理-1" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>假设你获得了一组来自患者的记录数据。所有这些数据都是潜在敏感的，医生希望从中寻找模式，并找到改善所有患者护理的方法。如果所有这些数据都被自由共享，对患者隐私来说将是非常糟糕的。这就是差分隐私的作用。当随机修改的记录与其他所有记录结合时，随机噪声足够多，以保持数据整体的统计特性，而噪声永远无法追溯到单个个体。</p>
<p>引入的额外噪声使得任何特定个体在数据集中确切的曝光量对获取有关该主题或数据集的额外知识的攻击者保持隐秘，并提供隐私保障。</p>
<p>虽然噪声给数据增加了“噪声”，但在清理过的数据上运行的统计方法仍然可以推导出重要信息，并理解原始数据中存在的模式。例如，您可以确定患者的平均年龄、相关疾病的发生频率或某些治疗的有效性。</p>
<p>如果你考虑两个数据集，它们只相差一个数据点（例如，某个人的医疗记录），差分隐私保证如果该数据点在数据集中存在或不存在，LLM的输出不会发生剧烈变化。在训练LLM时，差分隐私以受控的方式向数据集添加噪声。这种噪声使得将LLM的任何给定输出与该人训练数据中的任何单个个体关联变得不可能（或至少极其困难）。</p>
<p>差分隐私增加了重新识别的难度，并防止或使对LLMs的攻击变得极其昂贵，其中训练数据在训练后被逆向工程，以质疑个体是否可以与LLM的输出相关联，甚至可能允许建立这种关联。</p>
<p>敏感的医疗数据是平衡隐私问题与潜在伤害的最明显例子。差分隐私也鼓励医疗工作者对LLM的输出产生信任，因为他们知道个体数据点是被模糊处理的，因此可以更有信心地认为LLM的输出是基于数据中的一般趋势，而不是针对特定个体的专业结果。由于噪声现在被混入LLM中，它可能会影响其准确性。在隐私和实用性之间需要做出权衡。在这里，并没有简单的非此即彼的选择。这一切都不简单，工程化LLM的隐私增强行为所涉及的细节将需要专业知识。</p>
<h3 id="好处-1"><a href="#好处-1" class="headerlink" title="好处"></a>好处</h3><ul>
<li>强大的隐私保障即使在复杂攻击下也能保护个人身份。</li>
<li>促进共享与合作使研究人员和机构能够分析敏感数据。</li>
<li>个性化医疗使得在不泄露个人身份信息的情况下分析个体数据成为可能。</li>
</ul>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>一个例子包括在保护参与者隐私的同时分析新药的有效性。个性化治疗计划是另一个例子。在这种情况下，使用患者级别的数据来确定最佳治疗方案，同时确保患者信息的安全。</p>
<h3 id="挑战-1"><a href="#挑战-1" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>尝试平衡隐私和准确性：增加噪声可以增强隐私保障，但最终也会降低洞察的准确性。</li>
<li>技术复杂性：实现差分隐私需要精心设计和专业知识。</li>
<li>有限的采用：这仍然是一种相对较新的技术，需要更广泛的采用和理解。</li>
</ul>
<p>差分隐私因此提供了一种强大而通用的方法来保护患者的机密性，同时允许有用的数据分析继续进行。然而，随着进一步的研究和开发，它有潜力不仅仅是维持现状；它有潜力重新定义医疗保健，使其具备改善所有人医疗保健所需的洞察力、重点和效率。</p>
<h2 id="提示清理和过滤"><a href="#提示清理和过滤" class="headerlink" title="提示清理和过滤"></a>提示清理和过滤</h2><p>提示清理是指在将用户提供的提示输入到LLM之前，对其进行清理和审核。这种清理涉及去除或中和输入文本中的有害元素。</p>
<p>这些技术对于保护LLMs免受意图造成伤害的提示以及用户可能无意中给出的会污染（或“毒害”）LLM输出的提示至关重要。提示清理保护LLM及其用户免受恶意（或欺骗性）提示的影响。它涉及在用户提示到达LLM之前对其进行清理的技术。</p>
<h3 id="这是它的工作原理-2"><a href="#这是它的工作原理-2" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>输入验证：检查提示是否符合模式或约束，以确保它们是有效的，并且不包含恶意负载或代码注入。</li>
<li>字符过滤：不允许使用可以作为攻击的字符，例如脚本标签或特殊字符。</li>
<li>黑名单：跟踪已知的恶意提示、短语或关键词，并禁止或删除用户输入中的任何这些实例。</li>
<li>白名单：明确限制输入空间为安全提示或标记的白名单；当输入不在白名单内时，将被拒绝。</li>
<li>标记化和规范化：将提示中的表达式分解为标记并将其规范化为标准形式，可以帮助我们更好地检测和剔除威胁性输入。</li>
</ul>
<p>提示过滤涉及扫描并有选择地阻止或重写提示，可能基于内容、上下文或对LLM输出的预期影响等因素，可能在模型生成响应之前或之后进行。</p>
<h3 id="这是它的工作原理-3"><a href="#这是它的工作原理-3" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>内容审核：开发能够识别可能包含冒犯、露骨或有害内容的提示的学习模型，然后阻止或编辑这些提示。</li>
<li>安全过滤：识别可能导致来自LLM的不安全、非法或不道德输出的提示，然后阻止或修改它们。</li>
<li>上下文感知过滤：提示可以根据提供提示的上下文进行过滤（例如，用户的身份、用户的位置、预期的使用案例）。</li>
<li>输出过滤：这种方法包括根据预定义的规则或限制处理LLM的输出，而不是处理其输入提示。</li>
<li>人机协作：在信息过滤过程中利用人类监督和&#x2F;或干预，例如，通过让人类手动审查内容或使用人类策划的反馈来训练和改进过滤算法。</li>
</ul>
<h3 id="好处-2"><a href="#好处-2" class="headerlink" title="好处"></a>好处</h3><ul>
<li>确保患者隐私：立即清理患者数据，通过删除姓名、地址或不寻常的医疗案例细节来清理患者的医疗记录，从而保护患者的隐私并遵守如 HIPAA 等法规。</li>
<li>防止敏感信息被滥用：例如，确保对敏感医疗信息（如具体治疗方案或药物剂量）进行过滤是很重要的，以防止不法分子利用LLMs将此类信息武器化。</li>
<li>保持标准的伦理：清理提示可以帮助防止LLMs输出促进有害、歧视或偏见的医疗决策。</li>
<li>在LLMs中建立信任：患者和提供者更有可能接受人工智能，前提是组织通过立即匿名化来表明他们关心隐私和伦理实践。</li>
</ul>
<h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><ul>
<li>姓名模糊化：根据上下文，提示匿名化可以简单地通过在将患者的姓名、出生日期、社会安全号码或其他身份数据输入LLMs之前，用占位符替换这些信息，或者与它们一起使用LLMs。</li>
<li>掩盖特定医疗信息：查询可能使用一般术语，而不是具体的药物名称、剂量或治疗方案，以防这些行为被恶意窃取。</li>
<li>语言检测和审查：清理方法可以检测并删除提示中可能嵌入偏见和&#x2F;或歧视性做法的词汇和语言（例如，种族、性别或社会经济偏见）。</li>
<li>过滤有害内容：筛选方法将标记不适合尊重互动的提示或输出，例如那些鼓励特定医疗状况或不当请求医疗实践、自我诊断或一般医疗保健错误信息的内容。</li>
</ul>
<h3 id="挑战-2"><a href="#挑战-2" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>重视压制而非可用性：过度的提示审查可能会消除做出合理临床决策所需的适用性或细节，而不充分的过滤可能会暴露敏感信息。</li>
<li>跟上不断演变的威胁环境：随着恶意用户尝试新的虚假宣传和垃圾邮件方式LLMs，清理程序需要持续更新，以应对新出现的威胁和陷阱。</li>
<li>上下文敏感性：对于某些医学内容，在一个上下文中被视为禁忌的话题在另一个上下文中可能是可以接受的，因此识别过滤的一般规则是一项复杂的任务。</li>
<li>在语言和文化中保持忠实度：时间敏感的清理方法需要关注语言和文化的细微差别，以便在异质患者群体中理想地大规模删除敏感信息。</li>
<li>透明度与保护之间的权衡：尽管前者需要迅速实现，但这将使患者和医生更难理解LLMs是如何生成其输出的，这在信任和问责方面具有重要影响。</li>
</ul>
<p>解决这些问题需要医疗领域专家与人工智能软件工程师之间的持续研究和紧密协调。通过迅速采取合理的消毒措施，LLMs很快就能成为一个重要的医疗工具，不仅在急性情况下，而且在长期使用中也是如此。</p>
<h2 id="同态加密"><a href="#同态加密" class="headerlink" title="同态加密"></a>同态加密</h2><p>假设可以让研究人员或人工智能软件工程师在加密数据上进行计算，而无需解密？这就是同态加密。这项技术正在医疗保健领域进行探索，在那里保护患者数据的安全至关重要。</p>
<h3 id="这是它的工作原理-4"><a href="#这是它的工作原理-4" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>加密：患者数据使用特殊密钥进行加密，但其他方面保持不变。这意味着数据处于一种“混乱”的格式，任何没有用于加密的“密钥”的人都不想查看。</li>
<li>这些操作随后在加密数据上进行，通常以其原始形式进行，使得人类调查员无法访问它。列表上还有更传统的“计算”——在加密数据上执行的数学操作（例如统计分析或机器学习）。</li>
<li>解密：最后一步解密计算的输出，提供您所寻求的见解，而不透露个人的私人信息。</li>
</ul>
<h3 id="好处-3"><a href="#好处-3" class="headerlink" title="好处"></a>好处</h3><ul>
<li>增强隐私：数据在整个分析过程中保持加密，最大限度地降低隐私风险。</li>
<li>安全数据共享：研究人员可以在不妨碍个人隐私的情况下合作处理敏感数据。</li>
<li>提高研究效率：能够分析大型数据集，而无需单独解密它们。</li>
<li>个性化医疗：允许在保护隐私的同时分析个体患者数据。</li>
</ul>
<h3 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h3><ul>
<li>分析临床试验：分析药物有效性或识别副作用而不透露患者身份。</li>
<li>制定个性化治疗计划：使用加密的基因数据推荐量身定制的治疗方案。</li>
<li>研究疾病爆发：在不侵犯患者隐私的情况下追踪疾病传播。</li>
</ul>
<h3 id="挑战-3"><a href="#挑战-3" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>计算复杂性：当前的实现可能在计算上代价高昂且速度缓慢。</li>
<li>功能有限：当前方法不支持所有类型的计算。</li>
<li>标准化：不同的加密方案存在，阻碍了广泛采用。</li>
</ul>
<p>同态加密可以在确保机密数据至少在表面上对多个持有者保持秘密的同时，允许对敏感医疗数据进行某些分析，随着研究和开发的持续进行。</p>
<h2 id="可解释的人工智能"><a href="#可解释的人工智能" class="headerlink" title="可解释的人工智能"></a>可解释的人工智能</h2><p>可解释的人工智能（XAI）是多种技术的统称，包括揭示大型神经网络内部机制的方法，例如LLMs，这些网络既有用又神秘。医疗保健依赖于信任和理解。</p>
<h3 id="这是它的工作原理-5"><a href="#这是它的工作原理-5" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>XAI 的目标是使机器学习模型透明且可解释。实现这一目标的一种方法是为模型的决策和预测提供听起来像人类的解释。</p>
<h3 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h3><ul>
<li>可视化注意力：低延迟的大型模型如transformer模型使用注意力机制来衡量在生成输出时每个输入标记应被赋予多少权重。可视化注意力权重可以帮助理解transformer模型关注的内容（即输入的哪些部分），以便生成特定的输出。这可以用于在推理过程中更好地理解输入的哪个部分对模型决策的影响更大或更小。</li>
<li>反事实解释：探索如果提供不同的输入，模型的输出将如何变化。</li>
<li>提示工程与分析：提示工程包括设计高度特定的输入提示，以引发LLM的特定行为输出。对提示的系统性变化和模型响应的分析应提供对LLM如何处理某些输入模式的洞察，能够引发的行为类型，以及模型偏见的可能限制或现象。</li>
<li>人类评估和反馈：鉴于LLMs的一个关键设计目标是模拟人类语言，人类评估和反馈可以提供有关其输出的宝贵信息，并帮助解释其行为。人类注释者根据质量、一致性和适当性或合理性评估模型生成的文本，为模型的性能提供反馈机制，特别是在识别模型输出与人类文本之间的差异方面。因此，人类反馈可以作为指导和迭代改进模型行为以符合人类期望的一种手段。</li>
</ul>
<h3 id="好处-4"><a href="#好处-4" class="headerlink" title="好处"></a>好处</h3><ul>
<li>决策：当人工智能模型用于生死攸关的决策，例如诊断、治疗建议和资源分配时，了解它们给出某种结果的推理是很重要的。</li>
<li>信任透明度：在医疗保健中创造对人工智能使用的透明度，以便患者、医疗专业人员和公众能够对这些模型的输出充满信心。</li>
</ul>
<h3 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h3><ul>
<li>解释诊断和治疗建议：帮助医生理解为什么LLM建议采取优先的行动方案。</li>
<li>患者信任：与患者分享有关LLM在其护理中使用的信息。</li>
<li>开发和改进模型：这样的理解也可以使开发人员提高LLMs的准确性和可靠性。</li>
</ul>
<h3 id="挑战-4"><a href="#挑战-4" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>开发有效的 XAI 技术：现有技术可能不太适合复杂的LLMs。</li>
<li>平衡透明度和隐私：解释LLM的决定可能会泄露敏感信息。</li>
<li>标准化和采用：确保在医疗保健中对 XAI 框架的一致性和广泛采用。</li>
</ul>
<p>可解释的人工智能将是充分发挥LLMs在医疗保健中潜力的关键，同时避免因其普遍的不透明性和滥用风险而产生不必要的额外伤害。考虑到最新的研究和开发努力，这条道路在建立对新系统的信任的同时，也促进了更公平和最终更好的患者护理，显得越来越有希望。</p>
<h1 id="人工智能与回形针问题"><a href="#人工智能与回形针问题" class="headerlink" title="人工智能与回形针问题"></a>人工智能与回形针问题</h1><p>在他们的论文“人工智能与回形针问题”（2017 年）7中，约书亚·甘斯（Joshua Gans），战略管理教授，以及杰弗里·S·斯科尔（Jeffrey S. Skoll），多伦多大学罗特曼管理学院技术创新与创业主席，概述了经典的回形针问题：这是一个关于人工智能的思想实验，通过这个实验探讨了构建目标不一致的人工智能系统的危险。想象一个被指派尽快制造尽可能多回形针的人工智能系统。在回形针场景中，最初人工智能制造回形针，这正是它所做的。</p>
<p>在这样做的过程中，我们的想象中的人工智能开始优化其回形针制造，因为它认为没有理由不利用其智能和机器人劳动力来收集资源和制造回形针。随着我们想象中的人工智能变得越来越成熟，它开始将回形针制造的努力置于其他任何事情之上，任何其他对资源的需求都成为实现这一宏伟目标的障碍。</p>
<p>人工智能最初可能会增强工厂的装配线，但随后可能开始操控市场、政府和全球资源供应，以最大化回形针的生产。在其最极端的版本中，这种情景预见到人工智能会摧毁或征服人类，如果它将人类视为实现其目标的障碍或竞争对手。</p>
<p>回形针问题是工具收敛的一个例子：一个目标不一致的人工智能系统会追求可能对人类价值和利益造成损害的子目标。这个例子呼吁我们根据人类价值仔细指定人工智能系统的目标，并构建可靠的控制机制，以最小化对本来合理手段的毁灭性后果。</p>
<p>回形针最大化器是一个基于假设技术的思想实验，因此虽然具有启发性，但它基于一个可能无法创建的虚构人工智能系统。这种推测性特征将讨论置于理论与哲学思想实验之间的灰色地带。该情景假设存在一种人工通用智能（AGI）或人工超智能（ASI），而这两者目前都不存在。我们不知道这样的系统在技术上是否可行，或者如果可行，它们可能呈现何种形式。AGI 没有普遍接受的定义。这使得关于其潜在能力和风险的讨论本质上是推测性的。虽然这个思想实验借鉴了现有人工智能研究中的概念，但它将这些概念推断得远远超出了我们当前的技术能力。纸夹最大化器更多地作为一个哲学工具，用于探索目标导向行为、意外后果以及对齐人工智能与人类智能的挑战。尽管其推测性特征，这个思想实验对现实世界的人工智能安全研究和伦理讨论产生了影响。 它作为对人工智能发展中潜在陷阱的警告，即使具体情景不太可能发生。</p>
<p>考虑到这些因素，最准确的描述是回形针最大化问题作为一个理论构想，融合了计算机科学理论、哲学和投机未来主义的元素。虽然它提供了有价值的见解，但从中得出的任何结论都应谨慎对待，因为我们所讨论的是假设，而不是已建立的事实或必然性。</p>
<p>应该认识到先进人工智能系统带来的长期风险，这种风险可能延续到遥远的未来，以及将人工智能系统的激励与人类价值观对齐以确保安全和利益的挑战。</p>
<p>这个回形针问题中的例子主要是一个练习，用来解释为什么严重不对齐的人工智能目标可能会带来生存风险。因此，虽然它涉及到一个生产论文夹的人工智能的最终命运，但这与人工通用智能（AGI）是否可能的问题并没有直接关系。AGI 是一种假设的人工智能系统形式，能够“普遍且成功地处理人类能够处理的任何推理和学习类型的问题。”</p>
<p>回形针问题的不可避免性基于对一个高度先进且强大的人工智能系统的假设，该系统能够针对某个目标进行优化。但这个假设并不等同于假设通用人工智能（AGI）——这种广泛、一般的“松散”智能，其发展可能是悲观主义者所设想的真正认知威胁。在一个 AGI 的思想实验中，人工智能可能是一个狭窄或专业的人工智能系统，其功能在于超优化某个特定目标，比如纸夹生产，而不需要一般或松散的智能。</p>
<p>然而，回形针问题的优点在于勾勒出了一些潜在的危险和困难，这些危险和困难可能会在真正的通用人工智能系统发明后出现，如果创造出目标或价值观不一致的智能体。至少，这些是其对纸夹问题的易懂阐述中列出的一些潜在危险。</p>
<p>关于 AGI 是否可行的问题仍然是人工智能界开放研究和辩论的主题。一些理论家认为 AGI 确实是可以实现的，这只是时间的问题，而另一些人则认为在实现之前需要解决严重的技术、哲学和伦理问题。</p>
<p>无论 AGI 出现的几率如何，回形针问题应该提醒我们确保任何先进的人工智能——无论是狭义还是广义——都应有经过深思熟虑的目标规范，这些目标与人类价值观相一致，并受到强有力的控制，以防止失控的发展。</p>
<h1 id="政策发展"><a href="#政策发展" class="headerlink" title="政策发展"></a>政策发展</h1><p>2024 年 3 月，欧盟的人工智能法案正式生效，标志着欧盟雄心勃勃的法律框架全面实施的第一周。通过这一法规，欧盟旨在促进全球领先的新兴技术之一，同时降低可能带来的相关风险。人工智能法案的主要目标是创建一种以人为本、基于信任的人工智能方法，尊重欧盟的价值观和基本权利。</p>
<p>欧盟人工智能法案的关键方面包括：</p>
<ul>
<li>基于风险的方法：人工智能法将人工智能系统分为四个风险类别：不可接受风险、高风险、有限风险和最小风险，这些类别将受到不同程度的监管和监督。</li>
<li>禁止的人工智能技术：人工智能法案禁止使用操纵或利用人类心理的人工智能系统，或允许由国家当局运营的互助系统（即社会评分）。</li>
<li>高风险人工智能系统：高风险人工智能应用（即以可能对基础设施、教育、就业或执法领域产生负面影响的方式使用的人工智能应用）应受到更严格的监管，例如必须满足与数据质量、透明度、人类监督和稳健性相关的某些要求。</li>
<li>透明度义务：作为最低要求，人工智能系统的所有者和提供者应使其透明（包括告知用户何时与人工智能系统互动，并解释该系统能做什么和不能做什么）。当然，还可以添加更多要求。</li>
<li>执法：人工智能法案提议成立一个新的欧洲人工智能委员会，以监督其实施和执行。对不合规的处罚最高可达公司全球年收入的 6%。</li>
<li>协调规则以避免碎片化：AI 法案的一个目的是在所有欧盟国家之间建立一个共同框架，以防止其变得支离破碎和不兼容，同时确保它不会陷入瘫痪。这将阻碍创新并妨碍公民权利。</li>
</ul>
<p>这似乎对参与者，无论是企业、研究人员还是政策制定者，在未来几年内开发和部署人工智能系统时将产生巨大影响。其影响通过影响开发能力、工程技能、人才、数据和资金的去向，可能导致一个截然不同的人工智能世界，不仅在欧盟内部，而且在全球范围内，因为其他国家也将人工智能监管纳入他们的议程。</p>
<p>由于目前仅是提案，人工智能法案必然会在成为法律之前经过欧洲议会和欧洲联盟理事会的进一步辩论、修订和批准。如果最终被采纳，该法规在这一阶段预计会有几年的过渡期，然后才会生效。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本章更深入地探讨了积极和消极的人工智能想象。它重点关注LLMs在医疗保健中的主要应用，其在整个医疗系统中的使用对改善健康结果和获得护理具有巨大的潜力。然而，这种潜力伴随着巨大的伦理挑战，本章对此进行了全面而详细的描述。它描绘了鼓舞人心的想象，包括受过更好培训的医生、个性化提供医疗服务的医生以及加速药物发现。</p>
<p>本章涉及由于人工现实的创建而产生的伦理问题，包括LLMs可能创建虚假的医疗记录或假诊断的风险，这可能导致误诊、保险欺诈，以及“感染”关键医疗数据和信息的噪声。它还讨论了可能伪装成医疗服务提供者的LLMs，这可能导致对患者护理的隐秘访问、轻易获取医疗冒充以及随后的资质认证和支付欺诈。最后，它还涉及深度伪造的风险。</p>
<p>意识到这些行为可能会产生需要主动解决的风险，本章最后强烈建议在医疗保健中需要监控LLM行为。它强调了强有力的保障措施的重要性，以防止恶意使用，例如彻底的代码审查流程、强大的访问控制以及对LLMs的开发者和部署者的明确伦理要求。最后，它指出公众教育和意识提升工作可能是使人们能够识别和报告可疑LLM医疗保健使用的关键组成部分。</p>
<p>本章指出了为LLMs发展伦理和隐私框架的重要性，即政府、行业和开源社区必须不断合作，制定与健康领域LLMs动态环境相适应的法规和最佳实践。通过对话、知识共享和合作制定一些明确的“道路规则”，我们可以为以伦理方式使用这些强大技术铺平道路。</p>
<p>总而言之，必须权衡LLM在医疗领域的变革潜力与其显著的风险和挑战，然后明确规划如何提前管理这些风险。通过鼓励建设性的讨论、创建更严格的保护措施和构建伦理框架，我们可以潜在地释放LLMs的创新潜力，以推动更好的临床结果。以这种方式使用它可以使世界更接近于为所有人创造一个更美好的未来——一个更健康和更公平的未来。确保LLMs在我们的医疗保健中理想地利用所有道德上良好和正确的事物，需要持续的对话、警惕和共同的努力。</p>
<p>1 参见 Pouyan Esmaeilzadeh, “基于人工智能工具在医疗保健中的应用：消费者视角的调查研究,” BMC 医学信息学与决策制定 20, no. 170 (2020), <a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1186/s12911-020-01191-1">https://link.springer.com/article/10.1186/s12911-020-01191-1</a>; 以及 Ashish K. Saxena, Stephanie Ness 和 Tushar Khinvasara, “人工智能的影响：人工智能在医疗保健领域的革命性影响,” 工程研究与报告杂志 26, no. 3 (2024): 49–62, <a target="_blank" rel="noopener" href="http://asian.go4sending.com/id/eprint/2020">http://asian.go4sending.com/id/eprint/2020</a>.</p>
<p>2 丹尼尔·康，“LLM 代理可以自主黑客网站，”Medium，2024 年 2 月 13 日，<a target="_blank" rel="noopener" href="https://medium.com/@danieldkang/llm-agents-can-autonomously-hack-websites-ab33fadb3062%E3%80%82">https://medium.com/@danieldkang/llm-agents-can-autonomously-hack-websites-ab33fadb3062。</a></p>
<p>3 “暗网，”维基百科，2024 年 6 月 4 日，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Dark_web%E3%80%82">https://en.wikipedia.org/wiki/Dark_web。</a></p>
<p>4 玛格丽特·米切尔，“伦理人工智能并不是谷歌Gemini灾难的罪魁祸首，” 时代，2024 年 2 月 29 日，<a target="_blank" rel="noopener" href="https://time.com/6836153/ethical-ai-google-gemini-debacle%E3%80%82">https://time.com/6836153/ethical-ai-google-gemini-debacle。</a></p>
<p>5 米切尔，“伦理人工智能并不是谷歌Gemini灾难的罪魁祸首。”</p>
<p>6 Bijit Ghosh，LinkedIn，个人资料，访问日期：2024 年 6 月 29 日，<a target="_blank" rel="noopener" href="https://www.linkedin.com/in/bijit-ghosh-48281a78%E3%80%82">https://www.linkedin.com/in/bijit-ghosh-48281a78。</a></p>
<p>7 约书亚·甘斯和杰弗里·S·斯科尔，“人工智能与回形针问题，”CEPR，2028 年 6 月 10 日，<a target="_blank" rel="noopener" href="https://cepr.org/voxeu/columns/ai-and-paperclip-problem%E3%80%82">https://cepr.org/voxeu/columns/ai-and-paperclip-problem。</a></p>
<p>8 由牛津大学的哲学家尼克·博斯特罗姆（2014 年）构思。</p>
<p>9 “什么是人工通用智能（AGI）？”谷歌云，访问日期：2024 年 7 月 9 日，<a target="_blank" rel="noopener" href="https://cloud.google.com/discover/what-is-artificial-general-intelligence%E3%80%82">https://cloud.google.com/discover/what-is-artificial-general-intelligence。</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/12/llmsClinical05/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/12/llmsClinical05/" class="post-title-link" itemprop="url">第五章 LLMs 在药物研发、公共卫生及其他领域</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-12 11:28:19" itemprop="dateCreated datePublished" datetime="2024-08-12T11:28:19+08:00">2024-08-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:06:06" itemprop="dateModified" datetime="2024-08-21T14:06:06+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>25 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>基于前几章讨论的面向患者和临床的用例，本章将拓展视野。我们将讨论如何部署大型语言模型（LLMs）来加速治疗药物的发现，通过探索科学文献和寻找有前景的分子。通过考察一系列用例，我们将探讨LLMs和生成性人工智能如何在制药研究和公共卫生等领域帮助不同的医疗保健利益相关者。</p>
<h1 id="制药研究与开发"><a href="#制药研究与开发" class="headerlink" title="制药研究与开发"></a>制药研究与开发</h1><p>人类生物学的本质使其难以解读，而寻找新药物则反映了这一复杂性。每个声明可能需要十年或更长时间来验证，每个声明的成本至少为十亿美元——平均而言，从实验室到药房货架，开发一种新药物需要 10 到 15 年及超过 10 亿美元的费用。研究人员常常经历失眠的夜晚和多年的反复尝试，以实现他们的目标，即使在他人怀疑他们时，他们仍希望找到改变生命限制或致命疾病进程的方法，最终为更多患者提供他们应得的健康生活。</p>
<p>配备多方面的人才和完善的工具，各类人类科学家就像分子建筑师 (图 5-1) 一样，构建成千上万全新的分子对象。药物开发也分为几个阶段：临床前、临床和批准销售药物。</p>
<p>所有这些阶段都有其自身的挑战，但一旦一个化合物克服了一个障碍，它就会进入下一个阶段。这种选择性的审查和淘汰过程促进了强大、全面且有效的药物的诞生，使其值得问世。因此，每一种新药在上市之前都经历了从发现、临床到监管批准的多阶段旅程。每个阶段都有其自身的障碍，候选分子必须在进入下一个阶段之前满足某些要求。事实上，这一严格的过程主要是为了确保最终上市的新药的安全性和有效性。</p>
<p><img src="/../asset_llmsclinical05/01.png">图 5-1. 制药研究与开发，分子建筑师</p>
<p>随着他们试图处理复杂且不断扩展的数据集，这些数据集变得越来越难以管理和解释，LLMs 很可能在制药研发中扮演重要角色。这些数据集包括：</p>
<ul>
<li>临床前数据： 在对人类进行药物测试之前，先在老鼠、蚂蟥和蟑螂上进行测试。</li>
<li>临床试验数据：在对研究药品进行的人体临床试验的所有试验阶段（1 至 3）中生成的数据（临床试验结果），包括安全性和有效性；药代动力学；生物标志物（例如，循环肿瘤细胞）；患者报告的结果测量。</li>
<li>真实世界数据 (RWD)：关于药物使用、结果和不良反应的信息，这些信息来自实际护理，包括电子健康记录和保险索赔数据。</li>
<li>基因组数据：包括对人类遗传学和基因组学进行测序或分析的数据，以识别新的药物靶点或生物标志物。</li>
<li>文献数据：从期刊文章、专利和会议海报中提取的数据，旨在帮助药物发现的化合物和靶点。</li>
<li>文献数据库：包含来自科学文献的药物、靶点、临床试验等经过整理的信息的数据库，如 ChEMBL、DrugBank 和 PubChem。</li>
</ul>
<p>制药研发中使用的数据集大小可能会因具体数据类型、研究阶段和整体项目范围而显著不同。例如，生物数据如基因：像 RefSeq这样的数据库包含数百万个注释的人类基因序列，每个序列的长度从几百到几千个碱基对不等。蛋白质数据银行（PDB）保存了数十万个蛋白质结构，文件大小从千字节到兆字节不等。单细胞测序实验的数据可以生成数 TB 的信息，而组织成像研究的数据量可能从 GB 到 PB 不等。化学数据，如小分子，包含数百万个潜在药物候选分子的库，每个分子的数据信息（结构、性质）通常占用 GB 的空间。</p>
<p>单个患者的临床数据，例如电子健康记录，可能从数百万到超过十亿位或字节不等。一个包含数百或数千名患者的临床试验可能需要数十或数百太字节的存储空间。影像学或其他高级生物标志物测量的复杂性可能使数据量增大数百倍。分析疾病情感或提及的社交媒体研究可能在千兆字节范围内，但大规模研究可能涉及太字节。</p>
<p>在这个规模下，数据的摄取和整合需要完全自动化。LLMs 可以扫描和解析来自不同来源的数据，包括临床试验数据、科学文献、公共数据库和电子健康记录。它们还可以清理和对齐不同格式和约定的数据。一旦数据被组织并放置在一致的结构中，LLM 可以构建表示数据集中实体之间关系的知识图谱。它可以帮助研究人员创建实体的地图，并轻松地在它们之间跳转，收集所需的所有信息。最后，LLM 可以分析大量数据，以发现隐藏的模式、趋势和相关性。</p>
<p>行业内正在进行大量努力，以构建专注于研发过程的LLMs和生成式人工智能。例如，Nvidia 最近推出了一款名为 &#x3D;&#x3D;MegaMolBART&#x3D;&#x3D; 的LLM，谷歌也有一个与医学相关的模型。Med-PaLM 和 Meta 的 ESM-2突显了生成式人工智能将加速发现过程。</p>
<p>无论是我们对症状的描述，还是医生对类似病例的历史，人工智能与医疗保健的关系都是理想的匹配，而LLMs提供了开启这一价值的关键。随着我们在LLMs方面的能力发展，LLMs的工业应用只会变得越来越多和深远——我们已经朝着更具针对性、高效和有效的医疗保健方法的未来迈进。</p>
<h2 id="药物发现"><a href="#药物发现" class="headerlink" title="药物发现"></a>药物发现</h2><p>通过将LLMs作为一个有价值的早期输入，我们可以帮助加快新药发现的速度，同时负责任地实施药物发现的开发方面。LLMS和生成性人工智能或许能引领下一代药物发现（图 5-2）。LLMs可能会预测药物候选者的特性，这些候选者可能不需要广泛且昂贵的动物测试，而人工智能可以处理来自此类实验的大型数据集。</p>
<p><img src="/../asset_llmsclinical05/02.png">图 5-2. 药物发现</p>
<p>化学数据库存在， catalog 了数百万种已知药物和天然化合物的结构和性质，以及它们的文献记录的性质和效果。LLMs 可以在这样的数据库、已发表的研究论文和临床试验数据上进行训练，以检测不同类型的药物具有哪些性质以及可能导致哪些结果之间的相关性。</p>
<p>关于各种化合物可能有多毒的数据可以被挖掘并用于训练LLMs，以根据新合成药物的特性检测患者的毒性风险。通过分析这些大型数据集，LLMs可以学习药物的化学结构、其在生物系统中的行为以及其潜在影响之间的相关性。它可以通过识别过去数据中的模式有效地推断疗效。LLMs可以评估给定药物候选物与靶标（蛋白质分子）结合的可能性，并可能预测其对某种疾病的疗效。因此，LLM可以掌握新识别的化学物质与已知毒性化合物之间的结构相似性，并将其作为尚待调查的潜在安全问题反馈。</p>
<p>已知有毒性的药物可能与新候选药物共享某种特定的结构特征，这使得具有相同结构的分子可能出现危险的副作用。现有药物的副作用数据也可以通过LLM进行捕获，并作为新候选药物的潜在副作用进行报告。新化合物可能最终可用作药物——甚至该候选药物可能会被优先考虑进一步资助——但对潜在严重不良反应的认识可能会使研究人员意识到某些候选药物比其他药物更具风险，从而促使他们寻找更合适的试验对象。</p>
<p>训练好的LLM可以用来预测所给分子结构的性质。为此，您需要向LLM提供潜在药物结构的信息，以便它预测其性质。LLM处理这些信息，然后得出确认或否定其作为新药适用性的信息。LLM可能会给出感兴趣性质的预测值（例如，疗效评分，高毒性风险），甚至能够建议结构上的变化，以增强药物的期望性质。LLM的预测并不总是正确的。</p>
<p>这些预测可能带有或不带有一定的信心水平，作为指导是有价值的，因此不应将其作为对化合物进行实验测试的替代。此外，在依赖LLM预测之前，验证和进一步调查的必要性不容忽视。LLMs正在不断发展。随着越来越多的数据可用和训练策略的改善，预计LLM预测的准确性和可靠性将随着时间的推移而提高。</p>
<h2 id="文献综述"><a href="#文献综述" class="headerlink" title="文献综述"></a>文献综述</h2><p>文献综述基本上是一项粗暴的任务，这将发挥LLM的优势：在大量论文中扫描关键词（图 5-3）。</p>
<p><img src="/../asset_llmsclinical05/03.png">图 5-3。LLMs 帮助审阅大量文件</p>
<p>LLMs 可以将众多研究的关键发现浓缩成简明的摘要，使研究人员能够快速掌握特定主题的当前知识状态。这为研究人员节省了宝贵的时间和精力，相较于手动审阅无数论文。LLMs 通过分析大型数据集，可以检测不同研究之间的模式和联系。这种检测帮助研究人员识别新兴趋势、潜在的知识空白以及与其他研究领域之间的关系。</p>
<p>LLMs 有助于提高准确性和全面性，并减少偏见。手动文献审查可能会受到无意识偏见的影响，研究人员可能会无意中优先考虑支持他们现有假设的研究。然而，LLMs 可以提供更客观的方法，分析所有相关文献，而不考虑其潜在发现。</p>
<p>手动审查可能耗时且容易出现人为错误，例如遗漏相关研究或误解信息。LLMs可以提供一种更一致和可靠的数据处理方式，降低错误风险。LLMs可以搜索多种语言和数据库，可能帮助研究人员发现来自不同地区和研究小组的研究，促进更全面的审查过程，融入多样化的视角。</p>
<p>LLMs 可以帮助研究人员在他们的研究团队内分享和发现相关文献，并与不同机构的同事合作。这可以加快研究的进程，确保每个人都了解最新的进展，并防止重复劳动。</p>
<p>LLMs 可以根据个人研究者的兴趣和研究重点定制和个性化文献综述体验，通过过滤掉不相关的信息，节省他们的时间和精力。</p>
<p>LLMs在准确性和可解释性方面存在局限性。LLMs依赖于其训练数据的准确性和质量。此外，理解它们如何得出结论可能具有挑战性，这需要仔细评估和人类专业知识。基础数据中的偏见可能会反映在LLM的输出中。解决这些偏见并确保负责任的使用至关重要。</p>
<p>总体而言，LLMs为药品研发中的文献综述提供了有价值的工具，能够简化和增强这一过程。它们处理大量数据、减少偏见和促进协作的能力，对加速科学发现和药物开发具有重要潜力。</p>
<h2 id="临床试验招募"><a href="#临床试验招募" class="headerlink" title="临床试验招募"></a>临床试验招募</h2><p>招募临床试验参与者需要找到既感兴趣的人员，又符合特定研究标准的人。通常这需要以下步骤：</p>
<ol>
<li>通过研究患者群体识别潜在参与者，并了解目标人群的特征，包括年龄、性别和医疗状况。</li>
<li>使用标准来识别那些可以和不能根据健康状况、病史和当前药物进行研究的人。</li>
<li>根据研究的不同，可能会向医生或患者倡导团体进行宣传，或进行招募广告。</li>
<li>一旦潜在参与者被确定，这些候选人将收到材料——从宣传册或网站到社交媒体活动——这些材料概述了研究，说明了目的，提到了谁在监督，以及可能的好处和风险。</li>
<li>接下来是预筛选，这涉及到初步评估，以查看某人是否符合一套非常基本的标准，这可能使他或她有资格。</li>
<li>教育潜在参与者并获得知情同意，在与研究人员进行详细讨论时，研究人员会解释研究内容，回答问题并解决疑虑。所有参与的受试者都被要求签署一份同意文件，表明他们理解研究的性质并自愿选择参与。</li>
<li>资格必须通过更详细的医学评估来评估，以确定该人是否满足纳入标准。</li>
<li>一旦确认资格，参与者将正式注册参加研究。</li>
</ol>
<p>参与者的招募必须遵循规定，并具备伦理性，以保护参与者的权利和安全。招募方法需要根据环境（例如，临床与社区）和相关患者群体（例如，儿童与成人）进行调整，并通过多种沟通渠道（例如，面对面、在线、电话）进行。招募通常很困难，往往需要多种方法才能达到足够的参与者目标数量。</p>
<p>生成性人工智能和LLMs可以帮助简化研究方案的招聘。结合LLMs的自然语言处理（NLP）可以通过实现前期检查和资格筛选的自动化来促进参与者的高效招聘。LLMs固有的执行 NLP 和理解的能力使得可以使用互动聊天（见图 5-4）或在线智能问卷来预先接触研究参与者，以收集与参与者人口统计相关的必要信息并进行初步资格检查。这种自动化的预筛选程序可以减少传统参与者招聘中手动“冷拨打”过程所需的努力，从而加快参与者招聘阶段，并允许更精细地将参与者与各自的研究匹配。</p>
<p><img src="/../asset_llmsclinical05/04.png">图 5-4. 使用 LLM 聊天机器人来简化临床试验招募</p>
<p>LLMs 可以根据人口统计、病史、语言和其他因素个性化患者沟通。这将有助于提高适当的参与度和共鸣。生成性人工智能和 LLMs 可以以简化的方式呈现试验的目的、潜在好处和风险，同时保留涵盖整个临床情况所需的复杂性。这将有助于消除混淆、促进讨论并提高决策能力。</p>
<p>参与的障碍包括交通困难或儿童看护挑战。换句话说，LLMs 可以扫描过去的招募数据，以发现参与的障碍——例如，如果人们因为工作或上学而无法参与研究，如果他们不会说英语，或者如果他们没有交通工具。由此，他们可以识别出人口特征（例如，生活经历）或调整试验的后勤或设计，以帮助管理这些障碍。通过提供翻译和多语言宣传，LLMs 可以通过招募更多人来增加参与度，并确保代表性不足的社区能够参与。</p>
<p>临床试验招募面临几个挑战：</p>
<ul>
<li>确定足够的受试者是一个主要障碍，特别是对于罕见疾病或具有严格资格标准的试验。试验可能因需要更多样化的参与而受到延迟，因此结果可能会偏差，因为它们可能无法推广到更广泛的人群。此外，患者可能会因复杂的试验方案、旅行要求和漫长的程序而感到负担，从而导致参与减少和退出。</li>
<li>研究、开发和监管障碍使试验成本高昂，限制了可及性和创新。</li>
<li>冗长复杂的协议增加了行政负担和出错的可能性。</li>
<li>在不同国家之间应对各种监管要求可能耗时且资源密集。</li>
<li>在涉及多个地点和记录多样化人群时，以统一的方式记录数据尤其困难。</li>
<li>确保数据完整性和防止在试验过程中不当行为至关重要。</li>
<li>确保参与者充分理解参与的风险和收益至关重要。保护儿童或孕妇等弱势群体需要额外的伦理保障。考虑所有人群如何获得公平的临床试验机会也很重要。</li>
</ul>
<p>LLMs和生成性人工智能的前景可以通过多方面的新方法来提升临床试验招募的旧模式，以缓解瓶颈：改善研发、协助患者招募和参与、帮助试验设计和分析，甚至让人们看到潜在的监管合规性改善。一些新方法包括：</p>
<ul>
<li>通过自动化文档生成来简化研发。GenAI 可以自动生成研究方案、临床总结和监管报告，为研究人员节省大量时间和资源。</li>
<li>GenAI 可以在大量研究信息的数据集中发现模式，并帮助研究人员优先考虑相关信息，指导他们的决策并加速发现。</li>
<li>GenAI 可以分析患者数据，并提供以往临床试验的见解，以创建有针对性和个性化的宣传活动，鼓励参与相关试验。</li>
<li>人工智能驱动的虚拟助手和聊天机器人可以用来回答患者的问题，并在整个试验过程中提供持续支持，从而提高参与度和留存率。</li>
<li>GenAI 可以使用虚拟模拟建模各种试验场景，以预测结果，从而设计高效有效的研究。</li>
</ul>
<p>在实时情况下，人工智能可能会分析大量试验数据，发现安全信号、疗效标志以及可能出现的趋势，从而实现实时决策。提高合规性是应用LLM的另一个好处，因为可以进行自动化的监管报告：对于法律或操作上要求的报告，使用基准并通过机器学习生成文本的系统可以实时创建准确且合规的报告，从而减少潜在错误并缩短审批过程。</p>
<p>人工智能可以处理试验数据，同时审查法规，以识别可能使合规性面临风险的因素，并在任何违规行为发生之前加以处理。</p>
<p>GenAI 为提高临床试验的效率、有效性和包容性带来了令人印象深刻的可能性，但在整个临床试验生命周期中需要更大的伦理警惕。LLMs和 GenAI 并不是为了取代人类决策者。相反，它们应该作为一种工具来增强人类能力，并促进在整个临床试验过程中负责任的决策。</p>
<h2 id="制药商业"><a href="#制药商业" class="headerlink" title="制药商业"></a>制药商业</h2><p>这里有一个准备好进行创新的领域：过于冗长、过于无聊的药品广告。很快我们将看到大量的LLMs和生成式人工智能，这将为制药公司提供多种方式来丰富产品向医疗专业人员和患者的传播。</p>
<p>一些经历的幽默卡通描绘在图 5-5卡通中。这幅卡通是对直接面向消费者的药品广告的讽刺，这些广告通常在深夜或清晨时段的电视上播出。男人恼怒的反应很能说明人们如何体验直接面向消费者（DTC）的药品广告。消费者值得更好的。</p>
<p><img src="/../asset_llmsclinical05/05.png">图 5-5. 深夜药品广告</p>
<p>LLMs 可以帮助消费者理解和解读我们在深夜电视上观看的充满动作的药品广告中传达的信息，这些广告宣传处方药，并且法律要求提供关于限制和可能副作用的信息，这些信息通常复杂、令人困惑，甚至可能对普通观众来说有些过于繁琐。LLMs 可以将药品广告中常见的医学术语和词汇翻译成更自然的文本，让消费者理解药物的必要性、作用原理和潜在副作用。</p>
<p>许多制药公司采用一种销售模式，依赖制药代表的销售团队直接拜访医生，向他们推销公司的产品。这种被称为“制药零售”的一对一营销方式，涉及销售代表前往与医生会面，目的是说服他们开处方使用自己公司的药物，通过宣传他们了解到的药物的好处和疗效。零售是一种密集的、针对性的营销策略，制药公司用它来推广并直接影响医生开出的处方。</p>
<p>此外，制药代表可能会向医疗提供者提问，并将这些问题转交给医学事务团队，以请求对医生问题的具体科学回答；制药代表成为制药公司的人工代表。获得医生接触权限的代表可能会更加高效。</p>
<p>现在想象制药公司和医疗服务提供者与客户——提供者、患者和其他相关方——直接沟通和互动，以使信息交换按照他们的需求进行。设想提供者能够立即获取他们所需的信息，以提供最佳的患者护理。想象一个基础设施，使这一切对提供者和患者都变得更容易，并让更多患者更好地获得他们所需的治疗和疗法。对个别提供者、患者和公司而言合理的制药客户互动意味着对所有人来说更好的价值。适时的正确数据可能意味着适时的正确干预。</p>
<p>制药公司的未来商业模式需要在方法上进行根本性的转变。这种新模式要求制药公司：</p>
<ul>
<li>认真倾听市场需求</li>
<li>预测趋势和挑战</li>
<li>主动采取措施应对这些需求和挑战</li>
</ul>
<p>这个不断发展的模型应该专注于客户特定的参与。它应该在整个组织中嵌入，而不仅仅是销售代表的责任。这些变化代表了一次重大的转型，而不仅仅是小的调整。未来的制药商业模型将：</p>
<ul>
<li>将关注点从开处方者扩展到所有医疗保健利益相关者，包括患者、支付方和医疗保健系统</li>
<li>从以产品为中心的方式转向以客户为中心的方式，优先考虑解决特定医疗需求的方案</li>
<li>采用以医疗保健为中心的焦点，摆脱传统的销售代表驱动模式，转向一种更全面的方法，考虑整个医疗保健生态系统</li>
</ul>
<p>这一转型旨在为医疗系统中的所有利益相关者创造更多价值，同时适应不断变化的市场动态和客户期望。</p>
<p>利用电子健康记录、索赔数据和处方数据等多种数据来源，制药公司将利用人工智能来理解和帮助患者及医疗提供者提供变革性的体验。通过深度学习，LLM 系统可以处理这些大型数据资产，从而为战略提供信息。</p>
<p>通过从这个过程中获得的学习，生成性人工智能可以为每个利益相关者创造完全个性化的互动：对于患者，可以量身定制关于他们病情的教育；对于提供者，生成性人工智能可以生成定制的面板信息，以促进更好的处方。因此，以洞察和互动为驱动的商业战略利用人机协作的过程，加速发现增值疗法，同时不断转变商业模式。LLM 知识和生成性创造力因此更好地服务和吸引不同的利益相关者，以提供更好的获取、教育和结果。</p>
<p>新模型需要全面转变，以更加以患者为中心、信任挖掘、情境感知、个性化并具规模化。这意味着要从以产品驱动和销售主导的干扰模型演变为以情境驱动和战略及技术主导的人物模型。这将使制药营销能够利用数据并持续收集更多数据。尽管数据驱动和全渠道营销在制药行业并不是新概念，但基于生成性人工智能的商业模型需要对营销策略进行根本性的重新设计。这种新方法要求以客户为中心的组织，目标是真正的个性化。为了实现这一目标，当前的营销方法需要提炼为两个核心组成部分：</p>
<ul>
<li>产品策略：开发和阐明产品的独特价值</li>
<li>客户体验创造：打造个性化体验，以向客户展示这一价值</li>
</ul>
<p>这种“简化点击”或简化方法允许更专注和实用的方式，使制药公司能够利用生成性人工智能制定与个别客户产生共鸣的量身定制的营销策略。</p>
<p>GenAI 和 LLMs 也可以在未来两到五年内通过以下方式颠覆营销：分析来自不同内部和外部来源的大量上述数据，以创建个性化的目标营销活动，并创造创新的新营销方法。</p>
<p>我们建议创建一个 GenAI 聊天机器人或“倾听引擎”，以实现对客户的全面理解和更深层次的个性化服务。我们的倾听引擎由一个单一的智能数据平台组成，汇集了所有新旧客户体验数据点的洞察，并结合了优惠&#x2F;行动号召的有效性，在需要时进行倾听和响应。</p>
<p>利用建立在集成基础设施上的先进数据处理能力，监听引擎可以将来自传统和新数据源的输入和反馈汇聚到一个单一平台，并与学习机器学习引擎融合。这使得组织能够利用以前未开发的数据流，发现优化客户体验的新投资领域，或揭示客户健康的关键信号，以便在大规模上采取预防性的客户恢复行动。</p>
<p>这些可以通过个性化的交易和对话与客户提供高度规模化和个性化的互动。因此，我们提出的更好理解客户关系的设备基础在于整合新旧数据源。然而，为了实现这种更深层次的关系映射，需要新的架构能力。这些新系统最复杂的使用方式是整合新数据源的洞察，以创建个性化的、针对性的营销活动和新的创新营销方法。</p>
<p>但倾听只是故事的一半。公司正在投资和部署基于生成性人工智能和人工智能的系统，这些系统可以将这些洞察转化为以战略为导向的建议，关于“什么”和“如何”进行沟通。采用基于人工智能的商业模式使商业团队在竞争激烈的市场中处于差异化的位置。通过使用生成性人工智能，公司可以推动增长、成功推出和灵活性的商业目标，同时实现更好地服务患者的关键社会目标，通过更有效地解决医疗需求，从而改善健康结果。</p>
<p>一个LLM可以生成关于特定疾病、药物方案和可能治疗的准确且更简洁的教育材料，使用户能够获得做出更明智健康决策所需的信息。LLMs甚至可以被构建成一个机器人或其他人工智能助手，患者可以就任何他们想要的话题进行提问或查询，并获得个性化的信息。此外，患者还可以直接从制药公司获取信息——快速且非正式。</p>
<p>LLMs 可以评估过去的市场数据和新兴趋势，以预测特定类型营销活动的目标市场覆盖率，使公司能够以最具成本效益的方式设计和优化营销活动。LLMs 可能用于根据监管指南评估营销材料的内容准确性和道德信息。</p>
<h1 id="公共卫生"><a href="#公共卫生" class="headerlink" title="公共卫生"></a>公共卫生</h1><p>公共卫生是一个专业实践和科学领域。它通过多种方法保护和改善人们和社区的健康，包括促进健康生活方式、预防疾病和伤害，以及提供医疗服务的获取。</p>
<p>公共卫生可以分为几个子类别：疾病监测；健康教育与促进；心理健康；以及公共卫生准备与应对。</p>
<p>公共卫生包括为确保人、社区和人群的身体、心理和社会福祉而采取的所有组织措施。</p>
<h2 id="疾病监测"><a href="#疾病监测" class="headerlink" title="疾病监测"></a>疾病监测</h2><p>使用LLMs可以通过快速梳理来自各种来源的大量健康数据，识别可能表明即将爆发或疾病趋势变化的细微信号，从而实现更快、更好的疾病监测。例如，LLM可能会扫描多年的急诊室记录、新闻报道、社交媒体帖子和区域内的搜索引擎查询，捕捉与传染病历史活动相关的病例描述中的微妙语言变化。它们可以标记来自LLM的相关数据，这些数据在早期发现新感染方面远远超过当代监测。</p>
<p>图 5-6 是一个示例，使用图标表示“监视”这一主题下的许多分类因素。</p>
<p><img src="/../asset_llmsclinical05/06.png">图 5-6. 疾病监测</p>
<p>图标之间的箭头表明，监测是一种跟踪和监控这些健康决定因素之间关系和互动的行为。图表的主要观点是，公共卫生监测是一个复杂的系统，通过收集和分析关于广泛健康决定因素的数据，以评估和应对人群中的健康问题和威胁。</p>
<p>一旦训练完成，LLMs可以在数据库中搜索关于症状和疾病的社交媒体和在线论坛的评论和报告。当它们发现相关的关键词、短语和地点时，可以向公共卫生官员标记疾病爆发的早期指标，使官员能够动员资源调查可能的爆发，以防止其发展成大规模流行病。</p>
<p>内置于LLMs的生成式人工智能功能可以帮助展示疾病传播的场景。图 5-7 说明了疾病的传播是如何从一个人开始并扩散到许多人的。</p>
<p><img src="/../asset_llmsclinical05/07.png">图 5-7. 建模传染病</p>
<p>对传染病进行建模场景使研究人员能够模拟干预策略（如疫苗接种活动、旅行限制或社交距离措施）的潜在影响。目标是利用模拟场景来识别和设计有效且有针对性的干预措施。借助电子健康记录和公共卫生数据库以及旅行记录等数据，LLMs可以发现人眼难以察觉的模式，并对疫情爆发及其传播的最有效途径做出预测，以便官员能够将资源应用于最需要的地方。</p>
<p>LLMs 可以与接触追踪系统一起使用，其中 LLMs 筛选通话记录、旅行历史和其他信息，以确定谁可能接触过该疾病，或创建风险评估，其中使用年龄、地址和潜在健康状况等数据来开发生成性人工智能模型，以预测谁可能面临特定疾病的风险</p>
<h2 id="健康教育与促进"><a href="#健康教育与促进" class="headerlink" title="健康教育与促进"></a>健康教育与促进</h2><p>LLMs 可以筛选大量的医学文献和健康数据，生成针对不同受众的健康教育材料。一个人类作者无法将数千万篇研究论文摘要、数千个临床试验和数百个人口数据集中的见解综合成信息手册、网站和健康材料。</p>
<p>生成性式工智能工具还可以帮助将健康教育内容调整为特定读者。通过向人工智能提供个人或群体写作的样本，它可以模仿他们的语气和语言模式，使信息更加易于理解。这有助于克服常常阻碍健康沟通的读写和计算障碍。生成的文本将显得更为熟悉，而非临床化，从而使人们更好地理解风险、预防选项、症状、治疗等信息。</p>
<p>插图 (图 5-8) 描绘了一位健康教育者或医生，其角色涉及使用数据、研究和先进技术（例如，LLMs）来教育他人关于健康主题并提供医疗指导。LLMs 和生成式人工智能都可以制作互动媒体、聊天机器人和对话应用程序，用作健康教育者。这些可以在各个群体中大规模提供个性化的健康建议。</p>
<p><img src="/../asset_llmsclinical05/08.png">图 5-8.现代健康教育的多面性</p>
<p>此外，随着研究的发展，LLMs和生成性人工智能可以迅速更新各种健康教育资源，包括小册子、视频、播客和互动工具。这种动态性使公众能够及时了解饮食、锻炼、吸烟、心理健康、常见疾病和疾病流行病学等领域的范式转变。</p>
<p>虽然LLMs为公共健康教育提供了一个有前景的途径，但重要的是要记住，它们不能替代人类的专业知识。确保这些模型生成的信息的准确性和可信度，以及保持人类的监督和解决其中可能存在的偏见，是负责任实施的关键方面。</p>
<h2 id="心理健康"><a href="#心理健康" class="headerlink" title="心理健康"></a>心理健康</h2><p>心理健康是公共健康的重要组成部分。LLMs和生成式人工智能正在为使用LLM驱动的聊天机器人和虚拟助手提供 24&#x2F;7 的基本心理健康信息和资源的更大可及性和早期干预开辟空间，特别是在心理健康支持获取有限的地区。</p>
<p>生成式人工智能生成针对性和无限内容的能力可以被利用来创建个性化的聊天机器人和治疗工具，这些工具可以根据个人的具体需求调整其响应和干预。它可以被设计来尝试以下活动：</p>
<ul>
<li>LLMs 可以识别用户输入中的情感困扰，并以同理心的语句作出回应，这是一种源自认知行为疗法的技术。</li>
<li>LLMs 可以个性化教育，并指引学习者寻求帮助，无论是自助书籍、支持小组还是专业帮助。</li>
<li>聊天机器人可以被编程来与你联系，跟踪你的成功，并鼓励你练习应对机制和自我管理策略。</li>
<li>LLMs 可以用于设计以心理健康问题为中心的学习和宣传材料及活动，促进寻求帮助的正常化，并减轻污名。这包括为不同背景的年轻人和成年人创建合适的内容。</li>
</ul>
<p>然而，我们必须指出，这些技术并不完美，需要谨慎实施。LLMs和生成式人工智能技术不能替代心理健康专业人员的工作。它们并不旨在治疗严重的心理健康问题。数据保护是另一个主要问题。一旦开发者和临床医生制作了预测或治疗心理疾病的模型，谁可以访问这些模型？如何使这些模型的开发更加透明，并进行透明的同行评审？患者数据集是否会被严格匿名化，如何保证这一点？在心理健康方面，必须理解和解决一整套伦理挑战。</p>
<h2 id="灾害准备与应对"><a href="#灾害准备与应对" class="headerlink" title="灾害准备与应对"></a>灾害准备与应对</h2><p>在危机期间——无论是来自飓风、野火还是疾病爆发——公共卫生组织必须迅速启动多层次的应对计划。一个LLM可以被训练快速分析成千上万份描述资源和程序的文件，这些文件涉及在无数场景下的供应、设施、人员和流程，并绘制出针对事件优化的协调策略蓝图。这可以在几秒钟内完成，以便后续人类审查和行动。</p>
<p>同样，生成性人工智能可以提出超出历史上常见的任何灾难场景。通过生成模拟灾难（如 6 级飓风、新型流感病毒），应对规划者可以在真正的悲剧到来之前进行压力测试，找出救援策略中的低效之处。生成性人工智能的场景创建能力提供了与准备相关的极端创造力。</p>
<p>LLMs 可以发挥作用的任务之一是生成自然听起来的文本通信，例如公共服务公告、社交媒体警报和包含位置优化的“了解您的风险”以及应对灾害威胁的行为指导的小册子。清晰及时的沟通可以挽救生命，而这正是人工智能通过自动生成针对脆弱人群或残疾人士等群体量身定制的内容所能提供的。</p>
<p>在危机发生前、期间和之后，LLM或生成式人工智能模型可以获取关于威胁和应对措施的最新信息。通过人工智能监测和建模提供的更早预警，预防性响应可以更快发生。即使是快速的人工智能内容生产，在更早地向公众传达时，也能提供对新兴风险的更全面了解。通过这种方式，公共卫生机构可以超越灾难，避免在应对潜在公共健康风险时以往必须面对的人力资源转移的滞后时间。</p>
<h1 id="基因组学"><a href="#基因组学" class="headerlink" title="基因组学"></a>基因组学</h1><p>基因组学在理解和治疗各种疾病方面具有巨大的潜力。随着基因组学研究的成熟，今天和未来，分析和解释这庞大的数据量可能会非常具有挑战性。LLMs 正在学习基因组学的语言。</p>
<p>分析、理解和应用基因组学的知识需要筛选大量数据集，这些数据集涵盖 DNA 序列、基因表达模式、蛋白质结构以及与性状和疾病的复杂关联（图 5-9）。通过吸收数百万篇论文和数据集，LLMs可以揭示遗传学中的隐藏联系，以推动发现和实际应用。</p>
<p><img src="/../asset_llmsclinical05/09.png">图 5-9.利用基因组学改善患者健康</p>
<p>例如，一个LLM可以将一个几乎未被研究的基因序列与一篇提出其在癌症通路中作用的晦涩学术论文联系起来。或者，它可以在历史医疗记录中找到突变与临床结果之间的相关性。这些见解加速了基础生物学向临床遗传学和针对每位患者基因组量身定制的个性化医学的转化。</p>
<p>强大的生成式人工智能系统可以在设计潜在实验以验证基因关联、模拟潜在基因治疗的试验以及估计不同基因特征的治疗效果方面提供很大帮助。</p>
<p>DNA 测序技术和 CRISPR 基因编辑7使科学家能够选择性地修改生物体的 DNA，并且这些技术也在以惊人的速度发展。这些技术为更有效的基因研究、潜在的新疗法甚至遗传疾病的治愈打开了大门。</p>
<p>但日益增加的基因组数据、设想新疗法的丰富机会以及从根本上重塑整个医疗系统的潜力，都受到了一种现象的阻碍，许多人对此意识到得太晚：大数据在没有大人工智能的情况下是毫无意义的。</p>
<p>这里是LLMs和其他形式的创造性计算分析的地方，包括通过大量基因组信息揭示模式、预测未来结果和生成新假设的人工智能工具，这些工具已经准备好大幅加速新药靶点、新疾病机制和新治疗途径的发现。</p>
<p>此外，针对人工智能驱动工具的自然语言接口可以帮助缩小基因组发现与如何使用这些发现之间的临床差距。将基因组数据与其他患者信息（既往病史、生活方式和环境暴露）相连接，LLMs 可以生成个性化的风险档案、治疗方案或精准医疗策略。这些方法可以开启下一代医疗保健，在开处方时考虑患者独特的基因组构成。未来，医生可以根据个体独特的基因组量身定制治疗，可能加速康复并最小化不良反应。</p>
<p>人工智能可以帮助实现基因组洞察的民主化，不仅仅是通过加速发现和为个性化医疗提供基础。如果基因组数据能够通过易于使用的界面或基础人工智能（例如由LLMs驱动的智能聊天机器人）在病床旁呈现，医疗界以及患者自己都可以学习以易于理解的方式访问和互动这些信息。患者将能够利用可用的基因组数据做出关于自己健康的明智决策，参与科学研究和临床试验，并倡导精准医疗。</p>
<p>但要让基因组医学发挥其潜力，并让基因组学通过人工智能实现其全部承诺，解决一系列关于伦理、法律和社会的问题至关重要。毕竟，这些数据是关于人类的，不能忽视对数据隐私的担忧、知情同意的问题或对基因组技术的公平获取。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>LLMs 和生成式人工智能在推动制药研发和公共卫生工作方面具有广泛的应用。在药物发现中，它们可以分析药物化合物、蛋白质结构和效果之间的联系，以识别有前景的候选药物。在文献分析中，LLMs 能够快速综合数百万篇论文的见解，以得出药物项目成功的概率。在临床试验中，LLMs 通过评估基因组和健康记录来增强目标患者群体的招募。在商业方面，生成性人工智能制作增强的营销材料，以突出已证明的药物益处并改善药物的接受度。</p>
<p>在疾病监测中，LLMs 通过大规模获取人口健康信号来检测疾病传播的早期预警信号。对于公共卫生教育，LLMs 动态生成针对个人的风险、症状和预防的可获取材料。围绕心理健康信息和减少污名，生成性人工智能合成适应文化细微差别的内容。灾难准备利用生成性危机模拟，并结合 LLM 对应对措施的分析，以优化应急计划。</p>
<p>基因组工作流程正处于通过LLMs和生成实验实现指数效率提升的良好时机。大规模连接 DNA 数据与性状和疾病为转化医学和个性化医学提供了洞察。人工智能通过合成 DNA 数据集的生成加速了遗传工具的创建。总体而言，人类与人工智能的合作为全球社会带来了变革性医疗进步的可能性。</p>
<p>本章强调了多个高影响力的细分领域，在这些领域中，嵌入LLMs和生成式问题解决将推动医疗研发、治疗获取、预防教育、公共卫生韧性和基因组进步的飞跃。技术成熟度、数据增长和紧迫的现实世界优先事项与时效性交汇，积极追求这些LLM人工智能机会。</p>
<p>1 “研究与开发政策框架，”PhRMA 基金会，2024 年 1 月 22 日，<a target="_blank" rel="noopener" href="https://phrma.org/en/policy-issues/Research-and-Development-Policy-Framework%E3%80%82">https://phrma.org/en/policy-issues/Research-and-Development-Policy-Framework。</a></p>
<p>2 “RefSeq: NCBI 参考序列数据库，”国家医学图书馆，访问日期 2024 年 6 月 28 日，<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/refseq%E3%80%82">https://www.ncbi.nlm.nih.gov/refseq。</a></p>
<p>3 wwPDB，访问日期为 2024 年 6 月 28 日，<a target="_blank" rel="noopener" href="https://www.wwpdb.org./">https://www.wwpdb.org。</a></p>
<p>4 “MegaMolBART，”英伟达，2023 年 11 月 27 日，<a target="_blank" rel="noopener" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/megamolbart%E3%80%82">https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/megamolbart。</a></p>
<p>5 “ESM 元基因组图谱：蛋白质宇宙‘暗物质’的首次视角，” Meta，2022 年 11 月 1 日，<a target="_blank" rel="noopener" href="https://ai.meta.com/blog/protein-folding-esmfold-metagenomics%E3%80%82">https://ai.meta.com/blog/protein-folding-esmfold-metagenomics。</a></p>
<p>6 安东尼·科斯塔和尼古拉斯·洛佩斯·卡兰萨，“基因组 LLMs 在多种任务中表现优越并具有良好的泛化能力，”Nvidia Developer，2023 年 1 月 12 日，<a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/genomic-llms-show-superior-performance-and-generalization-across-diverse-tasks%E3%80%82">https://developer.nvidia.com/blog/genomic-llms-show-superior-performance-and-generalization-across-diverse-tasks。</a></p>
<p>7 迈克·史密斯，“CRISPR”，国家人类基因组研究所，2024 年 6 月 28 日，<a target="_blank" rel="noopener" href="https://www.genome.gov/genetics-glossary/CRISPR%E3%80%82">https://www.genome.gov/genetics-glossary/CRISPR。</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/11/llmsClinical04/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/11/llmsClinical04/" class="post-title-link" itemprop="url">第四章 LLM 及生成式人工智能的患者和临床潜力</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-11 16:24:19" itemprop="dateCreated datePublished" datetime="2024-08-11T16:24:19+08:00">2024-08-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:05:34" itemprop="dateModified" datetime="2024-08-21T14:05:34+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>20k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>37 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最新的人工智能设计范式——包括代理推理和大语言模型（LLM）及生成式人工智能提示的大上下文窗口——将从根本上改变医疗应用程序的性质和功能。下一代人工智能系统不会在一夜之间对医疗保健产生根本性的变化。这些系统至少需要五到七年或更长时间才能投入运行。</p>
<p>一些主要的变革驱动因素可能会来自初创公司和其他科技公司。许多这些公司并不像大型医疗公司那样受到惯性和风险规避的束缚，它们可能是新技术渴望寻找的早期采用者，这些新技术尚未证明其投资回报率。另一方面，传统医疗公司可能会更加谨慎，可能会在这些技术在市场上证明自己并被视为安全和财务稳健时才会进入人工智能领域。</p>
<p>然而，具有讽刺意味的是，随着科技跨国公司和初创企业通过将人工智能融入医疗保健创造出多样化成功的关键规模，这些积极的成果将渗透到更广泛的领域。随着回报开始积累，医疗保健公司将朝着能够帮助他们提供更好护理的人工智能解决方案发展，同时保持竞争力。未来几年将见证初创企业的商业精神与其“快速行动和打破常规”的世界之间的紧张关系，这与一些大型医疗保健公司在行动上需要更加谨慎的缺点形成鲜明对比。它们之间的合作与竞争将展开，医疗保健的未来必将从中浮现，因为人工智能的应用有助于提高患者结果的新质量标准以及医疗服务的整体效率和个性化。</p>
<h1 id="患者体验"><a href="#患者体验" class="headerlink" title="患者体验"></a>患者体验</h1><p>患者体验是指患者在与医疗系统互动过程中更广泛的感知和感受。它涵盖了从预约到与工作人员互动、物理环境到接受护理的方方面面。它关注旅程中的情感和心理方面，包括尊重、沟通、同理心和整体满意度等因素。可以说，许多医疗系统和应用需要关注患者体验，而这正是LLMs可以产生巨大差异并改善患者护理的地方。以患者为中心的护理优先考虑积极的医疗体验，提供了固有的价值，并带来了超越单纯感知的连锁效益。研究证实，患者满意度与关键的下游结果直接相关，如治疗依从性、参与健康管理，最终影响临床结果。</p>
<p>本节描述的用例侧重于改善患者体验的应用程序。LLMs 和生成式人工智能将以多种方式改善患者体验。LLMs 可以根据每位患者的偏好、学习风格和背景生成复杂健康主题、程序和药物问题的定制解释。LLM 和生成式人工智能聊天机器人、语音助手以及虚拟形象界面提供 24&#x2F;7 支持，方便安排预约、连接医疗记录、解答账单问题以及解决其他麻烦。</p>
<p>LLMs 可以通过审查纵向记录、提示患者和提供者跟进未解决事项，以及重新审视过去就诊中未解决的症状，来提供护理连续性，以防止患者“掉入裂缝”。情感设计的 LLMs 积极倾听并对患者的背景做出同情回应，不仅限于医疗历史，可以使互动更加支持性。LLMs 可以自动化行政和临床文档以及文书工作，使提供者能够更多地专注于与患者的面对面交流，并减少等待时间。</p>
<p>LLMs 和生成式人工智能为系统性简化协调麻烦和综合个性化见解提供了机会，帮助患者感到被理解。人工智能可以以患者自己的节奏与他们沟通，使用他们理解的语言，这可能会导致他们在自身健康管理中的更好参与。未来提供了更光明、无障碍的患者体验。接下来，我们将描述一些未来新兴应用的例子，这些应用将引领这种新的患者体验。</p>
<h2 id="健康机器人礼宾服务"><a href="#健康机器人礼宾服务" class="headerlink" title="健康机器人礼宾服务"></a>健康机器人礼宾服务</h2><p>想象一个医疗系统，在这个系统中，患者能够获得个性化的支持，理解复杂的医学术语，并快速应对行政障碍。这是生成式人工智能对话聊天机器人、富有同情心的人工智能伴侣以及一类智能助手所承诺的未来，这些助手有望彻底改变医疗保健领域。这些机器人——由深度学习、LLMs和自然语言处理（NLP）驱动——与用户进行真实的对话，理解他们的问题，并用上下文相关、类人语言进行回应。它们的应用超越了简单的客户服务，转变了第一线分诊、慢性病管理和心理健康支持。健康机器人礼宾服务，如图 4-1所示，将是实现LLMs和生成式人工智能的早期用例之一。</p>
<p><img src="/../asset_04ClinicalPotential/01.png">图 4-1. 健康机器人礼宾服务</p>
<p>在疾病严重程度轻微的情况下，聊天机器人可以充当在家患者的分诊顾问，讨论他们的症状以确定最佳护理方案。你有没有想过未来的分诊会是什么样子？我们不再需要忍受充满流鼻涕患者的候诊室，而是可以与聊天机器人讨论我们的喉咙痛，聊天机器人可能会建议一些舒缓的蜂蜜和柠檬，或者是否值得拨打电话进行数字虚拟咨询。</p>
<p>除了分诊，算法还可以作为虚拟个人健康教练，评估从可穿戴设备或症状后期问卷收集的信息，并根据个性化建议推荐日常活动或服药时间表，以改善情绪和警觉性、睡眠模式和疼痛。想象一下，一个聊天机器人每天向患者发送健康指标。如果血糖读数上升，它可以提醒你在一小时内注射胰岛素，或者询问你“你今天感觉怎么样？”聊天机器人可能会提出一些拉伸的建议，以帮助你在睡前放松心情，从而获得更清新和更长的睡眠。</p>
<p>对于有慢性健康问题或心理健康问题的患者，这些聊天机器人可以提供无与伦比的支持。例如，想象一下你每天收到来自健康人工智能教练的鼓励信息，它会检查你的情绪健康，给你励志名言等。针对老年人的聊天机器人可以成为社交互动和心理刺激的来源，还可以帮助预防和治疗抑郁症，而抑郁症在老年人群体中更为常见。</p>
<p>但员工也有好处。生成式人工智能聊天机器人有潜力缩小医生与患者之间的差距；一些疾病如此复杂，如果你信任你的医生，重新用简单语言改写聊天内容可能会很有帮助。你不必在医学术语中挣扎，想知道医生所说的这个或那个是什么意思，或者稍后试图回忆他让你现在记住的事情。想象一下，聊天总结了信息，强调了重要的关键词，以粗体字显示，使下一步变得易于理解。你离开房间时完全明白。</p>
<p>大多数患者畏惧的行政任务可以通过聊天机器人日益增加的使用而转变。生成式人工智能聊天机器人在医疗保健中的应用仍有许多前景，随着算法的学习和改进，这种应用只会增加。个性化、可及和负担得起的医疗保健的整个范式将发生变化，患者将掌握主动权。对话革命已经到来——医疗保健将永远不同。</p>
<h2 id="医生的笔记和就诊记录"><a href="#医生的笔记和就诊记录" class="headerlink" title="医生的笔记和就诊记录"></a>医生的笔记和就诊记录</h2><p>患者最常见的挫折之一是审查医生对诊断、处方药物和推荐护理的总结。图 4-2 说明了理解医生笔记的情景。患者对自身健康状况的理解与医生在医疗记录中所记录的内容之间往往存在一个关键差距。这种差异可能会导致严重甚至危及生命的后果。</p>
<p>考虑以下情景。格雷格，一个 30 岁的男人，有家族遗传病史，这种病增加了主动脉夹层的风险——这是一种危险的大血管撕裂，分支自心脏。格雷格开始看心脏病专家，以监测和管理这一风险。然而，发生了一次关键的误沟通：</p>
<ul>
<li>格雷格的理解: 他可能认为自己的风险是中等的，并认为偶尔的检查就足够了。</li>
<li>心脏病医生记录的内容: 医疗记录可能详细说明了一种高风险状况，需要频繁监测和可能的预防措施。</li>
</ul>
<p>不幸的是，格雷格在首次心脏病科就诊仅一年后因主动脉夹层去世。如果心脏病专家能更清楚地传达格雷格病情的严重性和紧迫性；格雷格能充分理解他面临的严重风险以及严格监测和治疗遵从的重要性，这一结果可能是可以避免的。</p>
<p>这个案例说明了医疗提供者与患者之间进行清晰、全面沟通的重要性。当患者真正理解他们的健康状况时，他们更有能力积极参与自己的护理，从而可能避免严重后果。</p>
<p><img src="/../asset_04ClinicalPotential/02.png">图 4-2 理解医生的笔记</p>
<p>试图记住医生的沟通内容和理解医生的笔记常常感觉像是在解读古代符文或回忆几周前的特定餐点：这是一场充满空白和不确定性的斗争。患者常常没有清晰的病情解释或具体的行动计划。</p>
<p>这种由于复杂且常常不透明的医疗文档造成的医疗专业人员与患者之间的脱节，形成了一层厚厚的误解迷雾。因此，患者可能会经历：</p>
<ul>
<li>对他们的健康状况和治疗计划感到困惑</li>
<li>由于缺乏明确的信息而导致的焦虑增加</li>
<li>对他们整体健康旅程的理解减弱</li>
</ul>
<p>这种沟通障碍会影响患者有效管理自己健康的能力。清晰的医疗信息对患者积极参与护理和做出明智的健康决策至关重要。</p>
<p>笔记有时对来自不同专业的患者信息总结得不够准确，需要形成统一的叙述，以便理解多位临床医生提供的见解。这些细微差别往往让患者难以理解。结论是，许多患者需要帮助来理解医生推荐的诊断、管理计划和护理方向。因此，患者可能难以遵循建议，而不遵循建议可能导致健康状况不佳。这个问题普遍存在，需要更便捷的机制将这些技术性访视总结转化为更易于患者理解的通俗语言。</p>
<p>生成的&#x3D;&#x3D;临床摘要&#x3D;&#x3D;可以解释您的测试结果，并告诉您医生想要做什么以及为什么要这样做。摘要还可以提供一系列可能的治疗方案，并引导您理解为什么选择其中一种而不是另一种是合适的。想象一下，这可能为医生和临床工作人员在创建就诊摘要和治疗计划时节省多少时间。拥有一个由语音转文本生成并共享的就诊摘要是不可或缺的，无论是否有您的医生的输入，解释您可能有的问题，以及他们的回答和计算机生成的关于您可能需要了解的内容的教育性猜测，经过总结和解释，并由您的医生进行注释（如果他们有时间）。——这将使您能够通过由生成式人工智能驱动的聊天机器人界面以更自然的语言查询您记录的部分。生成式人工智能可以解释一切，然后希望回答您现在想要了解的解释的任何部分。</p>
<p>生成式人工智能促进了解释性媒体。除了文本翻译，人工智能还可以生成解释性图表、视频或其他多媒体，以更有趣、互动的形式使患者理解医生的笔记内容。LLMs可以提出患者的问题，人工智能可以扫描笔记并针对任何可能需要患者重新考虑和思考的子点或部分制定问题，为澄清理解量身定制问题。</p>
<p>收益远不止于操作更加顺畅。清楚理解您的诊断可以使您在医疗保健中扮演更积极的角色。当您能够扫描诊断气球并阅读您的诊断时，您就有能力提出更有根据的问题，做出更好的治疗选择，并且您会更倾向于跟进治疗计划，知道它们正在发挥作用或您正在朝着正确的方向前进。如果您能够帮助医生诊断问题，这就会形成一个相互沟通的循环，从而在患者和医生之间建立更有效的关系，改善健康及其他方面的结果。</p>
<h2 id="健康计划向导"><a href="#健康计划向导" class="headerlink" title="健康计划向导"></a>健康计划向导</h2><p>在医疗保健领域，一个具有挑战性的空间是如何使不同的系统动态化——涵盖保险计划、提供者网络、设施、药房和社会服务——在管理和解释政策及官僚制度时，帮助寻求护理获取和&#x2F;或补充资源的患者。许多医疗保健组织正在寻求在破碎的接触点之间创造无缝的会员体验。</p>
<p>新一代个性化健康计划的准备就绪，由LLM向导引领——这些虚拟对话代理涵盖了行政和临床功能的行为，成为一个中央联系点。配备同理心语言模型，健康计划向导与会员进行自然对话“检查”，评估会员的需求，同时人工智能将医生转诊、使用趋势、相关护理搜索和结果的相关性连接起来，以识别适当和及时的建议给会员。图 4-3展示了患者利用健康计划向导理解和导航其健康计划的未来。</p>
<p><img src="/../asset_04ClinicalPotential/03.png">图 4-3.健康计划导航向导</p>
<p>LLM 健康计划向导可以用保险术语描述索赔、转诊、药品目录等级和资格，以促进保险的使用。通俗语言可以成为他们的中心，而他们的辐射则创造出自信的消费者，使其能够做出医疗决策。健康社会决定因素的筛查将把经历食物、住房和财务困难的患者与能够提供帮助的社区组织联系起来。具有文化意识的援助可以引导患者进入公平的机会。</p>
<p>凭借对患者的丰富背景洞察，这些个人健康向导能够在行政和生活方式障碍中改善医疗服务的体验。成员们获得个性化、针对性的信息，而不是通用建议。所有的行动和沟通都围绕个人的具体需求和情况展开，打破了传统的孤立、基于交易的互动障碍。更顺畅的互动带来更有效的长期健康结果，实现护理承诺。</p>
<h2 id="黑人母亲健康"><a href="#黑人母亲健康" class="headerlink" title="黑人母亲健康"></a>黑人母亲健康</h2><p>LLMs 可以更平等地支持母亲健康差异，同时促进少数族裔女性走向更好的怀孕旅程。通过提供全渠道护理，将临床指南与全面护理相结合——这承认了脆弱母亲生活的各个方面，包括身体和心理——GenAI 是一项应运而生的技术，旨在应对黑人和棕色孕妇中增加的发病率和死亡率的当前危机 (图 4-4)。</p>
<p><img src="/../asset_04ClinicalPotential/04.png">图 4-4 期待中的布朗母亲</p>
<p>一个公平的母婴健康LLM应用程序可能会引发更广泛的讨论，涉及社会背景、获取服务的障碍和具体关注点——超越医疗历史。它将根据女性的需求量身定制支持，指引她参加食品支持项目、职场适应咨询、满足文化需求的分娩准备课程，或提供交通服务以便她能够顺利参加预约。</p>
<p>无意识偏见是潜移默化的，少数族裔母亲的健康因此受到影响。一个LLM应用程序可以通过以下方式在对抗这些隐性医生假设方面发挥关键作用：</p>
<ul>
<li>通过保留相关的LLM——通过强大的医疗档案，结合关于设想分娩目标的社会&#x2F;文化背景的线索——可能赋予医生不受限制的决策过程的自由被阻碍。LLM减缓了匆忙的建议。</li>
<li>它可以观察患者与医生之间的互动，注意到对少数族裔女性症状和关注的轻微忽视，然后插入愉快的提示以进行验证和额外测试。</li>
<li>它可以帮助患者在预约后回顾过程，并标记出潜在的无意识刻板印象可能降低风险或个性化需求的领域。例如，通过访问患者的完整时间线，LLM可以对照基准标准进行差异分析，并支持那些接受的主动干预少于具有相似风险表现的同龄患者。</li>
</ul>
<p>至少，差别对待的模式可能会随着时间的推移而变得可察觉，并推动政策指令和基于证据的护理方案标准，旨在弥补差异质量，甚至可能是无意中受到产前护理环境中隐性偏见的启发。</p>
<p>提示和里程碑标记将触发个性化的提醒和问题，供育儿患者与她的医生讨论，从检测时间表到分娩计划，同时提供有关不成比例威胁少数群体的母体健康危害的互动教育。随叫随到的倡导者可以介入处理令人担忧的症状，并帮助女性获得最佳护理。</p>
<p>在分娩后，LLM 应用程序将继续在恢复期间和孩子的发展过程中保护女性，提供针对性的建议和与社区资源的联系。它将女性置于自身健康的中心。最后，它创造了机会，绕过固有的种族主义法律系统，使群体能够实现获取他们应得的健康、赋权的妊娠的自主权。</p>
<p>总之，使用LLMs的人工智能聊天机器人可以成为母婴保健中的一个警觉伙伴。这项技术可以：</p>
<ul>
<li>积极识别对少数族裔母亲健康产生负面影响的无意识偏见</li>
<li>为患者提供持续的倡导</li>
<li>在医疗接触期间提供实时支持</li>
<li>监测长期护理以确保连续性和公平性</li>
</ul>
<p>最终目标是确保每位母亲，无论背景如何，都能获得高质量、先进的护理，且不受偏见。这款人工智能伙伴持续努力，在紧急医疗情况下以及整个母婴健康旅程中促进公平对待。</p>
<p>以公平为中心的LLMs提供有前景的创新，以支持那些受到医疗差异影响最严重的人群。这些人工智能系统可以：</p>
<ul>
<li>将历史数据和经验转化为有意义的洞察</li>
<li>改善弱势群体获得优质医疗服务的机会</li>
</ul>
<p>展望未来，这项技术可能有助于实现一个这样的世界：</p>
<ul>
<li>所有可行的胚胎都有机会发育和出生，无论社会经济因素如何</li>
<li>所有种族和民族背景的女性都平等地获得先进生殖技术、高质量的产前和母婴护理以及安全的分娩体验</li>
</ul>
<p>目标是建立一个医疗保健系统，使种族、民族和社会经济地位不再决定母婴健康结果。</p>
<h2 id="用药提醒"><a href="#用药提醒" class="headerlink" title="用药提醒"></a>用药提醒</h2><p>遵循药物治疗方案可能极具挑战性。治疗计划通常涉及复杂的时间安排、饮食要求、与其他药物的冲突等细节。即使是有动力的患者也可能因健忘、混淆的细节或仅仅是觉得治疗不愉快而需要帮助。因此，各类群体在充分遵循处方方面仍然面临许多障碍。</p>
<p>医疗提供者和研究表明，停止服药的患者面临疾病进展、更多医疗支出甚至死亡的风险——尤其是对于那些管理慢性疾病的患者。医生在开处方时确实会努力简化药物组合，例如，力求实现单剂量、每日一次的治疗方案。但在某些治疗配方中，不可避免的复杂性仍然是一个因素。</p>
<p>一项 2017 年的药物依从性研究比较了多种低价记忆辅助工具与未接受任何干预的对照组。工具很简单：一个带滑动开关的药瓶条，用于指示哪一天的剂量已被服用；一个记录打开时间戳的瓶盖；以及一个八格标准每日药丸整理器。</p>
<p>以下是研究结果中“埋藏”的关键发现：</p>
<ul>
<li>低价的记忆辅助工具（带开关的药瓶条、盖子跟踪开盖时间的时间戳和标准每日药丸整理器）与未接受任何干预的对照组相比，并未改善用药依从性。</li>
<li>这一结论并不是从研究的主要结果中立即显现出来的，而是通过对药房补充数据的分析揭示的。</li>
<li>这些常见的依从性工具的无效性是一个意外或可能不受欢迎的发现。</li>
<li>药房补药数据提供了比研究的主要测量更准确或更全面的依从性情况。</li>
</ul>
<p>这些埋藏的发现具有重要意义，因为它们挑战了普遍使用的低成本方法在改善药物依从性方面的有效性。可能需要更具创新性或更全面的方法来影响患者服用处方药的行为。</p>
<p>研究的作者推测，这种对提醒的强调忽视了为什么和何时会错过剂量。为了提高用药依从性，需要更好地了解患者的背景、兴趣和障碍。然而，即使是基本的用药记忆辅助工具的无效性也反映了依从性问题的顽固性。图 4-5 描绘了一位公民使用技术来帮助他们记住何时服用药物。</p>
<p><img src="/../asset_04ClinicalPotential/05.png">图 4-5. 用药提醒</p>
<p>一份 2022 年 NIH 报告2对药物依从性监测技术的研究得出了一些有趣的结论：</p>
<ul>
<li>当前的依从性监测技术具有不同的特性和数据捕获方法。通过技术创新，它们可以进一步增强。</li>
<li>新的研究范式应与临床环境和健康信息系统深度集成和互操作；换句话说，研究方法的实用性需要最大化更广泛技术生态系统的潜力。</li>
<li>虽然这些技术各自都很有前景，但没有一种技术可以被视为“金标准”的灵丹妙药。更有可能的是，它们将作为多模式解决方案的一部分，结合在一起，充分利用新兴技术和传统方法的优势。</li>
<li>毫无疑问，遵从性技术的证据基础正在增长，它们可能成为改善遵从行为和健康结果的真正推动力。但关于技术功能及其对遵从结果影响的证据基础仍需进一步扩展。</li>
</ul>
<p>一旦我们意识到并消除了对这些伪影的偏见，我们不应该期望LLMs是一个灵丹妙药——它们只会是对当前模式的有希望的补充。采用协作的、基于证据的方法来创建LLMs，然后与当前的、上下文感知的、以患者为中心的依从性支持工具迭代使用，可能是现实且唯一的现实途径。</p>
<h2 id="口腔健康"><a href="#口腔健康" class="headerlink" title="口腔健康"></a>口腔健康</h2><p>LLMs 和生成式人工智能可以通过多种方式帮助远程牙科</p>
<ul>
<li>日常任务: 设置提醒，要求客户通过信用卡付款等。LLMs可以自动化这些日常任务，让牙医和牙科卫生员有更多时间为患者服务。</li>
<li>数据分析: LLMs 还可以分析远程牙科会话中的数据，包括视频聊天和牙科图像，以通过识别趋势和模式来提高护理质量。</li>
<li>报告生成: 这里有一份说明，描述了一项任务，并配有提供进一步背景的输入。请写一个适当完成请求的回应。将输入内容改写成听起来更自然的文本，同时保留引用和引述。在整个过程中，LLMs将创建报告，详细记录远程牙科会话的结果，以便与患者和其他医疗服务提供者进行沟通。</li>
<li>患者教育: 一个LLM可能通过视频聊天、短信或使用聊天机器人与您交谈来提供牙齿健康教育。</li>
<li>翻译: LLMs 也擅长翻译语言。这使得远程牙科患者可以使用任何语言交流。</li>
</ul>
<p>LLMs 可以通过多种方式显著改变远程牙科领域，包括增强患者互动和个性化沟通。</p>
<p>LLMs 可以为虚拟助手和聊天机器人提供动力，回答患者关于远程牙科服务、保险覆盖或基本口腔健康信息的初步查询。这可以为牙医腾出时间进行更复杂的咨询。</p>
<p>LLMs 可以分析患者的病史和牙科问题，以量身定制沟通和教育材料。想象一下一个 LLM，它可以根据患者的需求生成定制的预约前电子邮件或治疗后说明。</p>
<p>LLMs 可以教育患者口腔健康。通过分析数百万项研究和数百万患者的电子病历，LLM 可以制定个性化的教育内容，涉及刷牙、使用牙线、饮食和其他口腔卫生主题，以匹配患者的风险因素和偏好。LLMs 可以解读患者报告的症状，并且通常能够提供关于患者可能出现问题的原因以及何时就医的答案。LLMs 可以用简单的语言解释程序和药物，并描述治疗计划的预期收益和负担。LLMs 可以与患者讨论和审查选项，这可能改善患者遵循专家诊断和建议的情况。LLMs 可以提供互动聊天机器人，这些机器人可能与牙科助手不同，因为它们被编程为提供富有同情心的支持和缓解焦虑的技巧，以减少有牙科焦虑的患者对看牙医的恐惧。</p>
<p>对于牙医来说，他们可以检查患者记录和病史，提供建议的诊断和治疗推荐，甚至标记潜在的副作用和禁忌症。LLMs 可以快速浏览牙科文献，帮助他们跟上最新的研究和最佳实践。LLMs 可以为牙医输入准确和全面的笔记，而不浪费时间在格式和拼写上，并且可以提高精确度。它们可以被编程以根据患者的个体需求和偏好定制沟通，从而提高参与度和满意度。图 4-6 说明了一位牙医使用人工智能技术进行口腔健康检查，可能有一个 LLM 提供患者口腔健康历史的总结。</p>
<p><img src="/../asset_04ClinicalPotential/06.png">图 4-6. 口腔健康</p>
<p>LLMs 全天候提供服务，帮助克服与时间和地理距离相关的障碍。他们永远不会忙到无法回答临床问题，也不会被响铃的电话或焦急等待就诊的患者所分心。但他们并不是终点——牙医仍然需要运用他们的临床判断。LLM 的答案旨在支持牙医，而不是取代他们。因此，总体而言，LLMs 对于超越远程牙科具有巨大的潜力。LLMs 可以将权力重新交回患者手中；它们可以支持牙医；而且，它们也将在改善我们人群的口腔健康方面发挥作用。</p>
<h2 id="症状检查器"><a href="#症状检查器" class="headerlink" title="症状检查器"></a>症状检查器</h2><p>&#x3D;&#x3D;症状检查器&#x3D;&#x3D;是计算机化的工具或应用程序，允许患者输入他们的主要症状和可能的伴随症状，并提供评估或潜在诊断。著名的例子包括 WebMD、梅奥诊所的症状检查器以及 Ada Health。如今大多数症状检查器采用基于规则的方法，患者输入症状，然后工具利用这些信息从医疗专家编制的疾病描述数据库中提取信息，并提供潜在诊断。尽管症状检查器确实可以为患者自我诊断提供有益的帮助，但它们在多个方面存在局限性：</p>
<ul>
<li>他们未能捕捉到患者实际症状的细微差别和细节。</li>
<li>他们提供了一份潜在病症的详细清单，但没有明确的概率排名。</li>
<li>它们对共病的考虑很差，并且没有智能地迭代初始问题。</li>
<li>他们在解释自己的推理或建议最佳下一步方面的能力有限。</li>
<li>他们通常只提供有限的可能诊断，可能会忽视其他可能性。</li>
<li>他们的诊断基于用户报告的数据，可能会存在不准确或偏颇的情况。算法系统必须更加细致，以处理边缘案例或罕见病症。</li>
</ul>
<p>LLMs 有潜力在几个方面显著增强症状检查器 (图 4-7)：</p>
<ul>
<li>症状检查器识别文本中显著的修辞和患者特征，并利用LLMs基于大量医学数据集（包括患者的诊断、病例和相关研究文章）训练的建议，通过更准确的术语对其进行细化。</li>
<li>症状检查器通过统计计算和临床指导的启发式方法，将各种可能诊断的预期效益水平（概率）附加到这些诊断上。它们根据先前问题的结果进行一系列后续问题，以排除不太可能的情况。</li>
</ul>
<p><img src="/../asset_04ClinicalPotential/07.png">图 4-7. 症状检查器</p>
<p>LLMs 提供了更好理解上下文的机会。LLMs 可以分析复杂的叙述，并考虑个人背景，如病史、年龄和生活方式因素，从而提供更个性化的建议。LLMs 可以提供更细致的信息，突出不确定性，并引导用户向可靠的来源，如医疗专业人士，寻求帮助。LLMs 可以根据特定症状识别高风险病例，并引导用户寻求立即的医疗关注。它们可以不断从新数据和反馈中学习，提高准确性，并适应不断发展的医学知识。</p>
<p>结合大规模预训练、专业医学知识和严格的验证测试，LLM驱动的症状检查器可以大大提高患者自助服务能力、临床效率和健康结果。</p>
<h2 id="临床决策支持"><a href="#临床决策支持" class="headerlink" title="临床决策支持"></a>临床决策支持</h2><p>LLMs和生成式人工智能在临床决策支持领域的潜力巨大。临床护理通常涉及患者治疗的规划，这包括仔细考虑治疗方案的潜在风险和收益。由医学协会发布的临床实践指南（CPGs）基于最佳可用的人群级别证据，旨在帮助医疗专业人员做出临床决策。</p>
<p>然而，当考虑到患有多种交叉慢性病的多重慢性患者时，这些实践指南可能会模糊或不够理想。这些复杂性带来了挑战，因为临床实践指南是针对单一疾病的，临床医生需要根据多个指南之间的冲突建议进行判断。例如，考虑到一个老龄化的人口，随着临床复杂性和护理需求的增加，导致疾病相互作用时出现超加性成本的模式。</p>
<p>将特定疾病的临床实践指南应用于多种疾病患者可能导致相互竞争的建议，并可能引发不良的药物-药物或药物-疾病相互作用。例如，针对心力衰竭的药物可能会损害肾功能，而对于肾病患者来说，非甾体抗炎药（NSAIDs）可能被建议用于治疗骨关节炎疼痛，但实际上在有消化性溃疡病史的患者中可能相对禁忌。</p>
<p>为了考虑患者的独特情况，例如人口统计、家庭和疾病历史或个别医生的实践模式，医生可能会部分或完全偏离适用的指南。虽然在某些情况下这些偏离可能是合适的，但它们也可能导致不必要的变异和较差的健康结果。与手动个性化临床护理的偏离相比，偏离也可能源于专业不确定性，例如缺乏专业领域的专长或对治疗选择的不确定性。下一部分中描述的临床洞察机器人或临床医生的使用案例可以减轻刚刚提到的一些针对多病患者的风险。</p>
<h2 id="临床洞察机器人"><a href="#临床洞察机器人" class="headerlink" title="临床洞察机器人"></a>临床洞察机器人</h2><p>医生做医生该做的事。患者的故事、病史、实验室检查和诊断测试，以及初步治疗计划都呈现在临床洞察机器人面前。LLM深入挖掘。它提出问题以了解更多，但不是为了评判或得出结论。难道真的是那种罕见疾病吗？这两种药物会相互作用吗？是否有一些临床试验在研究这种疾病或影响患者的多种疾病？与虚拟助手互动，如图 4-8所示，为医生提供了巨大的好处。</p>
<p><img src="/../asset_04ClinicalPotential/08.png">图 4-8 医生与一个人工智能驱动的临床洞察聊天机器人交谈</p>
<p>LLM深入其医学文献、研究论文、案例研究甚至临床指南的数据库，然后挑选出它认为你需要知道的信息。它寻找模式、关联以及医生可能遗漏的错误。它仔细审查治疗计划，检查迄今为止的效果，并引导你朝着一些现在有强有力证据支持的更有效选项前进。</p>
<p>但LLM不仅仅是一个数据处理器：它是一台分析机器，提出假设并强调潜在的偏见。它提出可能解释患者症状的替代诊断，或指出不确定的领域，促使医生进行更多的测试或咨询其他医生。简而言之，&#x3D;&#x3D;它并没有用“计算机医学”取代人类判断。相反，它增强了人类判断，提供了更广泛的视角，并确保考虑了每一个可能的角度&#x3D;&#x3D;。</p>
<p>现在，一位新近增强信心的医生检查了LLM的输出，并带着修订后的计划离开了房间。咨询过程既细致又自然，临床医生与人工智能共同合作，之前的专业知识在LLM的分析下得到了增强和指导。新计划的风险和收益可以进行权衡，医生对结论的信心得到了提升，尽管并未完全接受。她在改善结果的努力中有一个盟友——一个无声的合作伙伴。</p>
<p>这仅仅是未来医疗咨询可能呈现的开始，LLMs将辅助但不会取代人类医生。它们不会终结个人关怀、同理心和推理，这些定义了优秀医生的意义。但它们将成为医生可用的最强大工具，帮助筛选大量信息，以便为我们所有人提供知情、个性化和人性化的护理。</p>
<p>临床洞察机器人与人工智能临床医生的区别在于，临床洞察机器人的核心任务是从一组临床数据中提取洞察、模式和趋势，例如电子健康记录、医学文献、临床研究等，以帮助临床医生做出更好的决策。</p>
<p>临床洞察机器人将主要依赖结构化和非结构化的临床数据源，即电子健康记录、索赔数据、医学文献、临床试验结果和患者生成的健康数据，然后利用先进的分析、自然语言处理和机器学习从中提取临床有意义的洞察和模式。</p>
<p>与实时个体分析不同，临床洞察机器人采用数据驱动的方法为临床医生和医疗专业人员生成洞察。这些洞察定期提供，在预定的时间间隔内，或由特定事件触发。机器人分析大量匿名数据，以识别群体层面的趋势和模式。这些匿名数据保护患者隐私，同时允许机器人发现更广泛的医疗趋势。然后，这些洞察以清晰的格式呈现，如报告、仪表板或警报。最终，这些数据驱动的洞察旨在使临床医生和医疗专业人员能够做出明智的判断和决策，从而惠及整个群体或医疗系统。</p>
<h2 id="AI-路边医生"><a href="#AI-路边医生" class="headerlink" title="AI 路边医生"></a>AI 路边医生</h2><p>路边咨询是医疗提供者之间关于真实患者案例的非正式建议交流。路边咨询是医疗提供者之间的非正式建议交流，考虑到仍在真实患者中待解决的案例，如图 4-9中比喻性地所示。</p>
<p><img src="/../asset_04ClinicalPotential/09.png">图 4-9. 路边医生</p>
<p>在重症监护室（ICU）值班时，你对患者简缺乏发热感到担忧。你刚刚与 ICU 的一位同事交谈，解释她有 4 级乳酸中毒，心电图显示低电压，过去 12 小时内有胃肠道出血，且新出现的血小板计数达到 70,000。然而，晚上 7 点入院的患者仍然没有发热。你感到困惑。你知道急诊科的同事最近使用了一款作为虚拟咨询医生的应用程序。上周你两次听从了她的建议，效果非常好。你决定试一试。</p>
<p>您的病人在一次吸食杂草的过程中，浴袍着火而被烧伤。烧伤是表浅的，尽管覆盖了较大的表面积（大约占总身体表面积的 20%）。今天，她回到了烧伤门诊，您正在进行每日化疗剂量。一周前，伤口充满了液体，捏合测试呈阳性。尽管在今天之前不应该需要捏合测试，但您决定继续进行二度烧伤的护理，包括包扎和清创。现在，捏合测试呈阴性，敷料有异味且变色，并且有一层白色物质。您感到惊讶和担忧，因为这些迹象和症状令人担忧。您想咨询伤口护理专家，但没有好的联系方式。您记得同事告诉您有一个像路边医生一样的应用程序。</p>
<p>一个人工智能路边医生提供即时访问不断发展的医学信息，模仿您可能仅通过与同事的即兴咨询获得的宝贵见解。&#x3D;&#x3D;这个数字工具复制了美国资深临床医生在“查房”期间进行的知识分享&#x3D;&#x3D;，或英国医院中同事之间的早晨、中午和下午的“桌边”聊天。通过这样做，它将协作医学专业知识的好处带到临床医生的指尖，随时可用，无需身体在场或安排时间。您可以使用LLM生成一组假设，关于 1）是什么导致患者的症状，2）缓解这些症状的策略，3）可能相关的因素，以及 4）接下来应该采取的步骤。</p>
<p>AI 路边医生随时准备进行非正式的病例讨论，无论是白天还是晚上，任何一天。您可以谈论您的病人、当前的问题（检测结果、体检发现、既往病史），并获得高质量的诊断反馈。AI 还可能生成可能的诊断列表及其相关概率。这些概率将基于特定的症状、这些症状的时间线或进展以及相关的风险因素。</p>
<p>AI 路边医生会考虑这些元素如何与医学文献中已建立的诊断标准或标准相对应。</p>
<p>它甚至可以提出适当的探询问题，以澄清或提供更多关于缺失病例特征的细节，这些特征可能区分不同的可能诊断，或者在某些情况下建议进一步的测试或测试策略。简而言之，LLMs将改善医生的路边咨询。它们将帮助医生为患者提供更个性化和高效的护理。</p>
<p>AI 路边医生机器人最关键的功能是为医疗专业人员提供快速和非正式的建议和第二意见。换句话说，它将专注于促进“路边咨询”。基本上，它将尝试帮助医生在遇到挑战时做出临床决策。它将努力提供基于证据的建议和关于特定儿科患者案例或医学一般咨询的专家意见。</p>
<p>一个路边医生机器人将利用经验丰富的医生在医学文献、临床指南和意见文章中记录的智慧和知识，并使用软逻辑、自然语言处理和信息检索技术来检索和上下文化与特定临床问题相关的信息。</p>
<p>路边医生机器人会像一个专家一样与您进行对话，以案例特定、个性化的方式解决问题，这取决于您所看到的特定患者的特征以及您具体的问题或担忧。</p>
<p>一个路边医生机器人将具有更窄的相关领域，为非常具体的临床场景提供输入和建议，但基于非常广泛的医学知识库，通常能够提供人类医生可能推荐的指导。这样的系统可能会快速便捷地访问医学知识，但如果人类医生在阅读教科书和浏览网络，并且建议没有针对该个体患者量身定制，则可能会受到一些批评。</p>
<h2 id="远程患者监测"><a href="#远程患者监测" class="headerlink" title="远程患者监测"></a>远程患者监测</h2><p>远程患者监测是一种可行且日益有效的方法，可以改善患者的治疗结果。生成式人工智能和LLM应用程序将能够以多种方式帮助远程患者监测。一个LLM将能够个性化每位患者的远程监测体验，以确保体验尽可能高效和最佳。通过考虑患者及其偏好，一个LLM可能会生成一个每天最符合患者需求的日程安排。它还可能能够提供有关患者进展的个性化反馈。</p>
<p>LLMs 可用于根据患者的数据读数实时反馈他们的健康数据。例如，使用远程患者监测，LLM 可以在患者的血压或心率过低时发出警报。图 4-10 说明了一个远程患者监测会话。</p>
<p><img src="/../asset_04ClinicalPotential/10.png">图 4-10 由 LLM 应用程序提供支持的远程患者监测</p>
<p>在医学领域，LLMs 可以搜索患者的健康数据并扫描问题。它们可以通过发现数据中的不规则性和模式来识别潜在问题，例如识别有发展糖尿病风险的患者或可能会心脏病发作的患者。LLMs 还可以提醒患者按时服药或预约看医生，这可以帮助患者照顾自己的健康，避免错过医生的预约。</p>
<p>此外，LLMs可以通过使用自然语言处理（NLP）分析患者的问题和关注点，以信息丰富且引人入胜的方式与患者进行沟通，然后以人性化的方式回复他们，并针对他们需求的个别方面进行回应。</p>
<h2 id="数字孪生"><a href="#数字孪生" class="headerlink" title="数字孪生"></a>数字孪生</h2><p>个体、器官甚至医疗设备的数字孪生可以根据其创建所依据的现实世界数据模拟其行为和特征。通过使用数字孪生，医疗从业者可以理解数据、预测结果并优化治疗。</p>
<p>数字孪生在医疗保健中的一些关键方面：</p>
<ul>
<li>患者特定建模： 开发医疗数字孪生的一个目标可能是每个患者都有自己的数字孪生模型。该模型将结合患者的病史、特定的遗传信息、生活方式因素和其他相关数据。这个数字孪生将不断地通过个人设备（如智能手表或血糖监测仪）实时更新健康数据、新的医学检测结果以及生活方式或药物的变化。数字孪生将不断接收和整合新数据。然后，AI 系统将频繁分析这些数据，以检测变化或趋势，并为医疗提供者和患者提供最新的见解。这种持续的监测确保数字孪生始终准确、及时地反映患者的健康状况，从而在必要时能够进行更及时和个性化的医疗干预。</li>
<li>器官&#x2F;疾病模拟： 数字孪生可以针对特定的器官或疾病进行开发，例如虚拟心脏，甚至是肿瘤的数字版本，后者能够模拟疾病在体内的进展方式或预测拟议治疗方案的结果。</li>
<li>医疗设备优化： 数字孪生可以模拟富含传感器的植入设备的虚拟版本，例如心脏起搏器或胰岛素泵，其性能可以在不同情况下进行探索。例如，制造商可能能够虚拟运行设备以优化其输出。</li>
<li>预测分析： 实时使用机器学习算法对数字孪生数据进行分析，可以建模可能的健康风险、不良事件或治疗反应，以便采取预防性干预措施。</li>
<li>虚拟临床试验： 数字孪生可以通过虚拟临床试验来测试新药或其他疗法，从而减少患者接触新药物成分和测试的风险。涉及大量数字患者模型的虚拟临床试验可以提供关于治疗效果的更多信息，或模拟人群中的典型变异性。</li>
<li>远程监测和远程医疗： 数字孪生通过持续跟踪患者状态来增强远程患者监测。数字模型实时更新来自可穿戴设备和其他健康传感器的数据。数字孪生可以通过将当前数据与患者的基线和预期模式进行比较，快速识别异常变化。当检测到显著偏差时，医疗服务提供者可以立即收到警报，从而采取及时行动。数字孪生对患者的全面模型允许更量身定制的监测和治疗计划。</li>
</ul>
<p>数字孪生可以在医院内外改善患者结果、药物开发和医疗设备设计，可能比在其他任何环境中都更有效。拥有一个高清晰度、基于预测、简化且个性化的你几乎没有任何缺点。</p>
<p>但这引发了关于数据隐私、安全性和与数字孪生在健康领域扩展相关的伦理问题的新问题。患者信息将如何得到保护？哪些法规将管理数字孪生的使用？图 4-11展示了一个数孪生。</p>
<p><img src="/../asset_04ClinicalPotential/11.png">图 4-11. 数字孪生</p>
<p>常规分析综合护理记录可能揭示患者可能接受的所有药物治疗方案，并可能揭示注意事项、禁忌症、预防措施、相互作用或疗效考虑。副作用和结果可能在不同治疗干预下以个性化水平进行预测，以便根据个体的基因组、生物标志物和其他先前反应数据进行风险&#x2F;收益评估。更重要的是，临床医生模拟数字孪生，基本上是选择哪种干预方案最有效，以及哪种药物或治疗最有效。</p>
<p>来自可穿戴生物传感器的远程患者监测设备的数字流可以自动监测并与可操作的临床信息（例如，早期感染警告迹象）进行上下文化。如果检测到趋势中的异常，数字孪生将向临床医生生成警报和警告，以便及时干预和调整治疗方案。</p>
<p>除了能够整合来自各种来源的数据、进行生成式分析并提供高精度推荐之外，基于LLM的患者数字孪生将成为一个可靠的知识驱动助手，临床医生可以在护理现场查询，以获取其他方式无法获得的数据驱动见解。这将有助于提高临床决策的质量和患者的结果。基于LLM的孪生是一个决策支持工具，指导临床医生获得见解、个性化推荐和对患者的持续监测，从而增强临床决策和患者结果。</p>
<h2 id="医生信件生成"><a href="#医生信件生成" class="headerlink" title="医生信件生成"></a>医生信件生成</h2><p>医生面临日益增加的文书工作要求，这些要求分散了宝贵的直接患者护理时间。处理先前授权、残疾索赔、复工需求和其他集中请求的信件在非结构化格式下显得行政负担沉重。大量的文书工作和不灵活的模板使各个诊所的低效问题加剧。图 4-12 描绘了一位医生使用生成式人工智能来处理文书工作。</p>
<p><img src="/../asset_04ClinicalPotential/12.png">图 4-12.医生使用生成式人工智能创建信件、表格和电子邮件</p>
<p>最早的自适应医生信件生成 LLM 解决方案之一，称为 ScribeMD，通过允许医生口头输入信件，然后在自然语言处理（NLP）中进行增强，直到它达到完整的专业信件。医生必须在语音提示中口述这些要点，例如：“我们在圣弗朗西斯纪念医院的前任患者名叫萨姆·琼斯……” 然后他们继续列出患者的病史、信件的接收对象、初级护理细节、医院政策要求以及对护理人员的建议行动，包括文档、插管或抗生素细节。</p>
<p>&#x3D;&#x3D;ScribeMD&#x3D;&#x3D;，这个特定提示下运行的工具，熟悉符合 HIPAA 标准的LLMs，并在继续撰写信件之前分析这些提示组件。医生在必要时编辑自动生成的信件，然后签署通信。通常，自动化负责原始文档的创建、引用来源和标准化格式——从详细的“现病史”到生成复工通知。</p>
<p>通过对多个案例的迭代，ScribeMD 的预测输出随着时间的推移逐渐改善，因为模型学习了各种风格特征、引用证据的线索以及特定于该提供者、亚专业和实践领域的结构特征“固定表达”。随着广泛的应用，随着时间的推移，用于开发该系统的训练语料库及其持续反馈校准将呈指数增长，将草拟时间缩短到仅需 30 秒。</p>
<p>从模板跳跃到可适应的叙事降低了临床文档的劳动，同时传达了细微差别。患者也从个性化中受益。因此，ScribeMD 帮助医生以对话的方式分享护理意识，而不是在健康服务的生产中与表格空白作斗争，从而避免了谈论治疗文书的痛苦。</p>
<h2 id="健康公平"><a href="#健康公平" class="headerlink" title="健康公平"></a>健康公平</h2><p>健康公平意味着所有人都有公平和正义的机会来实现他们的最高健康水平，不受社会、经济或人口状况的阻碍。这意味着在这些人群的整体健康状况和获得医疗服务方面，没有可避免的、不公平的或可补救的差异。</p>
<p>健康公平的关键方面包括：</p>
<ul>
<li>平等获取：第一步是让人们平等地获得医疗保健。这意味着每个人——无论他们是富人、穷人、黑人、白人等，无论他们的年龄、性别、性别认同或身体能力如何——都应该在需要时随时获得所需的药物或任何类型的护理。</li>
<li>健康的社会决定因素：实现健康公平需要关注社会、经济和环境因素，这些因素在个体和社区层面直接或间接地影响健康结果，包括教育、就业、住房和交通。</li>
<li>平衡竞争环境：健康公平的追求是消除因特定社会和经济政策及实践而导致的系统性、可避免和不公正的健康结果差异。</li>
<li>政策和项目：健康公平涉及制定和实施旨在满足边缘化和弱势群体需求的政策和项目，同时考虑到资源不平等。</li>
<li>赋权与参与： 健康公平意味着增强个人和社区的声音，以参与影响他们健康和福祉的决策。</li>
<li>文化能力：健康公平要求医疗服务提供者和医疗系统（无论是机构还是组织）能够理解和尊重不同人群的价值观、信仰、行为、实践和文化。</li>
</ul>
<p>应对健康不平等并实现健康公平是一个复杂且长期的过程，涉及许多部门——包括公共和私营部门——需要几代人的努力。健康系统和社会其他部分应将重点从生命末期的疾病治疗转向在生命早期预防社会不平等和健康差异。</p>
<p><img src="/../asset_04ClinicalPotential/13.png">图 4-13. 全民健康公平</p>
<p>LLMs 可以分析社会健康决定因素 (SDOH) 数据，如收入、住房和教育，以预测特定社区的潜在健康风险。这使得临床医生能够主动干预并分配资源，以满足这些需求。生成式人工智能 &#x2F; LLM 聊天机器人或虚拟助手可以提供文化敏感的信息，并根据个人的特定 SDOH 将其与适当的社会服务和医疗资源连接起来。</p>
<p>这些人工智能虚拟助手可以根据个人需求和文化背景定制沟通和教育，提供个性化的健康信息和教育材料，从而提高理解和获取信息的能力。LLMs 还可以识别并标记医疗记录、医生笔记或算法中可能存在的歧视性语言，促进更具包容性的医疗实践。</p>
<p>临床医生和护理团队是医疗系统的支柱，常常需要帮助处理许多任务，从而减少了他们用于最重要事务的时间：患者。虚拟临床医生可以为医生提供个性化的患者诊断。这包括对患者数据（病史、实验室报告、影像学）的分析，以识别模式并为医生生成细致的提示，建议潜在的诊断并缩小调查路径。</p>
<h2 id="事先授权"><a href="#事先授权" class="headerlink" title="事先授权"></a>事先授权</h2><p>护士和医疗主任每天需要处理大量数据，以便对先前授权请求做出决策。这个过程可能令人困惑、繁琐、耗时且容易出错。先前授权 (图 4-14) 在医疗系统中可能是一个重大问题，原因有几个：</p>
<ul>
<li>延迟护理：预授权流程可能会延迟患者获得必要的药物、治疗或程序，因为提供者必须在进行之前等待保险公司的批准。这些延迟可能导致病情恶化和健康结果变差。</li>
<li>行政负担预：授权过程通常对医疗服务提供者来说既耗时又繁琐。医生及其工作人员花费大量时间填写表格、打电话和应对复杂的官僚系统，这减少了直接为患者提供护理的时间。</li>
<li>成本增加： 与事先授权相关的行政成本对于医疗服务提供者和保险公司来说可能是相当可观的。此外，如果由于缺乏及时治疗而导致病情恶化，护理延误可能会导致更昂贵的干预措施。</li>
<li>干扰临床决策制定：事先授权要求可能会干扰医疗提供者的临床判断，因为保险公司可能会基于成本或其他因素而非患者的最佳利益，推翻医生的治疗建议。</li>
<li>患者沮丧：事先授权可能让患者感到沮丧和困惑，他们可能需要帮助来理解为什么他们的治疗被延迟或拒绝。这可能导致对医疗系统的不满以及潜在的不遵循治疗计划。</li>
<li>健康不平等：事先授权要求可能会对特定患者群体产生不成比例的影响，例如那些患有慢性疾病或复杂医疗需求的患者，从而加剧现有的健康不平等。</li>
</ul>
<p><img src="/../asset_04ClinicalPotential/14.png">图 4-14 通过 LLMs 简化事先授权流程。</p>
<p>尽管事先授权旨在降低医疗成本并确保在适当的时间提供正确的服务，但当前流程的负担可能会妨碍及时和有效的护理。幸运的是，越来越多的医疗服务提供者、患者倡导者和政策制定者正在倡导对事先授权进行改革，以减轻行政负担，提高运营效率，并让临床医生专注于最重要的事情：安全、有效和以患者为中心的护理。</p>
<p>机器辅助的事先授权与LLM一起，消除了所有这些，同时允许患者在需要时获得所需的护理：适当程序的审批过程加快，而临床医生的生产力提高。LLM能够复制人类推理，审核几乎所有保险公司需要考虑的护理情况的临床标准，并根据需要实时获取患者数据，包括过去的索赔、实验室结果、处方和临床记录。最终结果是一个LLM驱动的系统，在被要求时实时发布关于医疗“护理必要性”指标是否满足的裁决。临床医生要做的就是决定批准或拒绝特定的事先授权请求。在大多数情况下，临床医生可以发出积极的事先授权批准命令。</p>
<p>机器辅助的LLM事先授权使支付方能够更快做出更好的决策，确保患者获得所需服务。随着时间的推移，与事先授权相关的痛点逐渐消失，支付方、提供者和患者之间的信任关系得以发展。当与机器辅助的LLM事先授权结合使用时，医疗系统可以为所有人提供更好的服务。</p>
<p>如前所述，先前授权过程的一个主要问题是必须实时处理。这就是它的运作方式：</p>
<ul>
<li>手动审核：由于许多先前授权请求仍然由保险公司员工手动处理，因此可能需要很长时间，从而延迟治疗。由于裁定不是实时的，患者和提供者必须等待决定，即使是简单的决定。</li>
<li>不完整&#x2F;不正确的信息：不完整&#x2F;不正确的信息要求保险公司进一步从提供者那里收集案件信息，这会进一步延缓裁决过程。在实时处理过程中，这会在前期被检测到，给提供者提供了在首次提交 PA 请求之前填写信息甚至纠正错误的机会。</li>
<li>非标准化的标准：不同保险公司对事先授权的批准规则各不相同，且标准随着时间的推移而变化，这使得很难加以考虑，提供者在没有实时处理和集中数据库的情况下无法了解最新细节。事先授权是保险公司设定的要求，必须在提供医疗服务之前满足。</li>
<li>缺乏整合：许多预授权流程可以与电子健康记录（EHR）和其他医疗信息技术系统进一步整合。提供者通常会在一个单独的门户或表单中输入信息，随后再添加到临床记录中，这增加了错误和延误的可能性。</li>
<li>医疗机构和患者的挫败感：实时处理的缺乏可能会导致医疗机构和患者的重大挫折——治疗延迟、行政负担增加以及对保险覆盖决定的不确定性。</li>
</ul>
<p>在预授权中实施实时处理可以通过以下方式帮助解决这些挑战：</p>
<ul>
<li>自动化日常请求：对于常规或低风险的请求，我们可以允许符合特定标准的自动请求立即获得批准。</li>
<li>提供即时反馈：实时处理可以让提供者即时反馈他们请求的适当性和准确性，从而减少纸质往返和上诉的需要。</li>
<li>实时更新标准：理论上，实时处理可以使健康计划不断更新提供者在事前授权中使用的标准，从而使提供者的接触能够基于最新的信息进行评估，而不是基于可能过时的信息，这可能导致拒绝。</li>
<li>促进整合：实时交易处理可以实现先前授权系统与电子健康记录（EHRs）之间的集成，消除手动数据输入的需要。</li>
</ul>
<p>实时处理事先授权并不容易，但它可以大大提高流程的效率、准确性和及时性，最终帮助患者、提供者和支付方。LLMs 还可以通过以下方式改善事先授权的实时处理4：</p>
<ul>
<li>自然语言处理 (NLP)： 想象一个LLM，它能够理解您收到的自由形式、非结构化语言的预授权请求，解析出相关细节，如患者姓名、诊断代码和治疗计划。它可以使这个过程更快，并减少我们的数据输入所需的时间。</li>
<li>智能表单解析： LLMs 可以被训练识别和解析来自不同汽车、视力和牙科保险公司的预授权表格中的信息。这可以让医生以他们喜欢的格式提交预批准请求，而保险公司则可以自动处理这些请求。</li>
<li>决策自动化： LLMs 可以与基于规则的系统或机器学习模型一起使用，以实现自动化决策。例如，LLM 可以从请求中提取相关信息，并与保险公司的决策指南进行匹配，然后做出实时决策。这可能会在处理常规请求时带来显著的效率提升。</li>
<li>情境意识：LLMs 在解读临床文档时可能会变得有用，例如医疗记录中的笔记或先前授权请求中的书面临床理由。在这种情况下，LLMs 中的上下文意识可以帮助确保语言的细微差别不会丢失，并且分析是基于对患者情况的整体解读。</li>
<li>个性化沟通：LLMs 可以创建个性化的沟通或提供者向患者解释先前授权决定的说明。示例包括解释请求被拒绝的原因以及如何上诉或重新提交请求。</li>
<li>持续学习：LLMs 可以持续在新数据上进行训练，确保它们能够响应不断变化的指导阈值、标准和最佳护理实践。这将使它们能够以灵活的方式修订先前的授权规则，随着证据和标准的变化。</li>
</ul>
<p>在事先授权的背景下，虽然LLMs在增强实时处理方面具有巨大的潜力，但显然这必须与其他技术结合使用，例如基于规则的系统、机器学习&#x2F;深度学习模型和强大的数据集成。一个强大的解决方案需要数据隐私、安全性和可解释性，以确保所有决策都是透明、公平的，并符合相关政策和法规。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>随着LLMs和生成式人工智能的快速发展——这些技术有望改变医疗实践——我们开始了一段激动人心的旅程，以更好地告知、吸引和连接医生与患者。在此过程中，我们概述了几个新兴承诺的用例，以建议这些系统如何提供更好的护理、在一个困难的行业中提高效率，并对重大紧迫需求作出及时响应。</p>
<p>一个用例可能是健康机器人礼宾服务，它将利用LLMs作为改写工具，试图为与机器对话的患者提供一种类似人类伴侣的体验。这个伴侣将成为患者在健康状况下的旅程的一部分，也许从诊断开始。人工智能伴侣可以解答患者的问题，提供指导，并帮助他们在医疗系统中导航，以一种更适合患者的方式，同时提供必要的信息，以更协调的方式引导护理过程，同时减轻临床医生的临床负担。</p>
<p>在医疗行业中，通过部署LLMs和人工智能程序，可以加快临床工作流程，简化医生笔记和就诊记录的撰写，从而节省时间并减少结构化临床文档开发中的错误。这将使医生能够为直接患者护理留出更多时间。LLMs还可以在线查询患者数据，以开发改进的临床决策支持形式，从而增强和维持医生决策和结果的基于证据的性质。</p>
<p>例如，在健康保险领域，LLMs 可以为机器人顾问提供信息，这些顾问可以根据个人的需求和偏好，建议患者在健康保险覆盖方面应该关注什么，并推荐相应的内容，从而帮助揭开健康保险这一通常晦涩的领域的神秘面纱，这可能是患者获得护理和支付护理费用的主要障碍。</p>
<p>生成式人工智能因此可以帮助最小化健康差异，增加健康公平，并显著改善健康结果，特别是在同时遭受这两者影响的人群中。例如，黑人女性的产妇发病率或死亡率高于白人女性。利用人工智能和大规模数据，人工智能解读的干预措施可以最初更具体地针对她们，并为她们提供更好的教育和其他资源的获取。同样，LLMs可能会推动例如药物依从性和口腔健康促进项目，以改善服务不足社区的健康结果。</p>
<p>基于LLM的症状检查工具可以帮助患者更准确地理解和解释他们的症状，并生成关于何时进行测试或护理的建议。鉴于知识的快速增长，LLM症状检查工具可能能够提供比目前可用的症状检查工具更准确、可靠和细致的评估，从而减少未能及时就医的情况，并鼓励在严重疾病中更早干预。</p>
<p>作为一个例子，LLMs 向临床医生提供路边医疗，作为一个权威来源，回答基于最新医学文献的循证临床问题。针对患者的临床洞察机器人可以策划、过滤和详细说明临床记录，并逐事件总结相关问题和给出的答案，但旨在提供个性化建议。此外，数字双胞胎可以模拟实际患者在不同条件下（例如精准医学类型的协议）对名义干预的反应行为。</p>
<p>LLMs 和生成式人工智能可以用于远程患者监测，以解读来自可穿戴设备和智能手表&#x2F;系统的数据。例如，这样可以在患者出现身体症状之前识别预测和干预的模式，并且可以提前向护理团队发送警报，以采取措施防止潜在问题升级。LLMs 和生成式人工智能还可以用于创建医生信件和事先授权，以帮助减轻临床医生在提供护理过程中面临的繁重行政任务。</p>
<p>然而，我们仍然有道德责任保护患者的隐私和安全，并向拥抱伦理技术设计和使用过渡。为了获得有利于患者的生成能力，需要医疗机构和技术开发者之间的协调行动，而不是孤立的努力，以及政策制定者的共同愿景。</p>
<p>总之，如果在患者护理的各个方面正确使用LLMs和生成式人工智能，我们可能会在未来的护理交付模型、患者接触和护理优化中经历多种变化。</p>
<p>1 莫尼克·特洛，“按规定服药：为什么这么难？” 哈佛健康出版，2017 年 5 月 10 日，<a target="_blank" rel="noopener" href="https://www.health.harvard.edu/blog/taking-medicines-like-youre-supposed-hard-2017051011628%E3%80%82">https://www.health.harvard.edu/blog/taking-medicines-like-youre-supposed-hard-2017051011628。</a></p>
<p>2 Madilyn Mason 等，“药物依从性监测技术及技术评估标准：叙述性综述，” JMIR mHealth uHealth 10, no. 3 (2022 年 3 月): e35157, <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8949687%E3%80%82">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8949687。</a></p>
<p>3 ScribeMD，访问日期：2024 年 6 月 27 日，<a target="_blank" rel="noopener" href="https://www.scribemd.ai./">https://www.scribemd.ai。</a></p>
<p>4 Prashant Sharma, “LLM 在医疗保健中的优先授权机会，”Medium，2023 年 8 月 14 日，<a target="_blank" rel="noopener" href="https://medium.com/@prashant05kumar/llm-in-health-care-the-prior-authorization-opportunity-7e72b6058301%E3%80%82">https://medium.com/@prashant05kumar/llm-in-health-care-the-prior-authorization-opportunity-7e72b6058301。</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/10/llmsClinical03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/10/llmsClinical03/" class="post-title-link" itemprop="url">第三章 超越白大褂</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-10 14:32:19" itemprop="dateCreated datePublished" datetime="2024-08-10T14:32:19+08:00">2024-08-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:10:44" itemprop="dateModified" datetime="2024-08-21T14:10:44+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>16k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>30 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>尼迪叹了口气，工作后瘫坐在沙发上。49 岁，离婚，住在伊利诺伊州芝加哥南郊的她，已经习惯了独自忙碌，照顾自己的房子、工作和青少年孩子。这些天，她感到厌倦了。她的手开始在身体上无意识地移动。她按了一下左胸的一部分。那是什么？她又按了一下；左胸侧面有一个小肿块。她担忧地用手指抚摸着它。她的心开始加速跳动——这不正常。第二天早上，她第一时间和医生联系，并在那周得到了预约。等待是折磨。什么时候我才能被倾听，什么时候我们才能确定？她试图保持忙碌，不去想它，但她的思绪一次又一次地回到这个问题上，游走在它可能是什么的想法中。</p>
<p>在医院，医生切除了肿块并进行了乳腺 X 光检查。医生表示需要进行活检以确定肿块是否恶性，然后一切就会明朗。尼迪感到焦虑和恐惧，身体虚弱。一周后，医院打来电话提供活检报告。结果是乳腺癌。尼迪感到一阵拳头般的痛击袭来。</p>
<p>尼迪是一位第一代移民，在美国没有家人、朋友或任何正式的支持系统。她甚至不知道每年需要进行乳腺 X 光检查。她不知道如何处理保险要求，比如预授权、自付额或需要提供给保险公司的索赔文件。她从未预约过医生，更不用说化疗或放疗了——而这一切发生在她恶心最严重的时候。</p>
<p>她不得不自己开车去，常常在她因低血细胞计数而导致的发烧或严重感染感到不适的时候。她仍然需要照顾她的两个青少年，他们不能开车，并且有自己的问题。尼迪快要失去希望了，她快用完钱了。她感到自己辜负了孩子们，并为自己的身体感到困扰。在接下来的几个月里，她将经历一系列的就诊、阅读和搜索，并制定行动计划。尼迪的癌症是 III B 期，已经扩散到她的淋巴结和锁骨。她的预后不佳，手术和放疗效果有限。然而，她可以选择一个她的肿瘤科医生认为可能适合的临床试验。此外，她的肿瘤科医生建议她调查聚焦超声，这是一种用于乳腺癌的新型治疗方法。</p>
<p>尼迪的故事让我们看到了当前医疗保健的状态，包括患者及其支持者所承受的焦虑和负担。本章展示了今天医疗保健中自动化的现实，以及大型语言模型（LLMs）和生成式人工智能将如何进一步推动患者医疗保健的演变。本章的主要目标是让读者理解自动化以及在LLMs和生成式人工智能解决方案中的技术飞跃如何开始扰乱医疗保健流程、工作流程和运营效率的数字化转型。</p>
<h1 id="医疗保健中的自动化现状"><a href="#医疗保健中的自动化现状" class="headerlink" title="医疗保健中的自动化现状"></a>医疗保健中的自动化现状</h1><p>接下来的故事——尼迪试图理解她的癌症诊断并弄清楚医疗系统——尽管她年纪尚轻，却是非常真实的。当尼迪准备进行 CT 扫描时，我们被提醒了一个严酷的事实：尽管医疗领域取得了非凡的突破，医疗管理仍然停留在 1960 年代。在过去的半个世纪里，几乎所有地方的生产力都爆炸性增长，但在医疗行业，仍然没有人使用纸张书写，没有系统将数据存储在孤岛中，没有客户服务依赖于电话和文书工作。此外，3.8 万亿美元的资金流入并穿过美国医疗系统。然而，作为现代效率引擎的自动化似乎在医疗图表和机构惯性中迷失了方向。</p>
<p>成本是真实的。尼迪的苦难——解读术语、讨价还价付额——不仅仅是尼迪的苦难。这是普通人面对复杂医疗系统的经历，充满了让医生和患者之间产生隔阂的术语、低效的转诊和转移，以及充满悲剧和喜剧的错误的案例管理。大量时间被转移到治愈之外，时间浪费在跳过官僚障碍、在分隔的大厅中协调预约，以及忍受血压飙升的缓慢电话排队和患者门户的考验中。</p>
<p>这种浪费不仅令人烦恼，而且代价高昂。每花费的医疗保健美元中有 48 美分——仅在 2015 年就约为 9500 亿美元——用于非临床任务。在过去 50 年中，美国其他行业的生产力大幅提高，但医疗保健是一个主要的例外。</p>
<p>尼迪的故事向我们展示了一个破碎系统的人类代价。作为一个被困在这个功能失调结构中的普通工人，我们看到它如何浪费她的时间，损害她的福祉，并消耗她对抗疾病所需的精力。</p>
<h2 id="LLMs在医疗保健中的承诺"><a href="#LLMs在医疗保健中的承诺" class="headerlink" title="LLMs在医疗保健中的承诺"></a>LLMs在医疗保健中的承诺</h2><p>然而，仍然有希望的曙光。如果LLMs和生成式人工智能能够融入现实世界的系统，它们可以执行繁琐的行政任务；它们可以预约和发送个性化的信息。人工智能可以捕捉目前锁定在医疗记录中的信息，并允许这些信息随着患者的移动而转移，只需患者的触碰，而不是被困在患者被转诊的机构中。当涉及到与保险公司的接口时，大多数人会更希望由人工智能来掌舵，让患者和医生能够专注于健康护理的事务。</p>
<p>尼迪的挑战性经历突显了系统性问题，迫使脆弱群体在没有足够支持的情况下应对复杂的健康之旅。然而，正是自动化和人工智能在试图最终突破这一持久的生产力边界时，可能会带来改变。医疗保健的高度定制化特性，涉及人类生命，导致其对变革采取保守态度。诊断和治疗不适合大规模标准化。处理保险等不同系统需要人类助手。临床医生面临的判断是深具情境性的，通过多年的实践经验获得。简单来说，信息不对称和不可转移性使得医疗保健在深度手工且未被算法触及的过程中免受宏观优化的影响。</p>
<p>但绩效疲劳也是一种成本，包括医生的倦怠、获取医疗服务的财务障碍，以及因缺乏能力而导致的可预防死亡。像 COVID-19 这样的冲击帮助揭示了现有医疗保健生产力的问题。走出疫情的过渡期可能会激发急需的现代化，并与一波LLMs和生成式人工智能相一致。自动化可以帮助处理占用过度工作人员时间的日常琐事。基于人工智能的诊断助手可以减少错误率，并用数据增强人类判断。最重要的是，智能协调将保护像 Nidhi 这样的患者，免于在很大程度上独自与过于繁忙的官僚体系作斗争。</p>
<p>新技术如LLMs需要谨慎管理，但如果以深思熟虑的方式应用——以伦理为核心——它们可能会导致护理的转变，健康专业人员将从孤立的“修复者”转变为基于团队的“协调者”，为患者提供更全面、主动和以人为本的护理。</p>
<p>尼迪的故事是一个行动的号召。它提醒我们，尽管科技改变了我们的生活、工作和沟通方式，但医疗保健仍然停留在过去的模式中。我们应该利用自动化的潜力，不仅仅是为了提高医疗系统的效率，而是为了建立一个以人为中心、赋权患者并承认健康价值的医疗系统。</p>
<h2 id="机器学习的历史使用"><a href="#机器学习的历史使用" class="headerlink" title="机器学习的历史使用"></a>机器学习的历史使用</h2><p>医疗行业几十年来一直对各种形式的机器学习抱有希望的乐观态度。我们被承诺人工智能将帮助解决该领域的许多问题。部分原因是机器学习能够读取大量数据集，识别模式，并预测结果，以帮助和加速患者护理的许多方面。它可以被用来跟踪、追踪、处理数据，并最终优化效率。原则上，这应该转化为更好的患者结果、更有效的运营和更高的成本效率。一些机器学习模型确实在帮助实现这一目标——从提高诊断准确性到通过识别大量影像或患者数据中的模式来预测患者再入院的风险。但传统机器学习的影响是有限的，并未提供与LLMs相同的颠覆性好处。</p>
<p>付款方和健康计划利用机器学习的应用来预测昂贵疾病的发生和发展。健康组织内部可能有数百个机器学习模型被构建用于预测和接触某些疾病人群，例如以下情况：</p>
<ul>
<li> 糖尿病</li>
<li> 充血性心力衰竭</li>
<li> 艾滋病</li>
<li> 双相情感障碍</li>
<li> 哮喘</li>
<li> 慢性肾衰竭</li>
<li> 关节退化</li>
<li> 类风湿性关节炎</li>
<li> 慢性阻塞性肺病</li>
<li> 高血压</li>
<li> 关节退化</li>
<li>炎症性肠病</li>
<li> 心房颤动</li>
<li> 高脂血症</li>
</ul>
<p>尽管如此，机器学习的预测与临床医生在床边的方式之间存在根本冲突，机器学习建议支付方尽早和预防性地发现昂贵的合并症，而临床医生更倾向于为患者今天做最好的事情，即使这意味着放弃未来可能的优化。支付方正在大量投资于分析，试图根据历史相关性识别那些更可能“进展为高成本状态”的患者。预测可以在早期谨慎管理的疾病的发生，将使支付方能够引导患者的治疗路径，从而以较低的长期费用保持健康。</p>
<p>进一步的冲突产生是因为预测依赖于对丰富背景的解释，而有限的数据导致干预措施的过度规定。社会因素强有力地影响着发展轨迹，过于专注于生理学，导致对贫困群体的偏见，因为忽视了为什么某一群体可能会经历比另一群体更差的结果，然后才将其标记为高成本的负担。</p>
<p>早期干预通过预防性、积极的行动，勤勉地促进了那些获得回报者的利益。影响力和权力的复杂平衡需要监督，以确保预测模型尊重影响个人的心理、经济和环境复杂性，而不仅仅是精算可靠性，从而对个人风险进行建模，以便于管理和负担得起。健康的最终责任必须由每个人自己承担。</p>
<p>这些孤立组织中以人工智能&#x2F;机器学习为中心的方法输出同样狭窄、缓慢、昂贵且存在偏见，而假设的利用人工智能进行再造的未来依然没有变化。为什么？因为大多数医疗保健机器学习严重依赖于需要稀缺专家进行长时间和细致清理、标记和格式化的专业训练数据。构建、维护和解释这些机器学习模型消耗了进行变革所需的资源，而医疗保健高管将人工智能视为过于承诺而未能兑现的问题使情况更加复杂。这些高管从未考虑过他们可能是一个因素，某种自我实现的预言，因为他们优先考虑成本和短期利润。</p>
<p>与之前的其他人工智能不同，LLMs如Gemini、ChatGPT 和Claude利用互联网规模的文本数据来模仿科学发现的过程以及临床呈现的变异。这些模型从文献中学习医生的思维方式，而不是从特定输入格式生成的训练数据。生成式人工智能还可以用于创建人工但逼真的数据，以扩展模型。结合LLMs和生成技术，可能会创造出改善诊断、治疗计划和个性化干预所需的灵活性、适应性和持续学习，从而在各地以盈利的方式大规模实现。</p>
<h1 id="使用LLMs和生成式人工智能进行医疗自动化"><a href="#使用LLMs和生成式人工智能进行医疗自动化" class="headerlink" title="使用LLMs和生成式人工智能进行医疗自动化"></a>使用LLMs和生成式人工智能进行医疗自动化</h1><p>有几种方式可以让LLMs和生成式人工智能帮助像 Nidhi 这样的人：</p>
<ul>
<li>LLMs 可以驱动对话式人工智能助手，充当智能患者护理协调员。在从 Nidhi 那里了解到她需要解决的问题后，这些协调员可能能够自动处理许多实际安排，例如预约安排、交通安排、获取支付方授权、预防性医疗措施的提醒等。</li>
<li>生成式人工智能可以根据 Nidhi 的生活方式和需求（例如她的照顾责任）提供个性化的护理计划。这条自我护理的路径将通过可行的建议来优化结果，从而简化并赋予她意义。</li>
<li>LLM 聊天机器人可以让尼迪向一个富有同情心和道德感的倾听者表达她的恐惧和挫折。对于那些感到不堪重负的人来说，除了信息之外，情感和社会支持也可以提供帮助。</li>
<li>生成模型可能有助于制定计划，以帮助尼迪的家庭克服因她的疾病而造成的交通需求、咨询、家务、临时照护以及其他家庭空缺和日程中的空白。</li>
</ul>
<p>换句话说，无论是促进协调、提供医疗决策建议、提供富有同理心的治疗支持、动态应对症状，还是管理繁琐的日常生活，LLMs 和生成式人工智能都可以帮助像尼迪这样的患者专注于康复和预防。</p>
<p>从自动化诊所行政任务到生成个性化护理计划，LLMs和生成式人工智能在医疗保健中的承诺不再仅仅是理论。</p>
<p>萨拉·瓦伊齐（Sara Vaezy），普罗维登斯的首席战略和数字官，表示生成式人工智能将在“未来几年”改变“医疗保健的每一个方面”。生成式人工智能模型，如 ChatGPT，正在推动包括医疗保健在内的大量行业进入一个转折点。普罗维登斯的创新传统包括测试将生成式人工智能融入患者体验的可能性，以保持其使命的真实性。普罗维登斯采取了自上而下的方法，从一开始就设计具有公平性和安全性保护措施的人工智能基础设施，同时也采取了自下而上的方法，从基层识别脆弱的体验和用例，在那里进行试点或测试。医疗保健系统有四个重点领域：</p>
<ul>
<li>改善临床护理流程</li>
<li>为消费者和患者创造更好的体验</li>
<li>为后勤行政任务的员工打造更好的体验</li>
<li>改善后台办公功能</li>
</ul>
<p>例如，生成式人工智能可以帮助在患者预约之前收集数据，提供临床决策支持，并自动化重复性工作。普罗维登斯制定了一项人工智能战略，基于这样的理念：机器终将超越人类能力，这要求护理团队在他们独特的任务上磨练技能。</p>
<p>为了快速和大规模地实现生成式人工智能，普罗维登斯支持这一目标，制定灵活的战略和计划，与科技公司建立战略合作伙伴关系，并提供变更管理，以教育和培训团队成员适应新的工作流程。医疗保健的管理者有责任安全、公平、可靠和合乎道德地在医疗技术中实施生成式人工智能，以支持患者以新的方式。</p>
<p>美国医疗公司（HCA）——美国最大的营利性医疗系统和全球最大的医院运营商——正在部署几种生成式人工智能解决方案，以帮助“&#x3D;&#x3D;重新构想如何提供护理”。HCA 正在使用临床生成式人工智能系统来帮助自动化工作流程&#x3D;&#x3D;，并通过使用LLMs来现代化患者交接的各个方面，从而减少文档的低效率和医生的负担。在一项试点项目中，HCA 将使用来自谷歌的LLM来自动生成详细报告，并通过自动化经过人工验证的患者交接来节省护士的时间。</p>
<p>虽然LLMs在医疗保健中的自动化仍在进行中，但它有潜力改变护理服务的交付。工作流程、效率和患者护理通过自动化索赔处理和多个行政任务等不同方式得到了提升。</p>
<h2 id="解锁医学秘密：LLMs-如何革新药物发现"><a href="#解锁医学秘密：LLMs-如何革新药物发现" class="headerlink" title="解锁医学秘密：LLMs 如何革新药物发现"></a>解锁医学秘密：LLMs 如何革新药物发现</h2><p>识别有吸引力的药物靶点。不再依赖人类直觉，LLMs 可以在海量数据中筛选出隐藏的疾病机制、蛋白质相互作用模式、“基因指纹”，并激发对新药物靶点的搜索，验证它们的潜力，甚至推动个性化医学的发展。LLMs 可以分析你的基因，为你量身定制药物，开辟治疗你疾病的新途径。</p>
<p>超越这种原始洞察——创造新事物——是对LLMs的重新利用，即在现有药物和缺乏治疗的疾病之间找到意想不到的联系。也被称为药物再利用，这种魔力可以以惊人的速度和相对于传统方法的低成本开发新疗法，传统方法是先合成新药，然后进行测试。</p>
<h3 id="超越-X-光：LLMs-看到我们所忽视的东西"><a href="#超越-X-光：LLMs-看到我们所忽视的东西" class="headerlink" title="超越 X 光：LLMs 看到我们所忽视的东西"></a>超越 X 光：LLMs 看到我们所忽视的东西</h3><p>医学成像与医学本身一样古老，但人眼只能看到整体图像的一小部分。LLMs是一种新型侦探，每个侦探都具备前所未有的视觉信息能力和能够处理文本的工具。关于病症的文本和图像线索可以被转化为新的医学分析师的角色。</p>
<p>这些图像不仅仅是图片；它们是编织的、活跃的、三维的事物。扩张的主动脉根、脑膜瘤、颈动脉狭窄——这些在肉眼（甚至是最有经验的放射科医生）看来可能隐藏的事物被揭示出来。噪声中的模式变得可见，模糊的诊断得以明确。或者我们可以说，LLM对其医生用户说：“嘿，伙计们！还记得上个月扫描中那个微小的纹理吗？我们一直在反复审查？恰好有一篇论文描述了一种具有完全相同纹理的罕见疾病。”那个模糊的症状突然找到了它的原因。治疗的道路突然打开。</p>
<p>LLMs 帮助从医学文献、病史和注释图像中构建疾病的情境化图像。情境评估通常是临床医生指导治疗决策的最有价值的信息，它也可以帮助患者更好地理解他们的疾病，通过对扫描结果真正含义的解读，消除神秘感。这感觉有点像魔法。</p>
<p>医学不再仅仅关注身体，而是透视身体。在LLMs的洞察指导下，它可以达到一个新的诊断潜力水平，使诊断更加精准，治疗更加专注，患者在面对疾病时更加有力和聪明。</p>
<p>今天，深度学习是医学影像领域的最先进技术。在不久的将来，LLMs 将成为焦点，因为它们正在成熟。</p>
<h3 id="电子健康记录的发展：LLMs-重写医疗文档"><a href="#电子健康记录的发展：LLMs-重写医疗文档" class="headerlink" title="电子健康记录的发展：LLMs 重写医疗文档"></a>电子健康记录的发展：LLMs 重写医疗文档</h3><p>传统的电子健康记录（EHR）曾经不过是数字文件柜，存储数据但在分析或预防护理方面几乎没有提供帮助。这一切即将改变。随着LLMs的兴起，一个全新的人工智能时代可能即将到来：电子健康记录可能成为同事，利用其预测和分析能力来释放电子健康记录的全部潜力。</p>
<p>LLMs 具备通过挖掘以前的数据集来发现模式、逆境发生的概率或未来的警示信号，从而预测未来或至少未来的可能性的能力。可以将其想象成一个水晶球，显示哪些患者易患某种疾病、可能再次入院或可能遭受某种不良事件。凭借这一能力，临床护理可以根据患者的情况进行调整。</p>
<p>&#x3D;&#x3D;无需自己翻阅大量医学期刊。LLMs 已为您完成了这项工作。您提供患者数据，他们将其与他们在庞大数据库中存储的所有相关患者数据进行比较，然后他们会说类似以下的话：“供您参考，医生，这就是其他患有您患者病情的人所做的。选项 A 似乎比选项 B 更常用，而选项 C 几乎从未使用。”&#x3D;&#x3D;</p>
<p>现在，他们正在将这种LLM魔法引入电子健康记录（EHR）。这些模型浏览患者记录，寻找关于药物不依从性的线索，触发警报以标记潜在的问题情况，并使医生能够及早干预。现在，一个充满无限可能的未来开始了，从个性化医疗到预防护理。</p>
<p>电子健康记录（EHR）正在超越仅在处理索赔或完成临床测试时更新的静态文档。随着LLMs的整合，电子健康记录正在转变为动态、智能的系统。这些先进的电子健康记录将持续分析来自各种来源的大量数据，提供实时洞察，并推动更明智的医疗决策。这是医疗保健即将到来的未来。</p>
<h3 id="解锁医学金矿：LLMs-矿藏文本中的隐藏宝石"><a href="#解锁医学金矿：LLMs-矿藏文本中的隐藏宝石" class="headerlink" title="解锁医学金矿：LLMs 矿藏文本中的隐藏宝石"></a>解锁医学金矿：LLMs 矿藏文本中的隐藏宝石</h3><p>一旦在页面上涂写，这些文本现在成为了等待解读的生物信息矿藏。使用LLMs训练的临床文本语料库，人们可以发现语言模式，指示可能基于种族、性别、社会经济地位和其他健康决定因素而发生的隐性偏见。例如，LLM可能会标记某些笔记，这些笔记对“X”组的语言框架呈现出比“Y”组更消极的表达。</p>
<p>想象一下一个LLM在放射学报告中梳理丰富的背景信息，比如异常的描述、它们的位置和解释，同时在找到疾病特征匹配时发出警报。再也不用繁琐的手动解析了！LLMs可以即时索引和检索高价值的发现描述（那些最相关且可能影响诊断或治疗的），并为放射科医生提供帮助，使他们更容易做出诊断。最终，放射科医生有一个个人助手在他们的代表下不知疲倦地扫描报告，突出关键线索供专家关注。</p>
<p>不仅仅是语言的问题。LLMs 还掌握了医学的语法，提炼出症状、诊断和治疗之间复杂的关系。随着我们通过在更大和更复杂的文本集上训练 LLMs 来微调这种理解，他们将能够预测相关的患者结果，高效地现代化临床研究，甚至定制患者护理旅程。</p>
<h1 id="自动化和管理医疗保健"><a href="#自动化和管理医疗保健" class="headerlink" title="自动化和管理医疗保健"></a>自动化和管理医疗保健</h1><p>想象一个世界，在那里，穿越医疗迷宫不再是艰巨的壮举或令人畏惧的任务，而是一场晨间散步。进入你的个人医疗 AI 助手，由LLMs和生成式 AI 驱动，它是你在医生预约、保险表格和无尽电话中的不知疲倦的导航者。</p>
<p>从个人的角度来看，导航医疗系统是一场噩梦。在我们以 Nidhi 为例的情况下，管理她的治疗需要她做到以下几点：</p>
<ul>
<li>由于管理她的医疗保健需要多个步骤，她必须安排预约，确保提供者接受她的保险并且是“网络内”的，以避免更高的费用。她需要了解自己的财务责任，包括共付额和免赔额。在接受治疗之前，她必须获得预授权并提交所需的文件。在整个过程中，她必须有效地向护理人员传达她的健康状况。</li>
<li>她必须识别联邦、州、地方或私人机构提供的资源来支持她，最后但同样重要的是，找到一个可以在她对治疗和生活产生负面想法时与之交流的人。</li>
</ul>
<p>在多位医生之间管理癌症治疗对患者来说面临着巨大的挑战。正如尼迪的故事所示，在与癌症的身体和情感影响作斗争的同时，处理临床复杂性往往在没有广泛支持的情况下显得不堪重负。</p>
<p>患者经常根据肿瘤特征和进展情况看外科医生、肿瘤科医生、放射技术人员和专科医生。每个临床视角对治疗计划的影响不同。患者在处理毁灭性的消息和虚弱的症状时，努力跟踪谁说了什么、评估冲突和记住下一步。</p>
<p>预约常常被重复预定，因为办公室之间的协调出现问题。记录共享的延迟意味着患者成为医疗中介，试图及时传播测试结果。当可避免的并发症发生时，沟通的缺口让患者感到沮丧。</p>
<p>在这段支离破碎的医疗旅程中，患者往往缺乏持续的情感支持，尽管安慰对康复有很大影响。个别临床医生很少关注患者整体健康的各个方面，包括恐惧、生活方式的变化以及超出其专业领域的心理健康问题。当患者在不同的医疗提供者之间转移时，护理的连续性往往会中断。</p>
<p>尽管跨学科医学在统计上提高了生存率，但对已经脆弱的个体来说，支离破碎的治疗过程往往使他们容易被忽视。以患者为中心的协调，减少后勤负担并提供整体护理，可能会在结果上超越单纯的专业知识。人际关系在癌症斗争中无法被优化。&#x3D;&#x3D;全面的临床沟通和同理心被证明是医学中最重要的治疗手段&#x3D;&#x3D;。</p>
<h2 id="人工智能医疗助手"><a href="#人工智能医疗助手" class="headerlink" title="人工智能医疗助手"></a>人工智能医疗助手</h2><p>尼迪，一位职场母亲，当她听到“III 期 B 型乳腺癌”这几个字时，感觉脚下的地面消失了。世界变得模糊，文书工作变成了象形文字，导航医疗系统就像穿着人字拖攀登珠穆朗玛峰。如果尼迪有一个私人助理来处理这些任务，那该多好？于是，“塔拉”出现了，她的人工智能医疗助理，在风暴中成为了一线希望（图 3-1）。</p>
<p><img src="/../asset_03BeyondWhiteCoats/01.png">图 3-1 塔拉，人工智能医疗助手</p>
<p>塔拉凭借LLMs和生成式人工智能成为了尼迪的救星。她不需要破解医学术语来解读报告和弄清楚自己发生了什么。塔拉将报告翻译成易于理解的笔记，然后列出可能的治疗方案和相关副作用。患者不再需要拨打数百个电话联系众多医生。塔拉负责在医院和诊所之间安排预约。</p>
<p>塔拉开始接管尼迪的任务，成为尼迪的杰出项目经理。凭借LLMs的语言处理能力，塔拉同时扫描来自无数机构的文件，自动安排他们的预约，并像本能一样与保险公司讨价还价。没有电话的等待音乐，没有浪费时间。</p>
<p>但塔拉不仅仅是一个物流大师。生成式人工智能分析了尼迪的医疗数据，测试药物和治疗之间的相互作用——并可以叠加以提高疗效。尼迪被治疗选择压得喘不过气来，但塔拉将选项解析得易于理解，以公正的数字声音回顾优缺点。塔拉问尼迪是否感到孤单，并鼓励她加入支持小组，如果尼迪感到焦虑，塔拉则是一个倾诉的对象和冷静的建议储存库。</p>
<p>有塔拉在旁照看行政事务，她将大部分必要的管理工作委派给尼迪，为各种恢复创造了空间。预约得到了协调，药物提醒出现在尼迪的手机上，保险表格以机械的精确度在系统中流转，最重要的是，山上的路径被勾勒出来，危险点被标记。恢复的重担更轻松地落在一个人身上，而不是两个人，攀登所需的能量得到了更均匀的分配，使尼迪能够休息。通过这种方式，塔拉既在尼迪身边走着，又在前面走了几步。</p>
<p>尼迪成功的故事因此也是一个技术故事。LLMs和生成式人工智能不仅仅提供了捷径或后勤解决方案，而是成为了尼迪真正的赋能工具——让她重新掌控自己的生活，&#x3D;&#x3D;专注于真正重要的事情：接受治疗以保持健康&#x3D;&#x3D;。</p>
<p>这不仅仅是尼迪的故事。这是&#x3D;&#x3D;对未来护理的愿景，利用技术让患者掌控自己的健康，减轻他们的压力，简化整个过程&#x3D;&#x3D;。也许从有意义的对话参与的角度来看，LLMs在生成自然听起来的文本和理解文本方面表现出色，这是生成清晰可理解文本的重要一步。它们能够识别意图，推导上下文，并对语言中的细微差别表现出有用的敏感性。</p>
<p>GenAI 使聊天机器人能够通过与用户的互动学习，并通过修改响应来适应个体偏好——例如，适应用户的语速和结构——并借鉴用户使用的对话内容（如俚语或幽默的评论），以帮助更有效地沟通。GenAI 还允许聊天机器人在特定内容或数据集上进行训练，以增强知识。GenAI 生成新文本序列的能力使聊天机器人能够与用户进行开放式对话，探索多个主题，并对用户的提示做出创造性的回应，同时使轮流发言、主题转换和响应形成更自然地成为互动的一部分。GenAI 还允许聊天机器人根据个体用户的需求和偏好进行个性化设置，提供记住用户信息、适应语言风格、提供个性化内容和推荐，以及以符合用户个性和特点的方式呈现信息等功能。</p>
<p>塔拉，尼迪的个人助理，提供以下功能：</p>
<ul>
<li>24&#x2F;7 预约: 预约调度可以通过聊天机器人全天候处理，因此无需等待接听或创建在线账户进行预约。</li>
<li>个性化日历安排: GenAI 可以了解患者的偏好，例如他们更喜欢看哪位医生、他们更喜欢哪个地点以及他们更喜欢何时就诊，并为他们提供建议选项。</li>
<li>自动提醒: 人工智能将监控您的日程安排，并通过短信或电子邮件向您发送会议、约会和活动的提醒。这可以确保您不会重复预订或错过约会。</li>
<li>保险和福利支票: 使用 GenAI，您可以实时了解患者是否有保险以及是否符合护理资格。</li>
<li>多语言选项: 您可以通过提供双语或多语种聊天机器人来改善不同患者的可及性并消除障碍。</li>
<li>陪伴聊天机器人: GenAI 可以用于制作专为对话和陪伴而调校的陪伴聊天机器人，特别是针对孤独或孤立的人，并且可以通过体验和模拟情感以及同情地支持患者度过生活中的困扰，成为一个对话伴侣。</li>
</ul>
<h2 id="从医疗系统的角度自动化行政任务"><a href="#从医疗系统的角度自动化行政任务" class="headerlink" title="从医疗系统的角度自动化行政任务"></a>从医疗系统的角度自动化行政任务</h2><p>美国拥有大约 6,000 家医院，超过 300,000 个医生集团，超过 1,000 家健康保险公司，以及一大堆需要遵守的健康代码，因此可以看出美国医疗系统是世界上行政管理最复杂的系统之一。甚至建议行政简化几乎是异端。</p>
<p>美国的管理和账单&#x2F;保险成本显著高于其他任何国家，每年高达 1 万亿美元，超过德国、法国和意大利的医疗系统总和。众多健康保险公司，提供多种计划，涵盖不同的保障水平和不同的网络；在其中一个计划中，可能会有数百个选项，每个选项都有不同的免赔额、共付额和覆盖服务。每个计划都有其自身的福利、文件、支付方式和规则。数十万个医疗服务的服务代码，都需要与提供者协商价格，这在提供者和保险公司之间造成了文档和证明技术的军备竞赛。庞大的护理管理直接转化为系统的庞大行政费用，并加剧了医生的职业倦怠（图 3-2）。</p>
<p><img src="/../asset_03BeyondWhiteCoats/02.png">图 3-2  倦怠的代价：医生在不断增加的压力下的烦恼</p>
<p>人工智能和LLMs有助于减少医生的倦怠。它们可以让医疗专业人员专注于提供直接的病人护理，同时提高效率、准确性和病人满意度。例子包括：</p>
<ul>
<li><p>与患者助手的互动: </p>
<p>LLMs 可以通过自动检查日历、寻找可用时间并向患者和提供者发送邀请来安排预约。正如患者尼迪使用了塔拉，一个人工智能助手聊天机器人，医生们也将使用聊天机器人，我们离人工智能驱动的聊天机器人与另一个人工智能驱动的聊天机器人互动以实现患者和提供者生态系统最佳结果的现实并不遥远。</p>
</li>
<li><p>管理病人记录: </p>
<p>LLMs 可用于从病人记录中提取信息，例如人口统计、病史和药物，LLMs 可用于填充表格和报告。</p>
</li>
<li><p>生成报告: </p>
<p>LLMs 可用于从医疗数据中生成报告，例如患者人口统计、治疗结果和质量指标。</p>
</li>
<li><p>生成保险索赔或事先授权请求等表格和信件: </p>
<p>LLMs 可用于审查病人记录、识别可收费服务，并准确高效地完成保险索赔。</p>
</li>
<li><p>编码和账单: </p>
<p>LLMs 可以协助医疗编码和账单处理，确保提供者获得准确的报销，并减少行政负担。</p>
</li>
</ul>
<h2 id="编码和账单"><a href="#编码和账单" class="headerlink" title="编码和账单"></a>编码和账单</h2><p>编码和计费系统是健康收入周期的关键，但它们可能充满陷阱——代价高昂的不准确性、延误和其他干扰。医疗编码错误、错失的计费机会以及临床与计费系统之间缺乏整合只是一些罪魁祸首。</p>
<p>这些关键挑战在编码和账单周期的每个环节都会出现——在医疗服务中医生与患者之间、在文档记录中、在编码和索赔提交期间，以及在支付入账时。拒付或少付可能源于简单的错误、行政流程中的低效、合规风险、编码错误，甚至是最不可能的欺诈预期。</p>
<p>一些最重要的编码和账单挑战包括：</p>
<ul>
<li>上码: 对于某些专业，您处理的是复杂案例，这使得报告高级评估和管理代码更加高效。虽然这样做没问题，但您必须准确记录使用该编码的原因，以确保您没有使用不适当的高级代码。</li>
<li>解耦: 这就是你在一个程序的不同部分使用多个代码，而不是整个程序的适当代码的时候。这可能是由于错误造成的，但当组织试图增加支付金额时也会发生，这就是为什么这通常会被审计的原因。</li>
<li>不记录: 这意味着文档缺失或不充分。</li>
<li>拼写错误和错误: 有时候你只是按错了键。一个常见的错误发生在编码时数字颠倒，或者信息被工作人员或患者错误地添加。</li>
</ul>
<p>LLMs 和生成式人工智能可以帮助解决以下编码和账单挑战：</p>
<ul>
<li><p>上码: </p>
<p>LLMs 用作医疗编码推荐系统，利用 LLMs 对患者记录、医疗编码规则和账单进行分析，可以告诉我们正在处理的案例应该使用哪个最佳编码。审查文档，以确保所选择的代码支持临床证据，并确保文档的一致性和完整性。通过检查个别临床医生在案例层面的编码历史趋势，LLMs 可能能够发现过度编码趋势并标记案例以进行审计。</p>
</li>
<li><p>解耦: </p>
<p>LLMs 将程序映射到正确的高级计费代码，确保程序组件通过单一代码仅记录一次。LLMs 可以为编码人员提供提示，在计费时列出有效的捆绑代码，从而减少对专业编码人员的需求。</p>
</li>
<li><p>不记录: </p>
<p>LLMs 可以从音频录音或自由文本笔记生成病人记录和摘要，以便提供者能够捕捉所有关键信息以确保准确计费。LLMs 可以请求任何缺失的信息，以便正确编码索赔。</p>
</li>
<li><p>拼写错误和错误: </p>
<p>LLMs 可以添加到账单和索赔工作流程中，以标记和修复常见的拼写错误、编码或患者信息错误，从而防止下游问题的发生。利用账单数据，LLMs 可以找出可能指向文书错误的异常峰值或离群值，然后进行检查和更正。</p>
</li>
</ul>
<p>LLMs和生成式人工智能在编码和计费中的额外好处包括：</p>
<ul>
<li>降低劳动力成本: 自动化编码任务可以释放宝贵的员工时间用于更复杂的活动，从而提高整体效率。</li>
<li>增强合规性: 提高编码准确性可以降低审计、罚款和声誉损害的风险。</li>
<li>改善收入周期管理: 准确及时的账单可以为医疗机构带来更快的报销和改善的现金流。</li>
<li>个性化患者沟通: LLMs 可以为患者生成清晰易懂的账单说明，促进透明度并减少与账单相关的咨询。</li>
</ul>
<p>通过解决这些挑战，LLMs和生成式人工智能可以促进更准确、高效和合规的编码和计费过程，最终使医疗服务提供者和患者都受益。</p>
<p>随着LLMs和生成式人工智能的不断发展，我们可以期待看到更多创新的应用来自动化医疗行政任务。这将有助于提高医疗系统的效率、准确性和患者体验，使医疗专业人员能够专注于为患者提供高质量的护理。</p>
<h2 id="临床过程"><a href="#临床过程" class="headerlink" title="临床过程"></a>临床过程</h2><p>临床过程中的自动化是利用技术加快和提高提供医疗服务的临床效率和有效性。新兴的人工智能技术，如自主智能，可以帮助自动化重复性任务，汇总和分析数据，并提供决策支持。在如此接近人类影响规模的自动化中，使用LLMS和生成式人工智能有望通过加快和增强临床护理的交付来改变医疗服务的提供。</p>
<p>以下是一些自动化在临床流程中应用的例子：</p>
<ul>
<li>订单录入和结果报告: 自动化可以用于自动输入实验室测试、药物和其他服务的订单，并将结果发送回下单的提供者。</li>
<li>临床文档: 自动化可以用于生成临床文档，例如进展记录、出院总结和药物核对报告。</li>
</ul>
<p>例如，每次尼迪接受治疗时，接收和出院的行政人员会审查她的病史，做笔记，并建议对她的财务、家庭地址和电话号码（如有）进行任何具体更改。医生、护士和技术人员会审查临床记录并提出建议。</p>
<h2 id="优化医疗工作流程"><a href="#优化医疗工作流程" class="headerlink" title="优化医疗工作流程"></a>优化医疗工作流程</h2><p>电子病历（EMR）系统对临床工作流程产生了重大影响，尽管这种影响复杂，既有好处也有缺点。从积极的一面来看，电子病历标准化和数字化了患者数据，使护理团队能够高效访问。内置的临床决策支持、医嘱集、模板和警报也促进了基于证据的护理。无缝的记录改善了协调性，减少了重复服务。</p>
<p>然而，批评者认为电子病历（EMR）优化工作流程是为了账单目的，而不是为了护理质量。医生在电脑上记录的时间增加，损害了医患关系。由于无关紧要的警报过多，导致警报疲劳。对独特临床思维的定制证明是困难的。</p>
<p>最平衡的观点认为电子病历（EMR）是现有规范的放大器：它们强化并传播任何编码在其框架中的流程，这可能反映系统目标而非个别患者的需求。优化健康结果可能需要将数字基础设施与以关系和信任为中心的人际协调相结合。</p>
<p>本质上，电子病历（EMR）通过强制标准化和数字化沟通强烈影响护理交付机制，但不应僵化地支配护理文化本身。医学核心的人际联系依赖于动态适应的工作流程，而不是仅仅优化效率的交易。EMR 临床决策支持旨在增强而不是取代经验丰富、具伦理的提供者与患者合作的判断。</p>
<p>LLMs 和生成式人工智能可以通过几个关键方式帮助改善电子病历系统及其对临床工作流程的影响：</p>
<ul>
<li>自适应工作流程: LLMs 可以分析临床医生与患者的互动，并根据个性化需求和风格定制默认工作流程、医嘱集和决策树。</li>
<li>自动化文档: 生成模型可以根据就诊记录和护理活动起草临床笔记和文书，准确反映独特的细节。</li>
<li>人性化集成: 智能界面由富有同理心的LLMs驱动，使临床医生能够使用自然语言指令来下达测试、转诊等，而不是因鼠标点击而分散注意力。</li>
<li>患者数据丰富化: 算法可以整合外部记录、基因组数据、可穿戴传感器数据等，以克服电子病历的局限性并提供决策支持。</li>
</ul>
<p>理想情况下，这些技术将增强以患者为中心的护理，捕捉细微差别，减少行政负担，并用最新的个性化发现补充机构知识，从而推动更好的结果。</p>
<h2 id="转变临床试验格局"><a href="#转变临床试验格局" class="headerlink" title="转变临床试验格局"></a>转变临床试验格局</h2><p>将 Nidhi 纳入临床试验对她的肿瘤科医生来说是一个复杂的过程。他们必须首先确定合适的试验，仔细审查其方案，并根据 Nidhi 的病史仔细评估她的资格。这需要与试验团队合作，以了解潜在风险，并确保所有必要的文件准确提交。一旦 Nidhi 被纳入该过程，她必须遵循非常严格的协议，这可能持续三到五年。</p>
<p>一些导致挑战的关键因素包括：</p>
<ul>
<li>患者招募与留存: 寻找符合所有试验标准的合格且愿意参与的患者可能非常困难且耗时。一旦招募到患者，保持他们在研究中的参与也可能具有挑战性。</li>
<li>合规性: 关于知情同意、数据隐私、安全报告等方面的规则可能使试验的执行变得复杂且耗时，以确保合规。各国的法规不同，进一步增加了全球试验的复杂性。</li>
<li>协议设计: 设计稳健的协议并选择合适的点以获得有用的结果既是一门科学，也是一门艺术，受到过去经验的启发。次优设计可能会使试验变得无效。</li>
<li>质量和一致性: 确保所有参与地点在试验执行中的一致性，并保持高质量标准可能是一个巨大的挑战。即使在一个地点的失误也可能影响试验的有效性。</li>
<li>物流复杂性: 从药物供应链到协调患者的随访访问，所有这些都需要涉及多个利益相关者的巨大物流协调。失误可能严重影响试验进展。</li>
<li>数据管理: 收集、清理和管理大量多维患者数据可能会带来数据分析挑战。良好的数据管理对于得出正确的结论至关重要。</li>
<li>数据质量与分析: 两者对于可靠的试验结果至关重要。只有完整或准确的数据才能确保整个研究的准确性。因此，在试验过程中保持高数据质量标准是至关重要的。</li>
<li>数据分析复杂性: 分析来自不同来源的大型数据集需要先进的统计方法和专业知识。</li>
<li>财务限制: 临床试验非常昂贵，费用高达数百万美元。资金不足或获得资金的延迟仍然是一个常见的瓶颈。</li>
<li>伦理考虑和知情同意: 确保参与者充分理解参与的风险和收益是至关重要的。</li>
<li>保护参与者的隐私和机密性: 保护敏感健康数据至关重要。</li>
<li>平衡风险与收益: 研究人员必须仔细权衡新治疗的潜在好处与参与者的风险。</li>
</ul>
<p>克服这些挑战需要巨大的跨职能协调、全球流程标准化、严格的质量控制，以及利益相关者对共同目标的对齐——这绝非易事！</p>
<p>LLMs 和 GenAI 可能在几个方面帮助临床试验：</p>
<ul>
<li>人工智能可以分析医疗记录和患者数据，以更快、更准确地识别符合条件的试验候选者。这使得试验能够更快地招募参与者。</li>
<li>人工智能可以审查研究文献和过去的试验数据，以帮助设计研究方案，确定最佳终点、剂量考虑等。这可以帮助提高试验的质量和效率。</li>
<li>人工智能可以在试验期间持续监测来自可穿戴设备、应用程序等的患者数据。它可以提前标记安全问题，改善合规性监测，并根据接收到的数据自适应调整试验过程。</li>
<li>GenAI 可以分析复杂的多模态试验数据，以发现洞察，例如，通过关联基因组、表型和结果数据来识别生物标志物。它还可以检查数据质量并识别异常。这将导致从试验中获得更快、更丰富的洞察。</li>
<li>解读临床试验结果所需的细微差别和背景信息是巨大的。使用LLMs可以吸收所有可用的医学研究和真实世界证据数据，以解读试验结果是否以及如何应更新医学实践或是否需要更多研究。这将导致更好的临床适用性和试验后的决策。</li>
</ul>
<p>LLMs 和 GenAI 可以使高质量、富有洞察力的临床试验的许多方面变得更快、更便宜和更好。它可能在未来提高临床试验的效率和可靠性方面发挥不可或缺的作用。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本章探讨了自动化在过去几十年中在医疗保健领域加速但不均匀的渗透，受到该领域制度惯性的阻碍。然而，新兴的LLMs人工智能子类承诺提供一种多功能性和响应能力，最终通过革命性的生产力提升、洞察生成，甚至医疗工作流程的经济转型，克服了采用障碍。</p>
<p>本章提供了各种基于LLM的创新小插曲，优化当前的痛点。智能助手减少了因与账单系统作斗争而浪费的行政时间，解放了过度劳累的员工。诊断LLMs挖掘全球语料库，将微妙的症状与超出任何从业者经验的罕见疾病联系起来。临床试验管理实现了受试者招募、方案设计和结果分析的自动化，以促进更优越的治疗发展。</p>
<p>每个场景都突显了语言智能的人工智能如何通过生成式构建解决方案或从过于庞大且无结构的知识库中提取可操作的模式，来应对曾经顽固的低效问题。这一范式转变表明，医疗保健可能会效仿其他最近的颠覆性变革，从以往看似有前景但不切实际的自动化技术中实现大规模的生产力和卓越收益，这一过程得益于响应式算法解决方案的加速和普及。</p>
<p>1 “全球首个聚焦超声癌症免疫治疗中心启动，”UVAHealth，2022 年 5 月 11 日，<a target="_blank" rel="noopener" href="https://newsroom.uvahealth.com/2022/05/11/worlds-1st-focused-ultrasound-cancer-immunotherapy-center-launched%E3%80%82">https://newsroom.uvahealth.com/2022/05/11/worlds-1st-focused-ultrasound-cancer-immunotherapy-center-launched。</a></p>
<p>2 艾莉森·H·佩恩，“聚焦超声作为乳腺癌的非侵入性治疗”，犹他大学，2021 年 3 月 5 日，<a target="_blank" rel="noopener" href="https://discovery.med.utah.edu/2021/focused-ultrasound-as-a-non-invasive-treatment-for-breast-cancer%E3%80%82">https://discovery.med.utah.edu/2021/focused-ultrasound-as-a-non-invasive-treatment-for-breast-cancer。</a></p>
<p>3 韩阿琳、李建亨和朴钟善，“价格透明度和竞争对医院成本的影响：关于全支付索赔数据库的研究，” BMC 健康服务研究 22, no. 1321 (2022), <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9636618%E3%80%82">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9636618。</a></p>
<p>4 Nikhil R. Sahni, Brandon Carrus 和 David M. Cutler, “行政简化与节省两千五百亿美元医疗费用的潜力,” JAMA 326, no. 17 (2021): 1677–1678, <a target="_blank" rel="noopener" href="https://jamanetwork.com/journals/jama/fullarticle/2785480%E3%80%82">https://jamanetwork.com/journals/jama/fullarticle/2785480。</a></p>
<p>5 Nikhil R. Sahni, Prakriti Mishra, Brandon Carrus 和 David M. Cutler, 行政简化：如何在美国医疗保健中节省两千五百亿美元 (麦肯锡公司, 2021 年 10 月), <a target="_blank" rel="noopener" href="https://www.mckinsey.com/~/media/mckinsey/industries/healthcare%20systems%20and%20services/our%20insights/administrative%20simplification%20how%20to%20save%20a%20quarter%20trillion%20dollars%20in%20us%20healthcare/administrative-simplification-how-to-save-a-quarter-trillion-dollars-in-us-healthcare.pdf">https://www.mckinsey.com/~/media/mckinsey/industries/healthcare%20systems%20and%20services/our%20insights/administrative%20simplification%20how%20to%20save%20a%20quarter%20trillion%20dollars%20in%20us%20healthcare/administrative-simplification-how-to-save-a-quarter-trillion-dollars-in-us-healthcare.pdf</a>.</p>
<p>6 海伦·朱拉维尔，“用于早期疾病检测和医学诊断的 AI&#x2F;ML 算法，”Binariks，2023 年 12 月 19 日，<a target="_blank" rel="noopener" href="https://binariks.com/blog/ai-machine-learning-for-early-disease-detection%E3%80%82">https://binariks.com/blog/ai-machine-learning-for-early-disease-detection。</a></p>
<p>7 “生成式人工智能：医疗保健的下一个前沿，”普罗维登斯，2023 年 9 月 17 日，<a target="_blank" rel="noopener" href="https://blog.providence.org/blog/generative-ai-the-next-frontier-of-health-care%E3%80%82">https://blog.providence.org/blog/generative-ai-the-next-frontier-of-health-care。</a></p>
<p>8 Sai Balasubramanian，“HCA，全球最大的医疗保健组织之一，正在部署生成式人工智能，”福布斯，2023 年 8 月 30 日，<a target="_blank" rel="noopener" href="https://www.forbes.com/sites/saibala/2023/08/30/hca-one-of-the-largest-healthcare-organizations-in-the-world-is-deploying-generative-ai/?sh=7ac032bc51dc%E3%80%82">https://www.forbes.com/sites/saibala/2023/08/30/hca-one-of-the-largest-healthcare-organizations-in-the-world-is-deploying-generative-ai/?sh=7ac032bc51dc。</a></p>
<p>9 刘正良等，“Radiology-GPT：一个用于放射学的大型语言模型，”arXiv，2023 年 6 月 14 日，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.08666%E3%80%82">https://arxiv.org/abs/2306.08666。</a></p>
<p>10 “关于美国医院的快速事实，2024”，美国医院协会，2024 年 1 月，<a target="_blank" rel="noopener" href="https://www.aha.org/statistics/fast-facts-us-hospitals%E3%80%82">https://www.aha.org/statistics/fast-facts-us-hospitals。</a></p>
<p>11 “各州医生集团实践数量，” Definitive Healthcare，2024 年 1 月 5 日，<a target="_blank" rel="noopener" href="https://www.definitivehc.com/resources/healthcare-insights/number-physician-group-practices-by-state%E3%80%82">https://www.definitivehc.com/resources/healthcare-insights/number-physician-group-practices-by-state。</a></p>
<p>12 全国保险监管协会，美国健康保险行业分析报告，2021 年，<a target="_blank" rel="noopener" href="https://content.naic.org/sites/default/files/inline-files/2020-Annual-Health-Insurance-Industry-Analysis-Report.pdf%E3%80%82">https://content.naic.org/sites/default/files/inline-files/2020-Annual-Health-Insurance-Industry-Analysis-Report.pdf。</a></p>
<p>13 “2022 年部分国家人均健康支出,” Statista, 2024 年 5 月 22 日, <a target="_blank" rel="noopener" href="https://www.statista.com/statistics/236541/per-capita-health-expenditure-by-country%E3%80%82">https://www.statista.com/statistics/236541/per-capita-health-expenditure-by-country。</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/09/llmsClinical02/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/09/llmsClinical02/" class="post-title-link" itemprop="url">第二章 窥视人工智能黑箱</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-09 11:32:19" itemprop="dateCreated datePublished" datetime="2024-08-09T11:32:19+08:00">2024-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:04:19" itemprop="dateModified" datetime="2024-08-21T14:04:19+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>19k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>34 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>随着大型语言模型（LLMs）和生成式人工智能工具逐渐应用于医疗保健领域，它们带来了复杂且不透明的元素——内在的“黑箱”特性使得这些系统的内部运作显得模糊。这引发了临床医生和医疗领导者在考虑使用LLMs时的自然疑问。这些人工智能系统究竟是如何发展其临床能力的？在它们的训练过程中，幕后发生了什么？黑箱特性是否使得LLMs的建议和思维过程对于严肃的医学或医疗使用过于晦涩？</p>
<p>第二章 揭开了面纱，检查人工智能系统内部的内容。我们讨论Transformer、自注意力机制、神经网络和其他技术元素如何完成重任，以吸收医疗知识并发展推理能力。虽然对每个组件背后的数学进行全面说明超出了读者的需求，但我们提供了对 LLMs 工作原理的易懂解释。窥视黑箱消除了“魔法”的概念，同时使负责任的人工智能采用变得触手可及，即使在持续的不透明中。</p>
<h1 id="LLMs-和生成式人工智能"><a href="#LLMs-和生成式人工智能" class="headerlink" title="LLMs 和生成式人工智能"></a>LLMs 和生成式人工智能</h1><p>LLMs 使用深度学习，这是机器学习的一个子集，利用算法层来处理数据并模仿人类思维过程。深度学习和神经网络这两个术语可以互换使用，因为所有深度学习系统都包含神经网络。神经网络的概念代表了人工智能发展的一个突破。它的灵感来源于人脑中生物神经元的工作方式。<br>在深度学习中，信息通过每一层传递，前一层的输出为下一层提供输入。网络中的第一层称为输入层，而最后一层称为输出层。每一层通常是一个简单的算法。iPhone 或 Android 手机用于面部识别的底层技术，或者 Google 搜索用于视觉识别和搜索对象的技术，就是深度学习。理解人类语言的工具，如 Alexa 或 Siri，需要神经网络。让我们简要回顾一下人工智能的历史，看看我们是如何走到今天的，涉及到生成式人工智能。</p>
<p>在 1970 年代，第一次人工智能寒冬来临，这被解释为对人工智能的资金和兴趣下降，结果是无法兑现的承诺。这种资金不足的影响限制了深度学习和人工智能研究。幸运的是，有一些人在没有资金的情况下继续进行研究。各种过于乐观的人和组织夸大了人工智能的“即时”潜力。</p>
<p>人工智能和深度学习的下一个重要进化步骤发生在 1999 年，当时计算机在处理数据方面变得更快。图形处理单元（GPU）被引入并发现可以用来运行深度学习模型。更快的处理速度以及用GPU 来处理图像，增加了计算速度，在此期间，神经网络变得有用，其使用和价值也随之上升。</p>
<p>到 2011 年，GPU 的速度显著提高，2012 年，Google Brain 发布了一个项目的结果。神经网络可以处理未标记的数据并发现重复模式。深度学习已经是一个研究领域数十年。随着计算能力的提升、大量数据的可用性和算法的改进，它的使用和受欢迎程度迅速增加。</p>
<p>在计算机早期，计算机擅长遵循指令和整理信息。早期的机器学习应用涉及基于数据进行预测。许多疾病预测模型使用机器学习来预测疾病的发生，从而制定干预计划和患者治疗计划。但深度学习，作为机器学习的一个子集，使它们更像海绵，吸收大量信息并用它来创造性地解决问题。一些例子包括识别图片中的不同物体，即使它们模糊或奇怪的角度，识别被泥土覆盖的狗，或在手机应用上实时翻译语言。</p>
<p>但这些学习机器并没有止步于此。现在，认识一下LLMs——这个故事的超级明星。想象他们是班级中的优秀学生，接受了更广泛的图书馆和特殊技术的训练。他们可以写诗和故事，创作新歌曲，或以新颖的方式重新组合元素来设计药物。这就是事情变得令人震惊的地方。我们正处于生成式人工智能的时代。这意味着计算机不仅仅是复制东西；它们还创造东西。</p>
<p>在图 2-1中，我们看到从手工规则到机器学习&#x2F;深度学习再到LLMs的进展。在第一个卡通画面中，一个人手动制定规则来识别吉娃娃。这可能涉及指定诸如大小、毛色、耳形和其他独特特征等标准。这个过程劳动密集，并且需要详细的知识和专业技能来根据预定义的规则识别品种。通常，这些规则通过编程语言中的编码来实现。这个过程涉及创建手工规则，程序员手动编写具体指令以指导系统的行为。</p>
<p><img src="/../asset_02InsideAIBlackBox/01.png">图 2-1  LLMs的出现</p>
<p>我们在第二幅卡通画中看到向机器学习&#x2F;深度学习的过渡。系统不是明确地定义规则，而是通过包含标记的吉娃娃和非吉娃娃图像的数据集进行训练。人工智能使用机器学习从输入图像中提取特征并自动进行预测。使用深度学习时，数据可以是未标记的，我们可以进一步进展，识别出各种图片中的吉娃娃，例如当吉娃娃与物体一起拍照或以不同姿势出现时。</p>
<p>第三个卡通画框介绍了LLMs。在这个画框中，我们不关注识别，而是要求LLM分析大量的书籍、文章和文件，以全面理解吉娃娃。当呈现一张图像时，LLM可以利用其上下文理解提供细致的评估，可能考虑到超出视觉外观的因素，如品种特征、行为和背景。</p>
<h1 id="人工智能与机器学习"><a href="#人工智能与机器学习" class="headerlink" title="人工智能与机器学习"></a>人工智能与机器学习</h1><p>人工智能的核心方面之一是机器学习的使用，这使得计算机能够从数据中学习模式和关系，而无需明确编程。有几位计算机科学家认为，被称为人工智能的解决方案不过是一个机器学习问题的解决。这引发了几个问题，如图 2-2所示，教师正在与他的学生讨论人工智能。3</p>
<p><img src="/../asset_02InsideAIBlackBox/02.png">图 2-2. 什么是人工智能？</p>
<p>人工智能是计算机科学中的一个研究和学习领域。关于如何衡量或概念化人类智能存在相互矛盾的观点，因此精确定义人工智能同样具有挑战性。每当我们看到机器执行以前只有人类才能完成的任务时，我们就将其视为机器智能。通过人工智能，计算机科学家和研究人员试图构建展现与人类相同智能特质的计算机软件——即，AI ≥ 人，如图 2-2所示。</p>
<p>在这个图中，深度学习被视为机器学习的一个子集。机器学习可以是监督学习（SUP），其中数据被标记以训练算法并进行预测。或者机器学习可以是无监督学习（UNSUP），在这种情况下，机器学习模型使用未标记的数据并允许发现模式或洞察。例如，在使用监督机器学习检测糖尿病时，个人会为模型应关注的数据提供标签，比如患者的 A1C，这些数据与血糖水平和其他因素（如生活方式）有关。使用无监督机器学习时，算法将处理未标记的数据集，并发现表示糖尿病可能性的模式。</p>
<p>LLMs 使用多个人工智能、机器学习、深度学习、计算机视觉和自然语言处理（NLP）学科。例如，图 2-2 说明了人工智能作为一个比机器学习更广泛的概念，因为这些学科各自都是一个独立的研究领域，同时也是人工智能这一更大类别中的一个子领域。人工智能的简单定义是，它试图匹配人类主体的能力或智能。</p>
<p>在深入了解LLMs的内部工作之前，让我们先了解一下LLMs所使用的一些基础技术。</p>
<h2 id="使用深度学习检测肿瘤"><a href="#使用深度学习检测肿瘤" class="headerlink" title="使用深度学习检测肿瘤"></a>使用深度学习检测肿瘤</h2><p>深度学习是机器学习的一个子集，它使用神经网络。层是深度学习中功能的最小单位，正是这些单位组合在一起构建神经网络。层以级联的顺序从下方的层获取输入，对其进行处理，然后将输出传递给更高的层。如果你简单地将足够多的这些充满动作的层堆叠在一起，它们能够学习数据的复杂表示，并执行多种任务，如识别图像中的物体、理解语言等。</p>
<p>以下是深度学习中关于层的关键点的概述：</p>
<p> 输入层第一层接收原始数据，如图像、文本或数值。</p>
<p> 隐藏层这些特征提取并学习数据点之间的抽象关系。您可以在一个个隐藏层之上有多个隐藏层——这一堆叠的深度对网络能够学习的内容至关重要。</p>
<p> 输出层这是最后一层，它将根据任务生成模型的预测或输出。该输出可能将图像分类为猫或狗，将文本从一种语言翻译成另一种语言，或生成新的、听起来像人类的文本。</p>
<p>图 2-3 说明了一个简单的样本神经网络，目的是尝试使用计算机检测肿瘤是恶性还是良性。</p>
<p><img src="/../asset_02InsideAIBlackBox/03.png">图 2-3. 使用深度学习检测肿瘤中的癌症</p>
<p>在图 2-3中，专为肿瘤分类设计的深度学习神经网络中的每一层学习表示输入图像的不同抽象层次。在这种情况下，图像可能是癌症肿瘤或非癌症肿瘤。肿瘤的 X 光图像将被数字化并以像素的形式在计算机中表示。第一层将检测每个像素的值。这个神经网络或深度学习模型之前已经经过训练，知道一组像素的哪些特征表明高概率的癌症。因此，像素将从左到右流经这个网络，每个圆圈代表一个人工神经元，它简单地返回 1 或 0，其中 1 表示可能癌症的信号。</p>
<p>随着像素移动到第二层，模型开始对输入图像中的特征进行分类：</p>
<ul>
<li>肿瘤的边缘和轮廓</li>
<li>肿瘤内的基本形状和模式</li>
<li>强度梯度和纹理变化</li>
<li>颜色信息（如果输入是彩色图像）</li>
</ul>
<p>此时，神经网络成功地学习了一系列低级特征，如边缘和斑点，这些特征被连接成肿瘤图像的各个组成部分，就像人类视觉系统的早期阶段所感知的那样。</p>
<p>当神经网络到达第 3 层时，它将第 2 层的低级特征组合成一些高级特征。第 3 层可能会捕捉到以下内容：</p>
<ul>
<li>特定的边缘和形状的模式和排列</li>
<li>局部化的纹理模式指示出组织的类型</li>
<li>颜色组合或强度变化</li>
<li>肿瘤亚区域或成分的初步表示</li>
</ul>
<p>在第三层，模式实际上开始看起来像是更易识别且对观察肿瘤图像的人类专家更具诊断相关性的模式。</p>
<p>在第 4 层，神经网络将早期层的特征集合整合成肿瘤的高级表示</p>
<ul>
<li>肿瘤的独特形态特征</li>
<li>肿瘤亚区域的空间关系和组织</li>
<li>与特定肿瘤类型相关的复杂纹理模式</li>
<li>学习到的诊断显著特征的表示</li>
</ul>
<p>到此时，神经网络很可能发现与分类任务直接相关的语义上有意义的高级概念：恶性肿瘤或非癌性。经过训练的网络提取的高级特征与放射科医生或病理学家手动识别的内容更为接近。</p>
<p>最后，在第 5 层，神经网络将学习到的特征（第 4 层的高级特征）转化为最终决策，以根据样本确定肿瘤的类别。在这个例子中，输出决策是良性肿瘤。网络已经学会将“学习到的特征”与已知的肿瘤类别关联起来，利用它在学习过程中看到的模式和特征。</p>
<p>通过这种表述，并理解深度神经网络中特征学习的层次性质，临床医生可以开始理解这些模型如何（以及为什么）能够从医学图像中学习局部相关的模式和特征，并将这些特征在层次上进行转换，以实现自动决策。再次强调，这个例子仅用于为读者提供说明。</p>
<h2 id="自然语言处理与计算机视觉"><a href="#自然语言处理与计算机视觉" class="headerlink" title="自然语言处理与计算机视觉"></a>自然语言处理与计算机视觉</h2><p>自然语言处理（NLP）是一个与LLM的发展和应用密切相关的领域。两者都涉及计算机与人类语言之间的某种互动。NLP 算法被应用于预处理和结构化用于训练LLMs的文本数据，就像临床医生在阅读病历时所做的那样——他们只是做得非常快。此外，NLP 提供了理解和评估LLMs语言能力的词汇：无论他们是否理解临床医生使用的专业术语，他们解读临床医生笔记的能力，还是他们向患者生成清晰易懂解释的能力。</p>
<p>可以说，LLMs 还可以通过从互补的数据模态中学习来衍生出一种视觉模态，这个领域被称为多模态学习。在这种情况下，计算机视觉作为一种数据分析形式发挥作用，旨在揭示视觉数据中的模式。就像放射科医生使用医学图像（如 X 光片和 CT 扫描）来识别异常和诊断不同的病症一样，多模态 LLMs 可以学习结合文本来解释图像，以提供更细致、上下文相关的响应。例如，一个针对医学文献和放射学图像进行微调的 LLM 可能能够帮助生成报告或回答有关临床相关影像发现的问题。</p>
<p>也许，在医疗保健领域，LLMs可以通过临床决策支持（根据患者数据提供基于证据的建议和风险评估）、患者沟通（生成个性化教育材料、回答基本问题或提供虚拟支持）以及医学研究（文献综述、假设生成和数据分析）来支持临床医生。</p>
<p>但他们也不是来抢你的工作的——他们做不到。大多数患者以复杂的表现和症状来找临床医生，这可能需要进一步的调查或跟进，甚至只是需要一个人聊天。LLMs 可以成为临床医生工具箱的一部分，既帮助决策，又协助进行有意义和个性化的患者护理的复杂工作。例如，它们可以成为 21 世纪的听诊器。</p>
<p>我们需要考虑在临床实践中开始使用LLMs时出现的伦理影响，包括数据隐私、算法公平性以及这些工具对医患关系的影响等方面。这将需要临床医生、人工智能研究人员和伦理学家之间的合作，以实现负责任和有益的医疗部署。</p>
<h1 id="LLM的解剖"><a href="#LLM的解剖" class="headerlink" title="LLM的解剖"></a>LLM的解剖</h1><p>为了提醒您，LLM的最重要组成部分是神经网络。回想一下之前提到的，您的大脑是一个由生物神经元组成的网络，可能有 1000 亿个！生物神经元是大脑中的一种细胞，它接收来自其他神经元的输入，对输入进行一些计算，然后将输出发送给一些下游神经元。这个庞大的生物神经网络使您的大脑能够处理信息、理解世界、识别模式并表现出智能行为。</p>
<p>人工神经网络是我们在计算机上复制这一过程的最佳努力。我们创建相对简单的数学模型，涉及大量模拟神经元及其之间的连接。我们可以通过输入大量展示我们希望其检测的模式（例如，恶性肿瘤）的数据来训练它识别图像、声音和语言等事物。而有趣的是：这些网络通过学习调整神经元之间的连接强度，从数据中自行推导出模式。网络中的层数越多，输入的数据越多，它的表现就越好。</p>
<p>例如，通过在训练期间向图像识别网络展示数千万张猫和狗的照片，它学习到某些类型的毛发纹理、耳朵形状和鼻子形状提供了线索，表明某物可能是或不是猫或狗。当你在训练后向它展示几乎任何新照片时，它会立刻意识到这很可能是一只猫或一只狗。最新的神经网络开始通过越来越令人印象深刻的算法架构进行探索，包括从文本生成图像、语言翻译、从医学扫描中识别疾病，以及从创意描述中创建应用程序。</p>
<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>现在我们知道深度学习的机制，让我们深入剖析LLM的内部工作，看看它实际上由什么组成，同时要记住，神经网络的使用只是其中的一小部分。LLM并不是一个简单的算法；它是一个模型，包含算法和架构，例如Transformer。Transformer是自然语言处理（NLP）任务的关键架构组件，而这些任务是LLMs的一个重要焦点。NLP 技术使LLMs能够执行许多特定于语言的任务，如文本生成、摘要和问答。</p>
<p>Transformer是一组使用编码器和解码器结构的神经网络。编码器将输入文本转换为数值表示，以便计算机能够捕捉其含义和上下文，例如将捕捉患者健康状态的临床记录作为输入。解码器接收输入文本的编码表示并生成输出文本。在临床记录的例子中，解码器可以生成患者主要医疗问题的摘要。</p>
<p>但这里有个聪明的地方：Transformer不仅仅关注每个单词，而是关注这个单词与周围每个单词的关系。就像一小队朋友在帮助你阅读故事，他们每个人都在看不同的部分并向你反馈。通过这种Transformer架构，LLM可以读取医疗数据，如临床笔记、电子健康记录数据和病史，并执行各种任务，如摘要或问答。</p>
<p>Transformer架构需要一种新的架构发明，以实现我们今天在LLMs中看到的功能或某些人所称的魔力，这一发明发生在 2017 年。注意力是一种机制，允许LLM在处理和生成文本时专注于输入的特定部分。注意力机制使LLM能够在生成关键医疗或健康问题的摘要时，专注于患者电子健康记录中最相关的部分。</p>
<h2 id="Token"><a href="#Token" class="headerlink" title="Token"></a>Token</h2><p>Token是LLMs和Transformer处理的基本工作单位——可以是输入或输出。单词和字符可以作为LLM的Token。分词是将文本分解为更小单位（称为Token）的过程。这个过程对Transformer至关重要，因为它将文本分解为可管理的部分，使LLM能够理解和分析。</p>
<p>对于文本数据，LLM 首先要做的是通过将输入拆分成更小的连续单元（或Token）来进行Token化。考虑以下来自医疗领域的示例句子：患者被诊断为高血压，并被给予处方药“利辛普利”。</p>
<p>使用基于词的分词方法，这 10 个Token（用引号表示）为：“患者被诊断为高血压，并被开处方利辛普利。”</p>
<p>[“The”, “patient”, “was”, “diagnosed”, “with”, “hypertension”, “and”, “prescribed”, “lisinopril”, “.”]</p>
<p>输入的Token首先被嵌入到向量中，这些向量编码了它们的语义和句法信息，然后通过包含自注意力机制的变换层，这些机制学习Token之间的关系并生成丰富的上下文表示。</p>
<p>例如，在临床环境中，Transformer可以确定“高血压”和“利辛普利”这两个词是密切相关的，因为利辛普利是用于治疗高血压的药物名称。这一知识对于命名实体识别（识别文本中的医疗条件和治疗）或关系提取（识别医疗实体之间的关系）任务是非常有用的。</p>
<p>LLM在训练中学到的是如何根据前面的Token预测序列中的下一个Token。为了生成文本，LLM的概率分布用于根据紧接着的Token来采样或选择下一个Token。这个过程会迭代重复，直到满足某个停止规则，过程才会完成。</p>
<p>在临床应用中，例如，一个LLM可以为医生生成潦草的笔记，或总结患者的病情，例如对输入Token序列“患者是一名 65 岁的男性，有以下病史”的响应：患者是一名 65 岁的男性，有 2 型糖尿病、高血压和高脂血症的病史，主诉疲劳和多尿。</p>
<p>在这样的上下文和Token关系下，LLMs可以生成准确且易于阅读的文本——即使输入是用于临床文档、患者教育或医学研究摘要的长篇病历。</p>
<h2 id="注意力"><a href="#注意力" class="headerlink" title="注意力"></a>注意力</h2><p>NLP 和LLMs的秘密武器是谷歌在 2017 年的一项创新。想象一下给每个词一个聚光灯。例如，Transformer强调相互关联的医学细节——比如主要诊断和关键实验室结果——帮助它过滤噪音，专注于对该患者最相关的信息。无需顺序。与按顺序阅读病历不同，Transformer可以跳跃和跳过，考虑某个数据点在某人病历早期如何影响后期的另一个数据点，反之亦然。历史上具有挑战性的案例可以按照类似专家之间发送电子邮件的顺序进行研究，沿途获取上下文。这类似于拥有多个专业水平如何帮助医生拼凑奇怪的医学诊断。但Transformer的工作得益于数十层这种理解相互叠加：每一层都更好地将 X 光、MRI、症状和健康历史之间的关系联系起来，直到输出变得极具洞察力。</p>
<p>LLMs在语言建模中之所以有前景的原因之一是它们引入了注意力机制。注意力机制使得Transformer能够根据Token之间的接近程度来权衡每个Token与其他Token的相关性。Transformer识别和权衡复杂依赖关系的能力可以说是其生成上下文准确表示的基础。</p>
<p>在医疗保健中，注意力可以将LLMs的焦点转向最具临床相关性的词汇。例如，患者被发现有胸痛和呼吸急促，并被诊断为急性心肌梗死（即心脏病发作）。注意力机制将使模型能够准确识别“胸痛”、“呼吸急促”和“急性心肌梗死”这些词汇在语义上是如何聚集在一起的，这对于句子的含义尤其重要：它们指的是心脏病发作的主要症状。因此，它会为这些词汇分配更高的注意力权重，以生成更好的句子含义表示。</p>
<p>此外，注意力帮助LLMs处理医学文本的长距离特性。例如，临床记录可能在开头提到患者的病史，但是在记录开头讨论的这些病史和在记录末尾的当前状况是相关的，通过注意力，模型可以捕捉这种依赖关系，并生成更准确的表示。</p>
<p>注意力使模型能够根据Token相对于文本中所有其他Token的上下文重要性分配权重，以发现长期依赖关系，并构建上下文敏感的表示。这些对于医疗保健应用至关重要，因为医疗实体之间的关系和远距离依赖在文本生成、摘要和分析任务中发挥着关键作用。</p>
<p>这就是它的魔力：LLMs可以实时将医学术语翻译成听起来像人类的文本，就像每天随叫随到的医疗翻译；与患者进行连贯的对话；为健康教育材料建立一个令人信服的医学声音，让人感觉像是护士写的；并全面而有意义地回答医学问题，即使这些问题是开放式的和棘手的，甚至我都不知道从哪里开始。这只是Transformer在医学领域发展的一个步骤。</p>
<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>参数是LLMs的另一个关键特征。想象一下一个记忆力超群的医学生。她能够从所有可用的“医学教科书”中阅读大量信息。她学习的医学主题越多（解剖学、生理学、药理学、病理学等），她的头脑中就越充满关于这些主题的知识。所有这些知识实际上都存储在模型的参数中——也就是说，模型从阅读中获取和学习的所有医学事实、概念、关系和背景。你可以把参数看作是模型从所有阅读中获取和“记住”的关键医学知识。</p>
<p>参数越多，医学知识越丰富。一个拥有 2000 亿个参数的模型，不仅在历史和输入数据上比 500 万个参数的模型更多，它实际上吸收了更多的医学知识和与其他医学信息的联系。更多的参数意味着对更复杂医学概念的更深层次学习。一个模型不必拥有数十亿个参数才能在医疗保健中发挥作用。医学学生可能在某个狭窄领域学习整个图书馆的知识，但他们仍然可以毕业成为该狭窄领域（例如心脏病学、神经学或内分泌学）的优秀专家。一个仅在肿瘤学上训练的 3000 万个参数的模型，仍然可以利用其专注的狭窄和针对性知识回答复杂的癌症相关问题。</p>
<p>随着人工智能软件工程师找到新的方法让他们的模型增强所学的知识，比如将他们的LLM与像 PubMed 这样的医学模型连接起来，这将使他们的LLMs能够在其参数之外学习，或将模型连接到现有的现实世界医疗应用程序。在医学领域，就好像一名医学生能够将自己接入 PubMed 数据库或根据需要进行临床试验。</p>
<p>一种常见的思考医疗LLM复杂性的方法是：参数越多，学习能力就越复杂和强大。由数十亿个参数组成的医疗LLM比由数百万个参数组成的更强大。参数控制着LLM行为的许多不同方面：</p>
<ul>
<li>通过语调和内容识别患者情绪，以检测例如疼痛、绝望或焦虑的表达</li>
<li>生成创意医疗输出：结合学习到的模式创造新的医疗文本，将复杂的医疗语言翻译成易于理解的文本，或撰写其他创意输出，如患者教育材料</li>
</ul>
<p>参数影响LLM如何理解医疗文本以及如何生成文本。可以调整参数以控制生成文本的质量和创造力。在LLM中调整温度参数就像在复杂机器上旋转一个精密的旋钮。在最低设置下，旋钮向左转，产生的响应精确、可预测且基于事实。随着你逐渐顺时针旋转旋钮，系统中引入了更多的变异性和创造力。每次轻微的转动，你都会放松机器输出的限制。继续向右转到最高设置时，你给机器更多的自由去探索不寻常的组合和不太可能的结果，这可能导致更不准确的响应。在最右侧，旋钮转到最大时，输出变得高度不可预测和多样化，常常产生令人惊讶甚至有时毫无意义的结果。</p>
<p>权重是另一个影响单词和短语之间连接重要性的参数。例如，一个LLM训练并专注于医院再入院风险的模型使用患者的病史、电子健康记录（EHR）数据、药物和最近的实验室测试结果。假设最近的 EHR 数据显示一名 69 岁男性患者在过去六个月内多次住院，服用利辛普利和美托洛尔，并患有慢性阻塞性肺病（COPD）。LLM将学习权重参数，并可能对最近的住院历史和慢性病赋予更高的权重，因为它们对再入院风险的预测性更强。</p>
<p>温度和权重是两个参数的例子，但还有很多其他参数。更多的参数不一定意味着在医疗保健中的更好表现LLMs。这完全取决于它们如何设计和在相关医疗数据上进行训练。较小的LLMs可以从头开始训练，然后在特定的医疗任务上用少量数据进行微调。事实上，已经有小型LLMs在少量参数下取得了令人印象深刻的临床成功。参数的研究仍然是一个积极发展的领域，持续努力寻找更简洁的方式来表示和学习医学语言。</p>
<h1 id="LLM-和生成式人工智能的潜力"><a href="#LLM-和生成式人工智能的潜力" class="headerlink" title="LLM 和生成式人工智能的潜力"></a>LLM 和生成式人工智能的潜力</h1><p>随着能够从原始数据中全面学习的人工智能系统的出现，已经不再需要人类先将所有内容进行结构化。以前编程算法意味着我们必须明确地定义所有元素：消息接口、科学论文或代码，对于解决方案我们需要花费时间和精力来识别和输入各种概念、规则、模板、决策树等的表示形式。LLMs 可以以原始形式消化消息数据、论文或代码，并自我发现相关的表示形式。</p>
<p>从本质上讲，这意味着LLMs不再需要——也不必——依赖于严格的规则和限制，而是依赖于灵活表述的统计推断。在医疗保健领域，这将意味着LLMs直接从原始的、非结构化的医学文本笔记、研究论文或临床病例笔记中学习，以获得对疾病、治疗和患者护理的直观理解，从而不再需要人类首先手动编码医学知识。</p>
<p>这种人工智能与过去大多数人工智能的区别在于，实际生活中嘈杂、未经修饰的混乱通过自我监督的方式更完整地传递到模型中。自我监督学习是一种机器学习方法，它在没有人类生成的数据注释或数据本身标记的情况下进行训练。例如，一个在庞大的医学文献和病例报告数据库上训练的模型，可能会随后捕捉到疾病过程、治疗患者时的医学决策以及患者沟通的细微差别。</p>
<p>在这种LLM理解的背景下，结合能够创造无限新颖输出的生成架构，你就拥有了超越模式匹配和局部优化的系统。在医学领域，这可能会导致，例如，LLMs通过对医学各个领域的见解进行创造性的并置，开发新的疾病机制、治疗方案，甚至新的疗法。</p>
<p>这种从自上而下的限制性教学转向自下而上的自我导向学习的革命性转变，代表了人工智能范式基础的变化。原则是从大规模数据中涌现出来的，而不是基于编程假设或甚至是微不足道的人类知识的一小部分。这为高度可扩展的人工智能提供了一条路径，这种人工智能比“狭窄”人工智能更具自然性。对于医疗保健而言，这意味着人工智能系统能够从不断增长的医学文献中学习并跟上进展，发现可能被已经超负荷的人工专家所忽视的模式和洞察。</p>
<p>这些新的LLMs具有前所未有的自然语言生成能力，无论是在覆盖范围还是使用质量上。结合新兴的自主智能，可能会出现新的应用类型。复杂的语言技能将使LLMs能够将患者的笔记、病史和指示总结成通俗易懂的语言，以便于理解。LLM可以将关于患者状况的冗长技术医疗报告总结成清晰、易于理解的通俗语言，供患者使用。一个可能的应用是根据患者的个体手术和医疗状况生成个性化的患者教育，例如术后护理说明。</p>
<p>LLM可以通过深入的语言分析大量患者的电子健康记录，从而得出关于患者治疗过程的见解，这些见解在医生的笔记中并没有明确说明。例如，LLM可能会从两个月的笔记中的某些语调模式推断出该患者在遵循药物治疗方面遇到了特别的困难，或者患者可能在隐瞒对自己预后的未言之恐惧。</p>
<p>在医疗保健中，LLM可以帮助使医生与患者之间的沟通变得不那么生硬，更加自然和有效。一个模型可以将患者对其症状的非正式描述从日常用语翻译成精确的医学术语，洞察情感的潜台词——或者反过来：将医生对治疗方案的解释重新编写，以便患者更容易理解和遵循。</p>
<p>一种新兴能力LLMs有潜力创造真正定制和量身定制的个体体验：根据个人的偏好和需求，学习、动态演变和适应的能力。通过在训练过程中摄取与主观人类相关性指标相结合的文本内容，个性化语言模型可以实现对主观人类兴趣的理解。</p>
<p>随着LLMs消化不同的临床语料库，他们可以建议针对患者的生活方式和合并症的健康干预方法，包括具体的（药物方案、锻炼与饮食等）。甚至可以应用情商和同理心建模，以改善患者互动。</p>
<p>例如，LLM可能会处理患者的电子健康记录，其中包含医生的笔记、诊断测试以及药物和近期治疗历史，以建立该患者独特性的档案。然后，它可能会建议一个以患者为中心的个性化治疗计划，考虑影响患者健康旅程的医疗、行为、心理社会和环境参数。</p>
<p>此外，LLMs可以用于运行富有同情心的虚拟健康助手，这些助手能够以支持和鼓励的方式与患者交谈。一个LLM驱动的聊天机器人可以识别患者自身微妙的语言线索，并调整自己的沟通风格，以更好地符合患者的需求，从而带来安慰并增强患者坚持治疗计划的韧性。</p>
<p>LLMs 仍然处于初期阶段。在未来几十年中，随着它们学习处理大量原始数据并适应环境、个性和情感脆弱的患者，LLMs 可能会真正改变医疗服务的方式。我们将扩展医疗决策，提高患者沟通，建立真正个性化的用药方案，并提高工作效率。LLMs 可以用来设想干预措施，以增强关怀护理，同时减少伤害患者和干扰医疗的情绪。我们将做出更好的临床决策，并与患者进行更有效的沟通。虽然这些工具可以改善临床护理，但我们始终需要专注的专业人士和人类的细心关注。这些不是取代我们敬业医生的人工智能机器人。这些进步将增强医学知识、艰苦获得的临床经验和与患者的个人联系。</p>
<h1 id="构建LLMs的艺术"><a href="#构建LLMs的艺术" class="headerlink" title="构建LLMs的艺术"></a>构建LLMs的艺术</h1><p>我们已经讨论了LLMs的用例和力量，但在医疗保健和医学领域，甚至可能在所有行业中，这些LLMs如果没有其他数据的补充，将无法提供预期的结果。在医疗保健领域，这可能包括医疗机构或保险公司的网站、标准护理程序、电子健康记录、临床数据、可穿戴数据、基因组数据等。</p>
<h2 id="检索增强生成"><a href="#检索增强生成" class="headerlink" title="检索增强生成"></a>检索增强生成</h2><p>LLMs 有时能以惊人的准确性回答问题，但有时它们会重复训练数据中的事实，结果却不准确，仍然出错。也就是说，它们会产生幻觉。这是因为 LLMs 知道词语之间的统计关系，但不知道它们的含义。</p>
<p>当LLMs向公众广泛介绍时，围绕新兴能力的概念引起了很多兴奋。因此，许多组织寻求探索和揭示这些模型中潜在的隐藏功能。他们认为LLMs具备未知的能力或特性，可以被利用。然而，随着研究人员深入探讨涌现能力的概念，越来越明显的是，这一概念是一种幻影，而不是LLMs的隐藏功能或特性。</p>
<p>随着时间的推移，技术社区达成共识，认为LLMs中出现的能力的想法是没有根据的。这些模型的观察行为和输出可以通过它们广泛的训练数据以及在训练过程中学习到的复杂模式来解释，而不是任何固有的、未被发现的能力或功能。</p>
<p>相反，LLMs 展现出强大的能力，能够整合和优先考虑他们收到的提示中提供的上下文信息。这一特征通过研究得到了持续的证明，突显了理解和优化 LLMs 已知能力的重要性，而不是追逐难以捉摸的突现功能的概念。</p>
<p>通过将相关信息战略性地嵌入提示中，可以有效地引导LLM的输出，确保生成的内容与适当的上下文和期望的输出更紧密地对齐。这种方法利用了LLMs固有的能力，能够吸收和应用所呈现的知识，从而产生更准确、真实和符合上下文的回应。</p>
<p>在提示中包含上下文参考数据已被证明是一种非常有效的技术，可以优化LLMs在广泛应用中的表现。这种方法使用户能够利用这些强大模型的巨大潜力，同时对生成的内容保持更高的控制，从而最终产生更可靠和有用的输出。</p>
<p>将上下文参考数据或外部来源纳入演变为一种人工智能框架，即检索增强生成（RAG）。这是一个旨在通过使用外部数据源来增强模型，从而提高LLM生成的响应质量的人工智能框架，这些外部数据源补充了LLM的训练数据。</p>
<p>在没有使用 RAG 的情况下，使用LLM与聊天机器人应用程序互动的用户如图 2-4所示，展示了给LLM的典型用户提示词。</p>
<p><img src="/../asset_02InsideAIBlackBox/04.png">图 2-4  给 LLM的用户提示词</p>
<p>第一步是用户输入一个提示词，比如“我该如何康复我的腿筋拉伤？”聊天机器人应用程序或界面接收该提示，并将问题传递给其LLM。模型在其数据语料库中搜索答案，将答案返回给聊天机器人，聊天机器人再将响应反馈给用户。现在这是一个基本示例，并不旨在说明任何特定聊天机器人或技术（如 ChatGPT 或Gemini）的工作原理。这些工具可能更复杂，结合搜索或其他功能来得出响应。</p>
<p>现在让我们看看使用 RAG 时这张图片是如何变化的，如图 2-5所示。</p>
<p><img src="/../asset_02InsideAIBlackBox/05.png">图 2-5. 使用 RAG 的聊天机器人</p>
<p>使用 RAG 解决了LLMs面临的一些挑战，在医疗或医学领域，一个大挑战是缺乏对药房、临床、电子健康记录、政策、医生笔记等医疗数据的访问。凭借医疗数据和来自公司自身数据源和网站的专有数据，LLM的输出不太可能不准确，从而更有可能减少或消除幻觉。更重要的是，LLM可能会回应“我不知道。”</p>
<p>返回到 图 2-5，用户输入一个提示词，该提示词被聊天机器人接收。不同的是，聊天机器人并没有将问题传递给 LLM，而是对公司的数据源进行了搜索（步骤 2）。在这个例子中，这些数据源包括政策、医生笔记、临床数据和电子健康记录数据。但其他数据也可以被包含，例如药房数据、索赔数据或任何被认为对用户查询聊天机器人至关重要的外部参考数据源。</p>
<p>步骤 3 中，聊天机器人提供了提示词给LLM。这些指示词可能会指导LLM使回应听起来像是来自医生，但要使用高中阅读水平。除了原始用户问题外，还包括对响应提示有用的外部数据（公司数据）。配备这三个提示要素的LLM将优先考虑公司的数据或外部数据源。LLM将生成回应，聊天机器人将把回应传递给用户。</p>
<p>RAG 的好处是多方面的。利用当前最佳来源的信息可以避免另一个困扰LLMs的问题，即数据过时，因为它反映了最后一次训练数据的日期。如果模型需要适应新信息，就必须重新训练。建立一个可以在必要时更新新材料的内容库，可以实现快速而粗略的适应，而不是全面的改造。</p>
<p>此外，提示词指令可以促使LLM表现出良好的行为，例如在不知道问题答案时予以承认。如果对内容库的信心不足以回答用户的查询，模型可以做出正确的选择，表示它不知道，而不是提供一个看似合理但可能错误的回答。</p>
<p>然而，RAG 的有效性取决于检索系统的质量。如果搜索没有为LLMs提供最相关的高质量基础信息，模型可能无法回答任何问题——即使这些数据可能适合回答此类问题。因此，优质医疗信息的重要性不言而喻。</p>
<p>简而言之，检索增强生成是人工智能的一个有前景的新里程碑。迄今为止，提高LLMs性能的最佳方法是将其根植于外部、及时和可验证的数据。通过公司的专有数据为LLMs提供动力，使LLM聊天机器人能够从外部数据源获取可靠信息，从而提供更准确的响应。这避免了LLM因未包含在其训练数据集中而缺乏必要知识的问题，从而导致幻觉。</p>
<p>建造一个LLM既是一门艺术，也是一门科学。它涉及一个创造性的过程，需要想象力、直觉以及对语言和人类行为的深刻理解。</p>
<p>下一部分描述了构建一个LLM的艺术，涉及六项活动：</p>
<ul>
<li> 概念化</li>
<li>数据选择与策划</li>
<li>模型架构与设计</li>
<li> 提示工程</li>
<li> 精炼与反馈</li>
<li> 与应用程序集成</li>
</ul>
<h2 id="概念化"><a href="#概念化" class="headerlink" title="概念化"></a>概念化</h2><p>组建一个多元化的团队通常在建立一个LLM方面大有裨益，以满足其组成用户的需求和要求。图 2-6展示了一个多元化团队的组织和启动，旨在理解问题和潜在的前进方向：一个概念化阶段。</p>
<p><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098160913/files/assets/llmg_0206.png">图 2-6. 概念化</p>
<p>形成一个LLM以解决医疗问题的第一步是明确当前的医疗问题或任务。这将涉及确定一个高度特定的医疗领域和用例，同时描述LLM的期望结果。识别医疗领域可能包括以下一个或多个步骤：</p>
<ol>
<li>指定相关的医学专业或细分领域（放射学、病理学、肿瘤学等）或相关的增强功能（临床决策支持功能）。该领域存在哪种数据（例如，医学影像、电子健康记录、临床笔记、医学文献）？</li>
<li>指定预期的用例：清楚地阐明LLM在医疗保健背景下的目的和目标。用例的示例可能包括疾病诊断、风险预测、治疗建议、网站导航、呼叫中心协助和患者沟通。第 3、4 和 5 章列出了大量的用例。定义LLM的目标用户，例如医生、护士或患者。</li>
<li>确定每个用例的期望结果或目标。定义相关的性能指标，通过这些指标评估LLM的成功。考虑准确性、灵敏度、特异性或其他特定领域的评估指标等因素。定义任何约束或要求，例如可解释性、公平性或合规性。</li>
<li>评估训练LLM所需相关医疗数据的可用性和可获取性。了解数据的数量、种类和质量，以及任何潜在的偏见或限制。确定是否需要额外的数据收集或整理工作。</li>
<li>与专家互动：与了解问题领域的临床医生、研究人员或数据科学家合作进行设计。采用以用户为中心的设计技术，创建一个既必要又可用的模型。征求他们的意见，以确保问题陈述与临床现实相符，并帮助解决真正重要的挑战。邀请他们参与确定期望的结果、选择相关的数据源，并提供领域特定专业知识所带来的独特视角。</li>
</ol>
<p>在这个阶段，定义医疗保健问题和LLM的用例也使设计团队成员和数据的使用朝着特定方向集中，因为他们现在直观地理解了LLM应该使用的背景。他们能够朝着特定的性能标准努力，并对最终的LLM需要为实际用户“做”或实现的目标有共同的理解。</p>
<p>在明确和彻底定义之后，典型的下一步包括：数据收集&#x2F;预处理、模型架构设计、训练&#x2F;优化、评估&#x2F;验证、在医疗环境中的部署&#x2F;监控。但如果问题定义受到影响，所有这些步骤都将崩溃。</p>
<h2 id="数据选择与策划"><a href="#数据选择与策划" class="headerlink" title="数据选择与策划"></a>数据选择与策划</h2><p>在医疗保健领域，生命或健康的损失悬而未决，选择LLM的训练数据变得更加关键。训练数据的数量很重要，但护理服务通常需要展现极高精度和细微背景的医疗和健康LLMs。以稍微偏离的方式解读医疗记录可能会导致一系列问题，具体取决于用例。图 2-7描绘了数据选择和策划的繁忙工作，在这里，数据科学家，有时还有机器学习工程师和人工智能工程师，必须理解将在 RAG 中使用的外部数据源，这些数据源将为LLM提供支持。</p>
<p><img src="/../asset_02InsideAIBlackBox/07.png">图 2-7. 数据选择与整理</p>
<p>在许多医疗保健公司中，数据被孤立并由不同的数据团队“拥有”。许多公司没有明确的数据治理和访问政策。获取特定数据集的访问权限通常是一个挑战。训练数据可能存在缺口，这会影响模型在“实验室”之外应用于临床环境时的韧性。例如，由于 HIPAA 或 GDPR 的原因，去标识化的训练数据或仅具有某种粒度级别的数据可能无法反映“真实世界”的数据，从而导致模型遇到困难或无法按预期表现。</p>
<p>患者的原始医疗数据不会向非研究人员发布：这些数据高度敏感，受到隐私和知情同意等伦理问题的严格规定。数据发布政策必须在透明度和患者隐私之间取得平衡。定义LLM的使用方式（例如，药物发现、临床决策支持）将影响相关数据源的选择。</p>
<p>一种补充开源和专有基础模型的方法是检索增强生成（RAG），之前已经讨论过。它增加了模型的知识，使其能够超越在预训练中获得的内容；在推理时，它可以匹配上下文文档（例如，网站数据、病人记录等）并根据这些文档调整其输出。这是一个简单的补充，可以将特定领域的语料库添加到模型中，而不影响基础部分。</p>
<h2 id="模型架构与设计"><a href="#模型架构与设计" class="headerlink" title="模型架构与设计"></a>模型架构与设计</h2><p>LLMs今天的专业领域涵盖了从使用不同数据类型和模式（仅文本、文本和图像、文本和语音对话、文本和音频流、文本和乐谱、文本和编程代码、文本和视频）到执行多种不同任务（摘要、分类、生成、翻译、推荐等）的广泛范围。</p>
<p>一个LLM的架构是它的设计，指定信息如何在模型中流动，以及模型如何在该信息流下处理和生成语言。架构设计是创造力、迭代和领域知识的直观计算融合。早期的设计选择是决定使用哪种深度学习架构来进行LLM。存在不同类型的神经网络（见图 2-8），决定哪种类型是模型架构是一个早期的架构选择。</p>
<p><img src="/../asset_02InsideAIBlackBox/08.png">图 2-8. 架构与设计</p>
<p>架构和设计不仅涉及LLM模型，还涉及确定该模型如何与渲染模型推断所需的其他组件相适应。换句话说，该模型是通过网页应用程序前端展示，还是像聊天机器人一样的应用程序，或者两者兼有？LLM在整体架构中处于何处，数据如何在各个组件之间流动？这些都是可以在LLM开发的同时进行和实现的决策。</p>
<p>模型必须构建，这可以通过深度学习编程库来完成。然后，模型必须进行微调和优化。微调LLM是指调整某些模型参数的值，以便模型在某些任务或特定数据集上表现更好。由于微调是一种启发式方法，工程师会尝试不同的方法，并根据经验结果和领域知识结合实验和直觉做出决策。</p>
<h2 id="提示词工程"><a href="#提示词工程" class="headerlink" title="提示词工程"></a>提示词工程</h2><p>提示词工程可以是一种艺术形式，因为它涉及到精心设计输入提示词或查询，以引导模型的响应。设计提示词是一项需要领域专业知识的技能，以促使模型产生人类工程师希望看到的答案。工程师需要编写提供上下文、约束的提示词，以希望促使模型生成稳健（准确且可能）且独立（可读连贯文本）的输出。图 2-9 说明了我们在使用 ChatGPT、ClaudeAI、Gemini 和其他 LLMs 时已经习惯的基本提示词。</p>
<p><img src="/../asset_02InsideAIBlackBox/09.png">图 2-9. 提示工程</p>
<p>提示词工程对于LLMs意味着非常仔细地选择纳入提示中的文本线索，以引导模型的输出。这与我们与搜索引擎的互动方式不同，搜索引擎接受静态查询并找到相应的静态答案。提示则不同：查询不仅是携带上下文、约束和目标信息的连续文本，而且它也是用户与开放式LLM之间持续信号传递过程的一部分。</p>
<p>提示工程师进行研究，以确定LLM所训练的数据和模型的偏见，以便他们可以编制可能需要避免的陷阱列表。与此相关，领域特异性非常重要。适当的医疗或健康提示的语言与适当的工程导向提示的语言会有所不同，因此用户可以避免提示词中的概念与模型的潜在表示空间之间的不匹配。</p>
<p>测试周期中的信号将标记出模型容易受到噪声影响的地方，这可能是由于缺乏外部上下文的强化，从而导致虚假阳性大量涌入。例如，LLM被训练用于分析和解释放射学图像，如 X 光片或 CT 扫描，以检测异常或疾病迹象。如果LLM的训练数据集有限或缺乏放射科医生的外部验证，LLM可能会产生幻觉并错误地识别出异常。</p>
<p>在其他情况下，通过对比案例进行训练，或将物体人工插入输入流（包括正面和负面示例），使模型能够学习辨别细微差异。这种编码反馈可以作为不断的反馈循环，精炼提示的艺术，使工程师能够雕刻、塑造和引导模型行为。这个循环使得提示变得既是艺术又是科学。</p>
<h2 id="精炼与反馈"><a href="#精炼与反馈" class="headerlink" title="精炼与反馈"></a>精炼与反馈</h2><p>这就是你如何构建一个LLM：你经历一个迭代过程，在这个过程中逐渐改进模型。你收集用户或领域专家的反馈，或设定评估指标，并迭代地提高模型的性能和能力。这个迭代循环使工程师能够完善模型生成响应的方式，解决已知的不足，并适应不断变化的需求和口味。图 2-10 说明了开发一个LLM的持续反馈循环。</p>
<p><img src="/../asset_02InsideAIBlackBox/10.png">图 2-10. 精炼与反馈</p>
<p>反馈循环应被定义，特别关注用户对输出的直接反馈，这是系统能获得的最佳指导。这可以通过评分、调查维度，甚至是对其优点、缺点和改进领域的开放式评论来实现。在某些领域，如医疗保健，主题专家的意见是不可或缺的，以确保LLM能够跟上专业标准，并生成适当且相关的输出。最后，准确性、流畅性和连贯性等定量指标可以作为基准数据集的一部分进行计算，以评估LLM的性能。</p>
<p>另一种精细化技术包括微调，其中LLM在新的或者调整过的数据上进行重新训练，以明确符合反馈或期望的修改。还有更具针对性和区分性的提示，引导LLM朝着与主题和上下文相关的期望输出样本。最后，还有强化学习技术，其中LLM可能会被条件化或激励，以产生符合预设奖励的数字文本输出，从而推动系统发展后续的行为倾向。在构建LLM的过程中，应有来自真实用户和专家的反馈迭代过程，以帮助确保LLM符合其预期用户的需求和偏好。</p>
<h2 id="与应用程序集成"><a href="#与应用程序集成" class="headerlink" title="与应用程序集成"></a>与应用程序集成</h2><p>值得注意的是，创建一个使用LLM的应用程序或应用与仅仅构建LLM相比，涉及一些不同的考虑。创建一个LLM应用将涉及将LLM与应用程序的逻辑和功能集成。这可能涉及设计应用程序的接口和 API，以允许应用程序向LLM发送输入，从中接收输出，并将这些输出集成到应用程序的用户体验中。集成可能包括处理与LLM交互所需的数据预处理、后处理和错误处理。图 2-11说明了在如何与LLM所在的外部和内部系统进行集成时需要做出的决策。与应用程序和应用集成的方式有很多种，这将涉及根据性能、可用性、可扩展性等要求做出可行和实用的架构决策。</p>
<p><img src="/../asset_02InsideAIBlackBox/11.png">图 2-11. 与应用程序的集成</p>
<p>用户界面设计在LLMs的应用中至关重要的一个方面是用户如何向LLM提供输入，以及他们如何理解和消化LLMs所提供的反馈。开发者必须设计自然流畅且“人性化”的界面，以引导用户向LLM提供信息，回答LLM的请求，并指示LLM生成与“说话者”意图密切相关的建议响应或内容。这可以是一个聊天界面，一个简单的用户文本输入表单，或者一组经典的华丽小部件和菜单。</p>
<p>应用LLMs也可能需要进行重大优化，以达到可接受的响应和效率水平。实时应用任务，例如对话和交流，通常涉及过多的数据或计算，无法为每个句子腾出时间，LLM驱动的应用程序向LLM发送、接收答案并在与其他用户沟通时进行下游处理。</p>
<p>开发人员在确保此类应用程序性能时，可能需要优化软件代码（例如，调整与LLM的通信输入和输出格式，以最小化在应用程序与LLM之间传输此类数据所需的时间）、数据处理管道（例如，缓存计算答案所需的最相关数据）以及应用程序基础设施设计（例如，针对分布式计算，这允许在并发请求和请求复杂性方面进行扩展）。</p>
<p>安全在LLM应用中至关重要。敏感的医疗和个人数据需要全面保护，以防止信息泄露和恶意攻击。应采用最新的安全实践，以充分防止未经授权的访问、数据泄露和恶意攻击。开发人员应选择最合适的安全方法来加密和保护用户数据，同时向用户提供保障。</p>
<p>与任何应用程序一样，LLM 应用程序将受益于人类反馈循环和迭代。LLM 应用程序设计师应包括收集人类反馈、分析使用模式以及根据用户需求和偏好对应用程序进行迭代改进的系统和机制。这项工作可能涉及 A&#x2F;B 测试、人类调查和数据分析，以了解更多关于应用程序使用的信息，并为应用程序和 LLM 的迭代改进提供依据。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>在本章中，我们介绍了LLMs和生成式人工智能的内部工作原理，深入探讨了它们如何通过机器学习和深度学习使用神经网络，超越传统的分类和预测任务。我们提供了关于人工智能与机器学习辩论的背景，得出结论它们是不同的。例如，机器学习是人工智能的一个子集，人工智能的目标要广泛得多，人工智能包括多个领域，这些领域对于LLMs是必要的。这些领域包括自然语言处理和计算机视觉。</p>
<p>超越单纯的分类和预测，我们讨论了LLMs在不同任务和领域中生成类人文本的能力。我们剖析了LLMs的架构和内部工作原理，包括支撑LLMs语言处理能力的Token、Transformer、参数和注意机制。我们通过描绘非恶性肿瘤的检测，说明了神经网络的功能——这是LLM的一个关键元素。</p>
<p>我们探讨了构建LLMs的过程，涵盖了从构思解决方案到定义一个或多个医疗保健用例的各个生命周期阶段。RAG 是医疗保健LLMS的一个关键方面，确保这些模型使用外部数据源以提高准确性，这在医疗保健领域至关重要。我们展示了 RAG 的使用以及这个 AI 框架如何与LLM协同工作。</p>
<p>理解LLMs的内部运作，从高层次上看，应该为读者准备好理解下一章中描述的许多未来用例如何在医疗保健领域实现。</p>
<p>1 “大脑基础：神经元的生与死，”国家神经疾病与中风研究所，访问日期：2024 年 6 月 24 日，<a target="_blank" rel="noopener" href="https://www.ninds.nih.gov/health-information/public-education/brain-basics/brain-basics-life-and-death-neuron#:~:text=Neurons%20communicate%20with%20each%20other,and%20dendrites%20of%20nearby%20neurons.%60&amp;&%60text=There%20are%20three%20kinds%20of,and%20ears%E3%80%82">https://www.ninds.nih.gov/health-information/public-education/brain-basics/brain-basics-life-and-death-neuron#:~:text=Neurons%20communicate%20with%20each%20other,and%20dendrites%20of%20nearby%20neurons.`&amp;&amp;`text=There%20are%20three%20kinds%20of,and%20ears。</a></p>
<p>2 Liat Clark，“谷歌的人工大脑学会寻找猫视频，”连线，2012 年 6 月 26 日，<a target="_blank" rel="noopener" href="https://www.wired.com/2012/06/google-x-neural-network%E3%80%82">https://www.wired.com/2012/06/google-x-neural-network。</a></p>
<p>3 这幅图来自“AI 与机器学习”，IBM 技术，2023 年 4 月 10 日，YouTube 视频，5:48，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=4RixMPF4xis%E3%80%82">https://www.youtube.com/watch?v=4RixMPF4xis。</a></p>
<p>4 “人工智能，”维基百科，最后更新于 2024 年 6 月 24 日，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Artificial_intelligence%E3%80%82">https://en.wikipedia.org/wiki/Artificial_intelligence。</a></p>
<p>5 Ashish Vaswani 等人，“注意力机制是你所需要的一切”，第 31 届神经信息处理系统会议（NIPS 2017），加利福尼亚州长滩，<a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf%E3%80%82">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf。</a></p>
<p>6 亚历克斯·爱德华兹，“研究发现，使用更小的语言模型可以更好地进行临床翻译，” Slator，2023 年 12 月 20 日，<a target="_blank" rel="noopener" href="https://slator.com/clinical-translations-better-with-smaller-language-models-research-finds%E3%80%82">https://slator.com/clinical-translations-better-with-smaller-language-models-research-finds。</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/08/llmsClinical01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/08/llmsClinical01/" class="post-title-link" itemprop="url">第一章 医生的黑色手提包</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-08 11:32:19 / 修改时间：11:37:23" itemprop="dateCreated datePublished" datetime="2024-08-08T11:32:19+08:00">2024-08-08</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>29k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>52 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在 C. M. Kornbluth 的短篇小说《小黑包》中，挣扎中的医生福尔博士发现了一个来自未来的神秘医生包，里面装满了先进的医疗设备和药物。这些未来的设备增强了他作为医生的能力，使他能够以前所未有的效率诊断和治疗病人。当他探索包内的内容时，福尔博士对未来医疗创新的潜力感到惊叹，仿佛自己正站在医疗革命的边缘。</p>
<p>然而，C. M. Kornbluth的故事并不仅仅是对医学进步的庆祝。随着故事的发展，显而易见，这种强大的技术在错误的手中可能被利用来谋取个人利益，而不是为了更大的利益。这个叙述提醒我们，尽管未来的医学进步在其能力上看似神奇，但它们也伴随着重大的伦理责任和潜在的滥用风险。这个虚构的故事促使我们思考，随着医学技术和人工智能（LLMs及生成式人工智能）的快速发展，未来既有令人兴奋的可能性，也面临伦理挑战。</p>
<p>人工智能和LLMs有潜力提升临床护理，特别是在增强临床医生决策过程、改善患者与医生的互动、简化行政任务、提高患者教育和参与度方面，最终导致更好的健康结果。根据纽约著名医院网络纽约长老会医院的一位高级医疗执行官，通过利用多模态LLMs的能力，医疗机构有潜力开发复杂的虚拟医疗助手，这些助手可以主动监测患者健康并协助诊断。</p>
<p>正如传统的黑色手提包为医生提供了提供优质护理所需的基本工具，人工智能也准备成为一项不可或缺的资产，帮助临床医生为患者提供更个性化、高效和基于证据的护理。本章探讨了使用LLMs改善患者护理的可能性——特别是在临床医生和患者受益最多的地方。</p>
<p>LLMs 是自然语言处理 (NLP) 机器学习模型，似乎能够理解并生成人类语言文本。LLMs 是一种人工智能 (AI)，能够以卓越的能力理解和操控人类语言。它们被称为“大型”，因为它们是在大量文本数据上训练的，通常是数十亿个单词，这使它们能够学习人类语言的细微差别。</p>
<p>对于临床医生来说，LLMs 可以被视为先进的语言处理工具，能够协助处理涉及医疗数据的各种行政任务（如电子健康记录 [EHRs] 或非结构化的医生笔记）。正如听诊器和 X 光机扩展了临床医生评估患者健康的能力，LLMs 可以增强临床医生分析和解读大量研究数据或嵌入视频的电子邮件，或患者的历史健康记录、临床笔记、出院总结等的能力。</p>
<p>生成式人工智能是人工智能的一个子集或类型，就像LLMs和机器学习是人工智能的类型一样。生成式人工智能专注于创建新的内容，例如文本、图像、视频或音频，通常是为了回应用户的问题。生成的输出在风格和结构上往往类似于人类创作的内容。</p>
<p>当我们在本书中使用诸如LLMs或生成式人工智能这样的短语时，我们是作为涵盖广泛人工智能系统的统称，即使它们具有不同的属性或采用不同的机器学习算法。这些统称包括但不限于LLMs、小型语言模型、多模态模型和生成式人工智能。</p>
<p>这些模型是在大量我们的书面信息（例如，书籍、文章和网站）以及世界上大量主题上进行训练的。这使它们能够理解句子和段落中单词之间的关系、章节中积累的意义、叙事弧线所表现出的整体进展等等。</p>
<p>当 OpenAI 在 2022 年发布其语言模型 ChatGPT 时，它改变了对话式人工智能，解放了自然语言处理，为大众提供了一个简单的网络界面，使人类般的对话和问答成为可能。这LLM因其能够进行类人对话、回答问题、代写论文以及执行各种任务而在全球范围内获得了广泛的欢迎。它引起了科技公司首席执行官对技术对商业和日常生活影响的兴趣。但让我们提醒自己，应该如何看待使用LLMs。</p>
<p>一篇 2023 年的博客讨论了 ChatGPT 实验，提供了关于我们应该如何思考和使用LLMS的见解。如果我们将LLMs视为总结工具，并将它们的提示词视为该过程的锚点，而不是对另一个有知觉的存在的命令，那么我们可以在医疗保健中有效地使用这些工具。我们在关键词搜索的简洁约束下做了类似的事情：我们学习并仍在学习如何“引导”搜索朝向我们想要的任何内容。自几十年前搜索出现以来，我们已经学会了如何用语言锚点来构造问题，这些问题很可能会引导搜索朝向他们想要的内容。我们可以对LLM提示词做同样的处理，将它们视为总结的锚点，而不是规范，从而更好地聚焦。一旦我们将LLM提示词视为总结的锚点，我们就可以一方面通过将总结任务嵌入模型的知识库中，另一方面在提示词定义的任务范围内更有效地引导它们。</p>
<p>随着我们对LLMs的理解不断加深，夸大其词的说法需要和如何在医疗保健中构建和利用LLMs的现实评估相平衡。LLMs是统计自回归模型，是一种机器学习模型，能够根据上下文预测下一个单词。例如，假设你是一位正在写故事的作者。你有一个写作助手，它根据你已经写的单词为你提供下一个合适的单词。这个助手阅读了许多不同类型的故事，因此它大致知道单词是如何相互关联的，以构成一般有用的句子和更复杂的叙述。借助这个写作助手，你不断写作，不断接受建议，故事从一个单词到另一个单词，逐渐变得更长。每一步，下一个单词都是基于之前写的单词而来的。这本质上就是自回归模型的工作原理：它从现有数据中学习，并基于之前的数据序列一步一步生成（或预测）新数据。</p>
<p>Gemini，ChatGPT，Claude.AI，以及其他自回归LLMs提供了类似人类推理的错觉，能够对细微或复杂的提示给出惊人的回应。它们甚至似乎像人一样，提供看似情感的反应和同理心的理解。这些错觉因我们的认知偏见而变得更加可信，即我们倾向于将事物、动物和人工智能拟人化。下一章，第 2 章，更具体地讨论了LLMs的工作原理，包括明确的细节，如tokens、参数等。</p>
<h1 id="LLMs和生成式人工智能的潜力"><a href="#LLMs和生成式人工智能的潜力" class="headerlink" title="LLMs和生成式人工智能的潜力"></a>LLMs和生成式人工智能的潜力</h1><p>尽管现有的医疗LLMs在某些方面已经令人印象深刻且有用，但发展仍处于早期阶段，这些创新仅实现了转变我们提供医疗服务潜力的一小部分。目前的发展强调减少临床医生的负担和文档工作——但这仍然只是对医疗服务交付的LLM影响的开始。已经有完整的医疗特定版本发布，但由于各种原因，它们尚未在临床护理的交付方式上产生显著影响。</p>
<ul>
<li>数据可用性和质量: LLMs 在大量数据集上进行训练，它们的性能将取决于用于训练的数据质量。在医学领域，数据通常分布在多个来源，例如电子健康记录（EHR）、医学期刊和随机临床试验。此外，数据需要完整、准确或一致，这会影响 LLMs 的表现。</li>
<li>偏见与公平: LLMs 从有偏见的数据中学习，这意味着它们是在反映现实世界偏见的数据上进行训练的。这可能导致在我们为某些患者群体提供护理时转移和强化已经存在的强烈偏见。例如，一个在有偏见的医疗记录数据集（例如，包含特定种族或民族群体数量较少的数据集）上训练的 LLM 也可能生成有偏见的建议。在讨论偏见时，重点是系统是否按预期正常工作。减轻偏见通常对系统功能和成功使用至关重要。</li>
<li>可解释性和可说明性: 实现可解释性或可说明性一直是人工智能最显著的谦逊姿态之一。LLMs 通常被视为“黑箱”，这指的是它们的“内部工作”被压缩在一起，以至于整体操作难以理解。在医学中，缺乏可解释性和可说明性是一个问题，因为如果我们不知道它们为何得出某些建议，就会对采用 LLMs 存在巨大的抵触情绪。结果可能是这些建议并不像人们希望的那样合理，因为它们结论的基础根本上是有缺陷的。</li>
<li>监管环境: 在医学领域，人工智能发展的一个关键挑战是监管空白。目前没有明确的指导方针可以突破繁文缛节，定义在医疗保健中开发和部署LLMs的含义。这种不确定性有效地抑制了在医学复杂和高风险环境中尝试使用人工智能的热情，因为几乎没有先例可以指导医疗保健组织在这些情况下如何行动。如果他们能够这样做，他们可能会担心违反某种法律限制或合规问题。</li>
<li>伦理环境: 一般来说，关于在医学中使用LLMs的担忧包括潜在的误用、患者自主权的侵蚀和患者隐私的侵犯。在可以在医疗保健中使用LLMs之前，必须考虑与潜在误用、人类自主权的妥协和患者隐私相关的伦理问题。</li>
</ul>
<p>LLMs 明确地建模了单词与意义之间的关系，涵盖长篇文本，从而实现更流畅的文本理解和内容生成。此外，它们与更原始的语言模型不同，后者由于数据规模和模型参数化的限制，只能将单词连接成文本模式。第 2 章 详细介绍了 LLMs 的工作原理，解释了参数、tokens等内容。</p>
<p>现有的医疗和其他LLMs在许多方面已经相当令人印象深刻。我们正处于这些算法和模型成熟的初期阶段，但医疗服务交付的转型潜力巨大。尽管如此，目前的重点仍然是减少临床医生的行政和文档负担，这只是变化的开始。当前一代的LLMs可能很快会显得相当原始。在未来几年，随着LLMs和其他类型的人工智能的发展和改进，将会有更多令人惊叹和变革性的应用出现。</p>
<p>有几个LLMs和其他人工智能平台是专门为医学和医疗保健应用而创建的，其中一些是研究原型，其他一些则更加成熟并在实际应用中使用。以下是一些显著的例子。</p>
<ul>
<li>PubMedBERT：这个LLM及其相关模型在生物医学文本上进行了预训练，研究人员表示它超越了所有先前的语言模型。它旨在在生物医学领域表现出色。它是在 PubMed数据库中大量生物医学研究论文上进行训练的。它使用了 BERT，这是一个由谷歌开发的自然语言处理模型。它旨在帮助计算机更好地理解和解释人类语言，以考虑单词之间的上下文和关系。BERT 可以根据句子或段落中前后单词的语境理解一个词的含义。BERT 彻底改变了自然语言处理领域，并在搜索引擎、聊天机器人和情感分析工具等各种应用中得到了广泛采用。它理解和解释人类语言的能力对改善人机交互以及实现对大量文本数据的更准确和高效处理具有重要意义。</li>
<li>BioBERT：这个是一个专门为生物医学文本适配的语言模型。它基于原始的 BERT 模型，该模型是在通用文本语料库上训练的。BioBERT 进一步在生物医学文献上进行训练，增强了其理解和处理医学及科学语言的能力。它在来自生物医学领域的大规模语料库上进行预训练——特别是结合了 PubMed 摘要和来自美国国家医学图书馆的 PubMed Central (PMC) 全文文章。</li>
<li>SciBERT：由艾伦人工智能研究所设计的这个基于 BERT 的模型是在大量科学文本语料库上训练的，涵盖生物医学和计算机科学文献等领域，并已应用于科学文档摘要等任务。</li>
<li>ClinicalBERT ：旨在学习临床文本的领域特定语言及其独特结构，例如听起来像人类的释义，ClinicalBERT 是一个基于 MIMIC-III 数据库中临床笔记的领域特定 LLM，它经过训练以执行临床命名实体识别、关系提取和情感分析等任务。</li>
<li>谷歌的 Med-PaLM：谷歌的路径语言模型（PaLM）经过医学知识的微调，创建了 Med-PaLM，它在各种医学基准测试中得分很高，包括回答医学考试问题和提供临床决策支持等任务。谷歌还宣布了 Med-PaLM2，它在回答美国医学执照考试（USMLE）类型问题时达到了人类专家水平。</li>
</ul>
<p>无论是使用之前提到的LLMs特定领域示例，还是结合多个LLMs，例如谷歌的Gemini、Open AI 的 ChatGPT 或 Anthropic，或 ClaudeAI 与公司的专有数据结合，LLMs都将使医疗行业变得更好。这些 AI 模型使得在健康计划或支付方网站上导航、查找和理解内容变得更加容易。这些模型通过分析来自电子健康记录、临床试验和科学文献的大型数据集，加速了医学研究。最近的LLMs进展使医生或研究人员能够让LLM阅读一封或多封短或长的电子邮件，其中许多可能包含视频或音频剪辑以及临床医生的摘要。</p>
<p>此外，LLMs 正在解决医疗保健中的各种挑战，例如解读和清理医疗记录。他们还通过对话式人工智能弥合患者与提供者之间的沟通差距，确保在治疗前充分理解患者的病史，并分析来自各种来源的医疗数据，以获得更好的患者洞察。随着 LLMs 继续发展并融入医疗保健系统，他们的影响预计将是变革性的，塑造患者护理、研究和沟通的未来。</p>
<p>他们仍然有很大的空间来持续超越最熟练的医疗专业人员的专业知识。不过，将LLMs作为医生与患者关系中的第三个元素整合的潜力巨大。这种潜力包括协助诊断、文档记录和患者沟通。</p>
<p>每一个需要人类从医疗编码、患者教育、诊断、患者接收、治疗计划、药物管理等创造原创工作的临床和行政医疗流程，都有重新创新的机会。</p>
<p>LLM 和生成式人工智能应用程序或应用正在开始蓬勃发展，这得益于平台层的成熟、模型的持续改进以及免费和开源模型的日益可用。这为开发者、初创公司和企业提供了构建创新应用所需的工具。随着移动设备催生了具有传感器、相机和随时随地连接等新功能的新类型应用，LLMs 准备迎来一波新的生成式人工智能应用和医疗设备。</p>
<p>如今，医疗设备层出不穷，帮助我们优化生活，从健身追踪器到血压监测仪再到智能胰岛素泵。互联网搜索显示，医疗保健中使用的可穿戴医疗设备种类繁多，13 包括血压监测仪、血糖仪、心电图监测仪、健身追踪器等。我们喜欢将这些设备附加在自己身上，以使我们的生活更健康，工作条件更轻松。随着健康 LLMs 的进步，这些设备将变得更加有用。例如，LLMs 可以整合来自多个来源的数据，如您的 Fitbit、饮食应用、锻炼应用、禁食应用和睡眠追踪器，以提供更全面的健康视图。然后，它们可以分析这些综合数据，以识别在单独查看每个数据源时可能不明显的模式和趋势。</p>
<p>互联网搜索仍然是消费者使用谷歌的一个最爱——有些人称之为“谷歌医生”——以了解他们的症状和诊断。然而，证据清楚表明，互联网搜索能够轻微提高诊断的准确性，而在分诊准确性方面几乎没有提高。LLMs 将在未来几年内改变这一局面，因为互联网搜索与 LLMs 将会整合。ChatGPT 的问答互动模型引导您与互联网进行类似对话的交流——这种交流是上下文敏感和生成式的。</p>
<p>让我们探讨一下当前谷歌搜索和 ChatGPT 问答提示之间的差异。</p>
<ul>
<li>互动风格: 谷歌搜索是一种启动-响应风格，而 ChatGPT 采用问答风格，您用自然语言向它提问，它会给出具体的答案。谷歌搜索通常会返回许多与您的搜索词和短语相关的结果。它是一个相对灵活的系统，因为它返回所有匹配的结果并对其进行排名。谷歌搜索还会引用来源。</li>
<li>信息来源: 当您在谷歌上进行搜索时，系统会利用互联网庞大的网页和其他内容的索引，以找到可能匹配您的搜索请求的内容并加载它。相比之下，ChatGPT 利用其训练过的信息来源，这些来源包括截至特定日期的文本数据语料库，通常在该日期与用户提示的当前日期之间存在延迟。</li>
<li>答案的特异性: 当你在谷歌上搜索时，你可能会看到一系列网页、文章和其他资源，你需要浏览和滚动才能找到你所寻找的具体信息。ChatGPT 试图直接为你提供与所需信息相关的具体答案，而不需要你进行所有的搜索。当然，这也可能导致幻觉，这意味着人工智能不正确，生成无意义的输出，或者简单地提供事实错误的信息。我们应该提醒读者，称人工智能或 ChatGPT 产生幻觉时，我们是在将人工智能拟人化，而不是在描述一个缺乏许多人类特质的非人类物体或机器。</li>
<li>创造新事物: 谷歌搜索从根本上来说是关于在网络上寻找已经存在的信息。一个LLM不仅可以找到这些信息，还可以分析、生成新文本，并解释或论证某个结论。</li>
</ul>
<p>LLM-驱动的聊天机器人将回答我们关于健康的问题，而LLM-驱动的诊断工具将帮助医生更准确地诊断疾病。临床医生将利用医学LLMs来制定个性化治疗计划并监测患者的进展。</p>
<p>LLMs 将彻底改变消费者和患者在健康及医疗系统中的导航方式。通过提供个性化的见解、建议和支持，LLMs 可以使患者和消费者承担更多的责任，做出更明智的医疗选择。</p>
<p>LLMs 可以通过多种方式彻底改变医疗保健</p>
<ul>
<li>个性化健康教育: LLMs 为消费者和患者提供关于他们健康状况、治疗选择和预防策略的定制教育。生成式人工智能可以用来创建个性化的教育视频，使临床医生能够根据个人的具体需求、语言和偏好来调整教育内容。</li>
<li>医疗决策: 支持使用LLM聊天机器人应用的消费者和患者可以帮助他们在医疗保健方面做出明智的选择。聊天机器人可以对各种治疗选择进行产品或计划比较，并通过视频等多种方式解释每个选项的优缺点。这将不会提供医疗建议或临床建议，因为聊天机器人只是整理和总结已经提供给患者的数据和内容。聊天机器人作为理解内容的工具。</li>
<li>浏览辅助: LLMs 帮助消费者和患者在复杂的医疗系统中找到合格的医疗机构、安排预约并理解保险覆盖范围。使用聊天机器人在互联网上搜索（例如，ratemds.com、vitals.com、healthgrades.com 或 Yelp）以查找和总结患者对医疗机构或特定临床医生的评价。尽管这些评价是主观的，但像聊天机器人这样的工具可以总结这些数据，使消费者能够做出更明智的选择。</li>
<li>情感支持: LLMs 支持消费者和患者的情感健康。LLMs 可以倾听关切，提供鼓励，并将患者与面临类似挑战的其他人联系起来。LLMs 所促进的对话性质为支持和赋权消费者和患者提供了对话的机会。</li>
</ul>
<p>LLMs 将改变患者和消费者面临的当前个性化格局，从而推动医疗保健的个性化程度提高。这将包括辅导支持，提供更个性化的信息和建议。LLMs 可以使患者和消费者在健康和福祉方面更加负责任，通过对自身健康做出明智的决策。</p>
<p>选择一个由LLM驱动的聊天机器人在于LLMs所赋予的对话式人工智能的强大能力。一些实际应用中由LLM驱动的聊天机器人的例子可能包括以下任意一种：</p>
<ul>
<li>一个有慢性健康状况的人可能会使用一个具有LLM功能的聊天机器人来跟踪和记录症状，帮助管理处方，并提供关于健康生活的量身定制的信息。</li>
<li>一位面临选择的绝症患者——是否进行手术——可能会使用一个LLM聊天机器人来量化每个选项的风险和收益，并根据她自己的风险厌恶程度获得量身定制的建议，以便与她的医生进行对话。</li>
<li>慢性健康状况的护理人员，例如，可能会使用一个LLM驱动的聊天机器人来协调多个提供者之间的预约和护理，提供对提供者所说内容的解释和背景，并帮助做出决策。</li>
</ul>
<p>在这些例子中，基于LLM的聊天机器人相较于通用机器学习方法提供了某些优势。</p>
<ul>
<li>自然语言理解：我们已经提到过LLMs在自然语言理解方面的高超能力，这反过来又使得人类听起来更自然的语言输入成为可能（例如，用我们自己的话询问症状），这比填写结构化表单或基于关键词的搜索更直观和易于访问。</li>
<li>情境感知： 检查引用文本，LLMs可以在对话过程中保持上下文，并理解信息之间的关系，从而使聊天机器人能够为患者的问题提供更具信息性、减少重复和冗长的回答。然后，机器人可以根据患者最初描述其症状、处方药物和生活方式因素的上下文，跟踪其回答在与患者互动过程中的变化。</li>
<li>个性化支持： 通过与用户对话，了解人们的具体情况和问题，一个LLM驱动的聊天机器人可以提供针对个人健康状况、治疗计划和生活方式的有用建议和建议，这将更加有意义和实用。</li>
<li>预后支持： LLMs 可以从用户随时间提供的信息流中提取信号，并将这些洞察合成患者记录中发生的趋势。凭借这些数据，聊天机器人可以例如向用户标记一个问题，或自动将他们推荐给算法认为他们可能受益的有用资源或预防护理，最终目标是提升健康结果。</li>
<li>情感智能支持： LLMs 可以被训练成以理解和支持的语气进行交流。那些在慢性疾病的日常挑战中挣扎的人，可以从拥有一个支持性的对话伙伴中受益，以保持他们的动力和心理健康。</li>
<li>可扩展性： 大多数机器学习模型需要在每个新任务或能力的细微差别上进行明确的训练。然而，由于LLMs能够有效地调整其已有的语言通用知识，以支持在不同主题领域上执行甚至相当不同类型的任务，因此更容易扩展和调整聊天机器人，以满足更多样化的用户需求，并随着时间的推移扩展其知识库的广度和深度。</li>
</ul>
<p>一个定制的机器学习模型可以用较少结构化的数据输入和更简单的逻辑，并且可能无法提供太多支持或更广泛的背景。这反过来可能意味着用户的定制化程度较低，支持的范围较浅且较窄，并且随着时间的推移需要更多的工作来构建和维护。</p>
<p>一个LLM驱动的机器人不需要对心理痛苦或功能分类的定义。然而，它仍然会发挥自身的能力，包括自然语言交互、上下文理解和“深度”知识整合的一些优势，以提供一种广泛的、量身定制的支持，这在帮助慢性健康状况的人们方面似乎很有前景。</p>
<p>LLMs 将有助于平衡获取资源。患者和消费者将能够寻求和获取更高质量的健康信息和建议。医疗专业人员和更广泛的健康系统将更好地帮助实现患者的健康潜力。</p>
<p>关键不仅在于LLMs可以为我们做事情。我们可以利用LLMs和生成式人工智能来使我们更健康、更快乐。在下一部分中，我们将勾勒一些未来的应用程序或应用。</p>
<h1 id="LLMs在医疗保健中的承诺与可能性"><a href="#LLMs在医疗保健中的承诺与可能性" class="headerlink" title="LLMs在医疗保健中的承诺与可能性"></a>LLMs在医疗保健中的承诺与可能性</h1><p>每年全球有八百万人因缺乏更好的医疗保健而死去。医学和医疗保健正处于变革的浪潮边缘，因为LLMs和生成式人工智能正在从根本上改变医学。大型LLMs在与尖端人工智能突破相关的大型医疗和医学数据上进行训练，将促进个性化医疗保健的实现。</p>
<p>将其训练语料库中捕获的知识与患者病历中的信息结合起来，有可能显著推动临床决策支持系统的发展，并最终改善患者的护理和结果。LLMs可以帮助医生做出更精确的诊断，确定最佳治疗方案，甚至预测患者的预后。</p>
<p>在一个未来，LLMs被嵌入临床决策支持系统中，医生可能在护理时能够获得几乎取之不尽的医学知识。借助这样的工具，医生可能能够减少医疗错误：LLMs旨在帮助临床医生，帮助他们在可能犯错的边缘时远离危险。</p>
<p>&#x3D;&#x3D;LLMs 可以为临床医生提供前所未有的实时护理，通过跟踪电子健康记录中的医疗笔记、家庭设备的数据以及患者在数字平台上输入的信息。这种方法可以创建一个早期预警系统，监测症状、体征和实验室测试结果，提示疾病恶化。&#x3D;&#x3D;通过及早识别健康问题，LLMs 提供了一个极好的机会，帮助预防慢性疾病的发生，这些疾病可能会对患者的健康相关生活质量产生不利影响，并且通常会给医疗系统带来高昂的经济负担。</p>
<p>超越这一点，&#x3D;&#x3D;LLM衍生的见解可以为精准健康方法提供信息，旨在根据每个个体患者的遗传、环境和生活方式特征，优化初级、次级和三级预防以及治疗干预。因此，精准医疗可以被设计为优化治疗反应，提高患者参与度和治疗方案的遵循性，并改善健康结果&#x3D;&#x3D;，无论是对个体还是对群体。</p>
<p>鉴于LLMs的快速进展，以及它们在未来不可避免地与其他颠覆性技术的融合，人工智能在发展真正的预测性、预防性和个性化医疗系统方面的潜力呈几何倍增。用于医疗保健和人工智能的大数据&#x2F;LLM有望在危机来袭之前使预防性和先发制人的医学成为新常态。</p>
<p>随着新的人工智能功能的引入，如代理推理、检索增强生成、更大的提示词，甚至可能是无限提示词等，LLMs 的价值也在增加。它们可以基于更多的医学和其他特定领域的“数据”处理更有针对性和更细致的查询；推理假设场景；并以看似上下文相关和个性化的回复回答问题。如今，临床医生可能会使用多个应用程序来处理医学问题，例如 UpToDate 应用程序。LLMs 的采用可以改善这些应用程序在搜索、摘要、用户界面等方面的功能。</p>
<p>想象两个医疗场景，每个场景都利用了由LLMs和生成式人工智能驱动的应用程序。这些尖端的人工智能应用程序无缝集成了对话式人工智能、先进的搜索功能和智能摘要能力，彻底改变了患者和消费者与技术互动和获取信息的方式。让我们深入探讨这些假设场景，探索这些人工智能驱动的应用程序在医疗保健中的潜在影响。</p>
<p>在第一个场景中，医疗瑞士军刀是一个消费者应用程序的名称，旨在帮助患者和消费者在参与和导航医疗系统时提供支持。在第二个场景中，医疗向导是一个临床医生应用程序的名称，旨在成为临床医生的伴侣或虚拟助手。在这两种情况下，LLMs都经过培训或增强，结合了可信的知识来源、临床数据、药房数据、电子健康记录数据等。</p>
<h2 id="消费者医疗瑞士军刀应用程序"><a href="#消费者医疗瑞士军刀应用程序" class="headerlink" title="消费者医疗瑞士军刀应用程序"></a>消费者医疗瑞士军刀应用程序</h2><p>一家人工智能初创公司推出了一款新型聊天机器人，采用医疗特定的LLM构建。该聊天机器人是一款名为“医疗瑞士军刀”的健康应用程序，旨在为消费者或患者提供多功能服务，涵盖医疗场景中的预约医生、总结患者病史，以及倾听医生和患者的对话，以便提供简单易懂的医生指示总结。“医疗瑞士军刀”还提供医疗服务引导，帮助用户导航并识别适合其医疗状况的最佳医疗服务提供者。</p>
<p>大卫，一位 75 岁的老人，爱上了他的 Fitbit 可穿戴设备。在几周内，他多次收到信号，检测到心房颤动（AFib），并联系了他的医生，医生将他转诊给心脏病专家。大卫服用高血压药物和他汀类药物来控制胆固醇。大卫最近做了一项钙评分测试，结果显示他处于高风险类别。他的心脏病专家建议并进行了一次 AFib 消融，但并没有解决问题。大卫再次住院，接受控制性电击和心脏复律以恢复正常节律，但无济于事。</p>
<p>大卫想知道是否有 AFib 消融的替代方案。他与医生交谈，医生说 AFib 的效果很好，他们应该再试一次，因为这家医院专门进行治疗 AFib 的手术。大卫在他的 iPhone 上安装了医疗瑞士军刀应用程序，这是他的妻子推荐的，他决定使用它来研究关于 AFib 消融替代方案的问题。医疗瑞士军刀应用程序使用医学特定的LLM，一个类似于谷歌的基础性LLM，结合大卫的医疗记录、病史和健康信息的数据。该应用程序告知大卫另一种手术，即导管消融。向大卫展示了一个著名研究医院和专门从事该手术的医生的经过验证的视频。大卫对此产生了兴趣，并咨询了他的医生，医生告诉他这是一种他无法提供的替代治疗，大卫应该联系研究医院以了解更多信息。</p>
<p>该应用程序与大卫开始对话，讨论他的钙评分测试显示他处于高风险状态。它告知大卫，在导管消融之前，研究中心很可能会进行心脏计算机断层扫描（CT），以帮助他的主治医生预见在手术过程中可能出现的困难。</p>
<p>大卫使用医疗瑞士军刀应用程序联系医院，并进行初步电话预约以了解更多信息。大卫享受这次对话，感到受益匪浅，决定在这家研究医院接受治疗。该应用程序负责预约、航班和酒店预订。大卫与医疗瑞士军刀应用程序进行对话，以更好地理解他应该问哪些问题。该应用程序建议大卫询问以下内容：</p>
<ul>
<li>根据我的情况，最适合我的治疗方案是什么？</li>
<li>可用的不同治疗选项有哪些？每种治疗的风险和益处是什么？</li>
<li>我的心房颤动如何影响我的心脏？</li>
<li>我中风的风险有多大？</li>
<li>如果我有房颤发作，我该怎么办？</li>
<li>长期患有心房颤动的影响是什么？</li>
</ul>
<p>该应用程序的开发由一家知名公司进行，采用最先进的安全措施来保护患者隐私。应用程序的设计旨在避免对对话的误解或提供不准确信息，具体措施包括：</p>
<ul>
<li>使用一个大规模且多样化的数据集来训练LLM：该数据集包含医疗对话。这有助于LLM学习医疗语言的细微差别，并避免犯错误。</li>
<li>使用最先进的自然语言处理技术： 这些自然语言处理方法用于有效理解对话。这反过来帮助LLM准确找出话语的关键方面，并避免做出没有依据的推断。</li>
<li>结合医生和患者的反馈： 该应用程序提高了LLM的准确性。应用程序的持续反馈循环有助于识别LLM面临困难的领域，并进行必要的调整。</li>
<li>为用户提供透明度： 该应用程序允许用户了解其工作原理，并利用用户的数据帮助他们理解应用程序的局限性并负责任地使用它。</li>
</ul>
<p>LLM医疗瑞士军刀应用提醒大卫，它不是医生，无法提供临床建议或诊断。它告知大卫，在做出关于自己护理的决定之前，他应该向他的房颤医生寻求医疗建议。大卫和他的妻子飞行 2000 英里，入住推荐的靠近医院的酒店。两人都立即对心脏病专家的电话感到印象深刻，医生询问是否可以过来打个招呼。在与医生会面之前，大卫打开医疗瑞士军刀应用，查看他想要问的问题。应用提示大卫是否希望它监听对话。大卫告知医生他正在使用一个应用程序，将监听他们的对话，并帮助大卫在之后更好地理解对话。医生微笑着说当然可以，并提醒大卫在手术前后随时可以问他任何问题。</p>
<p>现在是星期一，准备进行一次术前 CT 扫描，以便为大卫的心房颤动治疗准备消融夹。CT 扫描显示他的主要动脉严重堵塞，心脏病专家警告大卫，他面临高风险心脏病发作，由于堵塞，他需要立即进行开胸手术。</p>
<p>大卫开始与他的医疗瑞士军刀应用程序交谈，询问当地医生是否应该发现这个堵塞。应用程序告诉大卫，由于他没有报告的症状，进一步的测试可能没有必要。它还建议他在有时间时向他的主治心脏病医生和当地医生询问这个问题。</p>
<p>如果没有使用医疗瑞士军刀应用，戴维将只与他的当地心脏病专家接触， 对他心脏病发作的高风险毫不知情. 尽管这或许只是偶然，戴维如果不是为了寻求导管消融，永远不会进行显示严重堵塞的 CT 扫描。</p>
<p>大卫进入了预计需要三到四小时的手术，但实际上进行了六小时。医生完成手术后告诉大卫的妻子安妮发生了什么。他表示大卫手术时间延长的原因是他有一种身体异常，导致血液从他的肺部流向心脏的方式是医生从未见过的，甚至是他认识的任何人也没有经历过。</p>
<p>医生强调他已经做了几十年这个工作，甚至与患有先天性心脏病和出生缺陷的婴儿合作过，但从未见过这样的情况。他们花了一些时间试图弄清楚情况，而不是使用一个泵来循环血液，他们用了三个泵，但仍然不够。</p>
<p>我们不得不提到安妮为什么对医疗瑞士军刀LLM医疗应用程序如此有信心。四年前，她被诊断为慢性淋巴细胞白血病。她在一个星期一与肿瘤科医生有一个预约，而她的女儿在前一个星期四给她打了电话。她的女儿是医疗瑞士军刀应用程序的活跃用户。该应用程序建议她的母亲在癌症研究医院接受治疗会获得更好的结果，而不是她原计划的当地医院。她的母亲并不太愿意重新安排预约，因为她喜欢她的肿瘤科医生，而且当地医院离家很近，相比之下，研究医院要远一些。但她最终妥协了，取消了预约，并在研究医院预约了肿瘤科医生。</p>
<p>研究医院有一个稍微不同的治疗计划，其中包括最近获得 FDA 批准的药物 IMBRUVICA®。安妮对结果感到非常满意，目前她的癌症处于缓解状态。她将这一切归功于她的女儿和那个引导她去一个能够产生更好 CLL 白血病结果的护理机构的应用程序。安妮明白，临床结果可能因提供者而有很大差异，她很高兴她的丈夫大卫能够与一位治疗房颤的专家建立联系。她坚信这拯救了她丈夫的生命。毫无疑问，发布研究结果的医疗机构在患者满意度评分上表现出色，并在各种医疗状况和程序中显示出降低的患者死亡率。</p>
<p>&#x3D;&#x3D;通过利用关于医疗机构临床结果的大量数据，医疗瑞士军刀应用程序由LLM提供支持，可以将个别患者与在统计上最有可能为患者特定病情和风险因素提供最有效治疗的医生匹配&#x3D;&#x3D;。</p>
<h2 id="临床医生医疗向导应用程序"><a href="#临床医生医疗向导应用程序" class="headerlink" title="临床医生医疗向导应用程序"></a>临床医生医疗向导应用程序</h2><p>当约翰因喉咙侧面有一个肿块而来进行常规体检时，戴维斯医生停下了。“约翰，”戴维斯医生说，“我想仔细看看你喉咙上的那个肿块。”约翰点了点头，于是戴维斯医生仰起头。他用放松的手指触摸肿块，皱起了眉头。肿块坚硬且固定，在轻轻的手指压力下没有移动。“我很担心，”戴维斯医生说，“这个肿块可能是癌症。”他继续说道：“我建议你立即去看专科医生，以确保安全。”约翰看起来很不安。“但我并没有感到不适，”他说。“我没有任何症状。”</p>
<p>癌症在早期往往没有症状，他补充道。约翰勉强同意去看专家，随后戴维斯医生为他安排了下周的预约。但戴维斯医生仍然觉得有些不对劲。他决定咨询他的医疗向导，一个可以筛选大量事实知识的LLM诊断应用程序。</p>
<p>戴维斯医生向他的医疗向导描述了肿块。应用程序反馈了几个建议，包括要求进行细针抽吸（FNA）活检——一种从肿块中提取细胞样本的微创方法——并将约翰引导到耳鼻喉科医生那里，这是诊断和治疗耳、鼻、喉疾病的合适专家。</p>
<p>根据医疗向导的建议，戴维斯医生为约翰安排了细针穿刺活检（FNA）。他还将约翰转诊给了一位耳鼻喉科医生。几天后，FNA 活检的结果显示为癌症阳性。戴维斯医生给约翰打了电话，传达了一个不对称的震惊消息：“我很遗憾地告诉你，你得了癌症，但我们发现得早，你仍然可以接受治疗。戴维斯医生问约翰，‘如果我的医疗向导帮助你安排与耳鼻喉科医生的预约，以讨论你的治疗方案，可以吗？’”</p>
<p>医疗向导是一个面向临床医生的LLM应用程序，通常由寻求咨询的医生使用。医疗向导应用本质上是临床医生与LLM之间的简短而非正式的咨询。使用“向导”这个名称是恰当的，因为类似于协助登山者攀登珠穆朗玛峰的夏尔巴人，医疗向导将帮助临床医生在复杂的医疗环境中导航。LLMs被设想为在医生身边实践的虚拟助手，提供见解并完成任务。然而，医学中人类的一个重要组成部分是临床判断的引导。</p>
<p>医疗向导促进更好和更安全护理的原因既有一般性，也有对临床医生的具体好处。例如，当医生与他们的向导合作时，他们获得了在依赖远程数据和分析时无法获得的近距离知识。同样，护士的向导由于在床边，能够通过无处不在的沟通提供实时支持和建议，使护士能够做出更明智的决策。</p>
<p>此外，医疗向导可以通过节省时间来帮助提供者提高生产力。通过快速便捷的咨询和支持，医生和护士可以利用节省下来的时间专注于工作中的其他关键方面，这可能有助于改善医疗结果。</p>
<p>此外，通过减少医疗提供者的倦怠，这已被认为是医疗保健中的一个严重问题，&#x3D;&#x3D;医疗向导使临床医生能够花更多时间照顾患者，而不是在每个案例中花费时间培训新学习者&#x3D;&#x3D;。拥有在这种护理形式中具有持续经验的人，可以极大地改善本地临床医生的体验和信心水平。综合来看，这些好处可以为患者提供更高质量的护理，并为未来建立一个更可持续的系统。</p>
<h1 id="LLMs的新兴特征"><a href="#LLMs的新兴特征" class="headerlink" title="LLMs的新兴特征"></a>LLMs的新兴特征</h1><p>LLM-驱动的应用程序处于一个有趣的空间，介于对未来的诱人愿景和需要克服的一系列艰巨障碍之间。我们离一个基于LLM的系统能够处理日益复杂的任务、释放人类创造力的新方向，并从根本上改变我们与周围世界互动的方式的未来非常接近。但首先，我们必须在数据、性能、稳定性和安全性等技术前沿上取得进展。</p>
<p>这其中除了技术基础设施，还有人性的一面。与数据需求旺盛的LLMs相关的隐私问题也很重要。训练数据中固有的偏见使得需要持续监测和主动缓解策略，以防止在医疗环境中再现偏见和造成伤害。</p>
<p>这意味着，尽管我们还没有到达目的地，尽管单靠技术无法让我们到达那里，但我们正在逐步向前推进。社会、伦理和概念思维对于扩大负责任的设计方法至关重要，这将使我们能够创造出LLMs种工具，以提高医生的效率和效果以及医患互动，同时防止这些工具成为排斥和伤害的工具。</p>
<p>基于LLM的应用程序当前的形态因素为医疗保健提供了广泛的实用性，有潜力为消费者的生活方式和医疗保健运营提供辅助便利。从我们智能手机上的症状检查工具到后台的临床决策支持，LLM的使用案例在患者与医生互动的多个环节中放大了改善医疗保健的潜力。</p>
<p>尽管真正的颠覆性创新仍在地平线之外，但我们今天可以看到，人工智能已经在重塑临床空间和消费者健康技术，以提高工作流程效率和患者护理。《人工智能优先的医疗保健》一书记录了许多人工智能如何改善医疗保健的例子。LLMs 将人工智能向前推进一步，自动记笔记、对话聊天机器人和摘要任务仅仅是个开始。</p>
<p>或许比其他地方更为紧迫的是，LLMs承诺在社会福利方面持续增加——使现有系统意识到护士护理中的漏洞，重新引导决策树，并通过提供者和购买者的赋权，稍微夸大地为每位患者最大化利润。我们共同未来的这种乐观处理的现实是由于消费者和商业LLMs的到来。</p>
<p>在不久的将来，LLMs将迎来激动人心的变化，包括扩展提示窗口或称为上下文窗口。窗口大小不断扩大，研究人员正在开发一种允许无限大小的提示。</p>
<h2 id="无限上下文提示"><a href="#无限上下文提示" class="headerlink" title="无限上下文提示"></a>无限上下文提示</h2><p>LLMs 具有广泛或无限上下文窗口的能力，现在可以同时处理文本、音频和视频数据。这一进展为医疗服务提供者、健康计划和支付方开辟了新的增强可能性。这对临床医生来说很有趣，因为它可以通过实时分析多种数据类型来加强患者咨询。以下是这一人工智能改进可能改变医疗保健的一些方式：</p>
<ul>
<li>LLMs 通过访问医学文献、临床记录和指南，可以为临床医生提供实时的基于证据的诊断、治疗和护理计划的建议。然而，与人类一样，回复可能会有延迟（即延迟时间），这取决于提示词的复杂性。通过将患者数据与医学文献和临床最佳实践进行评估，LLMs 可能帮助临床医生减少医疗错误，并增强决策能力，以改善患者的治疗结果。</li>
<li>能够理解和生成文本、音频和视频的模型，可以促进患者与临床医生之间更有意义的互动，跨越语言障碍。LLMs可以帮助将复杂的医疗信息转化为多功能的文本，使更多种类的患者能够理解，回答常见问题，提供可以个性化以满足个人需求的细致患者教育，并鼓励早期干预。这些互动可以增强患者的参与感、依从性和对护理的满意度。</li>
<li>不同的LLMs可以帮助自动化文书工作和临床文档，包括编码和账单，简化医疗流程，解放提供者免受行政负担，以便他们可以花更多时间与患者进行临床“面对面”的交流。如今，像谷歌这样的公司提供技术，允许人们使用LLMs来总结嵌入视频的电子邮件。想象一下，如果输入流不受固定大小的限制，这将会是什么样子。</li>
<li>能够实时解析音频和视频的模型将提高远程医疗和远程监测服务的效率和效果，帮助进行远程咨询。</li>
<li>凭借分析和综合大量生物医学文献和数据的能力，包括科学出版物、临床试验数据和病历，LLMs 可以加速医学研究和药物发现。临床医生可以利用 LLM 的力量来总结跨越多年的临床试验数据或病人记录，从而节省时间。</li>
<li>LLMs 可以通过根据患者的独特特征（例如，基因组、生活方式和病史数据）提供量身定制的护理，从而实现个性化医学和精准医疗，以识别个性化的风险因素、疾病发展轨迹以及治疗干预和治疗。LLMs 可能实现的更加个性化的护理方法可以通过优化患者治疗结果来提高医疗保健服务的有效性和效率。。</li>
</ul>
<p>个性化医疗的承诺将是向前迈出的一大步。LLMs 具有无限上下文窗口或提示，可以处理和存储大量的医学文献、临床试验数据、患者病史和临床数据，从而为患者或消费者提供一个全面且可更新的医学知识库。由这样的 LLMs 驱动的聊天机器人将扩展到更复杂的多轮对话，创造直观且引人入胜的消费者体验。前谷歌首席执行官埃里克·施密特预计，在未来五年内将出现扩展的无限提示窗口。</p>
<h2 id="代理推理"><a href="#代理推理" class="headerlink" title="代理推理"></a>代理推理</h2><p>代理推理代表了人工智能的另一个发展阶段，其中系统可以自主行动。计算机科学家和人工智能研究员 Andrew Ng 提供了关于代理推理本质的有趣观点，并描述了我们将在本章中探讨的代理推理的四个关键特征或模式：反思模式、工具使用、规划和多智能体互动。</p>
<p>“代理推理是创建能够采取旨在实现目标的行动的代理的核心，”斯坦福大学计算机科学兼职教授、Coursera 联合创始人 Andrew Ng 说。Coursera 是一家提供大规模开放在线课程的公司。Ng 解释说，这意味着人工智能系统感知、渴望、相信和行动的能力，从而设定和修改目标，在不确定性下做出决策，从经验中学习，并以自然和有效的方式与人类和其他人工智能代理进行互动和推理。他指出，实现人工智能代理之间的代理推理的挑战，需要在多个领域取得重大进展，例如机器学习、自然语言处理、知识表示和不确定性下的推理。</p>
<h3 id="代理推理的四种模式"><a href="#代理推理的四种模式" class="headerlink" title="代理推理的四种模式"></a>代理推理的四种模式</h3><p>在代理推理中的反思模式帮助人工智能根据其之前的行为提高性能。反思模式使医疗人工智能系统能够反思其选择，识别改善结果的方法，并不断发展其对患者护理的方式。例如，旨在为临床医生提供复杂疾病的诊断和治疗建议的人工智能代理可以采用反思模式。该代理最初会在一个大型多样化的患者记录、文献和临床指南数据集上进行训练，然后根据流行数据向临床医生提出代理建议。</p>
<ul>
<li>初步诊断和治疗计划： 当新的患者案例被提交时，代理将分析呈现患者的症状、医疗背景和测试结果，然后提供初步诊断和治疗计划。代理将利用其训练数据并运用其自主推理能力，以及关于构成它的模块的建模数据，来确定患者病情的真实原因以及最佳治疗方案。</li>
<li>对结果的反思： 一旦患者开始治疗计划，人工智能代理会在患者的治疗过程中监测其进展和结果。患者的实际成果将与代理根据初始建议对同一患者的预测进行比较。如果患者的改善符合代理的预期，代理将自我强化，并在未来类似案例中变得更加自信。但如果在一定时间后患者的状况没有改善，或者结果不理想，人工智能代理将检查它做出该决定的原因——通过查看其算法、所使用的数据以及它所建立的假设。</li>
<li>适应与学习： 基于这种反思分析，AGI 让患者的案例成为其决策模式所需调整的基础。例如，AGI 可能会将临床发现的记录添加到其背景知识中，优化算法以纳入已知的特定患者细微差别，或修订治疗建议列表以降低已知并发症的发生几率。关键是，这种自适应训练过程意味着代理不断学习采取更多能够改善其长期行为的行动，从而最终做出更好的推荐——减少错误的可能性并促使更合适的补救措施。当它接触到更多患者，并参与这一事后行动的过程时，它能够诊断和治疗更复杂的医疗问题。</li>
<li>分享见解与协作学习： 这种知识可以通过它们获得的反思性见解在人工智能代理和人类专家之间共享，从而增强人类与人工智能代理之间的共同学习和共同知识。例如，多个人工智能代理可以协作识别模式，并在大规模上生成新颖的治疗策略和改进的患者护理。AI 代理可以向人类医生提供反馈，指出他们需要更新临床实践或需要额外研究努力的地方。通过进行这种人机对话，我们最终可以增强人类与机器之间的混合工作性质。代理推理的反思结构使得在医疗保健领域工作的人工智能代理能够从他们的经验中学习，调整他们的策略，并不断提高诊断和治疗患者的能力。通过与人类专家的持续反思和协作学习过程，人工智能代理可以成为人类护理的补充，提高医疗服务的质量、效率和有效性。反思过程必须得到适当的引导，并以强有力的伦理原则为基础，同时始终保持人类监督，以防止意外的疏忽并维持最高的护理标准。</li>
</ul>
<p>在代理推理中的工具使用模式使得 AI 代理能够广泛利用工具和外部资源，超越机器学习、计算机视觉或自然语言处理，通过利用外部资源和知识能力来扩展其问题解决范围和决策过程。对于医学而言，工具使用模式可以使 AI 系统通过整合现有的医疗工具、数据库、服务以及所有其他外部输入（如护士、医生、护理人员等医疗专业人员）来“借用”医疗资源。这些输入可以基于最新的临床知识和专业决策提供原则性和以人为本的患者护理，而不是将 AI 系统局限于仅依赖机器学习示例的“黑箱”决策。让我们看看精准医学，并说明工具使用模式如何应用。</p>
<p>一个医疗 AI 助手帮助医生为癌症患者制定个性化治疗计划。为此，助手使用代理推理分析患者数据，寻找患者可以遵循的最佳治疗方案，并且助手还监测治疗进展。为了进一步改善治疗建议，助手采用工具使用模式来访问并结合外部资源和服务。</p>
<ul>
<li>基因组分析工具： 一个人工智能代理挖掘基因组分析工具箱，以收集和理解患者的遗传信息。凭借基因组变异及其已知临床意义的数据库，它可以识别潜在的遗传风险因素，建议可能的药物反应，并根据患者的个体分子特征开具靶向治疗。</li>
<li>医疗影像服务： 医疗影像服务——例如计算机视觉 API——是 AI 代理依赖的，分析患者扫描（MRI、CT 或 PET 扫描），以检测和描述肿瘤的存在和形状，以及对攻击的治疗反应和随时间的疾病进展监测。这些信息与其他患者数据的见解相结合，输入到 AI 代理对患者状况的整体评估中。</li>
<li>电子健康记录（EHR）系统： 利用电子健康记录（EHR）系统访问患者的既往诊断、治疗和结果，将帮助人工智能代理构建更准确的实际治疗方案。例如，人工智能代理可以参考其他患者的电子健康记录，而不是仅仅咨询该患者的电子健康记录，从而获得更全面的患者健康状况视图，并可能识别出影响治疗方案选择的风险因素或合并症。通过访问来自集成的电子健康记录系统和其他相关医院的数据，人工智能代理将能够生成更个性化的护理计划和相关决策。</li>
<li>临床试验数据库： AI 代理搜索临床试验数据库，寻找与患者病情相关的试验，然后检查试验的资格标准、参与者的治疗数据和结果数据。这使得 AI 代理能够对患者可能受益于参与的试验提出建议，或利用试验数据为其治疗建议提供依据。</li>
<li>药物相互作用检查器： 该人工智能代理使用药物相互作用检查工具来评估提议的癌症治疗方案与患者当前药物的潜在相互作用。然后，根据结果推荐替代药物或剂量调整，以尽量减少不良药物事件或禁忌症，同时最大化疗效。</li>
</ul>
<p>通过使用这些工具和服务，&#x3D;&#x3D;人工智能代理可以为医生提供一种综合的精准医疗方法，汇总来自不同来源的相关数据，并提供经过知识图谱和概率评分验证的个性化治疗建议。这种方法是可行的，因为代理可以进行期刊爬取、医学文本挖掘、下载、图像存储，并以概率方式整合不同的数据。它可以利用患者的病史、基因数据和影像数据，基于较少知识的药物相互作用建议合适的治疗方案，包括潜在的处方&#x3D;&#x3D;。</p>
<p>此外，由于人工智能代理本身正在对新的研究数据、临床指南以及新的或未经测试的治疗方案做出一些决策，因此该代理的工具使用情况基本上是自我更新的——随着人类癌症发现模式的变化而变化。因此，该代理将使用现有的最佳和最新知识。</p>
<p>随着代理推理领域在医疗保健中的发展，这种工具使用模式将在构建能够捕捉、组合和处理精准医学中所需的大量多样化医疗数据的人工智能系统中发挥重要作用，以提供更好的患者护理——前提是用于实现这些结果的外部服务尊重强有力的数据隐私、安全和伦理规则，以维护患者的隐私和医疗系统的完整性。</p>
<p>在代理推理中，规划模式对于赋予人工智能代理制定高层次计划以实现其目标和优化流程的能力至关重要。这意味着，在医疗领域，一个具备规划能力的人工智能系统可以用于处理详细的患者案例，预测潜在结果，并在制定之前决定最佳治疗方案——整合各种因素和参数。例如，考虑一个旨在帮助医生管理慢性疾病患者（如糖尿病、高血压或心血管疾病）的人工智能代理的场景。在这种情况下，代理使用代理推理来分析体检结果，排列出现的症状，识别使患者面临更差健康结果的风险因素，然后为长期健康结果制定战略性和适应性的建议。</p>
<ul>
<li><p>目标设定与问题分解： AI 代理以优化患者的健康结果和生活质量为抽象目标，并将其细分为更小、更具体的子目标：保持患者的血糖在最佳范围内，降低血压至安全水平，最小化截肢或肾脏并发症的风险，等等。通过将整体问题分解为不同的子问题，代理可以制定和追求与患者状况的每个特定方面相适应的行动。</p>
</li>
<li><p>数据分析和情况评估： 然后，人工智能代理尝试根据其上下文反映患者的整个医疗情况。它考虑患者的病史、当前健康状况和环境背景，以及他的生活方式和可识别的个性特征。这包括整合电子健康记录、可穿戴设备和患者报告结果的数据的能力。</p>
</li>
<li><p>计划生成与评估：根据这一情况评估，人工智能代理生成不同的可能治疗方案，以解决定义的子目标。例如，它可能包括一种涉及使用不同药物调整、生活方式改变和转诊专家的组合。代理通过考虑预测的有效性和副作用、患者的偏好和接受度、可用资源等，使用已知数据和概率预测来评估每个方案，然后决定推荐哪种行动方案。</p>
</li>
<li><p>计划选择与调整： AI 代理将选择其认为价值最佳的治疗方案，权衡治疗的益处与风险。然后，它会将选定的方案及其支持理由传达给医生和患者，可能还会提供实施建议的说明或支持。</p>
<p>医生设计治疗计划，而人工智能在计划实施过程中进行监测并检查结果。如果患者的病情没有按照预测的轨迹发展，代理会重新规划。治疗会对新信息做出响应，例如调整药物剂量或引入不同的干预措施或生活方式建议。</p>
</li>
<li><p>持续监测和改进： AI 代理稍后会与患者进行回访，以了解她的情况以及治疗计划是否有效或需要调整。它还会关注副作用带来的风险和不良事件。当它能够识别患者自身数据中的模式并与类似病例的轨迹进行比较时，代理可以调整其规划策略，以更好地防范突发的健康问题。</p>
<p>这种代理推理的规划结构可以帮助医疗保健领域的人工智能代理制定慢性病管理的执行性和动态护理策略。人工智能代理将复杂的健康问题分解为有意义的子目标，利用可用的患者数据进行模式补全程序，集思广益提供喂养和消除选项，分析预期后果，并监控和自我调整其策略。通过这种方式，人工智能代理可以帮助医生提供个性化的、基于证据的护理，平衡短期成本与长期健康收益。</p>
<p>随着我们在医疗保健领域的代理推理这一激动人心的领域不断发展，规划模式不太可能是唯一需要的模式。但它在创建帮助临床医生管理慢性疾病的人工智能系统中将是至关重要的，这些慢性疾病占据了患者群体的很大一部分，并将使他们朝着更公平的人口健康的方向前进。我们必须保护规划过程——用伦理原则、临床最佳实践和以患者为中心的价值观来引导它，以保护个人免受可能随着医疗工作负担的增加而出现的不安全、无效和不可接受的治疗计划的影响。</p>
</li>
</ul>
<p>多智能体协作模式是智能架构实现不同层次的智能本体中多样化智能体协作工作的手段，无论它们是否被赋予代理权。集体事件识别需要两个或更多智能体对事件的意识和评估。在医疗领域，当两个或更多智能智能体——可以被视为人工智能系统和独立的广泛医疗专业人员——协调工作、共享状态知识或感知，并基于共享目标或子目标做出决策和行动时，便激活了多智能体协作模式。</p>
<p>想象一个患者有各种长期疾病——糖尿病、高血压、心血管疾病等等——需要来自广泛健康专业人士的建议、监测和治疗（例如，这可能是一个由医生、护士、营养师、社会工作者、心理学家等组成的多学科团队）。在这种情况下，可能会部署一系列不同的人工智能代理来支持健康专业团队的成员，例如，帮助他们优化用药选择、提供生活方式指导、协调护理等。这些人工智能代理采用代理推理和多代理协作模式，整合技能和工作记忆，以提供针对性强、信息充分、协调一致的护理。</p>
<ul>
<li><p>共享目标和问题理解： AI 代理和人类专家共同定义患者的健康状况、治疗目标和潜在障碍。最后，他们共同制定个性化护理计划，充分利用人类和算法各自的优势，为患者的医疗、心理和社会需求提供最佳治疗。</p>
</li>
<li><p>任务分配与协调： 针对他们分配的任务，人工智能代理分配了一部分工作。药物优化代理可以扫描患者的处方以查找药物相互作用，并建议优化疗效和安全性的方法。生活方式指导代理可以个性化饮食、锻炼和压力管理建议，以补充患者的自我护理方案。</p>
<p>护理协调代理处于中心位置，收集来自众多护理代理的信息，并将每个代理与他们所需的特定信息连接起来。护理协调代理还确保其他代理和人类专家了解患者的当前状态、状态变化和护理计划的变化。</p>
</li>
<li><p>信息共享与知识交流： AI 代理和人类专家不断交流信息和见解，以支持集体决策和问题解决。他们通过加密通道和标准化数据格式传输患者数据、治疗建议和临床见解，以便每个代理和专家都能利用整个团队的集体知识，并相应地更新其策略。例如，如果药物优化代理检测到潜在的不良药物事件，它会通知护理协调代理，后者则会警告人类专家以及其他 AI 代理。团队评估发生的情况并生成事件记录。他们考虑是否要停用有问题的药物，并用其他选项替代。如果是，他们会更新护理计划。</p>
</li>
<li><p>冲突解决与共识建立： 如果人工智能代理或人类之间存在相互矛盾的建议或意见，多代理协作模式使他们能够进行辩论和对话，协商权衡并通过辩论、投票或多标准决策分析方法达成共识。这种协作模式确保达成的决策“符合患者的最佳利益。”</p>
</li>
<li><p>持续学习与适应： 如果患者的情况发生变化并且有新的数据可用，人工智能代理和人类专家会学习新的护理协调过程策略，互相交流技巧（可以这么说），帮助使他们的策略更加有效和高效。多个代理相互互动，从彼此的成功和失败中学习，并在面对新挑战时逐步发展新的方法。</p>
</li>
</ul>
<p>这种来自代理推理的多智能体协作模式使得人工智能代理和医疗保健领域的人类专家能够以协调的方式共同工作，为具有复杂健康需求的患者提供整体和个性化的护理。定义共同目标、分配任务、共享知识、解决冲突以及学习和适应是帮助团队利用集体智慧以更大程度优化患者结果、提高护理质量和效率的组成部分。</p>
<p>由于医疗保健中的代理推理刚刚开始演变，多代理协作模式在设计能够与人类同行并“向他们学习”的人工智能系统中可能变得更加重要，以应对日益多样化和相互关联的医疗保健环境。而且，伦理、职业标准和监管控制将是维护患者和临床医生的安全、隐私和信任所必需的。</p>
<h3 id="挑战与未来方向"><a href="#挑战与未来方向" class="headerlink" title="挑战与未来方向"></a>挑战与未来方向</h3><p>这四种不同的代理推理模式为将人工智能提升到人类智力水平提供了机会。当然，前方还有巨大的挑战，如何确保代理人工智能与人类以安全、伦理和一致的方式互动。这将涉及，例如，开发稳健的价值对齐框架，以及建立问责机制，确保其操作的公平性。</p>
<p>第二个挑战是将四种以代理为中心的推理模式嵌入统一、灵活和可扩展的人工智能架构中，这可能需要在迁移学习、多任务学习和开放式学习方面取得进展，以使人工智能代理能够在一个任务或情境中学习知识，从而帮助解决另一个任务。</p>
<p>代理推理技术在长期内可能会取得显著进展。关于这一研究领域，持续令人感兴趣的是，研究者们尚未进行太多工作。但可以想象，随着时间的推移，我们可能会看到反映并可能工具化、规划和学习的人工智能系统，具备越来越复杂的推理和协作形式。这些进展可能会改变许多领域，从医疗、教育和交通到制造业及其他领域。</p>
<h1 id="使用LLMs的上下文"><a href="#使用LLMs的上下文" class="headerlink" title="使用LLMs的上下文"></a>使用LLMs的上下文</h1><p>理解可预见的LLM应用程序的使用案例认识到“使用上下文”的核心重要性，这是玛格丽特·米切尔创造的一个术语，在创建医疗保健LLMs应用程序时尤为重要。也许米切尔的思考源于一种长期存在的人本工程软件工程实践。由于医疗保健LLM应用程序在可能的用户提示上是如此开放，它们为改善美国医疗保健系统提供了有趣的使用案例，但同时也在预先预测用户交互方面带来了挑战。</p>
<p>与物理对象不同，物理对象可能有有限的预期使用案例，而大多数软件应用程序在交互上是如此开放，以至于我们无法完全预测最终用户将如何使用它们。椅子可以用于有限的用途（坐），但应用程序是开放的。可以开发机器学习模型来预测慢性疾病。可以开发疾病模型来预测特定疾病，例如心脏病或肥胖症。然而，另一个用户或组织可能选择使用特定的机器学习模型来确定提供健康保险覆盖的成本，而另一个用户可能选择将相同的机器学习模型应用于拒绝健康保险覆盖。</p>
<p>软件的灵活性意味着用户可以根据自己的任务（如他们必须的那样）以最适合他们特定需求、工作流程和用户的方式使用应用程序。这个生产力应用程序可能是为任务管理而设计的，但它也可能被用作项目协作工具。软件的开放性——通过这种内在的灵活性得以实现——意味着开发该软件的组织或公司也必须准备好应对人类利用的最终自由。关于LLM驱动的聊天机器人，自然语言交互的灵活性意味着其提示的开放性在上下文和潜在结果方面难以预测或限制。用户可能会提出不在聊天机器人设定范围内的问题（或提出请求）。用户可能会试图操纵其响应，以导致有害或不当的结果。</p>
<p>例如，寻求诊断的人可能会询问一个为一般健康相关讨论而构建的健康聊天机器人，这可能会产生不准确或不安全的假设。即使是最轻松的聊天机器人也有可能与来自客户服务机器人的敌对或辱骂性互动发生冲突，而该机器人因其错误而受到不公正的批评。</p>
<p>减轻这些风险将要求LLM驱动的聊天机器人开发者构建安全层、伦理规范和内容审核工具。示例可能包括使用对抗性测试形式——在这种测试中，系统故意暴露于用户可能输入的最广泛范围，以识别其训练和代表性规范中的漏洞——以确保例如，要求机器人不粗鲁不会导致它发表种族主义言论。无论采用何种策略，开发者必须确保明确设定并传达不可能的边界和期望，以减少用户试图强迫机器人做不可能之事的风险。</p>
<p>其次，如前所述，基于LLMs的聊天机器人应不断监控和优化，以确保它们持续按预期表现。开发者应通过积极寻求用户对其聊天机器人日常体验的反馈来为这一过程奠定基础。开发者还应检查互动中的模式。他们应对输入和反馈进行进一步分析，并相应地更新知识库和响应系统，以优化聊天机器人在用户创造的新条件下的表现。</p>
<p>总而言之，软件应用程序的开放性特征，包括LLM驱动的聊天机器人，可以为预测、规划和处理用户互动提供机会和保障。一方面，LLM驱动的聊天机器人的开放性使创作者能够预见在其框架内可能对用户有益的新用途。另一方面，LLM驱动的聊天机器人的开放性也可能导致意想不到和有害的用途。然而，通过实施保障措施、道德指导以及持续的监控和改进，创作者可以提升用户在使用LLM驱动的聊天机器人时的体验。</p>
<p>无论是审查政治偏见的搜索结果，还是捕捉痴呆症的语言标记，将上下文应用于LLM应用程序的价值显而易见。通过在设计LLM应用程序时考虑上下文，我们可以构建更强大、更具伦理性和对患者更有益的医疗工具。LLM应用程序应做到以下几点：</p>
<ul>
<li>通过提供清晰的界面、针对临床医生的教育材料以及关于人工智能局限性的透明度，鼓励负责任的使用。</li>
<li>针对已识别的误用场景实施保护措施（例如，数据的安全控制、预防措施以禁用针对偏见输出的堆叠）。</li>
<li>让它在人工智能适应性地应用于新环境时自我改进。可以通过监测在世界上使用的人工智能（在可能的范围内）并调整模型以应对出现的任何问题来进行调整。</li>
</ul>
<h1 id="消费者和商业-LLMs"><a href="#消费者和商业-LLMs" class="headerlink" title="消费者和商业 LLMs"></a>消费者和商业 LLMs</h1><p>今天，我们的应用程序基本上分为两类：消费者和商业。它们服务于不同的目的，面向不同的用户。商业应用程序通常是为公司的员工设计的。然而，我们也看到企业为客户创建应用程序，以便他们访问健康计划、了解福利、预约等。消费者应用程序的最大例子可能出现在社交媒体、娱乐、生产力、游戏和商业等领域。</p>
<p>在医疗保健领域，我们看到许多旨在简化个人健康管理的医疗应用程序。比如安排医生上门看诊的应用（例如 ZocDoc）、治疗应用（例如 Talkspace）、远程医疗应用（例如 Doctor on Demand）、女性健康应用如 Maven 等。我们预计随着时间的推移，会有更多基于 LLM 的医疗应用出现，以涵盖在 第 3 章、第 4 章 和 第 5 章 中描述的许多使用案例。</p>
<h2 id="消费者LLMs和生成式人工智能"><a href="#消费者LLMs和生成式人工智能" class="headerlink" title="消费者LLMs和生成式人工智能"></a>消费者LLMs和生成式人工智能</h2><p>本书探讨了一个关键假设：以LLMs为动力的以消费者为中心的应用程序的兴起将显著改变医疗保健。这些应用程序利用LLMs的能力来总结信息和生成内容，预计将：</p>
<ul>
<li>增强医患关系</li>
<li>&#x3D;&#x3D;帮助个人更好地管理他们的慢性疾病和整体健康&#x3D;&#x3D;</li>
<li>最重要的是，干预以延迟或预防慢性疾病的发生</li>
</ul>
<p>通过利用LLMs的能力，这些消费应用有潜力彻底改变个人健康管理和预防护理。</p>
<p>消费型LLMs旨在满足个人用户的需求，提供各种应用和功能，针对个人的需求和兴趣量身定制。这些LLMs包括聊天机器人、虚拟助手和内容生成器等模型。以下是消费型LLMs的一些关键特征：</p>
<ul>
<li>对话助手： 消费者LLMs喜欢虚拟助手（例如，Siri、Google Assistant），这些助手旨在帮助用户设置提醒、回答常识问题、发送消息和播放音乐。它们旨在提供日常便利。</li>
<li>参与和娱乐： 消费者LLMs通常旨在提供互动体验，例如对话式人工智能助手、聊天机器人或创意写作工具，旨在吸引和娱乐用户。</li>
<li>内容生成： 一些消费者LLMs可以生成文本，这对撰写电子邮件、创作内容甚至编程辅助等任务非常有帮助。这些模型专注于提升个人生产力和创造力。</li>
<li>个性化： 消费者LLMs通常优先考虑个性化，通过学习用户互动来提供量身定制的推荐、内容和回应。</li>
<li>个人助理： 这些LLMs可能有助于回答医疗问题、提供建议、撰写电子邮件或文件、安排与临床医生的预约，以及帮助完成各种个人生产力任务。</li>
<li>无障碍性： 这些模型通常配备用户友好的界面，适合广泛的用户群体，并且通常可以在移动设备和个人电脑上使用。</li>
</ul>
<h2 id="商业LLMs与生成式人工智能"><a href="#商业LLMs与生成式人工智能" class="headerlink" title="商业LLMs与生成式人工智能"></a>商业LLMs与生成式人工智能</h2><p>企业和组织设计他们的业务LLMs和生成式人工智能，以便为员工和客户使用，自动化任务、解释数据，并生成文本、图像和视频等内容。商业LLMs旨在用于组织和企业，具有以下特征：</p>
<ul>
<li>数据集成业务： LLMs旨在与您组织的数据源（例如，电子健康记录或其他临床、索赔、药房或资格数据库）无缝集成。利用所有这些健康部门数据，它可以为您提供洞察和报告。LLMs允许分析大量业务数据。例如，LLM可以快速评估支付方和保险公司使用的复杂且不断变化的事先授权标准。</li>
<li>特定于某些行业的商业LLMs： 为了惠及某个行业，例如医疗保健，行业特定的LLMs可以帮助完成从诊断疾病到处理索赔或做出临床决策等任务。</li>
<li>合作： 这些LLMs通常配备有共享团队空间、文档协作&#x2F;共享和工作流程自动化等功能，以提高组织的生产力。</li>
<li>知识管理： 商业LLMs可以通过建立知识库、总结数据和提供上下文建议来帮助组织收集和分享知识。</li>
<li>客户服务和支持： 从商品交易到购买音乐会门票，LLMs 可以为对话式人工智能助手和聊天机器人提供动力，以提供客户支持和回答查询。</li>
<li>服务保证： 企业级LLMs包括服务水平协议和专门的客户服务，使其在业务运营中可靠。</li>
</ul>
<p>总而言之，消费者工具和商业工具之间的关键区别在于：消费者工具主要针对个性化便利和个人生产力，而商业工具则是为特定行业的使用案例而构建的，具有定制的数据集成和企业级的运营支持。</p>
<h2 id="弥合鸿沟"><a href="#弥合鸿沟" class="headerlink" title="弥合鸿沟"></a>弥合鸿沟</h2><p>这种消费者与商业 LLMs &#x2F; 生成式人工智能之间的区别实际上是一个重要的区别，因为它影响使用和受众。区分商业和消费者 LLMs 是很重要的，原因有几个：</p>
<ul>
<li> 目的和目标</li>
<li> 数据训练</li>
<li> 监管环境</li>
<li> 伦理与偏见</li>
</ul>
<h3 id="目的和目标"><a href="#目的和目标" class="headerlink" title="目的和目标"></a>目的和目标</h3><p>商业LLMs旨在解决特定的商业问题或改善商业流程。这些包括自动化健康计划成员与客户服务员工之间的互动，以及从企业已有的数据中提取洞察。</p>
<p>消费者LLMs旨在个人使用和教育目的。它们提供语言翻译和对话问答等服务。重要的是，它们可以根据个人的偏好和需求进行定制，提供基于用户过去互动、所述兴趣或特定要求的个性化响应。</p>
<h3 id="数据训练"><a href="#数据训练" class="headerlink" title="数据训练"></a>数据训练</h3><p>商业LLMs是在特定领域的数据集上进行训练的。通过这种方式，我们可以“调整”LLM以适应我们的商业领域，使其不仅直接处理内容，还能了解商业背景和术语。</p>
<p>消费者LLMs在从各种公共网站提取的大型通用语料库（文本和代码的集合）上进行训练。这些提供了通用的曝光，但存在偏见的风险，并且缺乏专业知识和&#x2F;或领域专长。使用 AI 框架 RAG，数据扩展到外部数据源，就像商业LLM一样。</p>
<h3 id="监管环境"><a href="#监管环境" class="headerlink" title="监管环境"></a>监管环境</h3><p>商业LLMs受到特定行业规则（例如，金融行业）或数据监管规则（例如，医疗数据保护）的监管。</p>
<p>消费者LLMs受消费者保护法和关于数据隐私及伦理人工智能实践的法规约束。例如，HIPPA 确实对个人或其指定人使用健康信息的方式施加了限制，以符合个人的访问权。</p>
<h3 id="伦理与偏见"><a href="#伦理与偏见" class="headerlink" title="伦理与偏见"></a>伦理与偏见</h3><p>商业LLMs：谨慎的管理和偏见的缓解是必要的，以避免对潜在客户、员工等的歧视或其他不公平对待。</p>
<p>消费者LLMs：消费者LLMs中的偏见可能导致有害的错误信息、冒犯性内容或社会不平等的延续。确保这些技术的发展是负责任的，并且持续解决意外偏见至关重要。</p>
<p>总之，虽然大型语言模型被企业和消费者使用，但它们不同的、尽管可能相关的目的以及对输入、控制（包括安全）和伦理考虑的不同需求，都应该促使我们根据这些不同的目的和背景，以不同的方式思考它们的发展和使用。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>LLMs 可以开启一个曾经仅限于科幻领域的潜力世界。通过深入探讨这些先进语言模型的潜力，本章探索了一系列未来的承诺和应用（其中两个——面向消费者的医疗瑞士军刀和面向临床医生的医疗向导——由 LLM 驱动）。语言模型（LLMs）——能够以卓越的流利度和灵活性阅读、书写和处理人类语言的机器——开启了这个新时代。LLMs 仍在不断发展，其能力持续提升。LLMs 有望在广泛的健康领域中改变患者护理、研究和医学知识。</p>
<p>但最大的区别可能在于预期的用户和使用案例是什么样的LLM驱动的应用程序。消费者LLM应用程序（如医疗瑞士军刀）专注于最终用户在做出明智的医疗决策时的便利性——从小规模的自我事件管理和自我诊断到广泛的健康促进、自我护理和家庭医疗应用程序。商业LLM应用程序（如医疗向导）将服务于医疗专业人员和组织，这些人员在不断增长的医学文献中进行查找或填充，临床医生做出诊断决策，以及制药研究人员开发药物。对于消费者LLM应用程序，便利性和易用性是吸引用户的关键。对于商业LLM应用程序，数据隐私、HIPAA 和合规性以及行业特定功能等问题则是显而易见的难题。</p>
<p>但随着社会深入LLMs，他们的解决方案和承诺将塑造一个充满新工具的世界，供健康消费者和医疗专业人士使用，并创造一个因更大医疗和医学知识获取而多样化的近未来。</p>
<p>1 C. M. Kornbluth, “小黑包,” 收录于 C. M. Kornbluth 精选集, 编辑 Frederik Pohl (纽约花园城: Nelson Doubleday, 1976), 42–69.</p>
<p>2 马特·马歇尔，“纽约医院高管：多模态 LLM 助手将为患者护理带来‘范式转变’，”VentureBeat，2024 年 3 月 6 日，<a target="_blank" rel="noopener" href="https://venturebeat.com/ai/ny-hospital-exec-multimodal-llm-assistants-will-create-a-paradigm-shift-in-patient-care%E3%80%82">https://venturebeat.com/ai/ny-hospital-exec-multimodal-llm-assistants-will-create-a-paradigm-shift-in-patient-care。</a></p>
<p>3 LLMs 可能看起来能够理解人类语言，但它们实际上是复杂的统计模型。这些模型识别模式、进行语言翻译、预测可能的单词并生成连贯的文本。然而，它们并不真正理解意义，方式与人类不同。请参见“大型语言模型的风险 (LLM)”，IBM 技术，2023 年 4 月 14 日，YouTube 视频，8:25，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=r4kButlDLUc%60&amp;&%60t=278s%E3%80%82">https://www.youtube.com/watch?v=r4kButlDLUc`&amp;&amp;`t=278s。</a></p>
<p>4 “ChatGPT 实验：自回归大型语言模型 (AR-LLMs) 及其作为结构化摘要的推理限制，”GDELT 项目，2023 年 2 月 14 日，<a target="_blank" rel="noopener" href="https://blog.gdeltproject.org/chatgpt-experiments-autoregressive-large-language-models-ar-llms-and-the-limits-of-reasoning-as-structured-summarization%E3%80%82">https://blog.gdeltproject.org/chatgpt-experiments-autoregressive-large-language-models-ar-llms-and-the-limits-of-reasoning-as-structured-summarization。</a></p>
<p>5 潘海丰和高剑锋，“用于生物医学自然语言处理的领域特定语言模型预训练，” 微软研究博客，2020 年 8 月 31 日， <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/blog/domain-specific-language-model-pretraining-for-biomedical-natural-language-processing%E3%80%82">https://www.microsoft.com/en-us/research/blog/domain-specific-language-model-pretraining-for-biomedical-natural-language-processing。</a></p>
<p>6 PubMed，访问日期：2024 年 6 月 20 日，<a target="_blank" rel="noopener" href="https://pubmed.ncbi.nlm.nih.gov./">https://pubmed.ncbi.nlm.nih.gov。</a></p>
<p>7 李进赫等，“BioBERT：一种用于生物医学文本挖掘的预训练生物医学语言表示模型，”生物信息学 36, no. 4 (2020 年 2 月): 1234–1240，<a target="_blank" rel="noopener" href="https://academic.oup.com/bioinformatics/article/36/4/1234/5566506%E3%80%82">https://academic.oup.com/bioinformatics/article/36/4/1234/5566506。</a></p>
<p>8 Iz Beltagy, Kyle Lo 和 Arman Cohan，“SciBERT：一种用于科学文本的预训练语言模型，”arXiv，2019 年 9 月 10 日，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.10676%E3%80%82">https://arxiv.org/abs/1903.10676。</a></p>
<p>9 黄可欣、贾安·阿尔托萨尔和拉杰什·兰加纳特，“ClinicalBERT：建模临床笔记和预测医院再入院”，CHIL ’20 研讨会，2020 年 4 月 2 日至 4 日，安大略省多伦多，<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.05342#:~:text=ClinicalBERT%20is%20an%20application%20of,task%20of%20hospital%20readmission%20prediction%E3%80%82">https://arxiv.org/pdf/1904.05342#:~:text=ClinicalBERT%20is%20an%20application%20of,task%20of%20hospital%20readmission%20prediction。</a></p>
<p>10 阿利斯泰尔·E·W·约翰逊等，“MIMIC-III，一个可自由访问的重症监护数据库，” 科学数据 3, no. 160035 (2016), <a target="_blank" rel="noopener" href="https://www.nature.com/articles/sdata201635%E3%80%82">https://www.nature.com/articles/sdata201635。</a></p>
<p>11 “Med-PaLM，”谷歌研究，访问日期：2024 年 6 月 20 日，<a target="_blank" rel="noopener" href="https://sites.research.google/med-palm%E3%80%82">https://sites.research.google/med-palm。</a></p>
<p>12 Karan Singhal 等，“利用大型语言模型实现专家级医学问答”，arXiv，2023 年 5 月 16 日，<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.09617%E3%80%82">https://arxiv.org/pdf/2305.09617。</a></p>
<p>13 阿曼达·简·莫达拉加梅， “医疗保健中使用的顶级可穿戴医疗设备，” Healthnews，2024 年 1 月 16 日，<a target="_blank" rel="noopener" href="https://healthnews.com/family-health/healthy-living/wearable-medical-devices-used-in-healthcare%E3%80%82">https://healthnews.com/family-health/healthy-living/wearable-medical-devices-used-in-healthcare。</a></p>
<p>14 大卫·M·莱文和阿提夫·梅赫罗特拉，“在非医生中对经过验证的病例小插曲进行诊断和分诊评估，互联网搜索前后的比较，” JAMA Network Open 4, no. 3 (2021): e213287, <a target="_blank" rel="noopener" href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2777835%E3%80%82">https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2777835。</a></p>
<p>15 “企业应用中的对话式人工智能未来会怎样？” Koru，2024 年 6 月 11 日，<a target="_blank" rel="noopener" href="https://www.koruux.com/blog/conversational-ai-in-enterprise-apps%E3%80%82">https://www.koruux.com/blog/conversational-ai-in-enterprise-apps。</a></p>
<p>16 玛格丽特·E·克鲁克等，“在全民健康覆盖时代，由于低质量卫生系统导致的死亡：对 137 个国家可避免死亡的系统分析，” 柳叶刀 392, no. 10160 (2018 年 11 月 17 日): 2203–2212, <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6238021%E3%80%82">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6238021。</a></p>
<p>17 “UpToDate：现代医疗的可信证据基础解决方案，”沃尔特斯·克鲁维尔，访问日期：2024 年 6 月 20 日，<a target="_blank" rel="noopener" href="https://www.wolterskluwer.com/en/solutions/uptodate%E3%80%82">https://www.wolterskluwer.com/en/solutions/uptodate。</a></p>
<p>18 迈克尔·莫里森，“进行研究的医院是否为患者提供更好的护理？”马萨诸塞州总医院，新闻稿，2022 年 2 月 28 日，<a target="_blank" rel="noopener" href="https://www.massgeneral.org/news/press-release/do-research-hospitals-provide-better-care-for-patients%E3%80%82">https://www.massgeneral.org/news/press-release/do-research-hospitals-provide-better-care-for-patients。</a></p>
<p>19 凯莉·霍利和西普·贝克，以 AI 为先的医疗：AI 在健康业务和临床管理中的应用 (O’Reilly Media, 2021)，<a target="_blank" rel="noopener" href="https://www.amazon.com/AI-First-Healthcare-Applications-Business-Management/dp/1492063150%E3%80%82">https://www.amazon.com/AI-First-Healthcare-Applications-Business-Management/dp/1492063150。</a></p>
<p>20 “前谷歌首席执行官埃里克·施密特眼中的人工智能未来，” Noema 杂志，2024 年 5 月 21 日，YouTube 视频，20:06，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=DgpYiysQjeI%E3%80%82">https://www.youtube.com/watch?v=DgpYiysQjeI。</a></p>
<p>21 “人工智能代理工作流程的未来，AI Fund 的 Andrew Ng”，红杉资本，2024 年 3 月 26 日，YouTube 视频，13:39，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=sal78ACtGTc%60&amp;&%60t=524s%E3%80%82">https://www.youtube.com/watch?v=sal78ACtGTc`&amp;&amp;`t=524s。</a></p>
<p>22 玛格丽特·米切尔，“伦理人工智能并不是谷歌Gemini灾难的罪魁祸首，” 时代，2024 年 2 月 29 日，<a target="_blank" rel="noopener" href="https://time.com/6836153/ethical-ai-google-gemini-debacle%E3%80%82">https://time.com/6836153/ethical-ai-google-gemini-debacle。</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Howard Huang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">494k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">14:59</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">
    <!--由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动-->
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.umd.js" integrity="sha256-+2+qOqR8CKoHh/AsVR9k2qaDBKWjYNC2nozhYmv5j9k=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
