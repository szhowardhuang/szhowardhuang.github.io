<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>如何设计一个数字人 --- 3D模型篇 | 嵌入式老兵博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="下面我就以制作一个数字人卖货视频为例 首先介绍一下将会用到的 AI 工具。  ChatGPT: 在制作数字人的过程中，ChatGPT 可以用于设定数字人的性格、生成演讲文本、回答技术问题等。  MetaHuman Creator: 这是一款由 Epic Games 开发的三维人物建模软件，可以通过对头部、身体等部位个性化的调整，实现高度逼真的数字人三维建模。  微软语音合成助手，由微软公司开发，用">
<meta property="og:type" content="article">
<meta property="og:title" content="如何设计一个数字人 --- 3D模型篇">
<meta property="og:url" content="https://szhowardhuang.github.io/2024/02/22/digital-human/index.html">
<meta property="og:site_name" content="嵌入式老兵博客">
<meta property="og:description" content="下面我就以制作一个数字人卖货视频为例 首先介绍一下将会用到的 AI 工具。  ChatGPT: 在制作数字人的过程中，ChatGPT 可以用于设定数字人的性格、生成演讲文本、回答技术问题等。  MetaHuman Creator: 这是一款由 Epic Games 开发的三维人物建模软件，可以通过对头部、身体等部位个性化的调整，实现高度逼真的数字人三维建模。  微软语音合成助手，由微软公司开发，用">
<meta property="og:locale">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/003.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/004.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/005.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/006.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/007.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/008.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/010.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/011.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/012.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/013.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/017.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/018.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/015.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/016.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/014.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/019.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/020.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_signup_1.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_signup_2.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_subscription_1.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_subscription_2.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_subscription_3.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_subscription_4.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_resource_1.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_resource_2.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_resource_3.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_resource_4.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/009.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_tts_open_2.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_tts_open_3.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_tts_open_4.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_tts_secret_1.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/azure_tts_secret_2.jpg">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/021.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/023.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/024.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/025.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/026.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/027.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/028.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/029.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/030.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/031.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_digitalhuman/022.png">
<meta property="article:published_time" content="2024-02-22T15:00:16.000Z">
<meta property="article:modified_time" content="2024-02-23T14:08:16.000Z">
<meta property="article:author" content="Howard Huang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://szhowardhuang.github.io/asset_digitalhuman/003.png">
  
    <link rel="alternate" href="/atom.xml" title="嵌入式老兵博客" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">嵌入式老兵博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://szhowardhuang.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-digital-human" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/02/22/digital-human/" class="article-date">
  <time class="dt-published" datetime="2024-02-22T15:00:16.000Z" itemprop="datePublished">2024-02-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      如何设计一个数字人 --- 3D模型篇
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>下面我就以制作一个数字人卖货视频为例</p>
<p>首先介绍一下将会用到的 AI 工具。</p>
<ol>
<li><p>ChatGPT: 在制作数字人的过程中，ChatGPT 可以用于设定数字人的性格、生成演讲文本、回答技术问题等。</p>
</li>
<li><p>MetaHuman Creator: 这是一款由 Epic Games 开发的三维人物建模软件，可以通过对头部、身体等部位个性化的调整，实现高度逼真的数字人三维建模。</p>
</li>
<li><p>微软语音合成助手，由微软公司开发，用于语音识别与合成，可以将 ChatGPT 生成的文本内容转化为数字人所需要的自然语音输出。</p>
</li>
<li><p>Audio2Face: 由英伟达公司开发的一款表情驱动技术软件，可以将音频的语调、音量等信息转化为数字人的面部表情，从而使数字人的表现更加生动真实</p>
</li>
<li><p>UE5: Epic Games 开发的一款高级游戏引擎，可以提供实时渲染、动态光照、体积雾等功能，可用于打造更加真实的数字人场景。</p>
</li>
</ol>
<p>下面是制作一个数字人卖货视频的大概流程:</p>
<p>AI人物设定和内容生成 一 3D建模 一 AI语音生成 一 AI表情驱动 一 AI场景搭建</p>
<p>接下来让我为你具体介绍每一部分的流程。</p>
<h3 id="AI人物设定和内容生成"><a href="#AI人物设定和内容生成" class="headerlink" title="AI人物设定和内容生成"></a>AI人物设定和内容生成</h3><p>人物设定是制作数字人的第一步，这里我们可以使用 ChatGPT 来进行人物设定，为数字人定制其个性化特征和语言风格等。</p>
<p><img src="/../asset_digitalhuman/003.png"></p>
<p>生成售卖文案</p>
<p><img src="/../asset_digitalhuman/004.png"></p>
<h3 id="3D建模"><a href="#3D建模" class="headerlink" title="3D建模"></a>3D建模</h3><p>登录 MetaHuman Creator 进行 3D 建模<br>进入 MetaHuman Creator <a target="_blank" rel="noopener" href="https://metahuman.unrealengine.com/mhc">https://metahuman.unrealengine.com/mhc</a> 在预设数字人中选择一个人物模型，结合chatgpt的描述进行个性化调整，如头发、服饰、发型等。</p>
<p><img src="/../asset_digitalhuman/005.png"></p>
<p>调整后如下图：</p>
<p><img src="/../asset_digitalhuman/006.png"><br>此模型会存在云端，后续从UE5导入此模型。</p>
<h3 id="AI语音生成"><a href="#AI语音生成" class="headerlink" title="AI语音生成"></a>AI语音生成</h3><p>使用语音合成助手，将 ChatGPT 生成的文本内容转化为数字人所需要的自然语音输出。<br>这里用小白兔AI工具包里面的微软语音合成把文本转成语音，语音文件会自动下载到本地。</p>
<p><img src="/../asset_digitalhuman/007.png"></p>
<p>微软语音合成需要用到Microsoft Azure API，需要注册Azure账号，并申请语音合成服务。</p>
<p><img src="/../asset_digitalhuman/008.png"><br>把密钥和区域填到小白兔AI里面</p>
<p>注：Microsoft Azure 是微软的公用云端服务平台，首先得有个 Microsoft 账号，然后再基于这个 Microsoft 账号开通 Microsoft Azure 帐户。<br>Microsoft Azure收费模式</p>
<table>
<thead>
<tr>
<th>服务</th>
<th>免费额度</th>
<th>超出免费额度</th>
<th>并发请求数</th>
</tr>
</thead>
<tbody><tr>
<td>文本转语音</td>
<td>每月50万字符</td>
<td>16美元&#x2F;100万字符</td>
<td>-</td>
</tr>
</tbody></table>
<p>Microsoft Azure支持通过国内的 Visa 卡申请。</p>
<p>后面讲一下如何开通 Azure 帐户</p>
<h3 id="AI表情驱动"><a href="#AI表情驱动" class="headerlink" title="AI表情驱动"></a>AI表情驱动</h3><p>Audio2Face是由英伟达公司开发的一款表情驱动技术软件，可以将音频的语调、音量等信息转化为数字人的面部表情，从而使数字人的表现更加生动真实。<br>我们将微软语音助手生成的语音转成WAV格式，并导入到Audio2Face中，进行表情驱动。</p>
<p>去nvidia官网下载Audio2Face标准版 <a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/omniverse/apps/audio2face/">https://www.nvidia.com/en-us/omniverse/apps/audio2face/</a></p>
<p>打开audio2face，如下图设置，确认可以说话动嘴。<br><img src="/../asset_digitalhuman/010.png"><br>然后存项目到本地</p>
<h3 id="AI场景搭建"><a href="#AI场景搭建" class="headerlink" title="AI场景搭建"></a>AI场景搭建</h3><p>先安装UE5，下载地址 <a target="_blank" rel="noopener" href="https://www.unrealengine.com/en-US/download/">https://www.unrealengine.com/en-US/download/</a></p>
<p>然后下载MetaHuman示例项目 </p>
<p><img src="/../asset_digitalhuman/011.png"></p>
<p>打开此工程，点击窗口，选择Quixel Bridge</p>
<p><img src="/../asset_digitalhuman/012.png"></p>
<p>出现如下界面，My MetaHuman 的模型就是之前MetaHuman Creator生成的模型，点击 add按钮，会把这个模型导入到UE5的工程里面。 下载模型的时间很长，耐心等。</p>
<p><img src="/../asset_digitalhuman/013.png"><br>然后可以在UE5里面使用你导入的模型，因为我修改的模型和示例工程的模型一致，所以UE5会直接替换掉。</p>
<p>然后设置Omniverse livelink，让UE5和Audio2Face连接起来，让数字人可以和你说话。</p>
<p>首先把Audio2Face的插件拷贝到UE5的Plugins文件夹下，Audio2Face的插件路径一般是 user目录下面的AppData目录下面</p>
<p><img src="/../asset_digitalhuman/017.png"></p>
<p>拷贝到UE5安装目录</p>
<p><img src="/../asset_digitalhuman/018.png"></p>
<p>打开UE5的插件，选择Nvidia</p>
<p><img src="/../asset_digitalhuman/015.png"></p>
<p>使能 NVIDIA Omniverse ACE</p>
<p><img src="/../asset_digitalhuman/016.png"></p>
<p>打开UE5的窗口，选择 虚拟制片 - Live Link，点击「启动 Live Link」</p>
<p><img src="/../asset_digitalhuman/014.png"></p>
<p>添加源 NVIDIA Omniverse Live Link，点击 OK<br><img src="/../asset_digitalhuman/019.png"></p>
<p>点击Audio2face的stage - audio2face - StreamLivelink， 勾选 Activate</p>
<p><img src="/../asset_digitalhuman/020.png"></p>
<p>点击audio2face的wave Play按钮，让数字人开始说话。</p>
<p>之后参考youtube视频，调整audio2face的模型参数，让数字人更加动人。</p>
<p>最后，修改UE5的场景，调整场景的光照、音效、材质，让场景更加生动。</p>
<p>教程结束，祝你玩得开心！</p>
<h2 id="附注"><a href="#附注" class="headerlink" title="附注"></a>附注</h2><h3 id="注册Azure账号"><a href="#注册Azure账号" class="headerlink" title="注册Azure账号"></a>注册Azure账号</h3><p>网页 <a target="_blank" rel="noopener" href="https://signup.azure.com/signup">https://signup.azure.com/signup</a></p>
<p>进入网页之后，先登陆 Microsoft 账号。</p>
<p>填写个人信息<br><img src="/../asset_digitalhuman/azure_signup_1.jpg"></p>
<p>填写卡信息用于身份验证，点击「注册」<br><img src="/../asset_digitalhuman/azure_signup_2.jpg"></p>
<p>创建 Azure 订阅, Azure 订阅主要就是决定如何计费，一般是有「免费使用版」和 「即用即付」两种选择。</p>
<p>如果是刚注册 Azure 确实是可以选择「免费使用版」的，但是只能使用 30 天，30 天之后还是得转为「即用即付」才可以继续使用。</p>
<p>所以我建议直接选「即用即付」订阅，也是享有同等的免费额度。从注册 Azure 开始，Microsoft 翻译可以拥有 12 个月的免费额度，12 个月之后就没有了，想要继续使用需要收费。但是 Microsoft 语音合成目前是每个月都有免费额度，没有 12 个月的限制。（当然，前提是 Microsoft 不改变免费规则）</p>
<p>进入「订阅页面」<a target="_blank" rel="noopener" href="https://portal.azure.com/?quickstart=True#view/Microsoft_Azure_Billing/SubscriptionsBlade">https://portal.azure.com/?quickstart=True#view/Microsoft_Azure_Billing/SubscriptionsBlade</a> ，点击「添加」，点击「即用即付」下方的「选择产品&#x2F;服务」</p>
<p><img src="/../asset_digitalhuman/azure_subscription_1.jpg"></p>
<p>选中「我同意…」、「我愿意…」，点击「下一步」</p>
<p><img src="/../asset_digitalhuman/azure_subscription_2.jpg"></p>
<p>之前注册的时候应该已经填写过卡信息了，这里会默认选中，然后点击「下一步」</p>
<p><img src="/../asset_digitalhuman/azure_subscription_3.jpg"></p>
<p>然后这里选择「没有任何技术支持…」，点击「注册」</p>
<p><img src="/../asset_digitalhuman/azure_subscription_4.jpg"></p>
<p>创建资源组, 进入 「资源组页面」 <a target="_blank" rel="noopener" href="https://portal.azure.com/?quickstart=True#view/HubsExtension/BrowseResourceGroups">https://portal.azure.com/?quickstart=True#view/HubsExtension/BrowseResourceGroups</a> ，点击「创建」</p>
<p><img src="/../asset_digitalhuman/azure_resource_1.jpg"></p>
<ul>
<li>订阅选刚才创建好的订阅，默认应该就一个</li>
<li>资源组可以直接命名为 Bob</li>
<li>区域可以选离自己地理位置近的，例如在中国就选 East Aisa 就行</li>
<li>然后点击「查看+创建」<br><img src="/../asset_digitalhuman/azure_resource_2.jpg"></li>
</ul>
<p>点击「创建」<br><img src="/../asset_digitalhuman/azure_resource_3.jpg"></p>
<p>如下所示即为创建成功<br><img src="/../asset_digitalhuman/azure_resource_4.jpg"></p>
<p>创建语音服务资源, 进入「Azure AI services | 语音服务 」页面 <a target="_blank" rel="noopener" href="https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/SpeechServices">https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/SpeechServices</a> ，点击「创建」<br><img src="/../asset_digitalhuman/009.png"></p>
<ul>
<li>订阅选刚才创建好的订阅</li>
<li>资源组选刚才创建好的资源组</li>
<li>区域可以选离自己地理位置近的，选跟前面创建资源组一样的就行，例如在中国就选 East Aisa 就行</li>
<li>名称这一栏随便取名，但是不能重名，所以输入和我一样的应该会报错，随便输入不一样的就行，由数字、字母和横线组成即可</li>
<li>定价层选中「Free F0」</li>
<li>然后点击「审阅并创建」<br><img src="/../asset_digitalhuman/azure_tts_open_2.jpg"></li>
</ul>
<p>点击创建<br><img src="/../asset_digitalhuman/azure_tts_open_3.jpg"></p>
<p>如下所示即为创建成功<br><img src="/../asset_digitalhuman/azure_tts_open_4.jpg"></p>
<p>获取秘钥, 进入「认知服务 | 语音服务 」页面 <a target="_blank" rel="noopener" href="https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/SpeechServices">https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/SpeechServices</a> ，应该能看到你刚才创建语音服务资源，点击进入详情<br><img src="/../asset_digitalhuman/azure_tts_secret_1.jpg"></p>
<p>选中「密钥和终结点」，如下图所示即为需要的秘钥<br><img src="/../asset_digitalhuman/azure_tts_secret_2.jpg"></p>
<p>填写秘钥<br>在 小白兔AI 的 设置 &gt; 微软付费订阅 中，将刚才获取到的秘钥填写到对应位置即可。</p>
<p>微软视素的文档可以看看， <a target="_blank" rel="noopener" href="https://learn.microsoft.com/zh-cn/azure/ai-services/speech-service/how-to-speech-synthesis-viseme">https://learn.microsoft.com/zh-cn/azure/ai-services/speech-service/how-to-speech-synthesis-viseme</a></p>
<h3 id="FFMPEG"><a href="#FFMPEG" class="headerlink" title="FFMPEG"></a>FFMPEG</h3><h4 id="使用FFmpeg将MP3文件转换成WAVE格式，你可以使用以下命令："><a href="#使用FFmpeg将MP3文件转换成WAVE格式，你可以使用以下命令：" class="headerlink" title="使用FFmpeg将MP3文件转换成WAVE格式，你可以使用以下命令："></a>使用FFmpeg将MP3文件转换成WAVE格式，你可以使用以下命令：</h4><pre><code>ffmpeg -i input.mp3 -ar 16000 output.wav
</code></pre>
<p>-i input.mp3 指定输入文件，其中 input.mp3 是你的源MP3文件的名称。</p>
<p>-ar 16000 指定了输出文件的采样率为16000 Hz。</p>
<h4 id="录屏视频截取，使用FFmpeg截取视频文件的一部分，你可以通过指定开始时间（-ss-参数）和持续时间（-t-参数）或结束时间（-to-参数）来完成。以下是一些常见的使用场景和相应的命令示例："><a href="#录屏视频截取，使用FFmpeg截取视频文件的一部分，你可以通过指定开始时间（-ss-参数）和持续时间（-t-参数）或结束时间（-to-参数）来完成。以下是一些常见的使用场景和相应的命令示例：" class="headerlink" title="录屏视频截取，使用FFmpeg截取视频文件的一部分，你可以通过指定开始时间（-ss 参数）和持续时间（-t 参数）或结束时间（-to 参数）来完成。以下是一些常见的使用场景和相应的命令示例："></a>录屏视频截取，使用FFmpeg截取视频文件的一部分，你可以通过指定开始时间（-ss 参数）和持续时间（-t 参数）或结束时间（-to 参数）来完成。以下是一些常见的使用场景和相应的命令示例：</h4><h5 id="使用-ss-和-t-参数"><a href="#使用-ss-和-t-参数" class="headerlink" title="使用 -ss 和 -t 参数"></a>使用 -ss 和 -t 参数</h5><p>在这个例子中，-ss 指定了开始截取的时间点，-t 指定了从开始点后要截取的持续时间。</p>
<pre><code>ffmpeg -i input.mp4 -ss 00:00:10 -t 00:00:20 -c copy output.mp4
</code></pre>
<p>input.mp4 是源视频文件。<br>-ss 00:00:10 表示从视频的第10秒开始截取。<br>-t 00:00:20 表示截取从开始点算起20秒的视频内容。<br>-c copy 表示使用“复制”模式，这样可以避免重新编码视频和音频流，加快处理速度并保持原有质量。<br>output.mp4 是输出的视频文件。</p>
<h5 id="使用-ss-和-to-参数"><a href="#使用-ss-和-to-参数" class="headerlink" title="使用 -ss 和 -to 参数"></a>使用 -ss 和 -to 参数</h5><p>与上面的例子不同，-to 参数指定的是截取的结束时间点，而不是持续时间。</p>
<pre><code>ffmpeg -i input.mp4 -ss 00:00:10 -to 00:00:30 -c copy output.mp4
</code></pre>
<p>-to 00:00:30 表示截取到视频的第30秒为止。</p>
<h4 id="音画不同步，画面延迟大约1秒，用FFMPEG调整，相对视频对音频时间戳进行偏移："><a href="#音画不同步，画面延迟大约1秒，用FFMPEG调整，相对视频对音频时间戳进行偏移：" class="headerlink" title="音画不同步，画面延迟大约1秒，用FFMPEG调整，相对视频对音频时间戳进行偏移："></a>音画不同步，画面延迟大约1秒，用FFMPEG调整，相对视频对音频时间戳进行偏移：</h4><p>音频相对于视频移后时间00:00:01.000</p>
<pre><code>ffmpeg -y -itsoffset 00:00:01.000 -i out.mp4 -i out.mp4 -map 0:a -map 1:v -vcodec copy -acodec copy -f mp4 -threads 2 -v warning out.sync.mp4
</code></pre>
<p>-y 可覆盖，如果文件已存在强制替换；</p>
<p>-itsoffset offset 设置以秒为基准的时间偏移，该选项影响所有后面的输入文件。该偏移被加到输入文件的时戳，定义一个正偏移意味着相应的流被延迟了 offset秒。 [-]hh:mm:ss[.xxx]的格式也支持</p>
<p>-i 输入，后面是空格，紧跟着就是输入视频文件</p>
<p>-f fmt 强迫采用格式fmt</p>
<p>-v：调试信息级别（quiet、panic、fatal、error、warning、info、verbose、debug）</p>
<p>-vcodec copy 和 -acodec copy表示所要使用的视频和音频的编码格式，这里指定为copy表示原样拷贝</p>
<p>-map file_number:stream_type[:stream_number]    选择媒体流语法</p>
<p>这有一些特别流符号的说明：</p>
<p>1、-map 0 选择第一个文件的所有流</p>
<p>2、-map i:v 从文件序号i(index)中获取所有视频流， -map i:a 获取所有音频流，-map i:v 获取所有视频流，-map i:s 获取所有字幕流等等。</p>
<p>3、特殊参数-an,-vn,-sn分别排除所有的音频，视频，字幕流。</p>
<h4 id="播放验证"><a href="#播放验证" class="headerlink" title="播放验证"></a>播放验证</h4><pre><code>ffplay out.sync.mp4
</code></pre>
<h3 id="如何定制数字人的人脸"><a href="#如何定制数字人的人脸" class="headerlink" title="如何定制数字人的人脸"></a>如何定制数字人的人脸</h3><p>用polycam扫描人脸</p>
<p>导出GLTF</p>
<p>打开blender，导入GLTF，删除多余部分，选中，按X键删除， 然后merge mesh</p>
<p>导出FBX，path mode选择copy，并点击旁边的按钮；object选择Animate和mesh；Geometry选择face；disable Bake Animation；然后点击export，保存为.fbx文件<br><img src="/../asset_digitalhuman/021.png"></p>
<p>到UE5，新建项目，影视和现场活动 - 空白<br><img src="/../asset_digitalhuman/023.png"></p>
<p>把fbx文件拖到UE5内容窗口，导入.fbx文件</p>
<p><img src="/../asset_digitalhuman/024.png"></p>
<p>导入后，双击material，调整material，添加常量节点</p>
<p><img src="/../asset_digitalhuman/025.png"></p>
<p>调整后，如下图</p>
<p><img src="/../asset_digitalhuman/026.png"></p>
<p>MetaHuman Plugin安装, 在Epic商城安装<br><a target="_blank" rel="noopener" href="https://www.unrealengine.com/marketplace/en-US/product/metahuman-plugin#">https://www.unrealengine.com/marketplace/en-US/product/metahuman-plugin#</a></p>
<p>打开插件菜单，enable metahuman plugin</p>
<p>在内容窗口右键，选择metahuman本体</p>
<p><img src="/../asset_digitalhuman/027.png"></p>
<p>双击这个本体，进入编辑窗口，导入mesh</p>
<p><img src="/../asset_digitalhuman/028.png"></p>
<p>调整人脸的位置， 快捷键 W&#x2F;R&#x2F;E ， 设置viewport的FOV到20</p>
<p><img src="/../asset_digitalhuman/029.png"></p>
<p>打开提升帧，选择自动追踪</p>
<p>点击metahuman本体解算</p>
<p>点击body，选择一个体型</p>
<p>点击Mesh to Metahuman，如下图</p>
<p><img src="/../asset_digitalhuman/030.png"></p>
<p>进入Quilel Bridge，选择metahuman - my metahuman， 选择你新建立的本体，启动MHC</p>
<p><img src="/../asset_digitalhuman/031.png"></p>
<p>进入metahuman后，调整人物各部分</p>
<p><img src="/../asset_digitalhuman/022.png"></p>
<p>结束，后续在UE5项目导入你定制的人脸即可。</p>
<h3 id="参考视频"><a href="#参考视频" class="headerlink" title="参考视频"></a>参考视频</h3><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=HEFIvFnUfpw">Audio2Face to MetaHuman | How to Animate MetaHuman using Audio2Face Live Link</a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=2tGPx0Athvk">Importing a Metahuman into Unreal Engine 5 (simplified way) </a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xFk_WU32igA">How to Use Mesh to Metahuman (From Scan to Metahuman)</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://szhowardhuang.github.io/2024/02/22/digital-human/" data-id="clto3ikk70005fgmjfchx76no" data-title="如何设计一个数字人 --- 3D模型篇" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/02/27/digital-human-2/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Neuer</strong>
      <div class="article-nav-title">
        
          如何设计一个数字人续篇 --- Video Retalking 模型篇
        
      </div>
    </a>
  
  
    <a href="/2024/02/01/lagent_sft/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Älter</strong>
      <div class="article-nav-title">微调Lagent的实践</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/03/12/ollama/">ollama使用方法</a>
          </li>
        
          <li>
            <a href="/2024/03/11/make-million-llm/">使用Python从头开始构建一个百万参数的LLM</a>
          </li>
        
          <li>
            <a href="/2024/03/08/springboot-music/">用VSCode实践一个Spring Boot项目</a>
          </li>
        
          <li>
            <a href="/2024/03/07/mysql5_7_21-cmd-install/">命令行安装MySQL 5.7.21</a>
          </li>
        
          <li>
            <a href="/2024/03/03/generativeDiffusion/">生成扩散模型综述</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Howard Huang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>