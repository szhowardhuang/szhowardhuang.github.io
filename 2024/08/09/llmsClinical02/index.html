<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"szhowardhuang.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="随着大型语言模型（LLMs）和生成式人工智能工具逐渐应用于医疗保健领域，它们带来了复杂且不透明的元素——内在的“黑箱”特性使得这些系统的内部运作显得模糊。这引发了临床医生和医疗领导者在考虑使用LLMs时的自然疑问。这些人工智能系统究竟是如何发展其临床能力的？在它们的训练过程中，幕后发生了什么？黑箱特性是否使得LLMs的建议和思维过程对于严肃的医学或医疗使用过于晦涩？ 第二章 揭开了面纱，检查人工智">
<meta property="og:type" content="article">
<meta property="og:title" content="第二章 窥视人工智能黑箱">
<meta property="og:url" content="https://szhowardhuang.github.io/2024/08/09/llmsClinical02/index.html">
<meta property="og:site_name" content="嵌入式老兵博客">
<meta property="og:description" content="随着大型语言模型（LLMs）和生成式人工智能工具逐渐应用于医疗保健领域，它们带来了复杂且不透明的元素——内在的“黑箱”特性使得这些系统的内部运作显得模糊。这引发了临床医生和医疗领导者在考虑使用LLMs时的自然疑问。这些人工智能系统究竟是如何发展其临床能力的？在它们的训练过程中，幕后发生了什么？黑箱特性是否使得LLMs的建议和思维过程对于严肃的医学或医疗使用过于晦涩？ 第二章 揭开了面纱，检查人工智">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/01.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/02.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/03.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/04.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/05.png">
<meta property="og:image" content="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098160913/files/assets/llmg_0206.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/07.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/08.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/09.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/10.png">
<meta property="og:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/11.png">
<meta property="article:published_time" content="2024-08-09T03:32:19.000Z">
<meta property="article:modified_time" content="2024-08-21T06:04:19.000Z">
<meta property="article:author" content="Howard Huang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://szhowardhuang.github.io/asset_02InsideAIBlackBox/01.png">


<link rel="canonical" href="https://szhowardhuang.github.io/2024/08/09/llmsClinical02/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://szhowardhuang.github.io/2024/08/09/llmsClinical02/","path":"2024/08/09/llmsClinical02/","title":"第二章 窥视人工智能黑箱"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>第二章 窥视人工智能黑箱 | 嵌入式老兵博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">嵌入式老兵博客</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#LLMs-%E5%92%8C%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="nav-number">1.</span> <span class="nav-text">LLMs 和生成式人工智能</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="nav-number">2.</span> <span class="nav-text">人工智能与机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A3%80%E6%B5%8B%E8%82%BF%E7%98%A4"><span class="nav-number">2.1.</span> <span class="nav-text">使用深度学习检测肿瘤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="nav-number">2.2.</span> <span class="nav-text">自然语言处理与计算机视觉</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LLM%E7%9A%84%E8%A7%A3%E5%89%96"><span class="nav-number">3.</span> <span class="nav-text">LLM的解剖</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transformer"><span class="nav-number">3.1.</span> <span class="nav-text">Transformer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Token"><span class="nav-number">3.2.</span> <span class="nav-text">Token</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="nav-number">3.3.</span> <span class="nav-text">注意力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E6%95%B0"><span class="nav-number">3.4.</span> <span class="nav-text">参数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LLM-%E5%92%8C%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%BD%9C%E5%8A%9B"><span class="nav-number">4.</span> <span class="nav-text">LLM 和生成式人工智能的潜力</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9E%84%E5%BB%BALLMs%E7%9A%84%E8%89%BA%E6%9C%AF"><span class="nav-number">5.</span> <span class="nav-text">构建LLMs的艺术</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90"><span class="nav-number">5.1.</span> <span class="nav-text">检索增强生成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5%E5%8C%96"><span class="nav-number">5.2.</span> <span class="nav-text">概念化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%80%89%E6%8B%A9%E4%B8%8E%E7%AD%96%E5%88%92"><span class="nav-number">5.3.</span> <span class="nav-text">数据选择与策划</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E4%B8%8E%E8%AE%BE%E8%AE%A1"><span class="nav-number">5.4.</span> <span class="nav-text">模型架构与设计</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B"><span class="nav-number">5.5.</span> <span class="nav-text">提示词工程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B2%BE%E7%82%BC%E4%B8%8E%E5%8F%8D%E9%A6%88"><span class="nav-number">5.6.</span> <span class="nav-text">精炼与反馈</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8E%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E9%9B%86%E6%88%90"><span class="nav-number">5.7.</span> <span class="nav-text">与应用程序集成</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">6.</span> <span class="nav-text">摘要</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Howard Huang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">54</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/09/llmsClinical02/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="第二章 窥视人工智能黑箱 | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第二章 窥视人工智能黑箱
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-09 11:32:19" itemprop="dateCreated datePublished" datetime="2024-08-09T11:32:19+08:00">2024-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:04:19" itemprop="dateModified" datetime="2024-08-21T14:04:19+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>19k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>34 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>随着大型语言模型（LLMs）和生成式人工智能工具逐渐应用于医疗保健领域，它们带来了复杂且不透明的元素——内在的“黑箱”特性使得这些系统的内部运作显得模糊。这引发了临床医生和医疗领导者在考虑使用LLMs时的自然疑问。这些人工智能系统究竟是如何发展其临床能力的？在它们的训练过程中，幕后发生了什么？黑箱特性是否使得LLMs的建议和思维过程对于严肃的医学或医疗使用过于晦涩？</p>
<p>第二章 揭开了面纱，检查人工智能系统内部的内容。我们讨论Transformer、自注意力机制、神经网络和其他技术元素如何完成重任，以吸收医疗知识并发展推理能力。虽然对每个组件背后的数学进行全面说明超出了读者的需求，但我们提供了对 LLMs 工作原理的易懂解释。窥视黑箱消除了“魔法”的概念，同时使负责任的人工智能采用变得触手可及，即使在持续的不透明中。</p>
<h1 id="LLMs-和生成式人工智能"><a href="#LLMs-和生成式人工智能" class="headerlink" title="LLMs 和生成式人工智能"></a>LLMs 和生成式人工智能</h1><p>LLMs 使用深度学习，这是机器学习的一个子集，利用算法层来处理数据并模仿人类思维过程。深度学习和神经网络这两个术语可以互换使用，因为所有深度学习系统都包含神经网络。神经网络的概念代表了人工智能发展的一个突破。它的灵感来源于人脑中生物神经元的工作方式。<br>在深度学习中，信息通过每一层传递，前一层的输出为下一层提供输入。网络中的第一层称为输入层，而最后一层称为输出层。每一层通常是一个简单的算法。iPhone 或 Android 手机用于面部识别的底层技术，或者 Google 搜索用于视觉识别和搜索对象的技术，就是深度学习。理解人类语言的工具，如 Alexa 或 Siri，需要神经网络。让我们简要回顾一下人工智能的历史，看看我们是如何走到今天的，涉及到生成式人工智能。</p>
<p>在 1970 年代，第一次人工智能寒冬来临，这被解释为对人工智能的资金和兴趣下降，结果是无法兑现的承诺。这种资金不足的影响限制了深度学习和人工智能研究。幸运的是，有一些人在没有资金的情况下继续进行研究。各种过于乐观的人和组织夸大了人工智能的“即时”潜力。</p>
<p>人工智能和深度学习的下一个重要进化步骤发生在 1999 年，当时计算机在处理数据方面变得更快。图形处理单元（GPU）被引入并发现可以用来运行深度学习模型。更快的处理速度以及用GPU 来处理图像，增加了计算速度，在此期间，神经网络变得有用，其使用和价值也随之上升。</p>
<p>到 2011 年，GPU 的速度显著提高，2012 年，Google Brain 发布了一个项目的结果。神经网络可以处理未标记的数据并发现重复模式。深度学习已经是一个研究领域数十年。随着计算能力的提升、大量数据的可用性和算法的改进，它的使用和受欢迎程度迅速增加。</p>
<p>在计算机早期，计算机擅长遵循指令和整理信息。早期的机器学习应用涉及基于数据进行预测。许多疾病预测模型使用机器学习来预测疾病的发生，从而制定干预计划和患者治疗计划。但深度学习，作为机器学习的一个子集，使它们更像海绵，吸收大量信息并用它来创造性地解决问题。一些例子包括识别图片中的不同物体，即使它们模糊或奇怪的角度，识别被泥土覆盖的狗，或在手机应用上实时翻译语言。</p>
<p>但这些学习机器并没有止步于此。现在，认识一下LLMs——这个故事的超级明星。想象他们是班级中的优秀学生，接受了更广泛的图书馆和特殊技术的训练。他们可以写诗和故事，创作新歌曲，或以新颖的方式重新组合元素来设计药物。这就是事情变得令人震惊的地方。我们正处于生成式人工智能的时代。这意味着计算机不仅仅是复制东西；它们还创造东西。</p>
<p>在图 2-1中，我们看到从手工规则到机器学习&#x2F;深度学习再到LLMs的进展。在第一个卡通画面中，一个人手动制定规则来识别吉娃娃。这可能涉及指定诸如大小、毛色、耳形和其他独特特征等标准。这个过程劳动密集，并且需要详细的知识和专业技能来根据预定义的规则识别品种。通常，这些规则通过编程语言中的编码来实现。这个过程涉及创建手工规则，程序员手动编写具体指令以指导系统的行为。</p>
<p><img src="/../asset_02InsideAIBlackBox/01.png">图 2-1  LLMs的出现</p>
<p>我们在第二幅卡通画中看到向机器学习&#x2F;深度学习的过渡。系统不是明确地定义规则，而是通过包含标记的吉娃娃和非吉娃娃图像的数据集进行训练。人工智能使用机器学习从输入图像中提取特征并自动进行预测。使用深度学习时，数据可以是未标记的，我们可以进一步进展，识别出各种图片中的吉娃娃，例如当吉娃娃与物体一起拍照或以不同姿势出现时。</p>
<p>第三个卡通画框介绍了LLMs。在这个画框中，我们不关注识别，而是要求LLM分析大量的书籍、文章和文件，以全面理解吉娃娃。当呈现一张图像时，LLM可以利用其上下文理解提供细致的评估，可能考虑到超出视觉外观的因素，如品种特征、行为和背景。</p>
<h1 id="人工智能与机器学习"><a href="#人工智能与机器学习" class="headerlink" title="人工智能与机器学习"></a>人工智能与机器学习</h1><p>人工智能的核心方面之一是机器学习的使用，这使得计算机能够从数据中学习模式和关系，而无需明确编程。有几位计算机科学家认为，被称为人工智能的解决方案不过是一个机器学习问题的解决。这引发了几个问题，如图 2-2所示，教师正在与他的学生讨论人工智能。3</p>
<p><img src="/../asset_02InsideAIBlackBox/02.png">图 2-2. 什么是人工智能？</p>
<p>人工智能是计算机科学中的一个研究和学习领域。关于如何衡量或概念化人类智能存在相互矛盾的观点，因此精确定义人工智能同样具有挑战性。每当我们看到机器执行以前只有人类才能完成的任务时，我们就将其视为机器智能。通过人工智能，计算机科学家和研究人员试图构建展现与人类相同智能特质的计算机软件——即，AI ≥ 人，如图 2-2所示。</p>
<p>在这个图中，深度学习被视为机器学习的一个子集。机器学习可以是监督学习（SUP），其中数据被标记以训练算法并进行预测。或者机器学习可以是无监督学习（UNSUP），在这种情况下，机器学习模型使用未标记的数据并允许发现模式或洞察。例如，在使用监督机器学习检测糖尿病时，个人会为模型应关注的数据提供标签，比如患者的 A1C，这些数据与血糖水平和其他因素（如生活方式）有关。使用无监督机器学习时，算法将处理未标记的数据集，并发现表示糖尿病可能性的模式。</p>
<p>LLMs 使用多个人工智能、机器学习、深度学习、计算机视觉和自然语言处理（NLP）学科。例如，图 2-2 说明了人工智能作为一个比机器学习更广泛的概念，因为这些学科各自都是一个独立的研究领域，同时也是人工智能这一更大类别中的一个子领域。人工智能的简单定义是，它试图匹配人类主体的能力或智能。</p>
<p>在深入了解LLMs的内部工作之前，让我们先了解一下LLMs所使用的一些基础技术。</p>
<h2 id="使用深度学习检测肿瘤"><a href="#使用深度学习检测肿瘤" class="headerlink" title="使用深度学习检测肿瘤"></a>使用深度学习检测肿瘤</h2><p>深度学习是机器学习的一个子集，它使用神经网络。层是深度学习中功能的最小单位，正是这些单位组合在一起构建神经网络。层以级联的顺序从下方的层获取输入，对其进行处理，然后将输出传递给更高的层。如果你简单地将足够多的这些充满动作的层堆叠在一起，它们能够学习数据的复杂表示，并执行多种任务，如识别图像中的物体、理解语言等。</p>
<p>以下是深度学习中关于层的关键点的概述：</p>
<p> 输入层第一层接收原始数据，如图像、文本或数值。</p>
<p> 隐藏层这些特征提取并学习数据点之间的抽象关系。您可以在一个个隐藏层之上有多个隐藏层——这一堆叠的深度对网络能够学习的内容至关重要。</p>
<p> 输出层这是最后一层，它将根据任务生成模型的预测或输出。该输出可能将图像分类为猫或狗，将文本从一种语言翻译成另一种语言，或生成新的、听起来像人类的文本。</p>
<p>图 2-3 说明了一个简单的样本神经网络，目的是尝试使用计算机检测肿瘤是恶性还是良性。</p>
<p><img src="/../asset_02InsideAIBlackBox/03.png">图 2-3. 使用深度学习检测肿瘤中的癌症</p>
<p>在图 2-3中，专为肿瘤分类设计的深度学习神经网络中的每一层学习表示输入图像的不同抽象层次。在这种情况下，图像可能是癌症肿瘤或非癌症肿瘤。肿瘤的 X 光图像将被数字化并以像素的形式在计算机中表示。第一层将检测每个像素的值。这个神经网络或深度学习模型之前已经经过训练，知道一组像素的哪些特征表明高概率的癌症。因此，像素将从左到右流经这个网络，每个圆圈代表一个人工神经元，它简单地返回 1 或 0，其中 1 表示可能癌症的信号。</p>
<p>随着像素移动到第二层，模型开始对输入图像中的特征进行分类：</p>
<ul>
<li>肿瘤的边缘和轮廓</li>
<li>肿瘤内的基本形状和模式</li>
<li>强度梯度和纹理变化</li>
<li>颜色信息（如果输入是彩色图像）</li>
</ul>
<p>此时，神经网络成功地学习了一系列低级特征，如边缘和斑点，这些特征被连接成肿瘤图像的各个组成部分，就像人类视觉系统的早期阶段所感知的那样。</p>
<p>当神经网络到达第 3 层时，它将第 2 层的低级特征组合成一些高级特征。第 3 层可能会捕捉到以下内容：</p>
<ul>
<li>特定的边缘和形状的模式和排列</li>
<li>局部化的纹理模式指示出组织的类型</li>
<li>颜色组合或强度变化</li>
<li>肿瘤亚区域或成分的初步表示</li>
</ul>
<p>在第三层，模式实际上开始看起来像是更易识别且对观察肿瘤图像的人类专家更具诊断相关性的模式。</p>
<p>在第 4 层，神经网络将早期层的特征集合整合成肿瘤的高级表示</p>
<ul>
<li>肿瘤的独特形态特征</li>
<li>肿瘤亚区域的空间关系和组织</li>
<li>与特定肿瘤类型相关的复杂纹理模式</li>
<li>学习到的诊断显著特征的表示</li>
</ul>
<p>到此时，神经网络很可能发现与分类任务直接相关的语义上有意义的高级概念：恶性肿瘤或非癌性。经过训练的网络提取的高级特征与放射科医生或病理学家手动识别的内容更为接近。</p>
<p>最后，在第 5 层，神经网络将学习到的特征（第 4 层的高级特征）转化为最终决策，以根据样本确定肿瘤的类别。在这个例子中，输出决策是良性肿瘤。网络已经学会将“学习到的特征”与已知的肿瘤类别关联起来，利用它在学习过程中看到的模式和特征。</p>
<p>通过这种表述，并理解深度神经网络中特征学习的层次性质，临床医生可以开始理解这些模型如何（以及为什么）能够从医学图像中学习局部相关的模式和特征，并将这些特征在层次上进行转换，以实现自动决策。再次强调，这个例子仅用于为读者提供说明。</p>
<h2 id="自然语言处理与计算机视觉"><a href="#自然语言处理与计算机视觉" class="headerlink" title="自然语言处理与计算机视觉"></a>自然语言处理与计算机视觉</h2><p>自然语言处理（NLP）是一个与LLM的发展和应用密切相关的领域。两者都涉及计算机与人类语言之间的某种互动。NLP 算法被应用于预处理和结构化用于训练LLMs的文本数据，就像临床医生在阅读病历时所做的那样——他们只是做得非常快。此外，NLP 提供了理解和评估LLMs语言能力的词汇：无论他们是否理解临床医生使用的专业术语，他们解读临床医生笔记的能力，还是他们向患者生成清晰易懂解释的能力。</p>
<p>可以说，LLMs 还可以通过从互补的数据模态中学习来衍生出一种视觉模态，这个领域被称为多模态学习。在这种情况下，计算机视觉作为一种数据分析形式发挥作用，旨在揭示视觉数据中的模式。就像放射科医生使用医学图像（如 X 光片和 CT 扫描）来识别异常和诊断不同的病症一样，多模态 LLMs 可以学习结合文本来解释图像，以提供更细致、上下文相关的响应。例如，一个针对医学文献和放射学图像进行微调的 LLM 可能能够帮助生成报告或回答有关临床相关影像发现的问题。</p>
<p>也许，在医疗保健领域，LLMs可以通过临床决策支持（根据患者数据提供基于证据的建议和风险评估）、患者沟通（生成个性化教育材料、回答基本问题或提供虚拟支持）以及医学研究（文献综述、假设生成和数据分析）来支持临床医生。</p>
<p>但他们也不是来抢你的工作的——他们做不到。大多数患者以复杂的表现和症状来找临床医生，这可能需要进一步的调查或跟进，甚至只是需要一个人聊天。LLMs 可以成为临床医生工具箱的一部分，既帮助决策，又协助进行有意义和个性化的患者护理的复杂工作。例如，它们可以成为 21 世纪的听诊器。</p>
<p>我们需要考虑在临床实践中开始使用LLMs时出现的伦理影响，包括数据隐私、算法公平性以及这些工具对医患关系的影响等方面。这将需要临床医生、人工智能研究人员和伦理学家之间的合作，以实现负责任和有益的医疗部署。</p>
<h1 id="LLM的解剖"><a href="#LLM的解剖" class="headerlink" title="LLM的解剖"></a>LLM的解剖</h1><p>为了提醒您，LLM的最重要组成部分是神经网络。回想一下之前提到的，您的大脑是一个由生物神经元组成的网络，可能有 1000 亿个！生物神经元是大脑中的一种细胞，它接收来自其他神经元的输入，对输入进行一些计算，然后将输出发送给一些下游神经元。这个庞大的生物神经网络使您的大脑能够处理信息、理解世界、识别模式并表现出智能行为。</p>
<p>人工神经网络是我们在计算机上复制这一过程的最佳努力。我们创建相对简单的数学模型，涉及大量模拟神经元及其之间的连接。我们可以通过输入大量展示我们希望其检测的模式（例如，恶性肿瘤）的数据来训练它识别图像、声音和语言等事物。而有趣的是：这些网络通过学习调整神经元之间的连接强度，从数据中自行推导出模式。网络中的层数越多，输入的数据越多，它的表现就越好。</p>
<p>例如，通过在训练期间向图像识别网络展示数千万张猫和狗的照片，它学习到某些类型的毛发纹理、耳朵形状和鼻子形状提供了线索，表明某物可能是或不是猫或狗。当你在训练后向它展示几乎任何新照片时，它会立刻意识到这很可能是一只猫或一只狗。最新的神经网络开始通过越来越令人印象深刻的算法架构进行探索，包括从文本生成图像、语言翻译、从医学扫描中识别疾病，以及从创意描述中创建应用程序。</p>
<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>现在我们知道深度学习的机制，让我们深入剖析LLM的内部工作，看看它实际上由什么组成，同时要记住，神经网络的使用只是其中的一小部分。LLM并不是一个简单的算法；它是一个模型，包含算法和架构，例如Transformer。Transformer是自然语言处理（NLP）任务的关键架构组件，而这些任务是LLMs的一个重要焦点。NLP 技术使LLMs能够执行许多特定于语言的任务，如文本生成、摘要和问答。</p>
<p>Transformer是一组使用编码器和解码器结构的神经网络。编码器将输入文本转换为数值表示，以便计算机能够捕捉其含义和上下文，例如将捕捉患者健康状态的临床记录作为输入。解码器接收输入文本的编码表示并生成输出文本。在临床记录的例子中，解码器可以生成患者主要医疗问题的摘要。</p>
<p>但这里有个聪明的地方：Transformer不仅仅关注每个单词，而是关注这个单词与周围每个单词的关系。就像一小队朋友在帮助你阅读故事，他们每个人都在看不同的部分并向你反馈。通过这种Transformer架构，LLM可以读取医疗数据，如临床笔记、电子健康记录数据和病史，并执行各种任务，如摘要或问答。</p>
<p>Transformer架构需要一种新的架构发明，以实现我们今天在LLMs中看到的功能或某些人所称的魔力，这一发明发生在 2017 年。注意力是一种机制，允许LLM在处理和生成文本时专注于输入的特定部分。注意力机制使LLM能够在生成关键医疗或健康问题的摘要时，专注于患者电子健康记录中最相关的部分。</p>
<h2 id="Token"><a href="#Token" class="headerlink" title="Token"></a>Token</h2><p>Token是LLMs和Transformer处理的基本工作单位——可以是输入或输出。单词和字符可以作为LLM的Token。分词是将文本分解为更小单位（称为Token）的过程。这个过程对Transformer至关重要，因为它将文本分解为可管理的部分，使LLM能够理解和分析。</p>
<p>对于文本数据，LLM 首先要做的是通过将输入拆分成更小的连续单元（或Token）来进行Token化。考虑以下来自医疗领域的示例句子：患者被诊断为高血压，并被给予处方药“利辛普利”。</p>
<p>使用基于词的分词方法，这 10 个Token（用引号表示）为：“患者被诊断为高血压，并被开处方利辛普利。”</p>
<p>[“The”, “patient”, “was”, “diagnosed”, “with”, “hypertension”, “and”, “prescribed”, “lisinopril”, “.”]</p>
<p>输入的Token首先被嵌入到向量中，这些向量编码了它们的语义和句法信息，然后通过包含自注意力机制的变换层，这些机制学习Token之间的关系并生成丰富的上下文表示。</p>
<p>例如，在临床环境中，Transformer可以确定“高血压”和“利辛普利”这两个词是密切相关的，因为利辛普利是用于治疗高血压的药物名称。这一知识对于命名实体识别（识别文本中的医疗条件和治疗）或关系提取（识别医疗实体之间的关系）任务是非常有用的。</p>
<p>LLM在训练中学到的是如何根据前面的Token预测序列中的下一个Token。为了生成文本，LLM的概率分布用于根据紧接着的Token来采样或选择下一个Token。这个过程会迭代重复，直到满足某个停止规则，过程才会完成。</p>
<p>在临床应用中，例如，一个LLM可以为医生生成潦草的笔记，或总结患者的病情，例如对输入Token序列“患者是一名 65 岁的男性，有以下病史”的响应：患者是一名 65 岁的男性，有 2 型糖尿病、高血压和高脂血症的病史，主诉疲劳和多尿。</p>
<p>在这样的上下文和Token关系下，LLMs可以生成准确且易于阅读的文本——即使输入是用于临床文档、患者教育或医学研究摘要的长篇病历。</p>
<h2 id="注意力"><a href="#注意力" class="headerlink" title="注意力"></a>注意力</h2><p>NLP 和LLMs的秘密武器是谷歌在 2017 年的一项创新。想象一下给每个词一个聚光灯。例如，Transformer强调相互关联的医学细节——比如主要诊断和关键实验室结果——帮助它过滤噪音，专注于对该患者最相关的信息。无需顺序。与按顺序阅读病历不同，Transformer可以跳跃和跳过，考虑某个数据点在某人病历早期如何影响后期的另一个数据点，反之亦然。历史上具有挑战性的案例可以按照类似专家之间发送电子邮件的顺序进行研究，沿途获取上下文。这类似于拥有多个专业水平如何帮助医生拼凑奇怪的医学诊断。但Transformer的工作得益于数十层这种理解相互叠加：每一层都更好地将 X 光、MRI、症状和健康历史之间的关系联系起来，直到输出变得极具洞察力。</p>
<p>LLMs在语言建模中之所以有前景的原因之一是它们引入了注意力机制。注意力机制使得Transformer能够根据Token之间的接近程度来权衡每个Token与其他Token的相关性。Transformer识别和权衡复杂依赖关系的能力可以说是其生成上下文准确表示的基础。</p>
<p>在医疗保健中，注意力可以将LLMs的焦点转向最具临床相关性的词汇。例如，患者被发现有胸痛和呼吸急促，并被诊断为急性心肌梗死（即心脏病发作）。注意力机制将使模型能够准确识别“胸痛”、“呼吸急促”和“急性心肌梗死”这些词汇在语义上是如何聚集在一起的，这对于句子的含义尤其重要：它们指的是心脏病发作的主要症状。因此，它会为这些词汇分配更高的注意力权重，以生成更好的句子含义表示。</p>
<p>此外，注意力帮助LLMs处理医学文本的长距离特性。例如，临床记录可能在开头提到患者的病史，但是在记录开头讨论的这些病史和在记录末尾的当前状况是相关的，通过注意力，模型可以捕捉这种依赖关系，并生成更准确的表示。</p>
<p>注意力使模型能够根据Token相对于文本中所有其他Token的上下文重要性分配权重，以发现长期依赖关系，并构建上下文敏感的表示。这些对于医疗保健应用至关重要，因为医疗实体之间的关系和远距离依赖在文本生成、摘要和分析任务中发挥着关键作用。</p>
<p>这就是它的魔力：LLMs可以实时将医学术语翻译成听起来像人类的文本，就像每天随叫随到的医疗翻译；与患者进行连贯的对话；为健康教育材料建立一个令人信服的医学声音，让人感觉像是护士写的；并全面而有意义地回答医学问题，即使这些问题是开放式的和棘手的，甚至我都不知道从哪里开始。这只是Transformer在医学领域发展的一个步骤。</p>
<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>参数是LLMs的另一个关键特征。想象一下一个记忆力超群的医学生。她能够从所有可用的“医学教科书”中阅读大量信息。她学习的医学主题越多（解剖学、生理学、药理学、病理学等），她的头脑中就越充满关于这些主题的知识。所有这些知识实际上都存储在模型的参数中——也就是说，模型从阅读中获取和学习的所有医学事实、概念、关系和背景。你可以把参数看作是模型从所有阅读中获取和“记住”的关键医学知识。</p>
<p>参数越多，医学知识越丰富。一个拥有 2000 亿个参数的模型，不仅在历史和输入数据上比 500 万个参数的模型更多，它实际上吸收了更多的医学知识和与其他医学信息的联系。更多的参数意味着对更复杂医学概念的更深层次学习。一个模型不必拥有数十亿个参数才能在医疗保健中发挥作用。医学学生可能在某个狭窄领域学习整个图书馆的知识，但他们仍然可以毕业成为该狭窄领域（例如心脏病学、神经学或内分泌学）的优秀专家。一个仅在肿瘤学上训练的 3000 万个参数的模型，仍然可以利用其专注的狭窄和针对性知识回答复杂的癌症相关问题。</p>
<p>随着人工智能软件工程师找到新的方法让他们的模型增强所学的知识，比如将他们的LLM与像 PubMed 这样的医学模型连接起来，这将使他们的LLMs能够在其参数之外学习，或将模型连接到现有的现实世界医疗应用程序。在医学领域，就好像一名医学生能够将自己接入 PubMed 数据库或根据需要进行临床试验。</p>
<p>一种常见的思考医疗LLM复杂性的方法是：参数越多，学习能力就越复杂和强大。由数十亿个参数组成的医疗LLM比由数百万个参数组成的更强大。参数控制着LLM行为的许多不同方面：</p>
<ul>
<li>通过语调和内容识别患者情绪，以检测例如疼痛、绝望或焦虑的表达</li>
<li>生成创意医疗输出：结合学习到的模式创造新的医疗文本，将复杂的医疗语言翻译成易于理解的文本，或撰写其他创意输出，如患者教育材料</li>
</ul>
<p>参数影响LLM如何理解医疗文本以及如何生成文本。可以调整参数以控制生成文本的质量和创造力。在LLM中调整温度参数就像在复杂机器上旋转一个精密的旋钮。在最低设置下，旋钮向左转，产生的响应精确、可预测且基于事实。随着你逐渐顺时针旋转旋钮，系统中引入了更多的变异性和创造力。每次轻微的转动，你都会放松机器输出的限制。继续向右转到最高设置时，你给机器更多的自由去探索不寻常的组合和不太可能的结果，这可能导致更不准确的响应。在最右侧，旋钮转到最大时，输出变得高度不可预测和多样化，常常产生令人惊讶甚至有时毫无意义的结果。</p>
<p>权重是另一个影响单词和短语之间连接重要性的参数。例如，一个LLM训练并专注于医院再入院风险的模型使用患者的病史、电子健康记录（EHR）数据、药物和最近的实验室测试结果。假设最近的 EHR 数据显示一名 69 岁男性患者在过去六个月内多次住院，服用利辛普利和美托洛尔，并患有慢性阻塞性肺病（COPD）。LLM将学习权重参数，并可能对最近的住院历史和慢性病赋予更高的权重，因为它们对再入院风险的预测性更强。</p>
<p>温度和权重是两个参数的例子，但还有很多其他参数。更多的参数不一定意味着在医疗保健中的更好表现LLMs。这完全取决于它们如何设计和在相关医疗数据上进行训练。较小的LLMs可以从头开始训练，然后在特定的医疗任务上用少量数据进行微调。事实上，已经有小型LLMs在少量参数下取得了令人印象深刻的临床成功。参数的研究仍然是一个积极发展的领域，持续努力寻找更简洁的方式来表示和学习医学语言。</p>
<h1 id="LLM-和生成式人工智能的潜力"><a href="#LLM-和生成式人工智能的潜力" class="headerlink" title="LLM 和生成式人工智能的潜力"></a>LLM 和生成式人工智能的潜力</h1><p>随着能够从原始数据中全面学习的人工智能系统的出现，已经不再需要人类先将所有内容进行结构化。以前编程算法意味着我们必须明确地定义所有元素：消息接口、科学论文或代码，对于解决方案我们需要花费时间和精力来识别和输入各种概念、规则、模板、决策树等的表示形式。LLMs 可以以原始形式消化消息数据、论文或代码，并自我发现相关的表示形式。</p>
<p>从本质上讲，这意味着LLMs不再需要——也不必——依赖于严格的规则和限制，而是依赖于灵活表述的统计推断。在医疗保健领域，这将意味着LLMs直接从原始的、非结构化的医学文本笔记、研究论文或临床病例笔记中学习，以获得对疾病、治疗和患者护理的直观理解，从而不再需要人类首先手动编码医学知识。</p>
<p>这种人工智能与过去大多数人工智能的区别在于，实际生活中嘈杂、未经修饰的混乱通过自我监督的方式更完整地传递到模型中。自我监督学习是一种机器学习方法，它在没有人类生成的数据注释或数据本身标记的情况下进行训练。例如，一个在庞大的医学文献和病例报告数据库上训练的模型，可能会随后捕捉到疾病过程、治疗患者时的医学决策以及患者沟通的细微差别。</p>
<p>在这种LLM理解的背景下，结合能够创造无限新颖输出的生成架构，你就拥有了超越模式匹配和局部优化的系统。在医学领域，这可能会导致，例如，LLMs通过对医学各个领域的见解进行创造性的并置，开发新的疾病机制、治疗方案，甚至新的疗法。</p>
<p>这种从自上而下的限制性教学转向自下而上的自我导向学习的革命性转变，代表了人工智能范式基础的变化。原则是从大规模数据中涌现出来的，而不是基于编程假设或甚至是微不足道的人类知识的一小部分。这为高度可扩展的人工智能提供了一条路径，这种人工智能比“狭窄”人工智能更具自然性。对于医疗保健而言，这意味着人工智能系统能够从不断增长的医学文献中学习并跟上进展，发现可能被已经超负荷的人工专家所忽视的模式和洞察。</p>
<p>这些新的LLMs具有前所未有的自然语言生成能力，无论是在覆盖范围还是使用质量上。结合新兴的自主智能，可能会出现新的应用类型。复杂的语言技能将使LLMs能够将患者的笔记、病史和指示总结成通俗易懂的语言，以便于理解。LLM可以将关于患者状况的冗长技术医疗报告总结成清晰、易于理解的通俗语言，供患者使用。一个可能的应用是根据患者的个体手术和医疗状况生成个性化的患者教育，例如术后护理说明。</p>
<p>LLM可以通过深入的语言分析大量患者的电子健康记录，从而得出关于患者治疗过程的见解，这些见解在医生的笔记中并没有明确说明。例如，LLM可能会从两个月的笔记中的某些语调模式推断出该患者在遵循药物治疗方面遇到了特别的困难，或者患者可能在隐瞒对自己预后的未言之恐惧。</p>
<p>在医疗保健中，LLM可以帮助使医生与患者之间的沟通变得不那么生硬，更加自然和有效。一个模型可以将患者对其症状的非正式描述从日常用语翻译成精确的医学术语，洞察情感的潜台词——或者反过来：将医生对治疗方案的解释重新编写，以便患者更容易理解和遵循。</p>
<p>一种新兴能力LLMs有潜力创造真正定制和量身定制的个体体验：根据个人的偏好和需求，学习、动态演变和适应的能力。通过在训练过程中摄取与主观人类相关性指标相结合的文本内容，个性化语言模型可以实现对主观人类兴趣的理解。</p>
<p>随着LLMs消化不同的临床语料库，他们可以建议针对患者的生活方式和合并症的健康干预方法，包括具体的（药物方案、锻炼与饮食等）。甚至可以应用情商和同理心建模，以改善患者互动。</p>
<p>例如，LLM可能会处理患者的电子健康记录，其中包含医生的笔记、诊断测试以及药物和近期治疗历史，以建立该患者独特性的档案。然后，它可能会建议一个以患者为中心的个性化治疗计划，考虑影响患者健康旅程的医疗、行为、心理社会和环境参数。</p>
<p>此外，LLMs可以用于运行富有同情心的虚拟健康助手，这些助手能够以支持和鼓励的方式与患者交谈。一个LLM驱动的聊天机器人可以识别患者自身微妙的语言线索，并调整自己的沟通风格，以更好地符合患者的需求，从而带来安慰并增强患者坚持治疗计划的韧性。</p>
<p>LLMs 仍然处于初期阶段。在未来几十年中，随着它们学习处理大量原始数据并适应环境、个性和情感脆弱的患者，LLMs 可能会真正改变医疗服务的方式。我们将扩展医疗决策，提高患者沟通，建立真正个性化的用药方案，并提高工作效率。LLMs 可以用来设想干预措施，以增强关怀护理，同时减少伤害患者和干扰医疗的情绪。我们将做出更好的临床决策，并与患者进行更有效的沟通。虽然这些工具可以改善临床护理，但我们始终需要专注的专业人士和人类的细心关注。这些不是取代我们敬业医生的人工智能机器人。这些进步将增强医学知识、艰苦获得的临床经验和与患者的个人联系。</p>
<h1 id="构建LLMs的艺术"><a href="#构建LLMs的艺术" class="headerlink" title="构建LLMs的艺术"></a>构建LLMs的艺术</h1><p>我们已经讨论了LLMs的用例和力量，但在医疗保健和医学领域，甚至可能在所有行业中，这些LLMs如果没有其他数据的补充，将无法提供预期的结果。在医疗保健领域，这可能包括医疗机构或保险公司的网站、标准护理程序、电子健康记录、临床数据、可穿戴数据、基因组数据等。</p>
<h2 id="检索增强生成"><a href="#检索增强生成" class="headerlink" title="检索增强生成"></a>检索增强生成</h2><p>LLMs 有时能以惊人的准确性回答问题，但有时它们会重复训练数据中的事实，结果却不准确，仍然出错。也就是说，它们会产生幻觉。这是因为 LLMs 知道词语之间的统计关系，但不知道它们的含义。</p>
<p>当LLMs向公众广泛介绍时，围绕新兴能力的概念引起了很多兴奋。因此，许多组织寻求探索和揭示这些模型中潜在的隐藏功能。他们认为LLMs具备未知的能力或特性，可以被利用。然而，随着研究人员深入探讨涌现能力的概念，越来越明显的是，这一概念是一种幻影，而不是LLMs的隐藏功能或特性。</p>
<p>随着时间的推移，技术社区达成共识，认为LLMs中出现的能力的想法是没有根据的。这些模型的观察行为和输出可以通过它们广泛的训练数据以及在训练过程中学习到的复杂模式来解释，而不是任何固有的、未被发现的能力或功能。</p>
<p>相反，LLMs 展现出强大的能力，能够整合和优先考虑他们收到的提示中提供的上下文信息。这一特征通过研究得到了持续的证明，突显了理解和优化 LLMs 已知能力的重要性，而不是追逐难以捉摸的突现功能的概念。</p>
<p>通过将相关信息战略性地嵌入提示中，可以有效地引导LLM的输出，确保生成的内容与适当的上下文和期望的输出更紧密地对齐。这种方法利用了LLMs固有的能力，能够吸收和应用所呈现的知识，从而产生更准确、真实和符合上下文的回应。</p>
<p>在提示中包含上下文参考数据已被证明是一种非常有效的技术，可以优化LLMs在广泛应用中的表现。这种方法使用户能够利用这些强大模型的巨大潜力，同时对生成的内容保持更高的控制，从而最终产生更可靠和有用的输出。</p>
<p>将上下文参考数据或外部来源纳入演变为一种人工智能框架，即检索增强生成（RAG）。这是一个旨在通过使用外部数据源来增强模型，从而提高LLM生成的响应质量的人工智能框架，这些外部数据源补充了LLM的训练数据。</p>
<p>在没有使用 RAG 的情况下，使用LLM与聊天机器人应用程序互动的用户如图 2-4所示，展示了给LLM的典型用户提示词。</p>
<p><img src="/../asset_02InsideAIBlackBox/04.png">图 2-4  给 LLM的用户提示词</p>
<p>第一步是用户输入一个提示词，比如“我该如何康复我的腿筋拉伤？”聊天机器人应用程序或界面接收该提示，并将问题传递给其LLM。模型在其数据语料库中搜索答案，将答案返回给聊天机器人，聊天机器人再将响应反馈给用户。现在这是一个基本示例，并不旨在说明任何特定聊天机器人或技术（如 ChatGPT 或Gemini）的工作原理。这些工具可能更复杂，结合搜索或其他功能来得出响应。</p>
<p>现在让我们看看使用 RAG 时这张图片是如何变化的，如图 2-5所示。</p>
<p><img src="/../asset_02InsideAIBlackBox/05.png">图 2-5. 使用 RAG 的聊天机器人</p>
<p>使用 RAG 解决了LLMs面临的一些挑战，在医疗或医学领域，一个大挑战是缺乏对药房、临床、电子健康记录、政策、医生笔记等医疗数据的访问。凭借医疗数据和来自公司自身数据源和网站的专有数据，LLM的输出不太可能不准确，从而更有可能减少或消除幻觉。更重要的是，LLM可能会回应“我不知道。”</p>
<p>返回到 图 2-5，用户输入一个提示词，该提示词被聊天机器人接收。不同的是，聊天机器人并没有将问题传递给 LLM，而是对公司的数据源进行了搜索（步骤 2）。在这个例子中，这些数据源包括政策、医生笔记、临床数据和电子健康记录数据。但其他数据也可以被包含，例如药房数据、索赔数据或任何被认为对用户查询聊天机器人至关重要的外部参考数据源。</p>
<p>步骤 3 中，聊天机器人提供了提示词给LLM。这些指示词可能会指导LLM使回应听起来像是来自医生，但要使用高中阅读水平。除了原始用户问题外，还包括对响应提示有用的外部数据（公司数据）。配备这三个提示要素的LLM将优先考虑公司的数据或外部数据源。LLM将生成回应，聊天机器人将把回应传递给用户。</p>
<p>RAG 的好处是多方面的。利用当前最佳来源的信息可以避免另一个困扰LLMs的问题，即数据过时，因为它反映了最后一次训练数据的日期。如果模型需要适应新信息，就必须重新训练。建立一个可以在必要时更新新材料的内容库，可以实现快速而粗略的适应，而不是全面的改造。</p>
<p>此外，提示词指令可以促使LLM表现出良好的行为，例如在不知道问题答案时予以承认。如果对内容库的信心不足以回答用户的查询，模型可以做出正确的选择，表示它不知道，而不是提供一个看似合理但可能错误的回答。</p>
<p>然而，RAG 的有效性取决于检索系统的质量。如果搜索没有为LLMs提供最相关的高质量基础信息，模型可能无法回答任何问题——即使这些数据可能适合回答此类问题。因此，优质医疗信息的重要性不言而喻。</p>
<p>简而言之，检索增强生成是人工智能的一个有前景的新里程碑。迄今为止，提高LLMs性能的最佳方法是将其根植于外部、及时和可验证的数据。通过公司的专有数据为LLMs提供动力，使LLM聊天机器人能够从外部数据源获取可靠信息，从而提供更准确的响应。这避免了LLM因未包含在其训练数据集中而缺乏必要知识的问题，从而导致幻觉。</p>
<p>建造一个LLM既是一门艺术，也是一门科学。它涉及一个创造性的过程，需要想象力、直觉以及对语言和人类行为的深刻理解。</p>
<p>下一部分描述了构建一个LLM的艺术，涉及六项活动：</p>
<ul>
<li> 概念化</li>
<li>数据选择与策划</li>
<li>模型架构与设计</li>
<li> 提示工程</li>
<li> 精炼与反馈</li>
<li> 与应用程序集成</li>
</ul>
<h2 id="概念化"><a href="#概念化" class="headerlink" title="概念化"></a>概念化</h2><p>组建一个多元化的团队通常在建立一个LLM方面大有裨益，以满足其组成用户的需求和要求。图 2-6展示了一个多元化团队的组织和启动，旨在理解问题和潜在的前进方向：一个概念化阶段。</p>
<p><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098160913/files/assets/llmg_0206.png">图 2-6. 概念化</p>
<p>形成一个LLM以解决医疗问题的第一步是明确当前的医疗问题或任务。这将涉及确定一个高度特定的医疗领域和用例，同时描述LLM的期望结果。识别医疗领域可能包括以下一个或多个步骤：</p>
<ol>
<li>指定相关的医学专业或细分领域（放射学、病理学、肿瘤学等）或相关的增强功能（临床决策支持功能）。该领域存在哪种数据（例如，医学影像、电子健康记录、临床笔记、医学文献）？</li>
<li>指定预期的用例：清楚地阐明LLM在医疗保健背景下的目的和目标。用例的示例可能包括疾病诊断、风险预测、治疗建议、网站导航、呼叫中心协助和患者沟通。第 3、4 和 5 章列出了大量的用例。定义LLM的目标用户，例如医生、护士或患者。</li>
<li>确定每个用例的期望结果或目标。定义相关的性能指标，通过这些指标评估LLM的成功。考虑准确性、灵敏度、特异性或其他特定领域的评估指标等因素。定义任何约束或要求，例如可解释性、公平性或合规性。</li>
<li>评估训练LLM所需相关医疗数据的可用性和可获取性。了解数据的数量、种类和质量，以及任何潜在的偏见或限制。确定是否需要额外的数据收集或整理工作。</li>
<li>与专家互动：与了解问题领域的临床医生、研究人员或数据科学家合作进行设计。采用以用户为中心的设计技术，创建一个既必要又可用的模型。征求他们的意见，以确保问题陈述与临床现实相符，并帮助解决真正重要的挑战。邀请他们参与确定期望的结果、选择相关的数据源，并提供领域特定专业知识所带来的独特视角。</li>
</ol>
<p>在这个阶段，定义医疗保健问题和LLM的用例也使设计团队成员和数据的使用朝着特定方向集中，因为他们现在直观地理解了LLM应该使用的背景。他们能够朝着特定的性能标准努力，并对最终的LLM需要为实际用户“做”或实现的目标有共同的理解。</p>
<p>在明确和彻底定义之后，典型的下一步包括：数据收集&#x2F;预处理、模型架构设计、训练&#x2F;优化、评估&#x2F;验证、在医疗环境中的部署&#x2F;监控。但如果问题定义受到影响，所有这些步骤都将崩溃。</p>
<h2 id="数据选择与策划"><a href="#数据选择与策划" class="headerlink" title="数据选择与策划"></a>数据选择与策划</h2><p>在医疗保健领域，生命或健康的损失悬而未决，选择LLM的训练数据变得更加关键。训练数据的数量很重要，但护理服务通常需要展现极高精度和细微背景的医疗和健康LLMs。以稍微偏离的方式解读医疗记录可能会导致一系列问题，具体取决于用例。图 2-7描绘了数据选择和策划的繁忙工作，在这里，数据科学家，有时还有机器学习工程师和人工智能工程师，必须理解将在 RAG 中使用的外部数据源，这些数据源将为LLM提供支持。</p>
<p><img src="/../asset_02InsideAIBlackBox/07.png">图 2-7. 数据选择与整理</p>
<p>在许多医疗保健公司中，数据被孤立并由不同的数据团队“拥有”。许多公司没有明确的数据治理和访问政策。获取特定数据集的访问权限通常是一个挑战。训练数据可能存在缺口，这会影响模型在“实验室”之外应用于临床环境时的韧性。例如，由于 HIPAA 或 GDPR 的原因，去标识化的训练数据或仅具有某种粒度级别的数据可能无法反映“真实世界”的数据，从而导致模型遇到困难或无法按预期表现。</p>
<p>患者的原始医疗数据不会向非研究人员发布：这些数据高度敏感，受到隐私和知情同意等伦理问题的严格规定。数据发布政策必须在透明度和患者隐私之间取得平衡。定义LLM的使用方式（例如，药物发现、临床决策支持）将影响相关数据源的选择。</p>
<p>一种补充开源和专有基础模型的方法是检索增强生成（RAG），之前已经讨论过。它增加了模型的知识，使其能够超越在预训练中获得的内容；在推理时，它可以匹配上下文文档（例如，网站数据、病人记录等）并根据这些文档调整其输出。这是一个简单的补充，可以将特定领域的语料库添加到模型中，而不影响基础部分。</p>
<h2 id="模型架构与设计"><a href="#模型架构与设计" class="headerlink" title="模型架构与设计"></a>模型架构与设计</h2><p>LLMs今天的专业领域涵盖了从使用不同数据类型和模式（仅文本、文本和图像、文本和语音对话、文本和音频流、文本和乐谱、文本和编程代码、文本和视频）到执行多种不同任务（摘要、分类、生成、翻译、推荐等）的广泛范围。</p>
<p>一个LLM的架构是它的设计，指定信息如何在模型中流动，以及模型如何在该信息流下处理和生成语言。架构设计是创造力、迭代和领域知识的直观计算融合。早期的设计选择是决定使用哪种深度学习架构来进行LLM。存在不同类型的神经网络（见图 2-8），决定哪种类型是模型架构是一个早期的架构选择。</p>
<p><img src="/../asset_02InsideAIBlackBox/08.png">图 2-8. 架构与设计</p>
<p>架构和设计不仅涉及LLM模型，还涉及确定该模型如何与渲染模型推断所需的其他组件相适应。换句话说，该模型是通过网页应用程序前端展示，还是像聊天机器人一样的应用程序，或者两者兼有？LLM在整体架构中处于何处，数据如何在各个组件之间流动？这些都是可以在LLM开发的同时进行和实现的决策。</p>
<p>模型必须构建，这可以通过深度学习编程库来完成。然后，模型必须进行微调和优化。微调LLM是指调整某些模型参数的值，以便模型在某些任务或特定数据集上表现更好。由于微调是一种启发式方法，工程师会尝试不同的方法，并根据经验结果和领域知识结合实验和直觉做出决策。</p>
<h2 id="提示词工程"><a href="#提示词工程" class="headerlink" title="提示词工程"></a>提示词工程</h2><p>提示词工程可以是一种艺术形式，因为它涉及到精心设计输入提示词或查询，以引导模型的响应。设计提示词是一项需要领域专业知识的技能，以促使模型产生人类工程师希望看到的答案。工程师需要编写提供上下文、约束的提示词，以希望促使模型生成稳健（准确且可能）且独立（可读连贯文本）的输出。图 2-9 说明了我们在使用 ChatGPT、ClaudeAI、Gemini 和其他 LLMs 时已经习惯的基本提示词。</p>
<p><img src="/../asset_02InsideAIBlackBox/09.png">图 2-9. 提示工程</p>
<p>提示词工程对于LLMs意味着非常仔细地选择纳入提示中的文本线索，以引导模型的输出。这与我们与搜索引擎的互动方式不同，搜索引擎接受静态查询并找到相应的静态答案。提示则不同：查询不仅是携带上下文、约束和目标信息的连续文本，而且它也是用户与开放式LLM之间持续信号传递过程的一部分。</p>
<p>提示工程师进行研究，以确定LLM所训练的数据和模型的偏见，以便他们可以编制可能需要避免的陷阱列表。与此相关，领域特异性非常重要。适当的医疗或健康提示的语言与适当的工程导向提示的语言会有所不同，因此用户可以避免提示词中的概念与模型的潜在表示空间之间的不匹配。</p>
<p>测试周期中的信号将标记出模型容易受到噪声影响的地方，这可能是由于缺乏外部上下文的强化，从而导致虚假阳性大量涌入。例如，LLM被训练用于分析和解释放射学图像，如 X 光片或 CT 扫描，以检测异常或疾病迹象。如果LLM的训练数据集有限或缺乏放射科医生的外部验证，LLM可能会产生幻觉并错误地识别出异常。</p>
<p>在其他情况下，通过对比案例进行训练，或将物体人工插入输入流（包括正面和负面示例），使模型能够学习辨别细微差异。这种编码反馈可以作为不断的反馈循环，精炼提示的艺术，使工程师能够雕刻、塑造和引导模型行为。这个循环使得提示变得既是艺术又是科学。</p>
<h2 id="精炼与反馈"><a href="#精炼与反馈" class="headerlink" title="精炼与反馈"></a>精炼与反馈</h2><p>这就是你如何构建一个LLM：你经历一个迭代过程，在这个过程中逐渐改进模型。你收集用户或领域专家的反馈，或设定评估指标，并迭代地提高模型的性能和能力。这个迭代循环使工程师能够完善模型生成响应的方式，解决已知的不足，并适应不断变化的需求和口味。图 2-10 说明了开发一个LLM的持续反馈循环。</p>
<p><img src="/../asset_02InsideAIBlackBox/10.png">图 2-10. 精炼与反馈</p>
<p>反馈循环应被定义，特别关注用户对输出的直接反馈，这是系统能获得的最佳指导。这可以通过评分、调查维度，甚至是对其优点、缺点和改进领域的开放式评论来实现。在某些领域，如医疗保健，主题专家的意见是不可或缺的，以确保LLM能够跟上专业标准，并生成适当且相关的输出。最后，准确性、流畅性和连贯性等定量指标可以作为基准数据集的一部分进行计算，以评估LLM的性能。</p>
<p>另一种精细化技术包括微调，其中LLM在新的或者调整过的数据上进行重新训练，以明确符合反馈或期望的修改。还有更具针对性和区分性的提示，引导LLM朝着与主题和上下文相关的期望输出样本。最后，还有强化学习技术，其中LLM可能会被条件化或激励，以产生符合预设奖励的数字文本输出，从而推动系统发展后续的行为倾向。在构建LLM的过程中，应有来自真实用户和专家的反馈迭代过程，以帮助确保LLM符合其预期用户的需求和偏好。</p>
<h2 id="与应用程序集成"><a href="#与应用程序集成" class="headerlink" title="与应用程序集成"></a>与应用程序集成</h2><p>值得注意的是，创建一个使用LLM的应用程序或应用与仅仅构建LLM相比，涉及一些不同的考虑。创建一个LLM应用将涉及将LLM与应用程序的逻辑和功能集成。这可能涉及设计应用程序的接口和 API，以允许应用程序向LLM发送输入，从中接收输出，并将这些输出集成到应用程序的用户体验中。集成可能包括处理与LLM交互所需的数据预处理、后处理和错误处理。图 2-11说明了在如何与LLM所在的外部和内部系统进行集成时需要做出的决策。与应用程序和应用集成的方式有很多种，这将涉及根据性能、可用性、可扩展性等要求做出可行和实用的架构决策。</p>
<p><img src="/../asset_02InsideAIBlackBox/11.png">图 2-11. 与应用程序的集成</p>
<p>用户界面设计在LLMs的应用中至关重要的一个方面是用户如何向LLM提供输入，以及他们如何理解和消化LLMs所提供的反馈。开发者必须设计自然流畅且“人性化”的界面，以引导用户向LLM提供信息，回答LLM的请求，并指示LLM生成与“说话者”意图密切相关的建议响应或内容。这可以是一个聊天界面，一个简单的用户文本输入表单，或者一组经典的华丽小部件和菜单。</p>
<p>应用LLMs也可能需要进行重大优化，以达到可接受的响应和效率水平。实时应用任务，例如对话和交流，通常涉及过多的数据或计算，无法为每个句子腾出时间，LLM驱动的应用程序向LLM发送、接收答案并在与其他用户沟通时进行下游处理。</p>
<p>开发人员在确保此类应用程序性能时，可能需要优化软件代码（例如，调整与LLM的通信输入和输出格式，以最小化在应用程序与LLM之间传输此类数据所需的时间）、数据处理管道（例如，缓存计算答案所需的最相关数据）以及应用程序基础设施设计（例如，针对分布式计算，这允许在并发请求和请求复杂性方面进行扩展）。</p>
<p>安全在LLM应用中至关重要。敏感的医疗和个人数据需要全面保护，以防止信息泄露和恶意攻击。应采用最新的安全实践，以充分防止未经授权的访问、数据泄露和恶意攻击。开发人员应选择最合适的安全方法来加密和保护用户数据，同时向用户提供保障。</p>
<p>与任何应用程序一样，LLM 应用程序将受益于人类反馈循环和迭代。LLM 应用程序设计师应包括收集人类反馈、分析使用模式以及根据用户需求和偏好对应用程序进行迭代改进的系统和机制。这项工作可能涉及 A&#x2F;B 测试、人类调查和数据分析，以了解更多关于应用程序使用的信息，并为应用程序和 LLM 的迭代改进提供依据。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>在本章中，我们介绍了LLMs和生成式人工智能的内部工作原理，深入探讨了它们如何通过机器学习和深度学习使用神经网络，超越传统的分类和预测任务。我们提供了关于人工智能与机器学习辩论的背景，得出结论它们是不同的。例如，机器学习是人工智能的一个子集，人工智能的目标要广泛得多，人工智能包括多个领域，这些领域对于LLMs是必要的。这些领域包括自然语言处理和计算机视觉。</p>
<p>超越单纯的分类和预测，我们讨论了LLMs在不同任务和领域中生成类人文本的能力。我们剖析了LLMs的架构和内部工作原理，包括支撑LLMs语言处理能力的Token、Transformer、参数和注意机制。我们通过描绘非恶性肿瘤的检测，说明了神经网络的功能——这是LLM的一个关键元素。</p>
<p>我们探讨了构建LLMs的过程，涵盖了从构思解决方案到定义一个或多个医疗保健用例的各个生命周期阶段。RAG 是医疗保健LLMS的一个关键方面，确保这些模型使用外部数据源以提高准确性，这在医疗保健领域至关重要。我们展示了 RAG 的使用以及这个 AI 框架如何与LLM协同工作。</p>
<p>理解LLMs的内部运作，从高层次上看，应该为读者准备好理解下一章中描述的许多未来用例如何在医疗保健领域实现。</p>
<p>1 “大脑基础：神经元的生与死，”国家神经疾病与中风研究所，访问日期：2024 年 6 月 24 日，<a target="_blank" rel="noopener" href="https://www.ninds.nih.gov/health-information/public-education/brain-basics/brain-basics-life-and-death-neuron#:~:text=Neurons%20communicate%20with%20each%20other,and%20dendrites%20of%20nearby%20neurons.%60&amp;&%60text=There%20are%20three%20kinds%20of,and%20ears%E3%80%82">https://www.ninds.nih.gov/health-information/public-education/brain-basics/brain-basics-life-and-death-neuron#:~:text=Neurons%20communicate%20with%20each%20other,and%20dendrites%20of%20nearby%20neurons.`&amp;&amp;`text=There%20are%20three%20kinds%20of,and%20ears。</a></p>
<p>2 Liat Clark，“谷歌的人工大脑学会寻找猫视频，”连线，2012 年 6 月 26 日，<a target="_blank" rel="noopener" href="https://www.wired.com/2012/06/google-x-neural-network%E3%80%82">https://www.wired.com/2012/06/google-x-neural-network。</a></p>
<p>3 这幅图来自“AI 与机器学习”，IBM 技术，2023 年 4 月 10 日，YouTube 视频，5:48，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=4RixMPF4xis%E3%80%82">https://www.youtube.com/watch?v=4RixMPF4xis。</a></p>
<p>4 “人工智能，”维基百科，最后更新于 2024 年 6 月 24 日，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Artificial_intelligence%E3%80%82">https://en.wikipedia.org/wiki/Artificial_intelligence。</a></p>
<p>5 Ashish Vaswani 等人，“注意力机制是你所需要的一切”，第 31 届神经信息处理系统会议（NIPS 2017），加利福尼亚州长滩，<a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf%E3%80%82">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf。</a></p>
<p>6 亚历克斯·爱德华兹，“研究发现，使用更小的语言模型可以更好地进行临床翻译，” Slator，2023 年 12 月 20 日，<a target="_blank" rel="noopener" href="https://slator.com/clinical-translations-better-with-smaller-language-models-research-finds%E3%80%82">https://slator.com/clinical-translations-better-with-smaller-language-models-research-finds。</a></p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/08/08/llmsClinical01/" rel="prev" title="第一章 医生的黑色手提包">
                  <i class="fa fa-angle-left"></i> 第一章 医生的黑色手提包
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/08/10/llmsClinical03/" rel="next" title="第三章 超越白大褂">
                  第三章 超越白大褂 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Howard Huang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">488k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">14:48</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">
    <!--由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动-->
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
