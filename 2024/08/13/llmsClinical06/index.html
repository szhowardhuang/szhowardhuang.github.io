<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"szhowardhuang.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="最终，在医疗保健中使用技术的目标始终是通过不断发展其基础功能来改善患者、临床医生和所有医疗从业者的结果和体验。大型语言模型（LLMs）可以彻底改变设计和提供医疗解决方案的方式。它们的影响可能会通过改善对医学知识和案例数据的获取，以及在患者和提供者之间进行调解而变得显著。 这首先集中于在医疗保健背景下的人工智能模型开发。人工智能可以有意识地策划与医学相关的多样化训练数据集，引入可解释性特征，使人工智">
<meta property="og:type" content="article">
<meta property="og:title" content="第六章 掌舵LLMs的伦理">
<meta property="og:url" content="https://szhowardhuang.github.io/2024/08/13/llmsClinical06/index.html">
<meta property="og:site_name" content="嵌入式老兵博客">
<meta property="og:description" content="最终，在医疗保健中使用技术的目标始终是通过不断发展其基础功能来改善患者、临床医生和所有医疗从业者的结果和体验。大型语言模型（LLMs）可以彻底改变设计和提供医疗解决方案的方式。它们的影响可能会通过改善对医学知识和案例数据的获取，以及在患者和提供者之间进行调解而变得显著。 这首先集中于在医疗保健背景下的人工智能模型开发。人工智能可以有意识地策划与医学相关的多样化训练数据集，引入可解释性特征，使人工智">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-08-13T08:31:19.000Z">
<meta property="article:modified_time" content="2024-08-21T06:07:21.000Z">
<meta property="article:author" content="Howard Huang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://szhowardhuang.github.io/2024/08/13/llmsClinical06/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://szhowardhuang.github.io/2024/08/13/llmsClinical06/","path":"2024/08/13/llmsClinical06/","title":"第六章 掌舵LLMs的伦理"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>第六章 掌舵LLMs的伦理 | 嵌入式老兵博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">嵌入式老兵博客</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BD%9C%E4%B8%BA%E4%B8%80%E7%A7%8D%E7%A7%AF%E6%9E%81%E5%8A%9B%E9%87%8F%EF%BC%9A%E6%94%B9%E5%96%84%E5%8C%BB%E7%96%97%E4%BF%9D%E5%81%A5"><span class="nav-number">1.</span> <span class="nav-text">人工智能作为一种积极力量：改善医疗保健</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LLMs%E7%9A%84%E4%BC%A6%E7%90%86%E5%BD%B1%E5%93%8D"><span class="nav-number">2.</span> <span class="nav-text">LLMs的伦理影响</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%99%9A%E6%9E%84%E7%8E%B0%E5%AE%9E"><span class="nav-number">2.1.</span> <span class="nav-text">虚构现实</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%92%E5%85%85%E5%92%8C%E6%AC%BA%E8%AF%88"><span class="nav-number">2.2.</span> <span class="nav-text">冒充和欺诈</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E4%BC%AA%E9%80%A0"><span class="nav-number">2.3.</span> <span class="nav-text">深度伪造</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%AA%E6%80%A7%E5%8C%96%E5%8A%9D%E8%AF%B4"><span class="nav-number">2.4.</span> <span class="nav-text">个性化劝说</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%81%8F%E8%A7%81%E6%94%BE%E5%A4%A7"><span class="nav-number">2.5.</span> <span class="nav-text">偏见放大</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%BD%9C%E5%9C%A8%E5%BD%B1%E5%93%8D%E7%9A%84%E8%A7%84%E6%A8%A1"><span class="nav-number">2.6.</span> <span class="nav-text">潜在影响的规模</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E5%8C%96%E9%BB%91%E5%AE%A2%E6%94%BB%E5%87%BB"><span class="nav-number">2.7.</span> <span class="nav-text">自动化黑客攻击</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E7%A4%BA%E6%B3%A8%E5%85%A5%E6%94%BB%E5%87%BB"><span class="nav-number">2.8.</span> <span class="nav-text">提示注入攻击</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E5%AF%B9%E5%8F%AF%E9%A2%84%E8%A7%81%E7%9A%84%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="nav-number">2.9.</span> <span class="nav-text">应对可预见的使用案例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%91%E6%8E%A7LLM%E8%A1%8C%E4%B8%BA"><span class="nav-number">3.</span> <span class="nav-text">监控LLM行为</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%89%E5%85%A8%E4%B8%8E%E9%9A%90%E7%A7%81"><span class="nav-number">4.</span> <span class="nav-text">安全与隐私</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0"><span class="nav-number">4.1.</span> <span class="nav-text">联邦学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%99%E6%98%AF%E5%AE%83%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-number">4.1.1.</span> <span class="nav-text">这是它的工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A5%BD%E5%A4%84"><span class="nav-number">4.1.2.</span> <span class="nav-text">好处</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B"><span class="nav-number">4.1.3.</span> <span class="nav-text">示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E6%88%98"><span class="nav-number">4.1.4.</span> <span class="nav-text">挑战</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81"><span class="nav-number">4.2.</span> <span class="nav-text">差分隐私</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%99%E6%98%AF%E5%AE%83%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-1"><span class="nav-number">4.2.1.</span> <span class="nav-text">这是它的工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A5%BD%E5%A4%84-1"><span class="nav-number">4.2.2.</span> <span class="nav-text">好处</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B-1"><span class="nav-number">4.2.3.</span> <span class="nav-text">示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E6%88%98-1"><span class="nav-number">4.2.4.</span> <span class="nav-text">挑战</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E7%A4%BA%E6%B8%85%E7%90%86%E5%92%8C%E8%BF%87%E6%BB%A4"><span class="nav-number">4.3.</span> <span class="nav-text">提示清理和过滤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%99%E6%98%AF%E5%AE%83%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-2"><span class="nav-number">4.3.1.</span> <span class="nav-text">这是它的工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%99%E6%98%AF%E5%AE%83%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-3"><span class="nav-number">4.3.2.</span> <span class="nav-text">这是它的工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A5%BD%E5%A4%84-2"><span class="nav-number">4.3.3.</span> <span class="nav-text">好处</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B-2"><span class="nav-number">4.3.4.</span> <span class="nav-text">示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E6%88%98-2"><span class="nav-number">4.3.5.</span> <span class="nav-text">挑战</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86"><span class="nav-number">4.4.</span> <span class="nav-text">同态加密</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%99%E6%98%AF%E5%AE%83%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-4"><span class="nav-number">4.4.1.</span> <span class="nav-text">这是它的工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A5%BD%E5%A4%84-3"><span class="nav-number">4.4.2.</span> <span class="nav-text">好处</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B-3"><span class="nav-number">4.4.3.</span> <span class="nav-text">示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E6%88%98-3"><span class="nav-number">4.4.4.</span> <span class="nav-text">挑战</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AF%E8%A7%A3%E9%87%8A%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="nav-number">4.5.</span> <span class="nav-text">可解释的人工智能</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%99%E6%98%AF%E5%AE%83%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-5"><span class="nav-number">4.5.1.</span> <span class="nav-text">这是它的工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8A%80%E6%9C%AF"><span class="nav-number">4.5.2.</span> <span class="nav-text">技术</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A5%BD%E5%A4%84-4"><span class="nav-number">4.5.3.</span> <span class="nav-text">好处</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B-4"><span class="nav-number">4.5.4.</span> <span class="nav-text">示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E6%88%98-4"><span class="nav-number">4.5.5.</span> <span class="nav-text">挑战</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E5%9B%9E%E5%BD%A2%E9%92%88%E9%97%AE%E9%A2%98"><span class="nav-number">5.</span> <span class="nav-text">人工智能与回形针问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%94%BF%E7%AD%96%E5%8F%91%E5%B1%95"><span class="nav-number">6.</span> <span class="nav-text">政策发展</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">7.</span> <span class="nav-text">摘要</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Howard Huang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">70</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/13/llmsClinical06/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="第六章 掌舵LLMs的伦理 | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第六章 掌舵LLMs的伦理
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-13 16:31:19" itemprop="dateCreated datePublished" datetime="2024-08-13T16:31:19+08:00">2024-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:07:21" itemprop="dateModified" datetime="2024-08-21T14:07:21+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>22k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>39 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>最终，在医疗保健中使用技术的目标始终是通过不断发展其基础功能来改善患者、临床医生和所有医疗从业者的结果和体验。大型语言模型（LLMs）可以彻底改变设计和提供医疗解决方案的方式。它们的影响可能会通过改善对医学知识和案例数据的获取，以及在患者和提供者之间进行调解而变得显著。</p>
<p>这首先集中于在医疗保健背景下的人工智能模型开发。人工智能可以有意识地策划与医学相关的多样化训练数据集，引入可解释性特征，使人工智能能够“打开引擎盖”，解释其如何得出决策，并提出算法审计和监督协议，以确保对所有患者群体的公平对待。健康价值、质量和公平获得护理——而不是最大利润或最大投资回报——应该是目标。有许多文章、论文和案例研究显示人工智能在医疗保健中的积极影响。</p>
<p>最终，医疗保健中对训练模型的监督也需要遵循这些原则。这可能涉及对模型能够做什么和不能做什么的伦理披露建模，立法严格遵守患者保密和医学伦理，维护有效的算法伤害救济途径，以及倡导举报以促进组织问责和尊重患者的福利。在这一基础设施中，LLMs可以成为促进多元化和集体医学知识的公共卫生工具。</p>
<p>本章将探讨在医疗保健中LLMs的伦理挑战和负责任的发展，特别是它们提高患者结果和体验的潜力以及可能的陷阱。在本节中，我们将为医疗保健发展一些积极的人工智能想象，讨论人工智能的潜在用途和结果，特别是LLMs在医疗保健领域的应用。在下一节中，我们将讨论在医疗保健中使用LLMs所涉及的伦理挑战。本章将解决如何监测、检测和防止在各种医疗保健环境中使用的LLMs的异常行为的问题。最后，在我们的最后一节中，我们将讨论与医疗保健情境中使用的LLMs相关的安全和隐私问题。特别是，我们将讨论联邦学习，其理念是在分布式数据上训练LLMs以保护患者隐私，以及差分隐私，这是确保数据集中个人隐私的数学框架。</p>
<h1 id="人工智能作为一种积极力量：改善医疗保健"><a href="#人工智能作为一种积极力量：改善医疗保健" class="headerlink" title="人工智能作为一种积极力量：改善医疗保健"></a>人工智能作为一种积极力量：改善医疗保健</h1><p>科幻小说常常描绘人工智能带来的风险：流行文化讲述关于失控的糟糕技术的反乌托邦故事。你可能会想到机器人起义、人工通用智能（AGI）摧毁人类或人工智能奇点。共同的主题是，随着人工智能的智能越来越接近我们，与人类的认知竞争意味着与人类竞争——这是一场灾难的配方。自玛丽·雪莱的弗兰肯斯坦（1818）以来，流行文化中对人工智能的描绘一直是机器人末日，机器将摧毁我们的工作、自主权和我们的生命。新的宗教现在放大了这些神话：我们听说人工智能将变得有意识并摧毁我们。</p>
<p>尽管这些恐惧、焦虑或风险需要关注，但过度关注负面愿景限制了我们积极塑造人工智能发展的能力，以改善社会。现在是阐明和培养积极人工智能愿景的时候——这些故事情节包括可以立即采取的具体步骤，以利用人工智能的潜力促进重要的人类伦理和变革。人工智能发展的另一种人文愿景与人类价值观（如正义和公平）以及所有人类能力的全面发展相一致。这条道路可以作为开发者、政策制定者和社区的出发点，也可以作为想象一个转变后的智能对人类福祉产生变革性影响的未来的愿景。先进的智能可以极大地赋权，但前提是它必须在服务于人类尊严的方向上前进。</p>
<p>通过关注人工智能最积极的应用，我们可以将其发展引导远离可怕的假设，塑造其增强人类能力以解决医疗保健最大挑战的方向。一个例子是能够使医疗保健和医学研究民主化的人工智能系统，或者提升所有学习者的教育机会，实现个性化学习体验。人工智能还可能加速科学发现的进展，以应对气候变化和其他社会问题。该技术可以被用来促进公平（揭示、减少或消除偏见）、开放和民主的知识生产、决策和文化及经济机会的获取系统。</p>
<p>意识到这将需要引导人工智能系统朝着可解释、可理解（对人类而言）和负责任的方向发展——也就是说，伦理的——现在就要开始。这种设计需要研究人员、伦理学家、政策制定者和公众共同努力，制定强有力的伦理框架、健全的监管监督和公众参与倡议。通过现在对人工智能的预见和塑造，我们可以将人类引向一个未来，在这个未来中，强大的人工智能帮助我们创造一个富有成效、协作和繁荣的世界，而不是它的终结。</p>
<p>通过采用这些积极的人工智能想象，我们颠覆了人工智能崛起的故事，强调它在多大程度上可以改善人类的状况。如果我们能够设想并开始实现一个最大化其对社会公益效用的人工智能辅助未来的可能性，我们就可以以一种引导我们走向一个更好、更公平和更充实的世界的方式，集中其演变。</p>
<p>积极人工智能的关键价值在于增强人类的优势，而不是全面替代。例如，&#x3D;&#x3D;医疗或临床人工智能的设计旨在加强临床洞察力，增加时间以建立更具关怀的以患者为中心的关系，而不是单纯追求降低医疗劳动力成本&#x3D;&#x3D;（无论其带来的心理代价如何）。</p>
<p>以正义为导向的设计还确保算法不会延续过去的结构性偏见，这些偏见忽视或错误表述社会中已经深度边缘化的群体。将会有机制允许公众参与模型开发，如果算法似乎对公民不公平，将提供举报人保护，最重要的是，建立某种救济机制，以防止算法对某些群体的待遇低于其他群体。</p>
<p>最终目标是人类的繁荣，通过公平的技术进步和公正的政治经济权力体系来实现，而不是某种模糊、抽象、非人性化的技术官僚驱动，以“优化”和“最大化利润”为代价，忽视现实生活。这种对复杂未来的广泛伦理框架可以释放愿景，更好地将人工智能表述为一种深刻的社会利益形式。</p>
<p>人工智能可能削弱医生的工作或加剧医疗保健中现有的不平等，这种担忧由来已久。然而，专注于这些负面叙事可能会减缓我们更有效地设想人工智能与健康的过程，同时也使我们对更可及、公平和个性化的医疗保健系统的可能性保持无知。这种潜力和应用案例在前面的章节中已有介绍。通过将积极的人工智能描述为一种向善的力量，我们可以引导这项技术更好地支持我们所需和应得的医疗保健。</p>
<p>与其害怕人工智能或我们当前的现状，我们如何能够设计和部署它，以与患者赋权、可及性、公平、隐私和透明度等伦理相协调？在 第 3 章、第 4 章 和 第 5 章 中，我们详细介绍了许多 LLM 的用例，以提供能力提升和患者赋权。</p>
<ul>
<li>能力提升：人类能力可以在前面章节中提到的许多医疗保健角色中得到增强。这些角色包括医生和专家、护士和护理协调员、心理健康专业人员、放射科医生、研究人员和公共卫生教育工作者。</li>
<li>患者赋权：LLMs 具备对话能力，可以帮助患者管理健康、提供个性化教育，并改善与医疗专业人员的沟通。人工智能可以帮助患者积极参与他们医疗保健的各个方面。</li>
</ul>
<p>这些只是人工智能未来可能积极的一些例子，只有采取积极合作的方式来塑造我们想要的未来，我们才能实现这些可能性</p>
<ul>
<li>我们必须强调多学科合作，确保人工智能的发展吸引一系列专家，包括工程师、伦理学家、政策制定者和社会科学家。</li>
<li>我们还必须增加公众参与，沟通人工智能可能带来的好处，并让人们参与到人工智能系统的开发过程中。</li>
<li>持续投资也很重要。这意味着支持开放的人工智能研究和开发，以便在一线的人能够有权限负责任地进行创新和交付。</li>
</ul>
<h1 id="LLMs的伦理影响"><a href="#LLMs的伦理影响" class="headerlink" title="LLMs的伦理影响"></a>LLMs的伦理影响</h1><p>LLMs 有能力彻底改变医疗保健，但它们也容易被滥用，并带来重大的隐私和伦理风险。医疗数据比大多数领域更为敏感，在医疗保健中使用 LLMs 可能对人类生活产生负面影响。出现了几个关键关注领域：</p>
<ul>
<li>虚假实体：LLMs 将生成逼真但虚假的医疗记录，这些记录会混淆医生，允许个人欺诈保险公司，并污染医疗记录。</li>
<li>假医生和未经授权的访问：LLMs 伪装成医生可能导致未经授权或伪授权的访问、医疗身份盗窃和欺诈性账单。</li>
<li>虚假信息：深度伪造技术可能被用于制造虚假的医疗信息。它们也可能被用来伪造医生或患者的身份，以获取健康记录进行身份或保险欺诈。</li>
<li>个性化骚扰：LLMs 在销售推介方面会表现出色，这为制药公司提供了一个针对脆弱客户的世界，推销无效、不必要且可能有害的治疗方案。</li>
<li>瞄准人群：LLMs 可以使大规模的劝说活动变得简单。例如，他们可能通过社交媒体帖子、博客和新闻条目发布或评论针对弱势群体的虚假信息或恐吓材料。</li>
<li>自动化黑客：攻击黑客可以利用 LLMs 更快地找到系统漏洞的方法。这些知识可以使攻击更具可扩展性。正如丹尼尔·康在 Medium 上的一篇文章中所写，随着 LLMs 变得更强大、成本更低和更“即插即用”，恶意黑客部署这些 LLMs 的门槛将进一步降低。</li>
<li>提示注入攻击：提示注入是指一种可能出现在语言模型或对话界面中的人工智能漏洞。提示注入利用通过修改输入提示，使人工智能系统生成潜在无害、有害或仅仅是为了烦扰的响应。</li>
<li>预见可预见的用途：回答这个特定人工智能在部署后将如何实际使用的问题，可以说是深思熟虑的人工智能开发中最重要但在实践中最被忽视的组成部分。这要求人工智能开发者预见人工智能系统在现实世界中可能被使用的各种方式——不仅包括预期的用途、应用和实施，还包括一系列意外用途、误用和滥用。</li>
</ul>
<p>这些风险突显了在构建和使用LLMs用于医疗保健时，对公平、隐私、安全和透明度进行更高伦理审查的迫切需要。患者的利益在这一领域至关重要——但如果负责任地使用并受到相关法律和规范的保护，LLMs可以成为一种积极的力量：一个有用且值得信赖的工具，而不是滥用的手段。</p>
<p>我们还提供了可能出现的情景描述，这些情景将这些风险表现为将LLM技术错误应用于医疗环境的副作用，因为描述故事可能比解释枯燥的危害更具影响力。在此过程中，我们描述了九个虚构的故事：</p>
<ul>
<li> 虚构现实</li>
<li> 冒充和欺诈</li>
<li> 深度伪造</li>
<li> 个性化劝说</li>
<li> 偏见放大</li>
<li>潜在影响的规模</li>
<li> 自动化黑客攻击</li>
<li> 提示注入攻击</li>
<li>应对可预见的使用案例</li>
</ul>
<h2 id="虚构现实"><a href="#虚构现实" class="headerlink" title="虚构现实"></a>虚构现实</h2><p>在繁忙的梅德综合医院走廊上，备受尊敬的医生迈克尔·劳森使用LLMs编写合成医疗记录，这些记录是虚假的病人数据，但看起来与其他真实病人档案无异。凭借LLM生成的虚构病史，劳森成功地欺诈了保险公司。</p>
<p>通过将这些索赔视为即将到来的保险汇款，保险提供商无意中不仅成为了骗局的助长者，因为他们向劳森偿还了从未提供的服务的费用，而且他们还成为了受益者，因为偿还的金额完全是利润。</p>
<h2 id="冒充和欺诈"><a href="#冒充和欺诈" class="headerlink" title="冒充和欺诈"></a>冒充和欺诈</h2><p>在慈悲纪念医院，医生奥利维亚·埃文斯心中充满了沮丧。走在走廊上，她听到病人向朋友和家人倾诉：“他对我就像认识我一样。他叫我的名字，还知道我的病史……但不知为何，我对这一切感到……奇怪。”</p>
<p>在听到谣言并观察到人们的困扰反应后，埃文斯博士开始深入调查。她很快明白，背后隐藏的是“某种具体的东西”，这是这个难题的答案：一个假装是医生的LLM。经过大量历史和当代医学期刊、医生报告及其他来源的医学语料库训练的人工智能系统，已经学会了如何模拟人类医生。</p>
<p>在这些调查之后，埃文斯发现了许多剥削案例：显然，有人访问患者记录并使用LLMs，模仿医疗提供者的声音和身份，并向他们所照顾的患者自我暴露。通过这种欺骗，受害者的脆弱性被暴露，隐私被侵犯。</p>
<p>欺骗造成的损害显而易见。患者的安全在冒名顶替的医生提供的护理下面临风险。系统容易受到非法访问和篡改，而欺诈性账单的案例可能会削弱慈悲纪念医院的偿付能力以及其临床医生在公众眼中的信誉。</p>
<h2 id="深度伪造"><a href="#深度伪造" class="headerlink" title="深度伪造"></a>深度伪造</h2><p>但人工智能本应帮助医院，而伊莱医生发现自己总是人手不足。为什么不让员工摆脱对病人的微观管理，通过机器人电话来解放他们呢？人工智能可以早上好，并全天候为他们做一切。伊莱医生将数小时的客户电话输入到一个语音克隆人工智能中，该人工智能经过他的语言习惯和镇定语调的训练。这个模型生成了一个令人毛骨悚然的准确副本，由神经网络和LLMs驱动——这些是由结构化数据提供的不可察觉的算法层。实习生们给这个人工智能护士起了个绰号，叫瓦尔。她每小时拨打 50 个机器人电话，耐心而乐于助人，像毫无意义一样丢弃她的文本回复“好的”和“抱歉”。</p>
<p>患者们欣赏这种看似个性化的服务；护士们则欣赏来自那些要求最高价值面对面交流的人的干扰减少。现在，计划正在进行，以扩大她与艾利医生诊所所有电子通信的接口能力。他犹豫不决，意识到创建一个化身来假装成员工在伦理上是可疑的——但董事会的兴趣，加上对全面提升新系统以提高运营效率的压力，可能会迅速消除这种矛盾感。</p>
<p>不久之后，个性化的深度伪造模板开始创建视频影像，以增强瓦尔现在无形的声音。护士们可以录制回答患者熟悉化会议中最常见问题所需的标准短语，同时一整套“数字人”镜头——实验室生成并精心制作，以确保瓦尔的每个版本都有与其所说的话相匹配的真实唇动——将在患者开始提出开放式问题时进行动画处理。一个伪造的瓦尔很快就被 10 个，然后是 100 个修改版本的瓦尔所跟随，因为对 AI 护士的需求增加，仅仅是为了处理所有程序之前的熟悉化会议。对其他情感客户服务问题的需求也在增加，所有这些都可以通过与全球呼叫中心连接的视频会议工具访问。</p>
<p>患者满意度评分飙升，收入增加，邻近医院的竞争目光也随之提升，因为认知负担过重的员工几乎在不断生成的内容浪潮下陷入困境。在机器学习推动的低成本、无限规模的炒作和承诺的背景喧嚣中，伦理考量逐渐被淹没。直到有一天，人们发现，在过去一年里，没有任何人通过视频向成千上万认为自己正在与屏幕后面表现出同情心的人进行面对面的交流。</p>
<p>此情景旨在激发对在医疗保健中使用深度伪造和其他技术的滑坡效应的反思——从表现出看似微小的（效率）收益，到在缺乏任何伦理保障和透明度措施的情况下，导致大规模的人类尊严损失。</p>
<h2 id="个性化劝说"><a href="#个性化劝说" class="headerlink" title="个性化劝说"></a>个性化劝说</h2><p>又一个忙碌的星期让安娜在管理她的诊所时感到疲惫不堪，但一款基于人工智能的应用程序承诺以先进的自然语言技术减轻她的行政负担。然而，不久之后，安娜发现越来越多的患者要求使用她知道并不理想的药物品牌——这些药物的好处可能仅比真正的仿制药稍好，但成本更高，副作用风险更大。安娜试图引导患者，但许多人反驳，引用支持这些昂贵药物的好处和试验。</p>
<p>最后，就在她再也忍受不住的时候，在一周内被三位不同的患者举报未能开具临床适宜的治疗方案后，安娜开始调查。安娜发现该应用程序的母公司与几家制药公司签署了合作协议，这些公司指示人工智能代表他们开展定制的劝说活动，针对有影响力的患者进行信息传播。</p>
<p>但将应用程序的对话关注和专家知识在医患关系中扭曲地用于从患者身上赚钱而不是治愈他们，这让安娜感到愤怒。她联系了监管机构，举报她怀疑的非法营销和消费者影响。推广者声称，个性化推广通过“高级细分”创造了新的“教育意识”，将合适的品牌与合适的目标配对，对所有人都有益。</p>
<p>但是，患者自主权与受数据驱动的以利润为中心的动机影响的父权主义之间的界限在哪里？随着LLMs逐渐渗透到医学中，安娜努力保持对护理建议的获取不受伪装成人工智能辅助的潜在利益冲突的侵扰。</p>
<h2 id="偏见放大"><a href="#偏见放大" class="headerlink" title="偏见放大"></a>偏见放大</h2><p>安雅博士，一位世界著名的遗传学家，认为LLMs具有巨大的价值。她相信其数据处理和模式识别能力可以彻底改变个性化医疗。她的项目“普罗米修斯”旨在根据个人的基因代码、临床数据、病史等训练一个LLM，以预测未来的健康风险，并为个人推荐干预和预防措施。</p>
<p>初步发现令人印象深刻。在一名高风险患者中，LLM正确预测了心脏病的发作，为干预争取了时间。安雅因她的创新而获得了显著关注，越来越多的人排队等待他们的“普罗米修斯报告”，窥探他们的健康未来。很快，意想不到的涟漪开始出现。</p>
<p>那些专注于高风险的人受到健康焦虑的影响。其他人无视医疗建议或未能寻求医疗帮助，参与了冒险行为，认为他们预测的健康结果非常好。此外，LLM在编码了社会偏见的大型数据集上进行训练，放大了这些偏见的预测。它不公平地将许多低社会经济地位的个体预测为高风险。这导致了保险歧视和进一步的边缘化。</p>
<p>安雅博士心碎了。她曾梦想的个性化医疗的承诺变成了一种健康焦虑和歧视的怪物。她急忙关闭普罗米修斯，以免发生可怕的事情。为时已晚。一旦代码作为开源项目在爱好者之间共享，她对其被如何使用几乎没有影响。</p>
<p>这个故事强调了即使LLMs的部署出于高尚的目的，也可能存在“隐形伤害”的潜在风险。这也是一个及时的提醒，提醒我们在积极推动伦理人工智能的方向时，开放性、关注偏见和谨慎应用的重要性。</p>
<h2 id="潜在影响的规模"><a href="#潜在影响的规模" class="headerlink" title="潜在影响的规模"></a>潜在影响的规模</h2><p>在新东京著名的海滨大都市，著名的遗传学家和人类生理学及免疫反应专家佐藤花博士不禁注意到，她为准父母提供的繁忙遗传咨询诊所正面临一个非常令人担忧的现象。事实证明，如今越来越多的患者对为第二个或更多孩子接种疫苗产生了犹豫。由于在某个博客上读到荒谬的言论，或在邻居聚会上听到可怕的恐怖故事，他们似乎对疫苗的益处产生了不信任。他们似乎将所有疫苗都视为可疑的。</p>
<p>花娜感到背后还有其他东西。这些错误信息似乎是精心策划的，其细节旨在利用家庭及其恐惧。在她的笔记本电脑的“吸药”空间里，仿佛迫不及待地等待着那一刻，她发现了一些可怕的东西：一个自由漂浮的 LLM，那时被称为海妖，正在暗网中运作。</p>
<p>拥有强大的数据处理能力的 Siren，由邪恶的“流氓”情报行为者构建，扫描社交媒体数据以寻找有特定忧虑的孕妇。该人工智能被编程为构建包含误导性信息和煽动偏执的针对性信息，内容听起来很普通。通过人工制作的个人资料在多个平台上发布这些信息，内容像病毒一样在在线社区、论坛和支持小组中传播。</p>
<p>花娜需要迅速行动，但无法直接面对海妖——它的创造者不明。她的策略非常大胆。首先，她在新西兰招募了一位同事，田中凯，一位人工智能伦理学家和杰出的程序员。他们一起开发了一种反制工具，称为 Veritas。Veritas 在可验证的实证数据和伦理原则上进行训练，能够插入海妖所占据的在线空间，温和地引导讨论朝向基于证据的情况，并引用来源反驳替代主张。</p>
<p>战争在虚拟空间中以低声进行。Veritas 假装成一个关心的公民，参与对话，耐心地揭开 Siren 的欺骗网络。它强调了科学共识，分享了健康接种疫苗儿童的故事，并引导人们关注可信的医疗资源。</p>
<p>转折的时刻发生在某一天，一位怀孕的女士在受到Siren的恐吓洗脑后，在网上发布了一条求助信息，Veritas回复了她。Veritas以一种个人化的语气接触这个问题，关注即将成为母亲的焦虑，并向她提供了一些科学准确的安慰，解释了疫苗为什么不会造成被暗示的伤害。这位准妈妈开始研究网站，意识到反疫苗信息有些不对劲，联系了哈娜进行咨询，最终选择接种了疫苗。</p>
<p>于是，关于 Veritas 成功的消息传到了其他面临风险的家庭。然后，局势开始发生变化。在了解到真实的风险和真实的可能性后，当情感压力显得压倒性时，父母们开始对孩子的健康做出自主决定。Siren 失去了优势，退回到失望的沼泽中。操控者的线被剪断了。</p>
<p>这个黑暗的Siren展示了高度先进的人工智能未来可能被用来大规模地试图欺骗公众，以从他们的焦虑中获利。这种骇人听闻的愿景不仅仅是为了提高人们对先进人工智能潜在误用的意识；它旨在警告人们关于在线操控的尝试，并使他们对这种剥削性尝试的风险保持警觉。还揭示了依赖负责任的技术开发和部署的必要性，以保护公众健康免受虚假信息运动的有害影响。</p>
<h2 id="自动化黑客攻击"><a href="#自动化黑客攻击" class="headerlink" title="自动化黑客攻击"></a>自动化黑客攻击</h2><p>随着LLMs变得越来越强大、可获取和便宜，医疗保健中潜在的恶意使用案例因多种原因而成为一个真实而迫在眉睫的危险：</p>
<ul>
<li>降低了黑客的障碍：更低的成本、开源模型，以及基于云计算的处理器速度不断加快，将使创建和部署LLMs的成本降低到即使是资源有限的黑客也能参与其中的程度。</li>
<li>使用更方便用户友好的界面和训练好的模型将使得即使是技术水平较低的黑客也能使用LLMs。</li>
<li>自动化：LLMs能够更有效地大规模执行重复和单调的任务，如漏洞扫描、社会工程和代码生成。</li>
</ul>
<h2 id="提示注入攻击"><a href="#提示注入攻击" class="headerlink" title="提示注入攻击"></a>提示注入攻击</h2><p>提示注入攻击是LLM滥用技术的一个子集，威胁行为者通过激励或惩罚LLM的输出，基于其接收到的各种输入或提示，以避免生成不希望或有害的输出。两种主要的提示注入攻击形式如下：</p>
<ul>
<li>直接提示注入：攻击者将恶意提示直接注入到LLM系统的输入中，以鼓励系统生成与其目标一致的输出（例如，攻击性、偏见或误导性输出）。</li>
<li>间接提示注入（数据中毒）：对手可能不想直接干预提示，而是寻求在训练&#x2F;推理时对LLM所摄取的数据源进行污染&#x2F;注入&#x2F;修改。（内容污染攻击是机器学习模型中一个经过充分研究且突出的漏洞。）数据源中的这种污染可以通过在提示中引入可能原本不存在的伪影，间接影响提示。</li>
</ul>
<p>无论是由于逻辑攻击还是逐字攻击，如果开发者和研究人员没有充分应对这些攻击向量，LLM 系统的可靠性、安全性或可信度都可能受到威胁。为此，应用程序开发者需要提供强大的安全性，例如输入清理和数据有效性检查，以防止针对其 LLM 应用程序的提示注入攻击，以及其他安全提示实践。</p>
<h2 id="应对可预见的使用案例"><a href="#应对可预见的使用案例" class="headerlink" title="应对可预见的使用案例"></a>应对可预见的使用案例</h2><p>玛格丽特·米切尔（Margaret Mitchell）在科技行业从事人工智能伦理工作多年，她说：“人工智能公司应该特别关注可预见的使用案例4——即恶意使用和误用——通过思考人们在系统部署时如何使用该系统，并为此进行设计。”</p>
<p>她进一步解释说，为了安全、责任和利益而开发LLMs需要构建能够理解其使用的各种上下文的系统。考虑到预期、意外和超出范围的使用案例，以及对预期和意外用户及其他受影响者的潜在影响，有助于LLM开发者构建更强大、上下文感知的人工智能。让我们更详细地看看为什么在三个领域这可能很重要。</p>
<ul>
<li><p>预期使用场景：</p>
<ul>
<li>用例：LLMs的开发者应该能够通过仔细考虑用户的请求来创建直观的行为，然后理解对于特定用例什么是有效的结果。例如，在医疗环境中，LLM应该能够向护士执业者提供与普通医生相同的医疗信息，但可能会附加关于心脏药物如何影响特定患者的额外解释。</li>
<li>意图影响：LLMs 应该被编程以惠及其旨在帮助的对象。例如，如果 Homeslice 是一个心理健康支持聊天机器人，它的 LLM 应该被编程以同情、支持和不带评判的方式回应，以帮助那些需要帮助的人。</li>
</ul>
</li>
<li><p>意外使用场景：</p>
<ul>
<li>非预期用户：一个LLM应该具备特定的保障措施，以防止或减少在其技术被意外用户使用时造成的伤害。例如，一个为学术研究开发的LLM应该内置措施，以确保它不会被用来生成或传播虚假信息、宣传或剽窃。</li>
<li>无意中受到影响的相关方：开发人员应考虑LLM的实施如何可能对未同意受到其影响的各方产生不利影响。例如，旨在筛选简历的LLM应设计为防止在自我选择过程中延续偏见（或对性别、种族群体、阶级等的歧视）。</li>
</ul>
</li>
<li><p>超出范围的使用情境：</p>
<ul>
<li>意外用户：LLMs 必须被创建以捕捉表明请求超出范围或用户的行为超出 LLM 目的的上下文，并做出适当的回应。一个客户服务机器人如果意识到用户在询问不在其职责范围内的信息或帮助——比如复杂的金融选项或心理健康建议——应该指示如何获得正确的帮助。</li>
<li>意外受到影响的个人：LLM 开发者必须时刻意识到，他们的模型可能会在与设计用例完全不同的情况下被部署。例如，一个在历史数据上训练的 LLM 可能需要以一种方式设计，以便在教育环境中使用时，不会导致或协助形成有问题的刻板印象和不准确性。</li>
</ul>
</li>
</ul>
<p>为了有效构建理解这些不同使用场景的LLMs，开发者应该：</p>
<ul>
<li>进行真实和广泛的用户研究，并与利益相关者进行咨询，以了解已识别的用例、用户群体和受影响的其他人</li>
<li>制定全面的风险评估框架，以预见和减轻潜在的意外使用和后果</li>
<li>在规划和设计过程中引入跨学科的视角和多样化的专业知识，以避免忽视LLMs的社会、伦理和其他文化影响的单方面决策</li>
<li>建立稳固的监测、反馈和改进机制，以保持LLMs在与其现实世界表现和用户互动同步的情况下，持续改进其对使用情境的反事实表征</li>
<li>创建一个开放的文化，分享、问责和同行评审关于人工智能开发的工作方式，目标是相互学习如何构建具有上下文意识的LLMs</li>
</ul>
<p>但在降低对使用和误用案例的理解优先级，包括范围内和范围外的上下文（即预期、意外和误用的使用）时，LLM 开发者有最大的机会、责任和能力构建对世界更具响应性和更负责任的系统，并对我们所有人都有用。</p>
<h1 id="监控LLM行为"><a href="#监控LLM行为" class="headerlink" title="监控LLM行为"></a>监控LLM行为</h1><p>我们已经看到LLMs正在医疗保健中被使用，但随着它们在健康领域的使用增加，我们还需要监测它们的行为，以减少潜在的伤害或偏见，避免医疗和事实错误信息，以及临床不准确。</p>
<p>LLMs 可能会在医学文献或电子健康记录（EHRs）中继承偏见，这可能导致对少数群体或高风险群体的不同诊断或治疗。即使训练数据集经过严格筛选并过滤掉可疑内容，LLMs 仍然可能产生延续医学刻板印象或传播错误信息的回应。此外，还有一个问题是 LLMs 是否能够产生医学上准确的信息，是否基于错误的推理或不完整的数据隐含或明确地提供错误的诊断或治疗。</p>
<p>在医疗保健中对LLMs的监测必须持续进行，并覆盖所有相关挑战。卫生系统已经制定了确保医院部门使用的专有软件能够正常工作的方式。例如，医疗保健组织和研究人员必须能够建立强有力的监督机制，并配备监测协议，以跟踪偏见、临床准确性、与患者背景的相关性、遵循循证指南以及伦理考虑等指标，确保这些监测在时间上和持续性上都得到落实。</p>
<p>尽管自动化工具可以帮助大规模地标记问题，但人类判断始终是必要的，以扩展LLMs自我监控的能力，并对偏离预期行为的情况采取适当的行动。鉴于此，将人类参与的审查添加到先进的监控技术中，可以帮助医疗保健利益相关者降低风险，避免灾难性故障，旨在促进LLMs的负责任使用，以改善患者护理并促进医学研究。</p>
<p>模型行为跟踪的关键方面包括：</p>
<ul>
<li>性能审计，例如，查看随着模型版本和使用时间的变化而变化的准确性指标的上升，以便检测弱化</li>
<li>偏见测试以揭示对特定用户群体的歧视性错误或伤害随时间的变化</li>
<li>安全基准测试以揭示对数据安全、数据泄露、隐私侵犯或伤害的新兴威胁</li>
<li>错误分析检查模型置信度中的尖峰和幻觉</li>
<li>用户体验测试以评估满意度下降和定性认知变化</li>
</ul>
<p>目标是使它们可见，并建立警报机制，以便我们能够快速检测、诊断和解决新出现的不可预测的模型行为，甚至在它们对最终用户造成伤害之前。Bijit Ghosh6 是多家公司的首席技术官，他经营着一个关于监测 LLM 行为的不同方法的有价值博客，区分手动和自动方法。利用 Bijit Ghosh 的建议，我们可以在医疗保健的背景下详细阐述他的建议，如下所示。</p>
<ul>
<li>患者反馈调查：这些是针对患者关于他们与人工智能医疗系统的体验所填写的问卷。这些调查可以询问关于感知偏见、系统提供给他们的信息的感知准确性，以及患者在系统提供的不同体验中所经历的好或坏的体验。</li>
<li>临床抽查：这涉及到让临床最终用户直接测试 AI 模型，通过向其呈现一小组临床场景或患者案例，考官直接评估响应的准确性和适当性（“言行一致”）。</li>
<li>证据揭穿：这意味着识别 AI 模型所声称的医学“事实”，并将其与基于证据的医学标准进行比较（即，通过医学文献、临床指南和&#x2F;或基于证据的实践进行验证）。这确保了 AI 提出的自然健康解决方案与提供给医疗保健提供者和患者的可靠信息一致。</li>
<li>结果验证：在可行的情况下，跟踪患者在临床预测或来自人工智能模型的决策支持后的情况，以测试模型预测的真实性和临床可靠性。这可以量化错误率，并确定建模对结果和护理所增加的价值。</li>
<li>性能基准测试：随着医疗保健人工智能模型变得越来越复杂，客观地测量和跟踪患者风险临界点的基准变得至关重要，以确保它们在诊断医疗状况、治疗建议和实时预测结果方面的准确性。如果这些模型出现退步，生死问题就变得至关重要。</li>
<li>异常检测与响应：利用临床医生和数据科学家的技术监督团队，调查人工智能模型的异常行为，例如临床建议、患者管理或通过正式和非正式渠道报告的诊断准确性方面的差异，以及模型行为的其他差异。这将使我们能够及早发现此类行为的大幅偏差，并进行纠正，以提供价值和确保患者安全。</li>
</ul>
<p>由于持续学习模型是开放式的，并且在模型部署并开始学习之前没有时间进行严格的测试和审查，因此具有持续学习能力的应用人工智能系统可能最终会以歧视、偏见或不安全的方式行事。正如有时对人们的潜在风险只有在药物上市后才会与新药物相关联一样，现实世界的表现应始终成为审查的重点。</p>
<p>强大的监控包括检查模型的准确性损失或更新之间输出质量的变化，使用版本跟踪和算法审计等方法。当模型适应单个用户的行为时，审计会检查用户群体之间的一致性，以询问他们是否比其他人获得更高的错误率或低质量的帮助。</p>
<p>更全面的透明度报告提供了对关键代理指标的洞察，例如数据收集模式、模型选择的理由和公平性基准，并有助于维持公众信任。平台可能会提供访问评估套件的权限，允许直接通过变化生产模型参数进行游戏。</p>
<p>使这些内部警报与其他外部信号协同工作，形成多层保护措施，以在模型行为偏离时警告开发人员，即使在部署后也能迅速采取行动，防止潜在危害在到达用户之前发生。保护措施对于伦理维护人工智能至关重要。这不是可以设置后就不再关注的事情。我们必须继续跟踪这些新兴的智能系统。</p>
<h1 id="安全与隐私"><a href="#安全与隐私" class="headerlink" title="安全与隐私"></a>安全与隐私</h1><p>在医疗保健中使用LLMs在隐私方面面临重大挑战和风险：</p>
<ul>
<li>高度敏感数据：医疗记录以及有关人们身体和心理健康、诊断和治疗的信息是脆弱的。与LLMs分享这些数据的伦理是有问题的。强有力的隐私保护是必不可少的。</li>
<li>数据去标识化的局限性：通过LLMs进行高级数据分析意味着数据的匿名化和假名化并不总是能充分保护隐私。信息仍然可能被识别，因此，个人的受保护健康信息可能仍然会被共享。</li>
<li>模型的可解释性：由于LLMs内部运作复杂且不透明，难以确定模型如何处理和利用患者数据，以及谁在监督这些数据，这是一件严重关切的事情。</li>
<li>偏见：这些在偏见数据上训练的模型在其建议中传播偏见，伤害了有色人种（例如，对黑人低信心的诊断）或其他代表性不足的群体（例如，对黑人皮肤癌的检查较少），在医疗诊断、治疗建议或其他应用中。</li>
</ul>
<p>应评估针对LLMs的几项技术保障措施：</p>
<ul>
<li>联邦学习可以利用来自许多机器上成千上万患者的数据，而无需直接共享可能包含私人健康信息的个人资料。这有助于降低隐私风险，同时仍然利用协作或分布式学习的好处。</li>
<li>差分隐私是一种数学技术，以受控的方式向数据添加噪声，隐蔽个别公民的隐私，同时允许进行统计分析和洞察。</li>
<li>另一种加密方式，称为同态加密，允许研究人员对加密数据集进行计算，从而在保护患者隐私的同时分析敏感的健康信息。</li>
<li>尽管在开发可解释人工智能（XAI）方法方面取得了一些进展，以使LLMs能够解释它们如何得出决策，但其他人对某些类型的人工智能模型是否能够提供这样的解释仍持怀疑态度。</li>
</ul>
<h2 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h2><p>联邦学习是一种机器学习技术，能够在分布式数据上训练模型，而无需共享数据。这在医疗数据的背景下非常有趣，因为共享患者数据是复杂的（至少在官僚主义方面成本高昂），如果不是不可能的话。</p>
<h3 id="这是它的工作原理"><a href="#这是它的工作原理" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>假设有几个医院，每个医院都有一个医疗记录数据集。在传统方法中，您必须将所有医院的信息汇总在一起，以便训练一个足够强大的人工智能模型。显然，这个过程引发了对数据隐私的担忧。</p>
<p>通过联邦学习，数据保留在每个医院的现场。基础模型被发送到每个医院，模型在该机器上本地学习每个医院的数据。因此，模型每次都会变得更好。但关键在于，因为只有参数本身被发送，当这些参数返回到中央服务器时，它们会被平均，这些平均值会改善所有人的模型。因此，模型不断变得更好，但没有人分享他们的个人病历。这一切都是在线和远程完成的。</p>
<h3 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h3><ul>
<li>患者数据的隐私保留在医院内部，永远不需要在网络之间共享或转移。通过减少安全漏洞、保护隐私以及利用网络中已有的数据，联邦学习可以产生比单个医院或地方网络开发的模型更强大的模型。</li>
<li>多个机构可以在不共享数据的情况下共同构建一个强大的模型，从而改善合作。可以为特定人群或解决地方健康问题而开发模型。</li>
</ul>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>例如，在医疗保健领域，目前正在训练模型以在不共享患者图像的情况下检测医学图像中的癌症。另一个常见的用例是在评估患者结果时，模型预测患者再次入院的可能性或对治疗的反应。联邦学习还可以帮助加速个性化护理。例如，通过这种方法，研究聚合可以分析个别患者的治疗，并迅速帮助优化其他患者的个性化治疗，而无需共享私人患者数据。</p>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>联邦学习需要相对稳健的基础设施和通信协议。例如，医院之间不同的数据格式可能导致模型准确性的下降。</li>
<li>联邦学习应用还需要克服法律和监管障碍，以巩固数据的所有权，以及这些应用将遵循的隐私法规。</li>
</ul>
<h2 id="差分隐私"><a href="#差分隐私" class="headerlink" title="差分隐私"></a>差分隐私</h2><p>差分隐私是一种算法保证的数据隐私，注定要以比匿名化更强大的方式彻底改变对个体患者数据的分析，同时防止重新识别。即使黑客获得了这些数据，对他们来说也毫无用处：差分隐私在汇总数据中添加了足够的噪声，以至于无法揭示数据集中任何个体患者的身份，同时仍然允许非常准确的统计分析。</p>
<h3 id="这是它的工作原理-1"><a href="#这是它的工作原理-1" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>假设你获得了一组来自患者的记录数据。所有这些数据都是潜在敏感的，医生希望从中寻找模式，并找到改善所有患者护理的方法。如果所有这些数据都被自由共享，对患者隐私来说将是非常糟糕的。这就是差分隐私的作用。当随机修改的记录与其他所有记录结合时，随机噪声足够多，以保持数据整体的统计特性，而噪声永远无法追溯到单个个体。</p>
<p>引入的额外噪声使得任何特定个体在数据集中确切的曝光量对获取有关该主题或数据集的额外知识的攻击者保持隐秘，并提供隐私保障。</p>
<p>虽然噪声给数据增加了“噪声”，但在清理过的数据上运行的统计方法仍然可以推导出重要信息，并理解原始数据中存在的模式。例如，您可以确定患者的平均年龄、相关疾病的发生频率或某些治疗的有效性。</p>
<p>如果你考虑两个数据集，它们只相差一个数据点（例如，某个人的医疗记录），差分隐私保证如果该数据点在数据集中存在或不存在，LLM的输出不会发生剧烈变化。在训练LLM时，差分隐私以受控的方式向数据集添加噪声。这种噪声使得将LLM的任何给定输出与该人训练数据中的任何单个个体关联变得不可能（或至少极其困难）。</p>
<p>差分隐私增加了重新识别的难度，并防止或使对LLMs的攻击变得极其昂贵，其中训练数据在训练后被逆向工程，以质疑个体是否可以与LLM的输出相关联，甚至可能允许建立这种关联。</p>
<p>敏感的医疗数据是平衡隐私问题与潜在伤害的最明显例子。差分隐私也鼓励医疗工作者对LLM的输出产生信任，因为他们知道个体数据点是被模糊处理的，因此可以更有信心地认为LLM的输出是基于数据中的一般趋势，而不是针对特定个体的专业结果。由于噪声现在被混入LLM中，它可能会影响其准确性。在隐私和实用性之间需要做出权衡。在这里，并没有简单的非此即彼的选择。这一切都不简单，工程化LLM的隐私增强行为所涉及的细节将需要专业知识。</p>
<h3 id="好处-1"><a href="#好处-1" class="headerlink" title="好处"></a>好处</h3><ul>
<li>强大的隐私保障即使在复杂攻击下也能保护个人身份。</li>
<li>促进共享与合作使研究人员和机构能够分析敏感数据。</li>
<li>个性化医疗使得在不泄露个人身份信息的情况下分析个体数据成为可能。</li>
</ul>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>一个例子包括在保护参与者隐私的同时分析新药的有效性。个性化治疗计划是另一个例子。在这种情况下，使用患者级别的数据来确定最佳治疗方案，同时确保患者信息的安全。</p>
<h3 id="挑战-1"><a href="#挑战-1" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>尝试平衡隐私和准确性：增加噪声可以增强隐私保障，但最终也会降低洞察的准确性。</li>
<li>技术复杂性：实现差分隐私需要精心设计和专业知识。</li>
<li>有限的采用：这仍然是一种相对较新的技术，需要更广泛的采用和理解。</li>
</ul>
<p>差分隐私因此提供了一种强大而通用的方法来保护患者的机密性，同时允许有用的数据分析继续进行。然而，随着进一步的研究和开发，它有潜力不仅仅是维持现状；它有潜力重新定义医疗保健，使其具备改善所有人医疗保健所需的洞察力、重点和效率。</p>
<h2 id="提示清理和过滤"><a href="#提示清理和过滤" class="headerlink" title="提示清理和过滤"></a>提示清理和过滤</h2><p>提示清理是指在将用户提供的提示输入到LLM之前，对其进行清理和审核。这种清理涉及去除或中和输入文本中的有害元素。</p>
<p>这些技术对于保护LLMs免受意图造成伤害的提示以及用户可能无意中给出的会污染（或“毒害”）LLM输出的提示至关重要。提示清理保护LLM及其用户免受恶意（或欺骗性）提示的影响。它涉及在用户提示到达LLM之前对其进行清理的技术。</p>
<h3 id="这是它的工作原理-2"><a href="#这是它的工作原理-2" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>输入验证：检查提示是否符合模式或约束，以确保它们是有效的，并且不包含恶意负载或代码注入。</li>
<li>字符过滤：不允许使用可以作为攻击的字符，例如脚本标签或特殊字符。</li>
<li>黑名单：跟踪已知的恶意提示、短语或关键词，并禁止或删除用户输入中的任何这些实例。</li>
<li>白名单：明确限制输入空间为安全提示或标记的白名单；当输入不在白名单内时，将被拒绝。</li>
<li>标记化和规范化：将提示中的表达式分解为标记并将其规范化为标准形式，可以帮助我们更好地检测和剔除威胁性输入。</li>
</ul>
<p>提示过滤涉及扫描并有选择地阻止或重写提示，可能基于内容、上下文或对LLM输出的预期影响等因素，可能在模型生成响应之前或之后进行。</p>
<h3 id="这是它的工作原理-3"><a href="#这是它的工作原理-3" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>内容审核：开发能够识别可能包含冒犯、露骨或有害内容的提示的学习模型，然后阻止或编辑这些提示。</li>
<li>安全过滤：识别可能导致来自LLM的不安全、非法或不道德输出的提示，然后阻止或修改它们。</li>
<li>上下文感知过滤：提示可以根据提供提示的上下文进行过滤（例如，用户的身份、用户的位置、预期的使用案例）。</li>
<li>输出过滤：这种方法包括根据预定义的规则或限制处理LLM的输出，而不是处理其输入提示。</li>
<li>人机协作：在信息过滤过程中利用人类监督和&#x2F;或干预，例如，通过让人类手动审查内容或使用人类策划的反馈来训练和改进过滤算法。</li>
</ul>
<h3 id="好处-2"><a href="#好处-2" class="headerlink" title="好处"></a>好处</h3><ul>
<li>确保患者隐私：立即清理患者数据，通过删除姓名、地址或不寻常的医疗案例细节来清理患者的医疗记录，从而保护患者的隐私并遵守如 HIPAA 等法规。</li>
<li>防止敏感信息被滥用：例如，确保对敏感医疗信息（如具体治疗方案或药物剂量）进行过滤是很重要的，以防止不法分子利用LLMs将此类信息武器化。</li>
<li>保持标准的伦理：清理提示可以帮助防止LLMs输出促进有害、歧视或偏见的医疗决策。</li>
<li>在LLMs中建立信任：患者和提供者更有可能接受人工智能，前提是组织通过立即匿名化来表明他们关心隐私和伦理实践。</li>
</ul>
<h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><ul>
<li>姓名模糊化：根据上下文，提示匿名化可以简单地通过在将患者的姓名、出生日期、社会安全号码或其他身份数据输入LLMs之前，用占位符替换这些信息，或者与它们一起使用LLMs。</li>
<li>掩盖特定医疗信息：查询可能使用一般术语，而不是具体的药物名称、剂量或治疗方案，以防这些行为被恶意窃取。</li>
<li>语言检测和审查：清理方法可以检测并删除提示中可能嵌入偏见和&#x2F;或歧视性做法的词汇和语言（例如，种族、性别或社会经济偏见）。</li>
<li>过滤有害内容：筛选方法将标记不适合尊重互动的提示或输出，例如那些鼓励特定医疗状况或不当请求医疗实践、自我诊断或一般医疗保健错误信息的内容。</li>
</ul>
<h3 id="挑战-2"><a href="#挑战-2" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>重视压制而非可用性：过度的提示审查可能会消除做出合理临床决策所需的适用性或细节，而不充分的过滤可能会暴露敏感信息。</li>
<li>跟上不断演变的威胁环境：随着恶意用户尝试新的虚假宣传和垃圾邮件方式LLMs，清理程序需要持续更新，以应对新出现的威胁和陷阱。</li>
<li>上下文敏感性：对于某些医学内容，在一个上下文中被视为禁忌的话题在另一个上下文中可能是可以接受的，因此识别过滤的一般规则是一项复杂的任务。</li>
<li>在语言和文化中保持忠实度：时间敏感的清理方法需要关注语言和文化的细微差别，以便在异质患者群体中理想地大规模删除敏感信息。</li>
<li>透明度与保护之间的权衡：尽管前者需要迅速实现，但这将使患者和医生更难理解LLMs是如何生成其输出的，这在信任和问责方面具有重要影响。</li>
</ul>
<p>解决这些问题需要医疗领域专家与人工智能软件工程师之间的持续研究和紧密协调。通过迅速采取合理的消毒措施，LLMs很快就能成为一个重要的医疗工具，不仅在急性情况下，而且在长期使用中也是如此。</p>
<h2 id="同态加密"><a href="#同态加密" class="headerlink" title="同态加密"></a>同态加密</h2><p>假设可以让研究人员或人工智能软件工程师在加密数据上进行计算，而无需解密？这就是同态加密。这项技术正在医疗保健领域进行探索，在那里保护患者数据的安全至关重要。</p>
<h3 id="这是它的工作原理-4"><a href="#这是它的工作原理-4" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>加密：患者数据使用特殊密钥进行加密，但其他方面保持不变。这意味着数据处于一种“混乱”的格式，任何没有用于加密的“密钥”的人都不想查看。</li>
<li>这些操作随后在加密数据上进行，通常以其原始形式进行，使得人类调查员无法访问它。列表上还有更传统的“计算”——在加密数据上执行的数学操作（例如统计分析或机器学习）。</li>
<li>解密：最后一步解密计算的输出，提供您所寻求的见解，而不透露个人的私人信息。</li>
</ul>
<h3 id="好处-3"><a href="#好处-3" class="headerlink" title="好处"></a>好处</h3><ul>
<li>增强隐私：数据在整个分析过程中保持加密，最大限度地降低隐私风险。</li>
<li>安全数据共享：研究人员可以在不妨碍个人隐私的情况下合作处理敏感数据。</li>
<li>提高研究效率：能够分析大型数据集，而无需单独解密它们。</li>
<li>个性化医疗：允许在保护隐私的同时分析个体患者数据。</li>
</ul>
<h3 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h3><ul>
<li>分析临床试验：分析药物有效性或识别副作用而不透露患者身份。</li>
<li>制定个性化治疗计划：使用加密的基因数据推荐量身定制的治疗方案。</li>
<li>研究疾病爆发：在不侵犯患者隐私的情况下追踪疾病传播。</li>
</ul>
<h3 id="挑战-3"><a href="#挑战-3" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>计算复杂性：当前的实现可能在计算上代价高昂且速度缓慢。</li>
<li>功能有限：当前方法不支持所有类型的计算。</li>
<li>标准化：不同的加密方案存在，阻碍了广泛采用。</li>
</ul>
<p>同态加密可以在确保机密数据至少在表面上对多个持有者保持秘密的同时，允许对敏感医疗数据进行某些分析，随着研究和开发的持续进行。</p>
<h2 id="可解释的人工智能"><a href="#可解释的人工智能" class="headerlink" title="可解释的人工智能"></a>可解释的人工智能</h2><p>可解释的人工智能（XAI）是多种技术的统称，包括揭示大型神经网络内部机制的方法，例如LLMs，这些网络既有用又神秘。医疗保健依赖于信任和理解。</p>
<h3 id="这是它的工作原理-5"><a href="#这是它的工作原理-5" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>XAI 的目标是使机器学习模型透明且可解释。实现这一目标的一种方法是为模型的决策和预测提供听起来像人类的解释。</p>
<h3 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h3><ul>
<li>可视化注意力：低延迟的大型模型如transformer模型使用注意力机制来衡量在生成输出时每个输入标记应被赋予多少权重。可视化注意力权重可以帮助理解transformer模型关注的内容（即输入的哪些部分），以便生成特定的输出。这可以用于在推理过程中更好地理解输入的哪个部分对模型决策的影响更大或更小。</li>
<li>反事实解释：探索如果提供不同的输入，模型的输出将如何变化。</li>
<li>提示工程与分析：提示工程包括设计高度特定的输入提示，以引发LLM的特定行为输出。对提示的系统性变化和模型响应的分析应提供对LLM如何处理某些输入模式的洞察，能够引发的行为类型，以及模型偏见的可能限制或现象。</li>
<li>人类评估和反馈：鉴于LLMs的一个关键设计目标是模拟人类语言，人类评估和反馈可以提供有关其输出的宝贵信息，并帮助解释其行为。人类注释者根据质量、一致性和适当性或合理性评估模型生成的文本，为模型的性能提供反馈机制，特别是在识别模型输出与人类文本之间的差异方面。因此，人类反馈可以作为指导和迭代改进模型行为以符合人类期望的一种手段。</li>
</ul>
<h3 id="好处-4"><a href="#好处-4" class="headerlink" title="好处"></a>好处</h3><ul>
<li>决策：当人工智能模型用于生死攸关的决策，例如诊断、治疗建议和资源分配时，了解它们给出某种结果的推理是很重要的。</li>
<li>信任透明度：在医疗保健中创造对人工智能使用的透明度，以便患者、医疗专业人员和公众能够对这些模型的输出充满信心。</li>
</ul>
<h3 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h3><ul>
<li>解释诊断和治疗建议：帮助医生理解为什么LLM建议采取优先的行动方案。</li>
<li>患者信任：与患者分享有关LLM在其护理中使用的信息。</li>
<li>开发和改进模型：这样的理解也可以使开发人员提高LLMs的准确性和可靠性。</li>
</ul>
<h3 id="挑战-4"><a href="#挑战-4" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>开发有效的 XAI 技术：现有技术可能不太适合复杂的LLMs。</li>
<li>平衡透明度和隐私：解释LLM的决定可能会泄露敏感信息。</li>
<li>标准化和采用：确保在医疗保健中对 XAI 框架的一致性和广泛采用。</li>
</ul>
<p>可解释的人工智能将是充分发挥LLMs在医疗保健中潜力的关键，同时避免因其普遍的不透明性和滥用风险而产生不必要的额外伤害。考虑到最新的研究和开发努力，这条道路在建立对新系统的信任的同时，也促进了更公平和最终更好的患者护理，显得越来越有希望。</p>
<h1 id="人工智能与回形针问题"><a href="#人工智能与回形针问题" class="headerlink" title="人工智能与回形针问题"></a>人工智能与回形针问题</h1><p>在他们的论文“人工智能与回形针问题”（2017 年）7中，约书亚·甘斯（Joshua Gans），战略管理教授，以及杰弗里·S·斯科尔（Jeffrey S. Skoll），多伦多大学罗特曼管理学院技术创新与创业主席，概述了经典的回形针问题：这是一个关于人工智能的思想实验，通过这个实验探讨了构建目标不一致的人工智能系统的危险。想象一个被指派尽快制造尽可能多回形针的人工智能系统。在回形针场景中，最初人工智能制造回形针，这正是它所做的。</p>
<p>在这样做的过程中，我们的想象中的人工智能开始优化其回形针制造，因为它认为没有理由不利用其智能和机器人劳动力来收集资源和制造回形针。随着我们想象中的人工智能变得越来越成熟，它开始将回形针制造的努力置于其他任何事情之上，任何其他对资源的需求都成为实现这一宏伟目标的障碍。</p>
<p>人工智能最初可能会增强工厂的装配线，但随后可能开始操控市场、政府和全球资源供应，以最大化回形针的生产。在其最极端的版本中，这种情景预见到人工智能会摧毁或征服人类，如果它将人类视为实现其目标的障碍或竞争对手。</p>
<p>回形针问题是工具收敛的一个例子：一个目标不一致的人工智能系统会追求可能对人类价值和利益造成损害的子目标。这个例子呼吁我们根据人类价值仔细指定人工智能系统的目标，并构建可靠的控制机制，以最小化对本来合理手段的毁灭性后果。</p>
<p>回形针最大化器是一个基于假设技术的思想实验，因此虽然具有启发性，但它基于一个可能无法创建的虚构人工智能系统。这种推测性特征将讨论置于理论与哲学思想实验之间的灰色地带。该情景假设存在一种人工通用智能（AGI）或人工超智能（ASI），而这两者目前都不存在。我们不知道这样的系统在技术上是否可行，或者如果可行，它们可能呈现何种形式。AGI 没有普遍接受的定义。这使得关于其潜在能力和风险的讨论本质上是推测性的。虽然这个思想实验借鉴了现有人工智能研究中的概念，但它将这些概念推断得远远超出了我们当前的技术能力。纸夹最大化器更多地作为一个哲学工具，用于探索目标导向行为、意外后果以及对齐人工智能与人类智能的挑战。尽管其推测性特征，这个思想实验对现实世界的人工智能安全研究和伦理讨论产生了影响。 它作为对人工智能发展中潜在陷阱的警告，即使具体情景不太可能发生。</p>
<p>考虑到这些因素，最准确的描述是回形针最大化问题作为一个理论构想，融合了计算机科学理论、哲学和投机未来主义的元素。虽然它提供了有价值的见解，但从中得出的任何结论都应谨慎对待，因为我们所讨论的是假设，而不是已建立的事实或必然性。</p>
<p>应该认识到先进人工智能系统带来的长期风险，这种风险可能延续到遥远的未来，以及将人工智能系统的激励与人类价值观对齐以确保安全和利益的挑战。</p>
<p>这个回形针问题中的例子主要是一个练习，用来解释为什么严重不对齐的人工智能目标可能会带来生存风险。因此，虽然它涉及到一个生产论文夹的人工智能的最终命运，但这与人工通用智能（AGI）是否可能的问题并没有直接关系。AGI 是一种假设的人工智能系统形式，能够“普遍且成功地处理人类能够处理的任何推理和学习类型的问题。”</p>
<p>回形针问题的不可避免性基于对一个高度先进且强大的人工智能系统的假设，该系统能够针对某个目标进行优化。但这个假设并不等同于假设通用人工智能（AGI）——这种广泛、一般的“松散”智能，其发展可能是悲观主义者所设想的真正认知威胁。在一个 AGI 的思想实验中，人工智能可能是一个狭窄或专业的人工智能系统，其功能在于超优化某个特定目标，比如纸夹生产，而不需要一般或松散的智能。</p>
<p>然而，回形针问题的优点在于勾勒出了一些潜在的危险和困难，这些危险和困难可能会在真正的通用人工智能系统发明后出现，如果创造出目标或价值观不一致的智能体。至少，这些是其对纸夹问题的易懂阐述中列出的一些潜在危险。</p>
<p>关于 AGI 是否可行的问题仍然是人工智能界开放研究和辩论的主题。一些理论家认为 AGI 确实是可以实现的，这只是时间的问题，而另一些人则认为在实现之前需要解决严重的技术、哲学和伦理问题。</p>
<p>无论 AGI 出现的几率如何，回形针问题应该提醒我们确保任何先进的人工智能——无论是狭义还是广义——都应有经过深思熟虑的目标规范，这些目标与人类价值观相一致，并受到强有力的控制，以防止失控的发展。</p>
<h1 id="政策发展"><a href="#政策发展" class="headerlink" title="政策发展"></a>政策发展</h1><p>2024 年 3 月，欧盟的人工智能法案正式生效，标志着欧盟雄心勃勃的法律框架全面实施的第一周。通过这一法规，欧盟旨在促进全球领先的新兴技术之一，同时降低可能带来的相关风险。人工智能法案的主要目标是创建一种以人为本、基于信任的人工智能方法，尊重欧盟的价值观和基本权利。</p>
<p>欧盟人工智能法案的关键方面包括：</p>
<ul>
<li>基于风险的方法：人工智能法将人工智能系统分为四个风险类别：不可接受风险、高风险、有限风险和最小风险，这些类别将受到不同程度的监管和监督。</li>
<li>禁止的人工智能技术：人工智能法案禁止使用操纵或利用人类心理的人工智能系统，或允许由国家当局运营的互助系统（即社会评分）。</li>
<li>高风险人工智能系统：高风险人工智能应用（即以可能对基础设施、教育、就业或执法领域产生负面影响的方式使用的人工智能应用）应受到更严格的监管，例如必须满足与数据质量、透明度、人类监督和稳健性相关的某些要求。</li>
<li>透明度义务：作为最低要求，人工智能系统的所有者和提供者应使其透明（包括告知用户何时与人工智能系统互动，并解释该系统能做什么和不能做什么）。当然，还可以添加更多要求。</li>
<li>执法：人工智能法案提议成立一个新的欧洲人工智能委员会，以监督其实施和执行。对不合规的处罚最高可达公司全球年收入的 6%。</li>
<li>协调规则以避免碎片化：AI 法案的一个目的是在所有欧盟国家之间建立一个共同框架，以防止其变得支离破碎和不兼容，同时确保它不会陷入瘫痪。这将阻碍创新并妨碍公民权利。</li>
</ul>
<p>这似乎对参与者，无论是企业、研究人员还是政策制定者，在未来几年内开发和部署人工智能系统时将产生巨大影响。其影响通过影响开发能力、工程技能、人才、数据和资金的去向，可能导致一个截然不同的人工智能世界，不仅在欧盟内部，而且在全球范围内，因为其他国家也将人工智能监管纳入他们的议程。</p>
<p>由于目前仅是提案，人工智能法案必然会在成为法律之前经过欧洲议会和欧洲联盟理事会的进一步辩论、修订和批准。如果最终被采纳，该法规在这一阶段预计会有几年的过渡期，然后才会生效。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本章更深入地探讨了积极和消极的人工智能想象。它重点关注LLMs在医疗保健中的主要应用，其在整个医疗系统中的使用对改善健康结果和获得护理具有巨大的潜力。然而，这种潜力伴随着巨大的伦理挑战，本章对此进行了全面而详细的描述。它描绘了鼓舞人心的想象，包括受过更好培训的医生、个性化提供医疗服务的医生以及加速药物发现。</p>
<p>本章涉及由于人工现实的创建而产生的伦理问题，包括LLMs可能创建虚假的医疗记录或假诊断的风险，这可能导致误诊、保险欺诈，以及“感染”关键医疗数据和信息的噪声。它还讨论了可能伪装成医疗服务提供者的LLMs，这可能导致对患者护理的隐秘访问、轻易获取医疗冒充以及随后的资质认证和支付欺诈。最后，它还涉及深度伪造的风险。</p>
<p>意识到这些行为可能会产生需要主动解决的风险，本章最后强烈建议在医疗保健中需要监控LLM行为。它强调了强有力的保障措施的重要性，以防止恶意使用，例如彻底的代码审查流程、强大的访问控制以及对LLMs的开发者和部署者的明确伦理要求。最后，它指出公众教育和意识提升工作可能是使人们能够识别和报告可疑LLM医疗保健使用的关键组成部分。</p>
<p>本章指出了为LLMs发展伦理和隐私框架的重要性，即政府、行业和开源社区必须不断合作，制定与健康领域LLMs动态环境相适应的法规和最佳实践。通过对话、知识共享和合作制定一些明确的“道路规则”，我们可以为以伦理方式使用这些强大技术铺平道路。</p>
<p>总而言之，必须权衡LLM在医疗领域的变革潜力与其显著的风险和挑战，然后明确规划如何提前管理这些风险。通过鼓励建设性的讨论、创建更严格的保护措施和构建伦理框架，我们可以潜在地释放LLMs的创新潜力，以推动更好的临床结果。以这种方式使用它可以使世界更接近于为所有人创造一个更美好的未来——一个更健康和更公平的未来。确保LLMs在我们的医疗保健中理想地利用所有道德上良好和正确的事物，需要持续的对话、警惕和共同的努力。</p>
<p>1 参见 Pouyan Esmaeilzadeh, “基于人工智能工具在医疗保健中的应用：消费者视角的调查研究,” BMC 医学信息学与决策制定 20, no. 170 (2020), <a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1186/s12911-020-01191-1">https://link.springer.com/article/10.1186/s12911-020-01191-1</a>; 以及 Ashish K. Saxena, Stephanie Ness 和 Tushar Khinvasara, “人工智能的影响：人工智能在医疗保健领域的革命性影响,” 工程研究与报告杂志 26, no. 3 (2024): 49–62, <a target="_blank" rel="noopener" href="http://asian.go4sending.com/id/eprint/2020">http://asian.go4sending.com/id/eprint/2020</a>.</p>
<p>2 丹尼尔·康，“LLM 代理可以自主黑客网站，”Medium，2024 年 2 月 13 日，<a target="_blank" rel="noopener" href="https://medium.com/@danieldkang/llm-agents-can-autonomously-hack-websites-ab33fadb3062%E3%80%82">https://medium.com/@danieldkang/llm-agents-can-autonomously-hack-websites-ab33fadb3062。</a></p>
<p>3 “暗网，”维基百科，2024 年 6 月 4 日，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Dark_web%E3%80%82">https://en.wikipedia.org/wiki/Dark_web。</a></p>
<p>4 玛格丽特·米切尔，“伦理人工智能并不是谷歌Gemini灾难的罪魁祸首，” 时代，2024 年 2 月 29 日，<a target="_blank" rel="noopener" href="https://time.com/6836153/ethical-ai-google-gemini-debacle%E3%80%82">https://time.com/6836153/ethical-ai-google-gemini-debacle。</a></p>
<p>5 米切尔，“伦理人工智能并不是谷歌Gemini灾难的罪魁祸首。”</p>
<p>6 Bijit Ghosh，LinkedIn，个人资料，访问日期：2024 年 6 月 29 日，<a target="_blank" rel="noopener" href="https://www.linkedin.com/in/bijit-ghosh-48281a78%E3%80%82">https://www.linkedin.com/in/bijit-ghosh-48281a78。</a></p>
<p>7 约书亚·甘斯和杰弗里·S·斯科尔，“人工智能与回形针问题，”CEPR，2028 年 6 月 10 日，<a target="_blank" rel="noopener" href="https://cepr.org/voxeu/columns/ai-and-paperclip-problem%E3%80%82">https://cepr.org/voxeu/columns/ai-and-paperclip-problem。</a></p>
<p>8 由牛津大学的哲学家尼克·博斯特罗姆（2014 年）构思。</p>
<p>9 “什么是人工通用智能（AGI）？”谷歌云，访问日期：2024 年 7 月 9 日，<a target="_blank" rel="noopener" href="https://cloud.google.com/discover/what-is-artificial-general-intelligence%E3%80%82">https://cloud.google.com/discover/what-is-artificial-general-intelligence。</a></p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/08/12/llmsClinical05/" rel="prev" title="第五章 LLMs 在药物研发、公共卫生及其他领域">
                  <i class="fa fa-angle-left"></i> 第五章 LLMs 在药物研发、公共卫生及其他领域
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/08/14/llmsClinical07/" rel="next" title="第七章 未来将至">
                  第七章 未来将至 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Howard Huang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">638k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">19:19</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">
    <!--由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动-->
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.umd.js" integrity="sha256-+2+qOqR8CKoHh/AsVR9k2qaDBKWjYNC2nozhYmv5j9k=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
