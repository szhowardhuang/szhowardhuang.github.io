<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"szhowardhuang.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="在 C. M. Kornbluth 的短篇小说《小黑包》中，挣扎中的医生福尔博士发现了一个来自未来的神秘医生包，里面装满了先进的医疗设备和药物。这些未来的设备增强了他作为医生的能力，使他能够以前所未有的效率诊断和治疗病人。当他探索包内的内容时，福尔博士对未来医疗创新的潜力感到惊叹，仿佛自己正站在医疗革命的边缘。 然而，C. M. Kornbluth的故事并不仅仅是对医学进步的庆祝。随着故事的发展，">
<meta property="og:type" content="article">
<meta property="og:title" content="第一章 医生的黑色手提包">
<meta property="og:url" content="https://szhowardhuang.github.io/2024/08/08/llmsClinical01/index.html">
<meta property="og:site_name" content="嵌入式老兵博客">
<meta property="og:description" content="在 C. M. Kornbluth 的短篇小说《小黑包》中，挣扎中的医生福尔博士发现了一个来自未来的神秘医生包，里面装满了先进的医疗设备和药物。这些未来的设备增强了他作为医生的能力，使他能够以前所未有的效率诊断和治疗病人。当他探索包内的内容时，福尔博士对未来医疗创新的潜力感到惊叹，仿佛自己正站在医疗革命的边缘。 然而，C. M. Kornbluth的故事并不仅仅是对医学进步的庆祝。随着故事的发展，">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-08-08T03:32:19.000Z">
<meta property="article:modified_time" content="2024-08-08T03:37:23.000Z">
<meta property="article:author" content="Howard Huang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://szhowardhuang.github.io/2024/08/08/llmsClinical01/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://szhowardhuang.github.io/2024/08/08/llmsClinical01/","path":"2024/08/08/llmsClinical01/","title":"第一章 医生的黑色手提包"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>第一章 医生的黑色手提包 | 嵌入式老兵博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">嵌入式老兵博客</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#LLMs%E5%92%8C%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%BD%9C%E5%8A%9B"><span class="nav-number">1.</span> <span class="nav-text">LLMs和生成式人工智能的潜力</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LLMs%E5%9C%A8%E5%8C%BB%E7%96%97%E4%BF%9D%E5%81%A5%E4%B8%AD%E7%9A%84%E6%89%BF%E8%AF%BA%E4%B8%8E%E5%8F%AF%E8%83%BD%E6%80%A7"><span class="nav-number">2.</span> <span class="nav-text">LLMs在医疗保健中的承诺与可能性</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E5%8C%BB%E7%96%97%E7%91%9E%E5%A3%AB%E5%86%9B%E5%88%80%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F"><span class="nav-number">2.1.</span> <span class="nav-text">消费者医疗瑞士军刀应用程序</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%B4%E5%BA%8A%E5%8C%BB%E7%94%9F%E5%8C%BB%E7%96%97%E5%90%91%E5%AF%BC%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F"><span class="nav-number">2.2.</span> <span class="nav-text">临床医生医疗向导应用程序</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LLMs%E7%9A%84%E6%96%B0%E5%85%B4%E7%89%B9%E5%BE%81"><span class="nav-number">3.</span> <span class="nav-text">LLMs的新兴特征</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E9%99%90%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8F%90%E7%A4%BA"><span class="nav-number">3.1.</span> <span class="nav-text">无限上下文提示</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E6%8E%A8%E7%90%86"><span class="nav-number">3.2.</span> <span class="nav-text">代理推理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E6%8E%A8%E7%90%86%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.2.1.</span> <span class="nav-text">代理推理的四种模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%91%E6%88%98%E4%B8%8E%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="nav-number">3.2.2.</span> <span class="nav-text">挑战与未来方向</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8LLMs%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="nav-number">4.</span> <span class="nav-text">使用LLMs的上下文</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E5%92%8C%E5%95%86%E4%B8%9A-LLMs"><span class="nav-number">5.</span> <span class="nav-text">消费者和商业 LLMs</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85LLMs%E5%92%8C%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="nav-number">5.1.</span> <span class="nav-text">消费者LLMs和生成式人工智能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%95%86%E4%B8%9ALLMs%E4%B8%8E%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="nav-number">5.2.</span> <span class="nav-text">商业LLMs与生成式人工智能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A5%E5%90%88%E9%B8%BF%E6%B2%9F"><span class="nav-number">5.3.</span> <span class="nav-text">弥合鸿沟</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E7%9A%84%E5%92%8C%E7%9B%AE%E6%A0%87"><span class="nav-number">5.3.1.</span> <span class="nav-text">目的和目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83"><span class="nav-number">5.3.2.</span> <span class="nav-text">数据训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%91%E7%AE%A1%E7%8E%AF%E5%A2%83"><span class="nav-number">5.3.3.</span> <span class="nav-text">监管环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%A6%E7%90%86%E4%B8%8E%E5%81%8F%E8%A7%81"><span class="nav-number">5.3.4.</span> <span class="nav-text">伦理与偏见</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">6.</span> <span class="nav-text">摘要</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Howard Huang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">69</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/08/llmsClinical01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="第一章 医生的黑色手提包 | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第一章 医生的黑色手提包
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-08 11:32:19 / 修改时间：11:37:23" itemprop="dateCreated datePublished" datetime="2024-08-08T11:32:19+08:00">2024-08-08</time>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>29k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>52 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>在 C. M. Kornbluth 的短篇小说《小黑包》中，挣扎中的医生福尔博士发现了一个来自未来的神秘医生包，里面装满了先进的医疗设备和药物。这些未来的设备增强了他作为医生的能力，使他能够以前所未有的效率诊断和治疗病人。当他探索包内的内容时，福尔博士对未来医疗创新的潜力感到惊叹，仿佛自己正站在医疗革命的边缘。</p>
<p>然而，C. M. Kornbluth的故事并不仅仅是对医学进步的庆祝。随着故事的发展，显而易见，这种强大的技术在错误的手中可能被利用来谋取个人利益，而不是为了更大的利益。这个叙述提醒我们，尽管未来的医学进步在其能力上看似神奇，但它们也伴随着重大的伦理责任和潜在的滥用风险。这个虚构的故事促使我们思考，随着医学技术和人工智能（LLMs及生成式人工智能）的快速发展，未来既有令人兴奋的可能性，也面临伦理挑战。</p>
<p>人工智能和LLMs有潜力提升临床护理，特别是在增强临床医生决策过程、改善患者与医生的互动、简化行政任务、提高患者教育和参与度方面，最终导致更好的健康结果。根据纽约著名医院网络纽约长老会医院的一位高级医疗执行官，通过利用多模态LLMs的能力，医疗机构有潜力开发复杂的虚拟医疗助手，这些助手可以主动监测患者健康并协助诊断。</p>
<p>正如传统的黑色手提包为医生提供了提供优质护理所需的基本工具，人工智能也准备成为一项不可或缺的资产，帮助临床医生为患者提供更个性化、高效和基于证据的护理。本章探讨了使用LLMs改善患者护理的可能性——特别是在临床医生和患者受益最多的地方。</p>
<p>LLMs 是自然语言处理 (NLP) 机器学习模型，似乎能够理解并生成人类语言文本。LLMs 是一种人工智能 (AI)，能够以卓越的能力理解和操控人类语言。它们被称为“大型”，因为它们是在大量文本数据上训练的，通常是数十亿个单词，这使它们能够学习人类语言的细微差别。</p>
<p>对于临床医生来说，LLMs 可以被视为先进的语言处理工具，能够协助处理涉及医疗数据的各种行政任务（如电子健康记录 [EHRs] 或非结构化的医生笔记）。正如听诊器和 X 光机扩展了临床医生评估患者健康的能力，LLMs 可以增强临床医生分析和解读大量研究数据或嵌入视频的电子邮件，或患者的历史健康记录、临床笔记、出院总结等的能力。</p>
<p>生成式人工智能是人工智能的一个子集或类型，就像LLMs和机器学习是人工智能的类型一样。生成式人工智能专注于创建新的内容，例如文本、图像、视频或音频，通常是为了回应用户的问题。生成的输出在风格和结构上往往类似于人类创作的内容。</p>
<p>当我们在本书中使用诸如LLMs或生成式人工智能这样的短语时，我们是作为涵盖广泛人工智能系统的统称，即使它们具有不同的属性或采用不同的机器学习算法。这些统称包括但不限于LLMs、小型语言模型、多模态模型和生成式人工智能。</p>
<p>这些模型是在大量我们的书面信息（例如，书籍、文章和网站）以及世界上大量主题上进行训练的。这使它们能够理解句子和段落中单词之间的关系、章节中积累的意义、叙事弧线所表现出的整体进展等等。</p>
<p>当 OpenAI 在 2022 年发布其语言模型 ChatGPT 时，它改变了对话式人工智能，解放了自然语言处理，为大众提供了一个简单的网络界面，使人类般的对话和问答成为可能。这LLM因其能够进行类人对话、回答问题、代写论文以及执行各种任务而在全球范围内获得了广泛的欢迎。它引起了科技公司首席执行官对技术对商业和日常生活影响的兴趣。但让我们提醒自己，应该如何看待使用LLMs。</p>
<p>一篇 2023 年的博客讨论了 ChatGPT 实验，提供了关于我们应该如何思考和使用LLMS的见解。如果我们将LLMs视为总结工具，并将它们的提示词视为该过程的锚点，而不是对另一个有知觉的存在的命令，那么我们可以在医疗保健中有效地使用这些工具。我们在关键词搜索的简洁约束下做了类似的事情：我们学习并仍在学习如何“引导”搜索朝向我们想要的任何内容。自几十年前搜索出现以来，我们已经学会了如何用语言锚点来构造问题，这些问题很可能会引导搜索朝向他们想要的内容。我们可以对LLM提示词做同样的处理，将它们视为总结的锚点，而不是规范，从而更好地聚焦。一旦我们将LLM提示词视为总结的锚点，我们就可以一方面通过将总结任务嵌入模型的知识库中，另一方面在提示词定义的任务范围内更有效地引导它们。</p>
<p>随着我们对LLMs的理解不断加深，夸大其词的说法需要和如何在医疗保健中构建和利用LLMs的现实评估相平衡。LLMs是统计自回归模型，是一种机器学习模型，能够根据上下文预测下一个单词。例如，假设你是一位正在写故事的作者。你有一个写作助手，它根据你已经写的单词为你提供下一个合适的单词。这个助手阅读了许多不同类型的故事，因此它大致知道单词是如何相互关联的，以构成一般有用的句子和更复杂的叙述。借助这个写作助手，你不断写作，不断接受建议，故事从一个单词到另一个单词，逐渐变得更长。每一步，下一个单词都是基于之前写的单词而来的。这本质上就是自回归模型的工作原理：它从现有数据中学习，并基于之前的数据序列一步一步生成（或预测）新数据。</p>
<p>Gemini，ChatGPT，Claude.AI，以及其他自回归LLMs提供了类似人类推理的错觉，能够对细微或复杂的提示给出惊人的回应。它们甚至似乎像人一样，提供看似情感的反应和同理心的理解。这些错觉因我们的认知偏见而变得更加可信，即我们倾向于将事物、动物和人工智能拟人化。下一章，第 2 章，更具体地讨论了LLMs的工作原理，包括明确的细节，如tokens、参数等。</p>
<h1 id="LLMs和生成式人工智能的潜力"><a href="#LLMs和生成式人工智能的潜力" class="headerlink" title="LLMs和生成式人工智能的潜力"></a>LLMs和生成式人工智能的潜力</h1><p>尽管现有的医疗LLMs在某些方面已经令人印象深刻且有用，但发展仍处于早期阶段，这些创新仅实现了转变我们提供医疗服务潜力的一小部分。目前的发展强调减少临床医生的负担和文档工作——但这仍然只是对医疗服务交付的LLM影响的开始。已经有完整的医疗特定版本发布，但由于各种原因，它们尚未在临床护理的交付方式上产生显著影响。</p>
<ul>
<li>数据可用性和质量: LLMs 在大量数据集上进行训练，它们的性能将取决于用于训练的数据质量。在医学领域，数据通常分布在多个来源，例如电子健康记录（EHR）、医学期刊和随机临床试验。此外，数据需要完整、准确或一致，这会影响 LLMs 的表现。</li>
<li>偏见与公平: LLMs 从有偏见的数据中学习，这意味着它们是在反映现实世界偏见的数据上进行训练的。这可能导致在我们为某些患者群体提供护理时转移和强化已经存在的强烈偏见。例如，一个在有偏见的医疗记录数据集（例如，包含特定种族或民族群体数量较少的数据集）上训练的 LLM 也可能生成有偏见的建议。在讨论偏见时，重点是系统是否按预期正常工作。减轻偏见通常对系统功能和成功使用至关重要。</li>
<li>可解释性和可说明性: 实现可解释性或可说明性一直是人工智能最显著的谦逊姿态之一。LLMs 通常被视为“黑箱”，这指的是它们的“内部工作”被压缩在一起，以至于整体操作难以理解。在医学中，缺乏可解释性和可说明性是一个问题，因为如果我们不知道它们为何得出某些建议，就会对采用 LLMs 存在巨大的抵触情绪。结果可能是这些建议并不像人们希望的那样合理，因为它们结论的基础根本上是有缺陷的。</li>
<li>监管环境: 在医学领域，人工智能发展的一个关键挑战是监管空白。目前没有明确的指导方针可以突破繁文缛节，定义在医疗保健中开发和部署LLMs的含义。这种不确定性有效地抑制了在医学复杂和高风险环境中尝试使用人工智能的热情，因为几乎没有先例可以指导医疗保健组织在这些情况下如何行动。如果他们能够这样做，他们可能会担心违反某种法律限制或合规问题。</li>
<li>伦理环境: 一般来说，关于在医学中使用LLMs的担忧包括潜在的误用、患者自主权的侵蚀和患者隐私的侵犯。在可以在医疗保健中使用LLMs之前，必须考虑与潜在误用、人类自主权的妥协和患者隐私相关的伦理问题。</li>
</ul>
<p>LLMs 明确地建模了单词与意义之间的关系，涵盖长篇文本，从而实现更流畅的文本理解和内容生成。此外，它们与更原始的语言模型不同，后者由于数据规模和模型参数化的限制，只能将单词连接成文本模式。第 2 章 详细介绍了 LLMs 的工作原理，解释了参数、tokens等内容。</p>
<p>现有的医疗和其他LLMs在许多方面已经相当令人印象深刻。我们正处于这些算法和模型成熟的初期阶段，但医疗服务交付的转型潜力巨大。尽管如此，目前的重点仍然是减少临床医生的行政和文档负担，这只是变化的开始。当前一代的LLMs可能很快会显得相当原始。在未来几年，随着LLMs和其他类型的人工智能的发展和改进，将会有更多令人惊叹和变革性的应用出现。</p>
<p>有几个LLMs和其他人工智能平台是专门为医学和医疗保健应用而创建的，其中一些是研究原型，其他一些则更加成熟并在实际应用中使用。以下是一些显著的例子。</p>
<ul>
<li>PubMedBERT：这个LLM及其相关模型在生物医学文本上进行了预训练，研究人员表示它超越了所有先前的语言模型。它旨在在生物医学领域表现出色。它是在 PubMed数据库中大量生物医学研究论文上进行训练的。它使用了 BERT，这是一个由谷歌开发的自然语言处理模型。它旨在帮助计算机更好地理解和解释人类语言，以考虑单词之间的上下文和关系。BERT 可以根据句子或段落中前后单词的语境理解一个词的含义。BERT 彻底改变了自然语言处理领域，并在搜索引擎、聊天机器人和情感分析工具等各种应用中得到了广泛采用。它理解和解释人类语言的能力对改善人机交互以及实现对大量文本数据的更准确和高效处理具有重要意义。</li>
<li>BioBERT：这个是一个专门为生物医学文本适配的语言模型。它基于原始的 BERT 模型，该模型是在通用文本语料库上训练的。BioBERT 进一步在生物医学文献上进行训练，增强了其理解和处理医学及科学语言的能力。它在来自生物医学领域的大规模语料库上进行预训练——特别是结合了 PubMed 摘要和来自美国国家医学图书馆的 PubMed Central (PMC) 全文文章。</li>
<li>SciBERT：由艾伦人工智能研究所设计的这个基于 BERT 的模型是在大量科学文本语料库上训练的，涵盖生物医学和计算机科学文献等领域，并已应用于科学文档摘要等任务。</li>
<li>ClinicalBERT ：旨在学习临床文本的领域特定语言及其独特结构，例如听起来像人类的释义，ClinicalBERT 是一个基于 MIMIC-III 数据库中临床笔记的领域特定 LLM，它经过训练以执行临床命名实体识别、关系提取和情感分析等任务。</li>
<li>谷歌的 Med-PaLM：谷歌的路径语言模型（PaLM）经过医学知识的微调，创建了 Med-PaLM，它在各种医学基准测试中得分很高，包括回答医学考试问题和提供临床决策支持等任务。谷歌还宣布了 Med-PaLM2，它在回答美国医学执照考试（USMLE）类型问题时达到了人类专家水平。</li>
</ul>
<p>无论是使用之前提到的LLMs特定领域示例，还是结合多个LLMs，例如谷歌的Gemini、Open AI 的 ChatGPT 或 Anthropic，或 ClaudeAI 与公司的专有数据结合，LLMs都将使医疗行业变得更好。这些 AI 模型使得在健康计划或支付方网站上导航、查找和理解内容变得更加容易。这些模型通过分析来自电子健康记录、临床试验和科学文献的大型数据集，加速了医学研究。最近的LLMs进展使医生或研究人员能够让LLM阅读一封或多封短或长的电子邮件，其中许多可能包含视频或音频剪辑以及临床医生的摘要。</p>
<p>此外，LLMs 正在解决医疗保健中的各种挑战，例如解读和清理医疗记录。他们还通过对话式人工智能弥合患者与提供者之间的沟通差距，确保在治疗前充分理解患者的病史，并分析来自各种来源的医疗数据，以获得更好的患者洞察。随着 LLMs 继续发展并融入医疗保健系统，他们的影响预计将是变革性的，塑造患者护理、研究和沟通的未来。</p>
<p>他们仍然有很大的空间来持续超越最熟练的医疗专业人员的专业知识。不过，将LLMs作为医生与患者关系中的第三个元素整合的潜力巨大。这种潜力包括协助诊断、文档记录和患者沟通。</p>
<p>每一个需要人类从医疗编码、患者教育、诊断、患者接收、治疗计划、药物管理等创造原创工作的临床和行政医疗流程，都有重新创新的机会。</p>
<p>LLM 和生成式人工智能应用程序或应用正在开始蓬勃发展，这得益于平台层的成熟、模型的持续改进以及免费和开源模型的日益可用。这为开发者、初创公司和企业提供了构建创新应用所需的工具。随着移动设备催生了具有传感器、相机和随时随地连接等新功能的新类型应用，LLMs 准备迎来一波新的生成式人工智能应用和医疗设备。</p>
<p>如今，医疗设备层出不穷，帮助我们优化生活，从健身追踪器到血压监测仪再到智能胰岛素泵。互联网搜索显示，医疗保健中使用的可穿戴医疗设备种类繁多，13 包括血压监测仪、血糖仪、心电图监测仪、健身追踪器等。我们喜欢将这些设备附加在自己身上，以使我们的生活更健康，工作条件更轻松。随着健康 LLMs 的进步，这些设备将变得更加有用。例如，LLMs 可以整合来自多个来源的数据，如您的 Fitbit、饮食应用、锻炼应用、禁食应用和睡眠追踪器，以提供更全面的健康视图。然后，它们可以分析这些综合数据，以识别在单独查看每个数据源时可能不明显的模式和趋势。</p>
<p>互联网搜索仍然是消费者使用谷歌的一个最爱——有些人称之为“谷歌医生”——以了解他们的症状和诊断。然而，证据清楚表明，互联网搜索能够轻微提高诊断的准确性，而在分诊准确性方面几乎没有提高。LLMs 将在未来几年内改变这一局面，因为互联网搜索与 LLMs 将会整合。ChatGPT 的问答互动模型引导您与互联网进行类似对话的交流——这种交流是上下文敏感和生成式的。</p>
<p>让我们探讨一下当前谷歌搜索和 ChatGPT 问答提示之间的差异。</p>
<ul>
<li>互动风格: 谷歌搜索是一种启动-响应风格，而 ChatGPT 采用问答风格，您用自然语言向它提问，它会给出具体的答案。谷歌搜索通常会返回许多与您的搜索词和短语相关的结果。它是一个相对灵活的系统，因为它返回所有匹配的结果并对其进行排名。谷歌搜索还会引用来源。</li>
<li>信息来源: 当您在谷歌上进行搜索时，系统会利用互联网庞大的网页和其他内容的索引，以找到可能匹配您的搜索请求的内容并加载它。相比之下，ChatGPT 利用其训练过的信息来源，这些来源包括截至特定日期的文本数据语料库，通常在该日期与用户提示的当前日期之间存在延迟。</li>
<li>答案的特异性: 当你在谷歌上搜索时，你可能会看到一系列网页、文章和其他资源，你需要浏览和滚动才能找到你所寻找的具体信息。ChatGPT 试图直接为你提供与所需信息相关的具体答案，而不需要你进行所有的搜索。当然，这也可能导致幻觉，这意味着人工智能不正确，生成无意义的输出，或者简单地提供事实错误的信息。我们应该提醒读者，称人工智能或 ChatGPT 产生幻觉时，我们是在将人工智能拟人化，而不是在描述一个缺乏许多人类特质的非人类物体或机器。</li>
<li>创造新事物: 谷歌搜索从根本上来说是关于在网络上寻找已经存在的信息。一个LLM不仅可以找到这些信息，还可以分析、生成新文本，并解释或论证某个结论。</li>
</ul>
<p>LLM-驱动的聊天机器人将回答我们关于健康的问题，而LLM-驱动的诊断工具将帮助医生更准确地诊断疾病。临床医生将利用医学LLMs来制定个性化治疗计划并监测患者的进展。</p>
<p>LLMs 将彻底改变消费者和患者在健康及医疗系统中的导航方式。通过提供个性化的见解、建议和支持，LLMs 可以使患者和消费者承担更多的责任，做出更明智的医疗选择。</p>
<p>LLMs 可以通过多种方式彻底改变医疗保健</p>
<ul>
<li>个性化健康教育: LLMs 为消费者和患者提供关于他们健康状况、治疗选择和预防策略的定制教育。生成式人工智能可以用来创建个性化的教育视频，使临床医生能够根据个人的具体需求、语言和偏好来调整教育内容。</li>
<li>医疗决策: 支持使用LLM聊天机器人应用的消费者和患者可以帮助他们在医疗保健方面做出明智的选择。聊天机器人可以对各种治疗选择进行产品或计划比较，并通过视频等多种方式解释每个选项的优缺点。这将不会提供医疗建议或临床建议，因为聊天机器人只是整理和总结已经提供给患者的数据和内容。聊天机器人作为理解内容的工具。</li>
<li>浏览辅助: LLMs 帮助消费者和患者在复杂的医疗系统中找到合格的医疗机构、安排预约并理解保险覆盖范围。使用聊天机器人在互联网上搜索（例如，ratemds.com、vitals.com、healthgrades.com 或 Yelp）以查找和总结患者对医疗机构或特定临床医生的评价。尽管这些评价是主观的，但像聊天机器人这样的工具可以总结这些数据，使消费者能够做出更明智的选择。</li>
<li>情感支持: LLMs 支持消费者和患者的情感健康。LLMs 可以倾听关切，提供鼓励，并将患者与面临类似挑战的其他人联系起来。LLMs 所促进的对话性质为支持和赋权消费者和患者提供了对话的机会。</li>
</ul>
<p>LLMs 将改变患者和消费者面临的当前个性化格局，从而推动医疗保健的个性化程度提高。这将包括辅导支持，提供更个性化的信息和建议。LLMs 可以使患者和消费者在健康和福祉方面更加负责任，通过对自身健康做出明智的决策。</p>
<p>选择一个由LLM驱动的聊天机器人在于LLMs所赋予的对话式人工智能的强大能力。一些实际应用中由LLM驱动的聊天机器人的例子可能包括以下任意一种：</p>
<ul>
<li>一个有慢性健康状况的人可能会使用一个具有LLM功能的聊天机器人来跟踪和记录症状，帮助管理处方，并提供关于健康生活的量身定制的信息。</li>
<li>一位面临选择的绝症患者——是否进行手术——可能会使用一个LLM聊天机器人来量化每个选项的风险和收益，并根据她自己的风险厌恶程度获得量身定制的建议，以便与她的医生进行对话。</li>
<li>慢性健康状况的护理人员，例如，可能会使用一个LLM驱动的聊天机器人来协调多个提供者之间的预约和护理，提供对提供者所说内容的解释和背景，并帮助做出决策。</li>
</ul>
<p>在这些例子中，基于LLM的聊天机器人相较于通用机器学习方法提供了某些优势。</p>
<ul>
<li>自然语言理解：我们已经提到过LLMs在自然语言理解方面的高超能力，这反过来又使得人类听起来更自然的语言输入成为可能（例如，用我们自己的话询问症状），这比填写结构化表单或基于关键词的搜索更直观和易于访问。</li>
<li>情境感知： 检查引用文本，LLMs可以在对话过程中保持上下文，并理解信息之间的关系，从而使聊天机器人能够为患者的问题提供更具信息性、减少重复和冗长的回答。然后，机器人可以根据患者最初描述其症状、处方药物和生活方式因素的上下文，跟踪其回答在与患者互动过程中的变化。</li>
<li>个性化支持： 通过与用户对话，了解人们的具体情况和问题，一个LLM驱动的聊天机器人可以提供针对个人健康状况、治疗计划和生活方式的有用建议和建议，这将更加有意义和实用。</li>
<li>预后支持： LLMs 可以从用户随时间提供的信息流中提取信号，并将这些洞察合成患者记录中发生的趋势。凭借这些数据，聊天机器人可以例如向用户标记一个问题，或自动将他们推荐给算法认为他们可能受益的有用资源或预防护理，最终目标是提升健康结果。</li>
<li>情感智能支持： LLMs 可以被训练成以理解和支持的语气进行交流。那些在慢性疾病的日常挑战中挣扎的人，可以从拥有一个支持性的对话伙伴中受益，以保持他们的动力和心理健康。</li>
<li>可扩展性： 大多数机器学习模型需要在每个新任务或能力的细微差别上进行明确的训练。然而，由于LLMs能够有效地调整其已有的语言通用知识，以支持在不同主题领域上执行甚至相当不同类型的任务，因此更容易扩展和调整聊天机器人，以满足更多样化的用户需求，并随着时间的推移扩展其知识库的广度和深度。</li>
</ul>
<p>一个定制的机器学习模型可以用较少结构化的数据输入和更简单的逻辑，并且可能无法提供太多支持或更广泛的背景。这反过来可能意味着用户的定制化程度较低，支持的范围较浅且较窄，并且随着时间的推移需要更多的工作来构建和维护。</p>
<p>一个LLM驱动的机器人不需要对心理痛苦或功能分类的定义。然而，它仍然会发挥自身的能力，包括自然语言交互、上下文理解和“深度”知识整合的一些优势，以提供一种广泛的、量身定制的支持，这在帮助慢性健康状况的人们方面似乎很有前景。</p>
<p>LLMs 将有助于平衡获取资源。患者和消费者将能够寻求和获取更高质量的健康信息和建议。医疗专业人员和更广泛的健康系统将更好地帮助实现患者的健康潜力。</p>
<p>关键不仅在于LLMs可以为我们做事情。我们可以利用LLMs和生成式人工智能来使我们更健康、更快乐。在下一部分中，我们将勾勒一些未来的应用程序或应用。</p>
<h1 id="LLMs在医疗保健中的承诺与可能性"><a href="#LLMs在医疗保健中的承诺与可能性" class="headerlink" title="LLMs在医疗保健中的承诺与可能性"></a>LLMs在医疗保健中的承诺与可能性</h1><p>每年全球有八百万人因缺乏更好的医疗保健而死去。医学和医疗保健正处于变革的浪潮边缘，因为LLMs和生成式人工智能正在从根本上改变医学。大型LLMs在与尖端人工智能突破相关的大型医疗和医学数据上进行训练，将促进个性化医疗保健的实现。</p>
<p>将其训练语料库中捕获的知识与患者病历中的信息结合起来，有可能显著推动临床决策支持系统的发展，并最终改善患者的护理和结果。LLMs可以帮助医生做出更精确的诊断，确定最佳治疗方案，甚至预测患者的预后。</p>
<p>在一个未来，LLMs被嵌入临床决策支持系统中，医生可能在护理时能够获得几乎取之不尽的医学知识。借助这样的工具，医生可能能够减少医疗错误：LLMs旨在帮助临床医生，帮助他们在可能犯错的边缘时远离危险。</p>
<p>&#x3D;&#x3D;LLMs 可以为临床医生提供前所未有的实时护理，通过跟踪电子健康记录中的医疗笔记、家庭设备的数据以及患者在数字平台上输入的信息。这种方法可以创建一个早期预警系统，监测症状、体征和实验室测试结果，提示疾病恶化。&#x3D;&#x3D;通过及早识别健康问题，LLMs 提供了一个极好的机会，帮助预防慢性疾病的发生，这些疾病可能会对患者的健康相关生活质量产生不利影响，并且通常会给医疗系统带来高昂的经济负担。</p>
<p>超越这一点，&#x3D;&#x3D;LLM衍生的见解可以为精准健康方法提供信息，旨在根据每个个体患者的遗传、环境和生活方式特征，优化初级、次级和三级预防以及治疗干预。因此，精准医疗可以被设计为优化治疗反应，提高患者参与度和治疗方案的遵循性，并改善健康结果&#x3D;&#x3D;，无论是对个体还是对群体。</p>
<p>鉴于LLMs的快速进展，以及它们在未来不可避免地与其他颠覆性技术的融合，人工智能在发展真正的预测性、预防性和个性化医疗系统方面的潜力呈几何倍增。用于医疗保健和人工智能的大数据&#x2F;LLM有望在危机来袭之前使预防性和先发制人的医学成为新常态。</p>
<p>随着新的人工智能功能的引入，如代理推理、检索增强生成、更大的提示词，甚至可能是无限提示词等，LLMs 的价值也在增加。它们可以基于更多的医学和其他特定领域的“数据”处理更有针对性和更细致的查询；推理假设场景；并以看似上下文相关和个性化的回复回答问题。如今，临床医生可能会使用多个应用程序来处理医学问题，例如 UpToDate 应用程序。LLMs 的采用可以改善这些应用程序在搜索、摘要、用户界面等方面的功能。</p>
<p>想象两个医疗场景，每个场景都利用了由LLMs和生成式人工智能驱动的应用程序。这些尖端的人工智能应用程序无缝集成了对话式人工智能、先进的搜索功能和智能摘要能力，彻底改变了患者和消费者与技术互动和获取信息的方式。让我们深入探讨这些假设场景，探索这些人工智能驱动的应用程序在医疗保健中的潜在影响。</p>
<p>在第一个场景中，医疗瑞士军刀是一个消费者应用程序的名称，旨在帮助患者和消费者在参与和导航医疗系统时提供支持。在第二个场景中，医疗向导是一个临床医生应用程序的名称，旨在成为临床医生的伴侣或虚拟助手。在这两种情况下，LLMs都经过培训或增强，结合了可信的知识来源、临床数据、药房数据、电子健康记录数据等。</p>
<h2 id="消费者医疗瑞士军刀应用程序"><a href="#消费者医疗瑞士军刀应用程序" class="headerlink" title="消费者医疗瑞士军刀应用程序"></a>消费者医疗瑞士军刀应用程序</h2><p>一家人工智能初创公司推出了一款新型聊天机器人，采用医疗特定的LLM构建。该聊天机器人是一款名为“医疗瑞士军刀”的健康应用程序，旨在为消费者或患者提供多功能服务，涵盖医疗场景中的预约医生、总结患者病史，以及倾听医生和患者的对话，以便提供简单易懂的医生指示总结。“医疗瑞士军刀”还提供医疗服务引导，帮助用户导航并识别适合其医疗状况的最佳医疗服务提供者。</p>
<p>大卫，一位 75 岁的老人，爱上了他的 Fitbit 可穿戴设备。在几周内，他多次收到信号，检测到心房颤动（AFib），并联系了他的医生，医生将他转诊给心脏病专家。大卫服用高血压药物和他汀类药物来控制胆固醇。大卫最近做了一项钙评分测试，结果显示他处于高风险类别。他的心脏病专家建议并进行了一次 AFib 消融，但并没有解决问题。大卫再次住院，接受控制性电击和心脏复律以恢复正常节律，但无济于事。</p>
<p>大卫想知道是否有 AFib 消融的替代方案。他与医生交谈，医生说 AFib 的效果很好，他们应该再试一次，因为这家医院专门进行治疗 AFib 的手术。大卫在他的 iPhone 上安装了医疗瑞士军刀应用程序，这是他的妻子推荐的，他决定使用它来研究关于 AFib 消融替代方案的问题。医疗瑞士军刀应用程序使用医学特定的LLM，一个类似于谷歌的基础性LLM，结合大卫的医疗记录、病史和健康信息的数据。该应用程序告知大卫另一种手术，即导管消融。向大卫展示了一个著名研究医院和专门从事该手术的医生的经过验证的视频。大卫对此产生了兴趣，并咨询了他的医生，医生告诉他这是一种他无法提供的替代治疗，大卫应该联系研究医院以了解更多信息。</p>
<p>该应用程序与大卫开始对话，讨论他的钙评分测试显示他处于高风险状态。它告知大卫，在导管消融之前，研究中心很可能会进行心脏计算机断层扫描（CT），以帮助他的主治医生预见在手术过程中可能出现的困难。</p>
<p>大卫使用医疗瑞士军刀应用程序联系医院，并进行初步电话预约以了解更多信息。大卫享受这次对话，感到受益匪浅，决定在这家研究医院接受治疗。该应用程序负责预约、航班和酒店预订。大卫与医疗瑞士军刀应用程序进行对话，以更好地理解他应该问哪些问题。该应用程序建议大卫询问以下内容：</p>
<ul>
<li>根据我的情况，最适合我的治疗方案是什么？</li>
<li>可用的不同治疗选项有哪些？每种治疗的风险和益处是什么？</li>
<li>我的心房颤动如何影响我的心脏？</li>
<li>我中风的风险有多大？</li>
<li>如果我有房颤发作，我该怎么办？</li>
<li>长期患有心房颤动的影响是什么？</li>
</ul>
<p>该应用程序的开发由一家知名公司进行，采用最先进的安全措施来保护患者隐私。应用程序的设计旨在避免对对话的误解或提供不准确信息，具体措施包括：</p>
<ul>
<li>使用一个大规模且多样化的数据集来训练LLM：该数据集包含医疗对话。这有助于LLM学习医疗语言的细微差别，并避免犯错误。</li>
<li>使用最先进的自然语言处理技术： 这些自然语言处理方法用于有效理解对话。这反过来帮助LLM准确找出话语的关键方面，并避免做出没有依据的推断。</li>
<li>结合医生和患者的反馈： 该应用程序提高了LLM的准确性。应用程序的持续反馈循环有助于识别LLM面临困难的领域，并进行必要的调整。</li>
<li>为用户提供透明度： 该应用程序允许用户了解其工作原理，并利用用户的数据帮助他们理解应用程序的局限性并负责任地使用它。</li>
</ul>
<p>LLM医疗瑞士军刀应用提醒大卫，它不是医生，无法提供临床建议或诊断。它告知大卫，在做出关于自己护理的决定之前，他应该向他的房颤医生寻求医疗建议。大卫和他的妻子飞行 2000 英里，入住推荐的靠近医院的酒店。两人都立即对心脏病专家的电话感到印象深刻，医生询问是否可以过来打个招呼。在与医生会面之前，大卫打开医疗瑞士军刀应用，查看他想要问的问题。应用提示大卫是否希望它监听对话。大卫告知医生他正在使用一个应用程序，将监听他们的对话，并帮助大卫在之后更好地理解对话。医生微笑着说当然可以，并提醒大卫在手术前后随时可以问他任何问题。</p>
<p>现在是星期一，准备进行一次术前 CT 扫描，以便为大卫的心房颤动治疗准备消融夹。CT 扫描显示他的主要动脉严重堵塞，心脏病专家警告大卫，他面临高风险心脏病发作，由于堵塞，他需要立即进行开胸手术。</p>
<p>大卫开始与他的医疗瑞士军刀应用程序交谈，询问当地医生是否应该发现这个堵塞。应用程序告诉大卫，由于他没有报告的症状，进一步的测试可能没有必要。它还建议他在有时间时向他的主治心脏病医生和当地医生询问这个问题。</p>
<p>如果没有使用医疗瑞士军刀应用，戴维将只与他的当地心脏病专家接触， 对他心脏病发作的高风险毫不知情. 尽管这或许只是偶然，戴维如果不是为了寻求导管消融，永远不会进行显示严重堵塞的 CT 扫描。</p>
<p>大卫进入了预计需要三到四小时的手术，但实际上进行了六小时。医生完成手术后告诉大卫的妻子安妮发生了什么。他表示大卫手术时间延长的原因是他有一种身体异常，导致血液从他的肺部流向心脏的方式是医生从未见过的，甚至是他认识的任何人也没有经历过。</p>
<p>医生强调他已经做了几十年这个工作，甚至与患有先天性心脏病和出生缺陷的婴儿合作过，但从未见过这样的情况。他们花了一些时间试图弄清楚情况，而不是使用一个泵来循环血液，他们用了三个泵，但仍然不够。</p>
<p>我们不得不提到安妮为什么对医疗瑞士军刀LLM医疗应用程序如此有信心。四年前，她被诊断为慢性淋巴细胞白血病。她在一个星期一与肿瘤科医生有一个预约，而她的女儿在前一个星期四给她打了电话。她的女儿是医疗瑞士军刀应用程序的活跃用户。该应用程序建议她的母亲在癌症研究医院接受治疗会获得更好的结果，而不是她原计划的当地医院。她的母亲并不太愿意重新安排预约，因为她喜欢她的肿瘤科医生，而且当地医院离家很近，相比之下，研究医院要远一些。但她最终妥协了，取消了预约，并在研究医院预约了肿瘤科医生。</p>
<p>研究医院有一个稍微不同的治疗计划，其中包括最近获得 FDA 批准的药物 IMBRUVICA®。安妮对结果感到非常满意，目前她的癌症处于缓解状态。她将这一切归功于她的女儿和那个引导她去一个能够产生更好 CLL 白血病结果的护理机构的应用程序。安妮明白，临床结果可能因提供者而有很大差异，她很高兴她的丈夫大卫能够与一位治疗房颤的专家建立联系。她坚信这拯救了她丈夫的生命。毫无疑问，发布研究结果的医疗机构在患者满意度评分上表现出色，并在各种医疗状况和程序中显示出降低的患者死亡率。</p>
<p>&#x3D;&#x3D;通过利用关于医疗机构临床结果的大量数据，医疗瑞士军刀应用程序由LLM提供支持，可以将个别患者与在统计上最有可能为患者特定病情和风险因素提供最有效治疗的医生匹配&#x3D;&#x3D;。</p>
<h2 id="临床医生医疗向导应用程序"><a href="#临床医生医疗向导应用程序" class="headerlink" title="临床医生医疗向导应用程序"></a>临床医生医疗向导应用程序</h2><p>当约翰因喉咙侧面有一个肿块而来进行常规体检时，戴维斯医生停下了。“约翰，”戴维斯医生说，“我想仔细看看你喉咙上的那个肿块。”约翰点了点头，于是戴维斯医生仰起头。他用放松的手指触摸肿块，皱起了眉头。肿块坚硬且固定，在轻轻的手指压力下没有移动。“我很担心，”戴维斯医生说，“这个肿块可能是癌症。”他继续说道：“我建议你立即去看专科医生，以确保安全。”约翰看起来很不安。“但我并没有感到不适，”他说。“我没有任何症状。”</p>
<p>癌症在早期往往没有症状，他补充道。约翰勉强同意去看专家，随后戴维斯医生为他安排了下周的预约。但戴维斯医生仍然觉得有些不对劲。他决定咨询他的医疗向导，一个可以筛选大量事实知识的LLM诊断应用程序。</p>
<p>戴维斯医生向他的医疗向导描述了肿块。应用程序反馈了几个建议，包括要求进行细针抽吸（FNA）活检——一种从肿块中提取细胞样本的微创方法——并将约翰引导到耳鼻喉科医生那里，这是诊断和治疗耳、鼻、喉疾病的合适专家。</p>
<p>根据医疗向导的建议，戴维斯医生为约翰安排了细针穿刺活检（FNA）。他还将约翰转诊给了一位耳鼻喉科医生。几天后，FNA 活检的结果显示为癌症阳性。戴维斯医生给约翰打了电话，传达了一个不对称的震惊消息：“我很遗憾地告诉你，你得了癌症，但我们发现得早，你仍然可以接受治疗。戴维斯医生问约翰，‘如果我的医疗向导帮助你安排与耳鼻喉科医生的预约，以讨论你的治疗方案，可以吗？’”</p>
<p>医疗向导是一个面向临床医生的LLM应用程序，通常由寻求咨询的医生使用。医疗向导应用本质上是临床医生与LLM之间的简短而非正式的咨询。使用“向导”这个名称是恰当的，因为类似于协助登山者攀登珠穆朗玛峰的夏尔巴人，医疗向导将帮助临床医生在复杂的医疗环境中导航。LLMs被设想为在医生身边实践的虚拟助手，提供见解并完成任务。然而，医学中人类的一个重要组成部分是临床判断的引导。</p>
<p>医疗向导促进更好和更安全护理的原因既有一般性，也有对临床医生的具体好处。例如，当医生与他们的向导合作时，他们获得了在依赖远程数据和分析时无法获得的近距离知识。同样，护士的向导由于在床边，能够通过无处不在的沟通提供实时支持和建议，使护士能够做出更明智的决策。</p>
<p>此外，医疗向导可以通过节省时间来帮助提供者提高生产力。通过快速便捷的咨询和支持，医生和护士可以利用节省下来的时间专注于工作中的其他关键方面，这可能有助于改善医疗结果。</p>
<p>此外，通过减少医疗提供者的倦怠，这已被认为是医疗保健中的一个严重问题，&#x3D;&#x3D;医疗向导使临床医生能够花更多时间照顾患者，而不是在每个案例中花费时间培训新学习者&#x3D;&#x3D;。拥有在这种护理形式中具有持续经验的人，可以极大地改善本地临床医生的体验和信心水平。综合来看，这些好处可以为患者提供更高质量的护理，并为未来建立一个更可持续的系统。</p>
<h1 id="LLMs的新兴特征"><a href="#LLMs的新兴特征" class="headerlink" title="LLMs的新兴特征"></a>LLMs的新兴特征</h1><p>LLM-驱动的应用程序处于一个有趣的空间，介于对未来的诱人愿景和需要克服的一系列艰巨障碍之间。我们离一个基于LLM的系统能够处理日益复杂的任务、释放人类创造力的新方向，并从根本上改变我们与周围世界互动的方式的未来非常接近。但首先，我们必须在数据、性能、稳定性和安全性等技术前沿上取得进展。</p>
<p>这其中除了技术基础设施，还有人性的一面。与数据需求旺盛的LLMs相关的隐私问题也很重要。训练数据中固有的偏见使得需要持续监测和主动缓解策略，以防止在医疗环境中再现偏见和造成伤害。</p>
<p>这意味着，尽管我们还没有到达目的地，尽管单靠技术无法让我们到达那里，但我们正在逐步向前推进。社会、伦理和概念思维对于扩大负责任的设计方法至关重要，这将使我们能够创造出LLMs种工具，以提高医生的效率和效果以及医患互动，同时防止这些工具成为排斥和伤害的工具。</p>
<p>基于LLM的应用程序当前的形态因素为医疗保健提供了广泛的实用性，有潜力为消费者的生活方式和医疗保健运营提供辅助便利。从我们智能手机上的症状检查工具到后台的临床决策支持，LLM的使用案例在患者与医生互动的多个环节中放大了改善医疗保健的潜力。</p>
<p>尽管真正的颠覆性创新仍在地平线之外，但我们今天可以看到，人工智能已经在重塑临床空间和消费者健康技术，以提高工作流程效率和患者护理。《人工智能优先的医疗保健》一书记录了许多人工智能如何改善医疗保健的例子。LLMs 将人工智能向前推进一步，自动记笔记、对话聊天机器人和摘要任务仅仅是个开始。</p>
<p>或许比其他地方更为紧迫的是，LLMs承诺在社会福利方面持续增加——使现有系统意识到护士护理中的漏洞，重新引导决策树，并通过提供者和购买者的赋权，稍微夸大地为每位患者最大化利润。我们共同未来的这种乐观处理的现实是由于消费者和商业LLMs的到来。</p>
<p>在不久的将来，LLMs将迎来激动人心的变化，包括扩展提示窗口或称为上下文窗口。窗口大小不断扩大，研究人员正在开发一种允许无限大小的提示。</p>
<h2 id="无限上下文提示"><a href="#无限上下文提示" class="headerlink" title="无限上下文提示"></a>无限上下文提示</h2><p>LLMs 具有广泛或无限上下文窗口的能力，现在可以同时处理文本、音频和视频数据。这一进展为医疗服务提供者、健康计划和支付方开辟了新的增强可能性。这对临床医生来说很有趣，因为它可以通过实时分析多种数据类型来加强患者咨询。以下是这一人工智能改进可能改变医疗保健的一些方式：</p>
<ul>
<li>LLMs 通过访问医学文献、临床记录和指南，可以为临床医生提供实时的基于证据的诊断、治疗和护理计划的建议。然而，与人类一样，回复可能会有延迟（即延迟时间），这取决于提示词的复杂性。通过将患者数据与医学文献和临床最佳实践进行评估，LLMs 可能帮助临床医生减少医疗错误，并增强决策能力，以改善患者的治疗结果。</li>
<li>能够理解和生成文本、音频和视频的模型，可以促进患者与临床医生之间更有意义的互动，跨越语言障碍。LLMs可以帮助将复杂的医疗信息转化为多功能的文本，使更多种类的患者能够理解，回答常见问题，提供可以个性化以满足个人需求的细致患者教育，并鼓励早期干预。这些互动可以增强患者的参与感、依从性和对护理的满意度。</li>
<li>不同的LLMs可以帮助自动化文书工作和临床文档，包括编码和账单，简化医疗流程，解放提供者免受行政负担，以便他们可以花更多时间与患者进行临床“面对面”的交流。如今，像谷歌这样的公司提供技术，允许人们使用LLMs来总结嵌入视频的电子邮件。想象一下，如果输入流不受固定大小的限制，这将会是什么样子。</li>
<li>能够实时解析音频和视频的模型将提高远程医疗和远程监测服务的效率和效果，帮助进行远程咨询。</li>
<li>凭借分析和综合大量生物医学文献和数据的能力，包括科学出版物、临床试验数据和病历，LLMs 可以加速医学研究和药物发现。临床医生可以利用 LLM 的力量来总结跨越多年的临床试验数据或病人记录，从而节省时间。</li>
<li>LLMs 可以通过根据患者的独特特征（例如，基因组、生活方式和病史数据）提供量身定制的护理，从而实现个性化医学和精准医疗，以识别个性化的风险因素、疾病发展轨迹以及治疗干预和治疗。LLMs 可能实现的更加个性化的护理方法可以通过优化患者治疗结果来提高医疗保健服务的有效性和效率。。</li>
</ul>
<p>个性化医疗的承诺将是向前迈出的一大步。LLMs 具有无限上下文窗口或提示，可以处理和存储大量的医学文献、临床试验数据、患者病史和临床数据，从而为患者或消费者提供一个全面且可更新的医学知识库。由这样的 LLMs 驱动的聊天机器人将扩展到更复杂的多轮对话，创造直观且引人入胜的消费者体验。前谷歌首席执行官埃里克·施密特预计，在未来五年内将出现扩展的无限提示窗口。</p>
<h2 id="代理推理"><a href="#代理推理" class="headerlink" title="代理推理"></a>代理推理</h2><p>代理推理代表了人工智能的另一个发展阶段，其中系统可以自主行动。计算机科学家和人工智能研究员 Andrew Ng 提供了关于代理推理本质的有趣观点，并描述了我们将在本章中探讨的代理推理的四个关键特征或模式：反思模式、工具使用、规划和多智能体互动。</p>
<p>“代理推理是创建能够采取旨在实现目标的行动的代理的核心，”斯坦福大学计算机科学兼职教授、Coursera 联合创始人 Andrew Ng 说。Coursera 是一家提供大规模开放在线课程的公司。Ng 解释说，这意味着人工智能系统感知、渴望、相信和行动的能力，从而设定和修改目标，在不确定性下做出决策，从经验中学习，并以自然和有效的方式与人类和其他人工智能代理进行互动和推理。他指出，实现人工智能代理之间的代理推理的挑战，需要在多个领域取得重大进展，例如机器学习、自然语言处理、知识表示和不确定性下的推理。</p>
<h3 id="代理推理的四种模式"><a href="#代理推理的四种模式" class="headerlink" title="代理推理的四种模式"></a>代理推理的四种模式</h3><p>在代理推理中的反思模式帮助人工智能根据其之前的行为提高性能。反思模式使医疗人工智能系统能够反思其选择，识别改善结果的方法，并不断发展其对患者护理的方式。例如，旨在为临床医生提供复杂疾病的诊断和治疗建议的人工智能代理可以采用反思模式。该代理最初会在一个大型多样化的患者记录、文献和临床指南数据集上进行训练，然后根据流行数据向临床医生提出代理建议。</p>
<ul>
<li>初步诊断和治疗计划： 当新的患者案例被提交时，代理将分析呈现患者的症状、医疗背景和测试结果，然后提供初步诊断和治疗计划。代理将利用其训练数据并运用其自主推理能力，以及关于构成它的模块的建模数据，来确定患者病情的真实原因以及最佳治疗方案。</li>
<li>对结果的反思： 一旦患者开始治疗计划，人工智能代理会在患者的治疗过程中监测其进展和结果。患者的实际成果将与代理根据初始建议对同一患者的预测进行比较。如果患者的改善符合代理的预期，代理将自我强化，并在未来类似案例中变得更加自信。但如果在一定时间后患者的状况没有改善，或者结果不理想，人工智能代理将检查它做出该决定的原因——通过查看其算法、所使用的数据以及它所建立的假设。</li>
<li>适应与学习： 基于这种反思分析，AGI 让患者的案例成为其决策模式所需调整的基础。例如，AGI 可能会将临床发现的记录添加到其背景知识中，优化算法以纳入已知的特定患者细微差别，或修订治疗建议列表以降低已知并发症的发生几率。关键是，这种自适应训练过程意味着代理不断学习采取更多能够改善其长期行为的行动，从而最终做出更好的推荐——减少错误的可能性并促使更合适的补救措施。当它接触到更多患者，并参与这一事后行动的过程时，它能够诊断和治疗更复杂的医疗问题。</li>
<li>分享见解与协作学习： 这种知识可以通过它们获得的反思性见解在人工智能代理和人类专家之间共享，从而增强人类与人工智能代理之间的共同学习和共同知识。例如，多个人工智能代理可以协作识别模式，并在大规模上生成新颖的治疗策略和改进的患者护理。AI 代理可以向人类医生提供反馈，指出他们需要更新临床实践或需要额外研究努力的地方。通过进行这种人机对话，我们最终可以增强人类与机器之间的混合工作性质。代理推理的反思结构使得在医疗保健领域工作的人工智能代理能够从他们的经验中学习，调整他们的策略，并不断提高诊断和治疗患者的能力。通过与人类专家的持续反思和协作学习过程，人工智能代理可以成为人类护理的补充，提高医疗服务的质量、效率和有效性。反思过程必须得到适当的引导，并以强有力的伦理原则为基础，同时始终保持人类监督，以防止意外的疏忽并维持最高的护理标准。</li>
</ul>
<p>在代理推理中的工具使用模式使得 AI 代理能够广泛利用工具和外部资源，超越机器学习、计算机视觉或自然语言处理，通过利用外部资源和知识能力来扩展其问题解决范围和决策过程。对于医学而言，工具使用模式可以使 AI 系统通过整合现有的医疗工具、数据库、服务以及所有其他外部输入（如护士、医生、护理人员等医疗专业人员）来“借用”医疗资源。这些输入可以基于最新的临床知识和专业决策提供原则性和以人为本的患者护理，而不是将 AI 系统局限于仅依赖机器学习示例的“黑箱”决策。让我们看看精准医学，并说明工具使用模式如何应用。</p>
<p>一个医疗 AI 助手帮助医生为癌症患者制定个性化治疗计划。为此，助手使用代理推理分析患者数据，寻找患者可以遵循的最佳治疗方案，并且助手还监测治疗进展。为了进一步改善治疗建议，助手采用工具使用模式来访问并结合外部资源和服务。</p>
<ul>
<li>基因组分析工具： 一个人工智能代理挖掘基因组分析工具箱，以收集和理解患者的遗传信息。凭借基因组变异及其已知临床意义的数据库，它可以识别潜在的遗传风险因素，建议可能的药物反应，并根据患者的个体分子特征开具靶向治疗。</li>
<li>医疗影像服务： 医疗影像服务——例如计算机视觉 API——是 AI 代理依赖的，分析患者扫描（MRI、CT 或 PET 扫描），以检测和描述肿瘤的存在和形状，以及对攻击的治疗反应和随时间的疾病进展监测。这些信息与其他患者数据的见解相结合，输入到 AI 代理对患者状况的整体评估中。</li>
<li>电子健康记录（EHR）系统： 利用电子健康记录（EHR）系统访问患者的既往诊断、治疗和结果，将帮助人工智能代理构建更准确的实际治疗方案。例如，人工智能代理可以参考其他患者的电子健康记录，而不是仅仅咨询该患者的电子健康记录，从而获得更全面的患者健康状况视图，并可能识别出影响治疗方案选择的风险因素或合并症。通过访问来自集成的电子健康记录系统和其他相关医院的数据，人工智能代理将能够生成更个性化的护理计划和相关决策。</li>
<li>临床试验数据库： AI 代理搜索临床试验数据库，寻找与患者病情相关的试验，然后检查试验的资格标准、参与者的治疗数据和结果数据。这使得 AI 代理能够对患者可能受益于参与的试验提出建议，或利用试验数据为其治疗建议提供依据。</li>
<li>药物相互作用检查器： 该人工智能代理使用药物相互作用检查工具来评估提议的癌症治疗方案与患者当前药物的潜在相互作用。然后，根据结果推荐替代药物或剂量调整，以尽量减少不良药物事件或禁忌症，同时最大化疗效。</li>
</ul>
<p>通过使用这些工具和服务，&#x3D;&#x3D;人工智能代理可以为医生提供一种综合的精准医疗方法，汇总来自不同来源的相关数据，并提供经过知识图谱和概率评分验证的个性化治疗建议。这种方法是可行的，因为代理可以进行期刊爬取、医学文本挖掘、下载、图像存储，并以概率方式整合不同的数据。它可以利用患者的病史、基因数据和影像数据，基于较少知识的药物相互作用建议合适的治疗方案，包括潜在的处方&#x3D;&#x3D;。</p>
<p>此外，由于人工智能代理本身正在对新的研究数据、临床指南以及新的或未经测试的治疗方案做出一些决策，因此该代理的工具使用情况基本上是自我更新的——随着人类癌症发现模式的变化而变化。因此，该代理将使用现有的最佳和最新知识。</p>
<p>随着代理推理领域在医疗保健中的发展，这种工具使用模式将在构建能够捕捉、组合和处理精准医学中所需的大量多样化医疗数据的人工智能系统中发挥重要作用，以提供更好的患者护理——前提是用于实现这些结果的外部服务尊重强有力的数据隐私、安全和伦理规则，以维护患者的隐私和医疗系统的完整性。</p>
<p>在代理推理中，规划模式对于赋予人工智能代理制定高层次计划以实现其目标和优化流程的能力至关重要。这意味着，在医疗领域，一个具备规划能力的人工智能系统可以用于处理详细的患者案例，预测潜在结果，并在制定之前决定最佳治疗方案——整合各种因素和参数。例如，考虑一个旨在帮助医生管理慢性疾病患者（如糖尿病、高血压或心血管疾病）的人工智能代理的场景。在这种情况下，代理使用代理推理来分析体检结果，排列出现的症状，识别使患者面临更差健康结果的风险因素，然后为长期健康结果制定战略性和适应性的建议。</p>
<ul>
<li><p>目标设定与问题分解： AI 代理以优化患者的健康结果和生活质量为抽象目标，并将其细分为更小、更具体的子目标：保持患者的血糖在最佳范围内，降低血压至安全水平，最小化截肢或肾脏并发症的风险，等等。通过将整体问题分解为不同的子问题，代理可以制定和追求与患者状况的每个特定方面相适应的行动。</p>
</li>
<li><p>数据分析和情况评估： 然后，人工智能代理尝试根据其上下文反映患者的整个医疗情况。它考虑患者的病史、当前健康状况和环境背景，以及他的生活方式和可识别的个性特征。这包括整合电子健康记录、可穿戴设备和患者报告结果的数据的能力。</p>
</li>
<li><p>计划生成与评估：根据这一情况评估，人工智能代理生成不同的可能治疗方案，以解决定义的子目标。例如，它可能包括一种涉及使用不同药物调整、生活方式改变和转诊专家的组合。代理通过考虑预测的有效性和副作用、患者的偏好和接受度、可用资源等，使用已知数据和概率预测来评估每个方案，然后决定推荐哪种行动方案。</p>
</li>
<li><p>计划选择与调整： AI 代理将选择其认为价值最佳的治疗方案，权衡治疗的益处与风险。然后，它会将选定的方案及其支持理由传达给医生和患者，可能还会提供实施建议的说明或支持。</p>
<p>医生设计治疗计划，而人工智能在计划实施过程中进行监测并检查结果。如果患者的病情没有按照预测的轨迹发展，代理会重新规划。治疗会对新信息做出响应，例如调整药物剂量或引入不同的干预措施或生活方式建议。</p>
</li>
<li><p>持续监测和改进： AI 代理稍后会与患者进行回访，以了解她的情况以及治疗计划是否有效或需要调整。它还会关注副作用带来的风险和不良事件。当它能够识别患者自身数据中的模式并与类似病例的轨迹进行比较时，代理可以调整其规划策略，以更好地防范突发的健康问题。</p>
<p>这种代理推理的规划结构可以帮助医疗保健领域的人工智能代理制定慢性病管理的执行性和动态护理策略。人工智能代理将复杂的健康问题分解为有意义的子目标，利用可用的患者数据进行模式补全程序，集思广益提供喂养和消除选项，分析预期后果，并监控和自我调整其策略。通过这种方式，人工智能代理可以帮助医生提供个性化的、基于证据的护理，平衡短期成本与长期健康收益。</p>
<p>随着我们在医疗保健领域的代理推理这一激动人心的领域不断发展，规划模式不太可能是唯一需要的模式。但它在创建帮助临床医生管理慢性疾病的人工智能系统中将是至关重要的，这些慢性疾病占据了患者群体的很大一部分，并将使他们朝着更公平的人口健康的方向前进。我们必须保护规划过程——用伦理原则、临床最佳实践和以患者为中心的价值观来引导它，以保护个人免受可能随着医疗工作负担的增加而出现的不安全、无效和不可接受的治疗计划的影响。</p>
</li>
</ul>
<p>多智能体协作模式是智能架构实现不同层次的智能本体中多样化智能体协作工作的手段，无论它们是否被赋予代理权。集体事件识别需要两个或更多智能体对事件的意识和评估。在医疗领域，当两个或更多智能智能体——可以被视为人工智能系统和独立的广泛医疗专业人员——协调工作、共享状态知识或感知，并基于共享目标或子目标做出决策和行动时，便激活了多智能体协作模式。</p>
<p>想象一个患者有各种长期疾病——糖尿病、高血压、心血管疾病等等——需要来自广泛健康专业人士的建议、监测和治疗（例如，这可能是一个由医生、护士、营养师、社会工作者、心理学家等组成的多学科团队）。在这种情况下，可能会部署一系列不同的人工智能代理来支持健康专业团队的成员，例如，帮助他们优化用药选择、提供生活方式指导、协调护理等。这些人工智能代理采用代理推理和多代理协作模式，整合技能和工作记忆，以提供针对性强、信息充分、协调一致的护理。</p>
<ul>
<li><p>共享目标和问题理解： AI 代理和人类专家共同定义患者的健康状况、治疗目标和潜在障碍。最后，他们共同制定个性化护理计划，充分利用人类和算法各自的优势，为患者的医疗、心理和社会需求提供最佳治疗。</p>
</li>
<li><p>任务分配与协调： 针对他们分配的任务，人工智能代理分配了一部分工作。药物优化代理可以扫描患者的处方以查找药物相互作用，并建议优化疗效和安全性的方法。生活方式指导代理可以个性化饮食、锻炼和压力管理建议，以补充患者的自我护理方案。</p>
<p>护理协调代理处于中心位置，收集来自众多护理代理的信息，并将每个代理与他们所需的特定信息连接起来。护理协调代理还确保其他代理和人类专家了解患者的当前状态、状态变化和护理计划的变化。</p>
</li>
<li><p>信息共享与知识交流： AI 代理和人类专家不断交流信息和见解，以支持集体决策和问题解决。他们通过加密通道和标准化数据格式传输患者数据、治疗建议和临床见解，以便每个代理和专家都能利用整个团队的集体知识，并相应地更新其策略。例如，如果药物优化代理检测到潜在的不良药物事件，它会通知护理协调代理，后者则会警告人类专家以及其他 AI 代理。团队评估发生的情况并生成事件记录。他们考虑是否要停用有问题的药物，并用其他选项替代。如果是，他们会更新护理计划。</p>
</li>
<li><p>冲突解决与共识建立： 如果人工智能代理或人类之间存在相互矛盾的建议或意见，多代理协作模式使他们能够进行辩论和对话，协商权衡并通过辩论、投票或多标准决策分析方法达成共识。这种协作模式确保达成的决策“符合患者的最佳利益。”</p>
</li>
<li><p>持续学习与适应： 如果患者的情况发生变化并且有新的数据可用，人工智能代理和人类专家会学习新的护理协调过程策略，互相交流技巧（可以这么说），帮助使他们的策略更加有效和高效。多个代理相互互动，从彼此的成功和失败中学习，并在面对新挑战时逐步发展新的方法。</p>
</li>
</ul>
<p>这种来自代理推理的多智能体协作模式使得人工智能代理和医疗保健领域的人类专家能够以协调的方式共同工作，为具有复杂健康需求的患者提供整体和个性化的护理。定义共同目标、分配任务、共享知识、解决冲突以及学习和适应是帮助团队利用集体智慧以更大程度优化患者结果、提高护理质量和效率的组成部分。</p>
<p>由于医疗保健中的代理推理刚刚开始演变，多代理协作模式在设计能够与人类同行并“向他们学习”的人工智能系统中可能变得更加重要，以应对日益多样化和相互关联的医疗保健环境。而且，伦理、职业标准和监管控制将是维护患者和临床医生的安全、隐私和信任所必需的。</p>
<h3 id="挑战与未来方向"><a href="#挑战与未来方向" class="headerlink" title="挑战与未来方向"></a>挑战与未来方向</h3><p>这四种不同的代理推理模式为将人工智能提升到人类智力水平提供了机会。当然，前方还有巨大的挑战，如何确保代理人工智能与人类以安全、伦理和一致的方式互动。这将涉及，例如，开发稳健的价值对齐框架，以及建立问责机制，确保其操作的公平性。</p>
<p>第二个挑战是将四种以代理为中心的推理模式嵌入统一、灵活和可扩展的人工智能架构中，这可能需要在迁移学习、多任务学习和开放式学习方面取得进展，以使人工智能代理能够在一个任务或情境中学习知识，从而帮助解决另一个任务。</p>
<p>代理推理技术在长期内可能会取得显著进展。关于这一研究领域，持续令人感兴趣的是，研究者们尚未进行太多工作。但可以想象，随着时间的推移，我们可能会看到反映并可能工具化、规划和学习的人工智能系统，具备越来越复杂的推理和协作形式。这些进展可能会改变许多领域，从医疗、教育和交通到制造业及其他领域。</p>
<h1 id="使用LLMs的上下文"><a href="#使用LLMs的上下文" class="headerlink" title="使用LLMs的上下文"></a>使用LLMs的上下文</h1><p>理解可预见的LLM应用程序的使用案例认识到“使用上下文”的核心重要性，这是玛格丽特·米切尔创造的一个术语，在创建医疗保健LLMs应用程序时尤为重要。也许米切尔的思考源于一种长期存在的人本工程软件工程实践。由于医疗保健LLM应用程序在可能的用户提示上是如此开放，它们为改善美国医疗保健系统提供了有趣的使用案例，但同时也在预先预测用户交互方面带来了挑战。</p>
<p>与物理对象不同，物理对象可能有有限的预期使用案例，而大多数软件应用程序在交互上是如此开放，以至于我们无法完全预测最终用户将如何使用它们。椅子可以用于有限的用途（坐），但应用程序是开放的。可以开发机器学习模型来预测慢性疾病。可以开发疾病模型来预测特定疾病，例如心脏病或肥胖症。然而，另一个用户或组织可能选择使用特定的机器学习模型来确定提供健康保险覆盖的成本，而另一个用户可能选择将相同的机器学习模型应用于拒绝健康保险覆盖。</p>
<p>软件的灵活性意味着用户可以根据自己的任务（如他们必须的那样）以最适合他们特定需求、工作流程和用户的方式使用应用程序。这个生产力应用程序可能是为任务管理而设计的，但它也可能被用作项目协作工具。软件的开放性——通过这种内在的灵活性得以实现——意味着开发该软件的组织或公司也必须准备好应对人类利用的最终自由。关于LLM驱动的聊天机器人，自然语言交互的灵活性意味着其提示的开放性在上下文和潜在结果方面难以预测或限制。用户可能会提出不在聊天机器人设定范围内的问题（或提出请求）。用户可能会试图操纵其响应，以导致有害或不当的结果。</p>
<p>例如，寻求诊断的人可能会询问一个为一般健康相关讨论而构建的健康聊天机器人，这可能会产生不准确或不安全的假设。即使是最轻松的聊天机器人也有可能与来自客户服务机器人的敌对或辱骂性互动发生冲突，而该机器人因其错误而受到不公正的批评。</p>
<p>减轻这些风险将要求LLM驱动的聊天机器人开发者构建安全层、伦理规范和内容审核工具。示例可能包括使用对抗性测试形式——在这种测试中，系统故意暴露于用户可能输入的最广泛范围，以识别其训练和代表性规范中的漏洞——以确保例如，要求机器人不粗鲁不会导致它发表种族主义言论。无论采用何种策略，开发者必须确保明确设定并传达不可能的边界和期望，以减少用户试图强迫机器人做不可能之事的风险。</p>
<p>其次，如前所述，基于LLMs的聊天机器人应不断监控和优化，以确保它们持续按预期表现。开发者应通过积极寻求用户对其聊天机器人日常体验的反馈来为这一过程奠定基础。开发者还应检查互动中的模式。他们应对输入和反馈进行进一步分析，并相应地更新知识库和响应系统，以优化聊天机器人在用户创造的新条件下的表现。</p>
<p>总而言之，软件应用程序的开放性特征，包括LLM驱动的聊天机器人，可以为预测、规划和处理用户互动提供机会和保障。一方面，LLM驱动的聊天机器人的开放性使创作者能够预见在其框架内可能对用户有益的新用途。另一方面，LLM驱动的聊天机器人的开放性也可能导致意想不到和有害的用途。然而，通过实施保障措施、道德指导以及持续的监控和改进，创作者可以提升用户在使用LLM驱动的聊天机器人时的体验。</p>
<p>无论是审查政治偏见的搜索结果，还是捕捉痴呆症的语言标记，将上下文应用于LLM应用程序的价值显而易见。通过在设计LLM应用程序时考虑上下文，我们可以构建更强大、更具伦理性和对患者更有益的医疗工具。LLM应用程序应做到以下几点：</p>
<ul>
<li>通过提供清晰的界面、针对临床医生的教育材料以及关于人工智能局限性的透明度，鼓励负责任的使用。</li>
<li>针对已识别的误用场景实施保护措施（例如，数据的安全控制、预防措施以禁用针对偏见输出的堆叠）。</li>
<li>让它在人工智能适应性地应用于新环境时自我改进。可以通过监测在世界上使用的人工智能（在可能的范围内）并调整模型以应对出现的任何问题来进行调整。</li>
</ul>
<h1 id="消费者和商业-LLMs"><a href="#消费者和商业-LLMs" class="headerlink" title="消费者和商业 LLMs"></a>消费者和商业 LLMs</h1><p>今天，我们的应用程序基本上分为两类：消费者和商业。它们服务于不同的目的，面向不同的用户。商业应用程序通常是为公司的员工设计的。然而，我们也看到企业为客户创建应用程序，以便他们访问健康计划、了解福利、预约等。消费者应用程序的最大例子可能出现在社交媒体、娱乐、生产力、游戏和商业等领域。</p>
<p>在医疗保健领域，我们看到许多旨在简化个人健康管理的医疗应用程序。比如安排医生上门看诊的应用（例如 ZocDoc）、治疗应用（例如 Talkspace）、远程医疗应用（例如 Doctor on Demand）、女性健康应用如 Maven 等。我们预计随着时间的推移，会有更多基于 LLM 的医疗应用出现，以涵盖在 第 3 章、第 4 章 和 第 5 章 中描述的许多使用案例。</p>
<h2 id="消费者LLMs和生成式人工智能"><a href="#消费者LLMs和生成式人工智能" class="headerlink" title="消费者LLMs和生成式人工智能"></a>消费者LLMs和生成式人工智能</h2><p>本书探讨了一个关键假设：以LLMs为动力的以消费者为中心的应用程序的兴起将显著改变医疗保健。这些应用程序利用LLMs的能力来总结信息和生成内容，预计将：</p>
<ul>
<li>增强医患关系</li>
<li>&#x3D;&#x3D;帮助个人更好地管理他们的慢性疾病和整体健康&#x3D;&#x3D;</li>
<li>最重要的是，干预以延迟或预防慢性疾病的发生</li>
</ul>
<p>通过利用LLMs的能力，这些消费应用有潜力彻底改变个人健康管理和预防护理。</p>
<p>消费型LLMs旨在满足个人用户的需求，提供各种应用和功能，针对个人的需求和兴趣量身定制。这些LLMs包括聊天机器人、虚拟助手和内容生成器等模型。以下是消费型LLMs的一些关键特征：</p>
<ul>
<li>对话助手： 消费者LLMs喜欢虚拟助手（例如，Siri、Google Assistant），这些助手旨在帮助用户设置提醒、回答常识问题、发送消息和播放音乐。它们旨在提供日常便利。</li>
<li>参与和娱乐： 消费者LLMs通常旨在提供互动体验，例如对话式人工智能助手、聊天机器人或创意写作工具，旨在吸引和娱乐用户。</li>
<li>内容生成： 一些消费者LLMs可以生成文本，这对撰写电子邮件、创作内容甚至编程辅助等任务非常有帮助。这些模型专注于提升个人生产力和创造力。</li>
<li>个性化： 消费者LLMs通常优先考虑个性化，通过学习用户互动来提供量身定制的推荐、内容和回应。</li>
<li>个人助理： 这些LLMs可能有助于回答医疗问题、提供建议、撰写电子邮件或文件、安排与临床医生的预约，以及帮助完成各种个人生产力任务。</li>
<li>无障碍性： 这些模型通常配备用户友好的界面，适合广泛的用户群体，并且通常可以在移动设备和个人电脑上使用。</li>
</ul>
<h2 id="商业LLMs与生成式人工智能"><a href="#商业LLMs与生成式人工智能" class="headerlink" title="商业LLMs与生成式人工智能"></a>商业LLMs与生成式人工智能</h2><p>企业和组织设计他们的业务LLMs和生成式人工智能，以便为员工和客户使用，自动化任务、解释数据，并生成文本、图像和视频等内容。商业LLMs旨在用于组织和企业，具有以下特征：</p>
<ul>
<li>数据集成业务： LLMs旨在与您组织的数据源（例如，电子健康记录或其他临床、索赔、药房或资格数据库）无缝集成。利用所有这些健康部门数据，它可以为您提供洞察和报告。LLMs允许分析大量业务数据。例如，LLM可以快速评估支付方和保险公司使用的复杂且不断变化的事先授权标准。</li>
<li>特定于某些行业的商业LLMs： 为了惠及某个行业，例如医疗保健，行业特定的LLMs可以帮助完成从诊断疾病到处理索赔或做出临床决策等任务。</li>
<li>合作： 这些LLMs通常配备有共享团队空间、文档协作&#x2F;共享和工作流程自动化等功能，以提高组织的生产力。</li>
<li>知识管理： 商业LLMs可以通过建立知识库、总结数据和提供上下文建议来帮助组织收集和分享知识。</li>
<li>客户服务和支持： 从商品交易到购买音乐会门票，LLMs 可以为对话式人工智能助手和聊天机器人提供动力，以提供客户支持和回答查询。</li>
<li>服务保证： 企业级LLMs包括服务水平协议和专门的客户服务，使其在业务运营中可靠。</li>
</ul>
<p>总而言之，消费者工具和商业工具之间的关键区别在于：消费者工具主要针对个性化便利和个人生产力，而商业工具则是为特定行业的使用案例而构建的，具有定制的数据集成和企业级的运营支持。</p>
<h2 id="弥合鸿沟"><a href="#弥合鸿沟" class="headerlink" title="弥合鸿沟"></a>弥合鸿沟</h2><p>这种消费者与商业 LLMs &#x2F; 生成式人工智能之间的区别实际上是一个重要的区别，因为它影响使用和受众。区分商业和消费者 LLMs 是很重要的，原因有几个：</p>
<ul>
<li> 目的和目标</li>
<li> 数据训练</li>
<li> 监管环境</li>
<li> 伦理与偏见</li>
</ul>
<h3 id="目的和目标"><a href="#目的和目标" class="headerlink" title="目的和目标"></a>目的和目标</h3><p>商业LLMs旨在解决特定的商业问题或改善商业流程。这些包括自动化健康计划成员与客户服务员工之间的互动，以及从企业已有的数据中提取洞察。</p>
<p>消费者LLMs旨在个人使用和教育目的。它们提供语言翻译和对话问答等服务。重要的是，它们可以根据个人的偏好和需求进行定制，提供基于用户过去互动、所述兴趣或特定要求的个性化响应。</p>
<h3 id="数据训练"><a href="#数据训练" class="headerlink" title="数据训练"></a>数据训练</h3><p>商业LLMs是在特定领域的数据集上进行训练的。通过这种方式，我们可以“调整”LLM以适应我们的商业领域，使其不仅直接处理内容，还能了解商业背景和术语。</p>
<p>消费者LLMs在从各种公共网站提取的大型通用语料库（文本和代码的集合）上进行训练。这些提供了通用的曝光，但存在偏见的风险，并且缺乏专业知识和&#x2F;或领域专长。使用 AI 框架 RAG，数据扩展到外部数据源，就像商业LLM一样。</p>
<h3 id="监管环境"><a href="#监管环境" class="headerlink" title="监管环境"></a>监管环境</h3><p>商业LLMs受到特定行业规则（例如，金融行业）或数据监管规则（例如，医疗数据保护）的监管。</p>
<p>消费者LLMs受消费者保护法和关于数据隐私及伦理人工智能实践的法规约束。例如，HIPPA 确实对个人或其指定人使用健康信息的方式施加了限制，以符合个人的访问权。</p>
<h3 id="伦理与偏见"><a href="#伦理与偏见" class="headerlink" title="伦理与偏见"></a>伦理与偏见</h3><p>商业LLMs：谨慎的管理和偏见的缓解是必要的，以避免对潜在客户、员工等的歧视或其他不公平对待。</p>
<p>消费者LLMs：消费者LLMs中的偏见可能导致有害的错误信息、冒犯性内容或社会不平等的延续。确保这些技术的发展是负责任的，并且持续解决意外偏见至关重要。</p>
<p>总之，虽然大型语言模型被企业和消费者使用，但它们不同的、尽管可能相关的目的以及对输入、控制（包括安全）和伦理考虑的不同需求，都应该促使我们根据这些不同的目的和背景，以不同的方式思考它们的发展和使用。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>LLMs 可以开启一个曾经仅限于科幻领域的潜力世界。通过深入探讨这些先进语言模型的潜力，本章探索了一系列未来的承诺和应用（其中两个——面向消费者的医疗瑞士军刀和面向临床医生的医疗向导——由 LLM 驱动）。语言模型（LLMs）——能够以卓越的流利度和灵活性阅读、书写和处理人类语言的机器——开启了这个新时代。LLMs 仍在不断发展，其能力持续提升。LLMs 有望在广泛的健康领域中改变患者护理、研究和医学知识。</p>
<p>但最大的区别可能在于预期的用户和使用案例是什么样的LLM驱动的应用程序。消费者LLM应用程序（如医疗瑞士军刀）专注于最终用户在做出明智的医疗决策时的便利性——从小规模的自我事件管理和自我诊断到广泛的健康促进、自我护理和家庭医疗应用程序。商业LLM应用程序（如医疗向导）将服务于医疗专业人员和组织，这些人员在不断增长的医学文献中进行查找或填充，临床医生做出诊断决策，以及制药研究人员开发药物。对于消费者LLM应用程序，便利性和易用性是吸引用户的关键。对于商业LLM应用程序，数据隐私、HIPAA 和合规性以及行业特定功能等问题则是显而易见的难题。</p>
<p>但随着社会深入LLMs，他们的解决方案和承诺将塑造一个充满新工具的世界，供健康消费者和医疗专业人士使用，并创造一个因更大医疗和医学知识获取而多样化的近未来。</p>
<p>1 C. M. Kornbluth, “小黑包,” 收录于 C. M. Kornbluth 精选集, 编辑 Frederik Pohl (纽约花园城: Nelson Doubleday, 1976), 42–69.</p>
<p>2 马特·马歇尔，“纽约医院高管：多模态 LLM 助手将为患者护理带来‘范式转变’，”VentureBeat，2024 年 3 月 6 日，<a target="_blank" rel="noopener" href="https://venturebeat.com/ai/ny-hospital-exec-multimodal-llm-assistants-will-create-a-paradigm-shift-in-patient-care%E3%80%82">https://venturebeat.com/ai/ny-hospital-exec-multimodal-llm-assistants-will-create-a-paradigm-shift-in-patient-care。</a></p>
<p>3 LLMs 可能看起来能够理解人类语言，但它们实际上是复杂的统计模型。这些模型识别模式、进行语言翻译、预测可能的单词并生成连贯的文本。然而，它们并不真正理解意义，方式与人类不同。请参见“大型语言模型的风险 (LLM)”，IBM 技术，2023 年 4 月 14 日，YouTube 视频，8:25，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=r4kButlDLUc%60&amp;&%60t=278s%E3%80%82">https://www.youtube.com/watch?v=r4kButlDLUc`&amp;&amp;`t=278s。</a></p>
<p>4 “ChatGPT 实验：自回归大型语言模型 (AR-LLMs) 及其作为结构化摘要的推理限制，”GDELT 项目，2023 年 2 月 14 日，<a target="_blank" rel="noopener" href="https://blog.gdeltproject.org/chatgpt-experiments-autoregressive-large-language-models-ar-llms-and-the-limits-of-reasoning-as-structured-summarization%E3%80%82">https://blog.gdeltproject.org/chatgpt-experiments-autoregressive-large-language-models-ar-llms-and-the-limits-of-reasoning-as-structured-summarization。</a></p>
<p>5 潘海丰和高剑锋，“用于生物医学自然语言处理的领域特定语言模型预训练，” 微软研究博客，2020 年 8 月 31 日， <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/blog/domain-specific-language-model-pretraining-for-biomedical-natural-language-processing%E3%80%82">https://www.microsoft.com/en-us/research/blog/domain-specific-language-model-pretraining-for-biomedical-natural-language-processing。</a></p>
<p>6 PubMed，访问日期：2024 年 6 月 20 日，<a target="_blank" rel="noopener" href="https://pubmed.ncbi.nlm.nih.gov./">https://pubmed.ncbi.nlm.nih.gov。</a></p>
<p>7 李进赫等，“BioBERT：一种用于生物医学文本挖掘的预训练生物医学语言表示模型，”生物信息学 36, no. 4 (2020 年 2 月): 1234–1240，<a target="_blank" rel="noopener" href="https://academic.oup.com/bioinformatics/article/36/4/1234/5566506%E3%80%82">https://academic.oup.com/bioinformatics/article/36/4/1234/5566506。</a></p>
<p>8 Iz Beltagy, Kyle Lo 和 Arman Cohan，“SciBERT：一种用于科学文本的预训练语言模型，”arXiv，2019 年 9 月 10 日，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.10676%E3%80%82">https://arxiv.org/abs/1903.10676。</a></p>
<p>9 黄可欣、贾安·阿尔托萨尔和拉杰什·兰加纳特，“ClinicalBERT：建模临床笔记和预测医院再入院”，CHIL ’20 研讨会，2020 年 4 月 2 日至 4 日，安大略省多伦多，<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.05342#:~:text=ClinicalBERT%20is%20an%20application%20of,task%20of%20hospital%20readmission%20prediction%E3%80%82">https://arxiv.org/pdf/1904.05342#:~:text=ClinicalBERT%20is%20an%20application%20of,task%20of%20hospital%20readmission%20prediction。</a></p>
<p>10 阿利斯泰尔·E·W·约翰逊等，“MIMIC-III，一个可自由访问的重症监护数据库，” 科学数据 3, no. 160035 (2016), <a target="_blank" rel="noopener" href="https://www.nature.com/articles/sdata201635%E3%80%82">https://www.nature.com/articles/sdata201635。</a></p>
<p>11 “Med-PaLM，”谷歌研究，访问日期：2024 年 6 月 20 日，<a target="_blank" rel="noopener" href="https://sites.research.google/med-palm%E3%80%82">https://sites.research.google/med-palm。</a></p>
<p>12 Karan Singhal 等，“利用大型语言模型实现专家级医学问答”，arXiv，2023 年 5 月 16 日，<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.09617%E3%80%82">https://arxiv.org/pdf/2305.09617。</a></p>
<p>13 阿曼达·简·莫达拉加梅， “医疗保健中使用的顶级可穿戴医疗设备，” Healthnews，2024 年 1 月 16 日，<a target="_blank" rel="noopener" href="https://healthnews.com/family-health/healthy-living/wearable-medical-devices-used-in-healthcare%E3%80%82">https://healthnews.com/family-health/healthy-living/wearable-medical-devices-used-in-healthcare。</a></p>
<p>14 大卫·M·莱文和阿提夫·梅赫罗特拉，“在非医生中对经过验证的病例小插曲进行诊断和分诊评估，互联网搜索前后的比较，” JAMA Network Open 4, no. 3 (2021): e213287, <a target="_blank" rel="noopener" href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2777835%E3%80%82">https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2777835。</a></p>
<p>15 “企业应用中的对话式人工智能未来会怎样？” Koru，2024 年 6 月 11 日，<a target="_blank" rel="noopener" href="https://www.koruux.com/blog/conversational-ai-in-enterprise-apps%E3%80%82">https://www.koruux.com/blog/conversational-ai-in-enterprise-apps。</a></p>
<p>16 玛格丽特·E·克鲁克等，“在全民健康覆盖时代，由于低质量卫生系统导致的死亡：对 137 个国家可避免死亡的系统分析，” 柳叶刀 392, no. 10160 (2018 年 11 月 17 日): 2203–2212, <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6238021%E3%80%82">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6238021。</a></p>
<p>17 “UpToDate：现代医疗的可信证据基础解决方案，”沃尔特斯·克鲁维尔，访问日期：2024 年 6 月 20 日，<a target="_blank" rel="noopener" href="https://www.wolterskluwer.com/en/solutions/uptodate%E3%80%82">https://www.wolterskluwer.com/en/solutions/uptodate。</a></p>
<p>18 迈克尔·莫里森，“进行研究的医院是否为患者提供更好的护理？”马萨诸塞州总医院，新闻稿，2022 年 2 月 28 日，<a target="_blank" rel="noopener" href="https://www.massgeneral.org/news/press-release/do-research-hospitals-provide-better-care-for-patients%E3%80%82">https://www.massgeneral.org/news/press-release/do-research-hospitals-provide-better-care-for-patients。</a></p>
<p>19 凯莉·霍利和西普·贝克，以 AI 为先的医疗：AI 在健康业务和临床管理中的应用 (O’Reilly Media, 2021)，<a target="_blank" rel="noopener" href="https://www.amazon.com/AI-First-Healthcare-Applications-Business-Management/dp/1492063150%E3%80%82">https://www.amazon.com/AI-First-Healthcare-Applications-Business-Management/dp/1492063150。</a></p>
<p>20 “前谷歌首席执行官埃里克·施密特眼中的人工智能未来，” Noema 杂志，2024 年 5 月 21 日，YouTube 视频，20:06，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=DgpYiysQjeI%E3%80%82">https://www.youtube.com/watch?v=DgpYiysQjeI。</a></p>
<p>21 “人工智能代理工作流程的未来，AI Fund 的 Andrew Ng”，红杉资本，2024 年 3 月 26 日，YouTube 视频，13:39，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=sal78ACtGTc%60&amp;&%60t=524s%E3%80%82">https://www.youtube.com/watch?v=sal78ACtGTc`&amp;&amp;`t=524s。</a></p>
<p>22 玛格丽特·米切尔，“伦理人工智能并不是谷歌Gemini灾难的罪魁祸首，” 时代，2024 年 2 月 29 日，<a target="_blank" rel="noopener" href="https://time.com/6836153/ethical-ai-google-gemini-debacle%E3%80%82">https://time.com/6836153/ethical-ai-google-gemini-debacle。</a></p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/08/08/llmclinical/" rel="prev" title="医疗保健的LLMs和生成式人工智能 --- 目录">
                  <i class="fa fa-angle-left"></i> 医疗保健的LLMs和生成式人工智能 --- 目录
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/08/09/llmsClinical02/" rel="next" title="第二章 窥视人工智能黑箱">
                  第二章 窥视人工智能黑箱 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Howard Huang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">628k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">19:03</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">
    <!--由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动-->
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.umd.js" integrity="sha256-+2+qOqR8CKoHh/AsVR9k2qaDBKWjYNC2nozhYmv5j9k=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
