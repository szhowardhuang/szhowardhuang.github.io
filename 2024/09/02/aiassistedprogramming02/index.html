<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"szhowardhuang.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="在本章中，我们将打开人工智能辅助编程工具的“引擎盖”，看看它们的工作原理。我们将简要回顾历史，体验transformer模型和LLMs，并演示OpenAI Playground。然后我们将获得一些关于如何评估LLMs的建议。 掌握这项强大技术的能力和局限性将为在实际软件项目中更智能地使用人工智能辅助编程工具铺平道路。 关键特性市场上一直在热议人工智能辅助编程工具，如 GitHub Copilot、">
<meta property="og:type" content="article">
<meta property="og:title" content="第2章 人工智能编码技术如何工作">
<meta property="og:url" content="https://szhowardhuang.github.io/2024/09/02/aiassistedprogramming02/index.html">
<meta property="og:site_name" content="嵌入式老兵博客">
<meta property="og:description" content="在本章中，我们将打开人工智能辅助编程工具的“引擎盖”，看看它们的工作原理。我们将简要回顾历史，体验transformer模型和LLMs，并演示OpenAI Playground。然后我们将获得一些关于如何评估LLMs的建议。 掌握这项强大技术的能力和局限性将为在实际软件项目中更智能地使用人工智能辅助编程工具铺平道路。 关键特性市场上一直在热议人工智能辅助编程工具，如 GitHub Copilot、">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://szhowardhuang.github.io/assets_aiassistedprogramming/net-img-aiap_0201-20240826170148-fbyzzp7.png">
<meta property="og:image" content="https://szhowardhuang.github.io/assets_aiassistedprogramming/net-img-aiap_0202-20240826170148-r6qslyl.png">
<meta property="og:image" content="https://szhowardhuang.github.io/assets_aiassistedprogramming/net-img-aiap_0203-20240826170149-c9ihr2k.png">
<meta property="og:image" content="https://szhowardhuang.github.io/assets_aiassistedprogramming/net-img-aiap_0204-20240826170149-eqapt0f.png">
<meta property="og:image" content="https://szhowardhuang.github.io/assets_aiassistedprogramming/net-img-aiap_0205-20240826170150-wm3665w.png">
<meta property="article:published_time" content="2024-09-02T03:48:32.000Z">
<meta property="article:modified_time" content="2024-09-26T03:55:47.000Z">
<meta property="article:author" content="Howard Huang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://szhowardhuang.github.io/assets_aiassistedprogramming/net-img-aiap_0201-20240826170148-fbyzzp7.png">


<link rel="canonical" href="https://szhowardhuang.github.io/2024/09/02/aiassistedprogramming02/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://szhowardhuang.github.io/2024/09/02/aiassistedprogramming02/","path":"2024/09/02/aiassistedprogramming02/","title":"第2章 人工智能编码技术如何工作"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>第2章 人工智能编码技术如何工作 | 嵌入式老兵博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">嵌入式老兵博客</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7"><span class="nav-number">1.</span> <span class="nav-text">关键特性</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%BB%BA%E8%AE%AE%E5%92%8C%E4%B8%8A%E4%B8%8B%E6%96%87%E6%84%9F%E7%9F%A5%E8%A1%A5%E5%85%A8-vs-%E6%99%BA%E8%83%BD%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8"><span class="nav-number">2.</span> <span class="nav-text">代码建议和上下文感知补全 vs 智能代码补全</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7"><span class="nav-number">3.</span> <span class="nav-text">编译器与人工智能辅助编程工具</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%83%BD%E5%8A%9B%E7%BA%A7%E5%88%AB"><span class="nav-number">4.</span> <span class="nav-text">能力级别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%92%8C%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLMs%EF%BC%89"><span class="nav-number">5.</span> <span class="nav-text">生成式人工智能和大型语言模型（LLMs）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%BC%94%E5%8C%96"><span class="nav-number">5.1.</span> <span class="nav-text">演化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Transformer%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.2.</span> <span class="nav-text">Transformer模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenAI-%E6%B8%B8%E4%B9%90%E5%9C%BA"><span class="nav-number">5.3.</span> <span class="nav-text">OpenAI 游乐场</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A4%E7%89%8C"><span class="nav-number">5.3.1.</span> <span class="nav-text">令牌</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%B9%B3%E5%8F%B0"><span class="nav-number">5.3.2.</span> <span class="nav-text">使用平台</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0LLMs"><span class="nav-number">6.</span> <span class="nav-text">评估LLMs</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LLMs%E7%9A%84%E7%B1%BB%E5%9E%8B"><span class="nav-number">7.</span> <span class="nav-text">LLMs的类型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7%E8%AF%84%E4%BC%B0"><span class="nav-number">8.</span> <span class="nav-text">人工智能辅助编程工具评估</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BB%93%E8%AE%BA"><span class="nav-number">9.</span> <span class="nav-text">结论</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Howard Huang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">68</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/09/02/aiassistedprogramming02/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="第2章 人工智能编码技术如何工作 | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第2章 人工智能编码技术如何工作
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-09-02 11:48:32" itemprop="dateCreated datePublished" datetime="2024-09-02T11:48:32+08:00">2024-09-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-26 11:55:47" itemprop="dateModified" datetime="2024-09-26T11:55:47+08:00">2024-09-26</time>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>13k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>24 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>在本章中，我们将打开人工智能辅助编程工具的“引擎盖”，看看它们的工作原理。我们将简要回顾历史，体验transformer模型和LLMs，并演示OpenAI Playground。然后我们将获得一些关于如何评估LLMs的建议。</p>
<p>掌握这项强大技术的能力和局限性将为在实际软件项目中更智能地使用人工智能辅助编程工具铺平道路。</p>
<h1 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h1><p>市场上一直在热议人工智能辅助编程工具，如 GitHub Copilot、Tabnine、CodiumAI 和 Amazon CodeWhisperer。每个产品的制造商都试图炫耀自己的一套功能。但这些工具有很多共同的能力。表 2-1 总结了一些主要特性。</p>
<p>表 2-1.  AI 辅助编程工具的常见功能</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>代码建议</td>
<td>根据注释和文件上下文提供代码建议；推荐单行或整个函数。</td>
</tr>
<tr>
<td>上下文感知补全</td>
<td>提供基于全部或部分代码库的上下文感知代码补全，以及帮助编码的建议。</td>
</tr>
<tr>
<td>测试生成</td>
<td>分析代码以生成有意义的测试，映射代码行为，并提出边缘情况以确保软件在发布前的可靠性。</td>
</tr>
<tr>
<td>用户–IDE 交互</td>
<td>在 IDE 中自动激活并提供指导，用户可以通过聊天与代码互动。</td>
</tr>
<tr>
<td>代码分析</td>
<td>分析代码片段、文档字符串和注释，以提供可靠的代码预测并标记可疑代码。</td>
</tr>
<tr>
<td>错误检测和修复</td>
<td>识别代码中的潜在错误并建议修复方法。</td>
</tr>
<tr>
<td>代码自动文档生成</td>
<td>自动添加文档字符串并增强代码文档。</td>
</tr>
<tr>
<td>例行任务自动化</td>
<td>帮助创建常规或耗时任务的代码，不熟悉的 API 或 SDK，以及其他常见编码场景，<br />如文件操作和图像处理。<br /></td>
</tr>
<tr>
<td>API 和 SDK 使用优化</td>
<td>帮助正确有效地使用 API 和 SDK。</td>
</tr>
<tr>
<td>开源发现与归属</td>
<td>促进开源代码和库的发现与归属。</td>
</tr>
</tbody></table>
<p>表 2-1 中的列表并不是全部；创新正在快速发展。显然，这些系统通过提供代码建议和上下文感知的补全可以大大帮助开发人员。我们将在下一节中详细介绍这些内容。</p>
<h1 id="代码建议和上下文感知补全-vs-智能代码补全"><a href="#代码建议和上下文感知补全-vs-智能代码补全" class="headerlink" title="代码建议和上下文感知补全 vs 智能代码补全"></a>代码建议和上下文感知补全 vs 智能代码补全</h1><p>智能代码补全的魔力，也称为自动补全或微软的术语智能感知，是许多集成开发环境（IDE）提供的功能。它通过建议、填充和突出显示代码片段来帮助开发人员，当人类在键盘上敲击时。这项技术实际上自 20 世纪 50 年代末拼写检查器问世以来就已经存在。</p>
<p>突破发生在 1990 年代中期。微软的 Microsoft Visual Basic 5.0 提供了实时建议和补全，重点是基本语法和函数签名。这大大提高了生产力并减少了错误。</p>
<p>那么你可能会想：像智能感知这样的东西与人工智能辅助编程工具相比如何？毕竟，智能感知有一些人工智能和机器学习的基础。</p>
<p>然而，有一个重要的区别需要指出。人工智能辅助工具是由生成式人工智能驱动的。它们不仅提供代码，还提供文档、规划文档和有用的指南等内容。得益于生成式人工智能，这些工具能够根据给定的上下文生成、调整和理解类人文本，使它们在翻译、摘要、文本分析、主题建模和回答查询方面表现出色。与这些工具互动有时就像与您的代码进行随意聊天。它们以LLM为核心，可以捕捉到您输入的上下文和意图。</p>
<h1 id="编译器与人工智能辅助编程工具"><a href="#编译器与人工智能辅助编程工具" class="headerlink" title="编译器与人工智能辅助编程工具"></a>编译器与人工智能辅助编程工具</h1><p>为了更好地理解人工智能辅助编程工具，了解编译器的工作原理是有帮助的。以下是编译器执行的主要步骤：</p>
<ul>
<li>词法分析（分词）：编译器像语言老师一样，将你的代码分解成标记。</li>
<li>语法分析：在这里，编译器检查你的标记是如何分组的。它确保你的代码具有正确的结构，而不仅仅是正确的命令。</li>
<li>语义分析（错误检查）：编译器确保您的代码在编程语言的上下文中是有意义的。这不仅仅是正确的语法问题。还涉及正确的含义。</li>
<li>中间代码生成：这是您的代码开始转换旅程的地方。编译器将您的高级代码转换为中间形式。它还不是机器语言，但正在接近。</li>
<li> 代码优化：在这一步，编译器就像你代码的私人教练，使其更精简、更高效。它调整中间代码以提高运行速度并减少占用空间。</li>
<li> 代码生成：这是最终转换。编译器将优化后的中间代码转换为您的 CPU 可以理解的机器代码或汇编语言。</li>
<li> 链接和加载：链接有时被视为编译过程的一部分，它涉及将各种代码和库组合成一个可执行程序。加载是将程序放入内存以便执行的过程。</li>
</ul>
<p>至于像 Copilot 这样的人工智能辅助编程工具，它们是另一种东西。它们并不真正“理解”编程语言，就像编译器那样。这没关系。编译器会这样做。相反，它们使用人工智能根据大量现有代码来猜测和建议代码片段。由于这些工具是在碰运气，建议可能会有很大差异。然后编译器会将这些代码处理成机器可以运行程序的形式。</p>
<p>有时候，人工智能工具可能会漏掉一些简单的东西，比如括号，而人类编码者或编译器可以在瞬间发现。这是因为LLMs是基于预测模式，而不是编译器引擎。如果某些内容在训练中不常见，它们可能无法捕捉到。此外，这些工具可能会变得花哨，并根据情况建议复杂的代码。是的，人工智能辅助编程工具可能会过于兴奋。</p>
<p>在发现错误方面，人工智能辅助编程工具通常有效，但仍然无法与编译器的高效错误检查技能相媲美。不过，这些工具仍然很强大。例如，它们可以帮助捕捉恼人的语法错误——缺少分号、函数名称中的拼写错误、不匹配的括号——并迅速建议正确的修复方案。它们在帮助你避免常见编码陷阱方面也表现出色。无论是提醒你在打开文件后正确关闭它，还是建议更高效的遍历数组的方法，这个工具都能为你提供支持。而在逻辑错误方面，人工智能辅助编程工具可能会给出意想不到的见解。它们可能无法解决每个复杂问题，但通常可以提出你可能没有考虑过的替代方法或解决方案，引导你的问题解决过程朝着正确的方向前进。</p>
<p>这意味着虽然人工智能工具有助于使编码更顺畅，但它们不能替代编译器的全面检查或人类编码者的敏锐眼光。</p>
<p>这些缺点确实强调了将人工智能辅助工具的智能与编译器检查的全面性和人类触感相结合的重要性。毕竟，您希望确保您的代码不仅好，而且准确无误。</p>
<h1 id="能力级别"><a href="#能力级别" class="headerlink" title="能力级别"></a>能力级别</h1><p>在 2023 年 10 月，Sourcegraph 的首席执行官兼联合创始人 Quinn Slack 分享了一篇深刻的博客文章。他深入探讨了像 Copilot 这样的人工智能辅助编程工具，并提出了一种有趣的思考方式，他称之为“代码人工智能的层次”。他的逐步框架使每个人都更容易理解这些人工智能工具能做什么，并检查销售这些工具的公司所夸大的说法是否真实。图 2-1 显示了代码的层次。</p>
<p>前三个级别侧重于人工编码，开发者是主要参与者。首先，级别 0 是没有人工智能辅助的地方，这就是传统编码。开发者完全手动完成所有工作，没有人工智能的参与。这是为后续人工智能介入奠定基础的基线。</p>
<p>然后是一级，代码补全。在这一阶段，人工智能开始参与，根据周围的情况生成单行或代码块。此时，开发者仍然掌控全局，指导整体程序，并将人工智能作为典型编码任务的捷径。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0201-20240826170148-fbyzzp7.png"> 图 2-1. 编程系统具有不同级别的人工智能能力</p>
<p>二级，代码创建，增强人工智能。在这里，它变得更加动手，编写更长的代码段。人工智能可以，例如，设计 API，甚至修复现有代码。当然，这一切都是在有人监督的情况下进行的。这个级别需要人工智能获取代码库及其上下文，以便生成不仅正确而且适合的代码。</p>
<p>从三级开始，监督自动化，我们看到人工智能在编码方面开始主导。在这个阶段，人工智能处理多个任务，以满足人类设定的更广泛目标，并且不需要每次都进行检查。在这个级别工作就像将工作委派给初级开发人员。这个级别的人工智能足够聪明，可以排除错误，添加新功能，并将系统结合在一起，在此过程中向人类同事寻求任何澄清。</p>
<p>在第四级，完全自动化，人工智能真正提升了其能力。在这里，它独立处理复杂任务，无需人类对代码进行最终确认。想象一下，如果你是首席执行官或产品经理，你会对一位顶尖工程师有多大的信任。这就是这一层级所追求的关系。人工智能不仅仅是被动反应。它主动监控代码，发现并解决出现的问题。</p>
<p>最后是第五级，人工智能主导的完全自主。这一级别是一个完全不同的游戏，人工智能不仅仅是遵循人类指令，而是设定自己的目标。这是关于人工智能基于核心奖励函数进行工作。可以把它看作是在一个与其他智能体对抗的世界中玩自己的游戏。当然，这一级别听起来有点像科幻，但考虑到事物发展的速度，认为我们可能在有生之年看到这一水平成为现实并不是太疯狂。</p>
<p>现在，像 Copilot 这样的工具大约处于 3 级左右。确定确切的级别可能很棘手，但 Quinn Slack 的框架很好地解释了技术及其关键交互。而且有一点是肯定的：技术没有放缓——它正在快速向前发展。</p>
<h1 id="生成式人工智能和大型语言模型（LLMs）"><a href="#生成式人工智能和大型语言模型（LLMs）" class="headerlink" title="生成式人工智能和大型语言模型（LLMs）"></a>生成式人工智能和大型语言模型（LLMs）</h1><p>使用人工智能辅助编程工具并不要求你精通生成式人工智能技术的细节。然而，对技术有一个宏观的了解是非常有帮助的。你将能够更清晰地评估这些工具的响应、能力和局限性。</p>
<p>透明度不仅仅是一个流行词。在新技术真正流行起来之前，清楚了解其内部机制至关重要。采用的关键在于信任。在编码世界中，可靠性和问责制不仅仅是花哨的附加功能——它们是基本要素。</p>
<p>随着我们进入接下来的部分，我们将简要介绍生成式人工智能和LLMs，以便给您一个更清晰的概念。</p>
<h2 id="演化"><a href="#演化" class="headerlink" title="演化"></a>演化</h2><p>生成式人工智能的故事可以追溯到几十年前，其中一个最早的例子是 ELIZA，这个开创性的聊天机器人是麻省理工学院教授约瑟夫·魏岑鲍姆在 60 年代中期开发的。ELIZA 被设计用来模拟与心理治疗师的对话（你仍然可以在网上找到它）。当然，它很基础，运行在基于规则的算法上，主要是重复用户输入。</p>
<p>然而，许多人发现与 ELIZA 聊天比与真实治疗师更愉快，有些人甚至被欺骗以为他们在与人类交流。这种奇怪的现象被称为“ELIZA 效应”，展示了人们多么容易想象计算机程序具有类人理解能力。</p>
<p>然而，生成式人工智能的旅程并不完全是一场短跑。其核心技术相对基础，进展更多是缓慢爬行。但到了 2010 年代，场景迎来了转折点。技术世界现在拥有强大的计算能力、炫酷的硬件系统如 GPU（图形处理单元）、丰富的数据宝库，以及对深度学习等复杂模型的微调。就这样，生成式人工智能回到了快车道。随着其发展，出现了不同的方法：</p>
<ul>
<li>变分自编码器（VAE）：这项技术于 2013 年首次亮相，感谢 Diederik P. Kingma 和 Max Welling 及其论文“自动编码变分贝叶斯”。他们的变分自编码器（VAE）模型由更复杂的高维数据生成的低维潜在空间组成，全部无需监督。它还包括编码器-解码器结构。当我们说高维数据时，我们指的是具有多个特征的数据，每个特征都是一个维度——想象一下在 784 维空间中的 28 × 28 像素图像。低维潜在空间就像这个数据的紧凑版本，保留了关键信息，同时去掉了多余的维度。这一点很重要，因为它减轻了计算负担，抵御了维度诅咒，并使数据更易于可视化和解释。从高维空间到低维空间的跃迁称为降维，它将数据简化到最基本的要素。与传统自编码器不同，后者为每个潜在属性输出单个值，VAE 中的编码器给出一个概率分布。然后，解码器从这个分布中选择样本以重建数据。 这种在潜在空间中提供一系列数据而不是单一值的巧妙技巧为创建新数据或图像打开了大门。</li>
<li>生成对抗网络（GANs）：生成对抗网络是由伊恩·古德费洛及其同事在 2014 年提出的一类用于无监督机器学习的人工智能算法。生成对抗网络的核心是两个神经网络，分别称为生成器和判别器，它们在类似游戏的对抗中相互竞争。生成器生成新的数据片段，而判别器充当评判者，区分真实数据和虚假数据。随着每一轮的进行，生成器不断提升其能力，生成与真实实例惊人相似的数据。这种巧妙的设置为新的可能性打开了大门，导致人工智能能够创建逼真的图像、语音录音等更多内容。</li>
</ul>
<p>这些类型的生成式人工智能将是transformer模型的重要构建块，这是一个真正的突破，使LLMs的能力成为现实。</p>
<h2 id="Transformer模型"><a href="#Transformer模型" class="headerlink" title="Transformer模型"></a>Transformer模型</h2><p>在transformers崭露头角之前，自然语言处理（NLP）的首选方法是递归神经网络（RNN）。RNN 被设计用来处理序列或时间序列数据。它们会跟踪一个隐藏状态，以记住序列中前一步的部分信息——这对于语言建模、语音识别和情感分析等任务非常有用。RNN 逐步处理，一次处理序列中的一个片段，根据当前输入和之前处理过的内容更新它们的隐藏状态——因此称为递归。但在面对长序列时，它们遇到了困难，受到梯度消失或爆炸问题的困扰。这使得它们很难跟踪数据中的长期关系。</p>
<p>transformer，完全翻转剧本。transformers并行处理数据，利用注意力机制跟踪输入序列中不同部分之间的关系，无论它们的位置如何，而不是采用递归神经网络（RNNs）的逐步方法。这种架构蓝图的切换使transformers能够轻松处理短序列和长序列。它还避免了梯度问题。此外，它们的并行处理能力与图形处理单元（GPU）或张量处理单元（TPU）等复杂芯片架构很好地结合。</p>
<p>阿希什·瓦斯瓦尼及其在谷歌的研究团队创建了transformer，并在 2017 年发表了开创性论文“注意力机制就是全部所需”。图 2-2 展示了模型的主要部分。</p>
<p>transformer模型就像一位出色的语言学家，擅长解开语言的复杂性。它的魔力分为两个主要阶段：编码和解码。每个阶段都由自己的一组层组成。在编码阶段，模型读取并理解输入文本，类似于语言学家理解外语句子。然后在解码阶段，模型根据编码阶段获得的理解生成一段新文本或翻译，就像语言学家将该句子翻译成你的母语一样。</p>
<p>在transformer的核心是一个称为注意力的机制，它允许模型评估句子中每个单词与其他单词的相关性。它为每个单词分配一个注意力分数。例如，考虑句子“猫坐在垫子上。”当模型关注单词坐时，单词猫和垫子可能会因为与坐的动作直接相关而获得更高的注意力分数。</p>
<p>该模型的一个显著特点是自注意力机制。这使得它能够查看整个句子，理解单词之间的关系，并在长文本中保留这些关系。这赋予了transformer一种长期记忆的形式，使其能够关注到目前为止出现的所有单词或标记（完整单词或单词的一部分），从而理解更广泛的上下文。</p>
<p>然而，尽管具备这些能力，transformer最初缺乏识别句子中单词顺序的能力，而这对于理解意义至关重要。在这里，位置编码发挥作用。它像 GPS 一样为模型提供句子中每个单词位置的信息，并帮助理解诸如“猫追老鼠”和“老鼠追猫”这样的从句。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0202-20240826170148-r6qslyl.png"></p>
<p> 图 2-2. transformer 模型的架构是 LLMs 的核心</p>
<p>增加复杂性，transformer采用了多头注意力机制。设想模型有多个眼睛对， 每对从独特的角度审视句子，关注单词之间的不同方面或关系。例如，一对可能专注于理解动作，另一对专注于识别角色，还有一对专注于识别地点。这种多视角的方法使transformer能够更丰富地理解文本。</p>
<p>此外，transformer的每个阶段都包含前馈神经网络的层，这是一种简单的网络，有助于处理词语之间的关系。这进一步增强了文本的理解和生成。</p>
<p>一个transformer是以预训练模型的形式存在。它已经在大量数据上进行了训练，准备好用于使用或进一步微调。一旦预训练，模型可以作为 API 访问，允许在各种语言处理任务中立即使用。公司或个人可以快速将该模型集成到他们的系统中，例如 AI 辅助编程应用。此外，预训练的LLM可以通过在特定领域的数据上进行微调，进一步优化以在专业领域（如医疗或法律文本分析）中表现出色。这消除了从头开发复杂语言模型的需要，节省了大量时间、精力和资源。预训练模型凭借其基础语言理解，成为生成式人工智能应用开发的跳板。</p>
<p>  注意</p>
<blockquote>
<p>构建和运营一个LLM的成本很高。根据《华尔街日报》，在 2023 年初，GitHub Copilot 每位用户平均每月亏损超过 20 美元。在某些情况下，一些用户每月让公司亏损 80 美元。然而，随着基础设施在未来几年为生成式人工智能扩展，每位用户的成本应该会降低。</p>
</blockquote>
<p>两种主要的transformer系统是生成式预训练transformer（GPT）和双向编码器表示的变换器（BERT）。GPT 是OpenAI的一个工具，适合创建文本、总结信息和翻译语言。它基于自回归LLM架构。这意味着它通过仔细考虑每个词来生成文本，基于它已经输出的内容，就像讲故事的人逐字构建叙述一样。它的技能来自于在大量文本数据上进行训练。GPT 使用解码器生成内容。</p>
<p>BERT 采用自编码方法。这种设计使其能够深入理解句子中单词的上下文，使其擅长解读语言的细微差别和含义。谷歌在 2018 年开发了 BERT 作为一个开源项目。从那时起，许多变体和对核心模型的增强相继出现。</p>
<p>关于人工智能辅助编程应用，主要类型的transformer模型是 GPT。它已被证明能够根据程序员提供的上下文有效地预测和自动完成代码。</p>
<h2 id="OpenAI-游乐场"><a href="#OpenAI-游乐场" class="headerlink" title="OpenAI 游乐场"></a>OpenAI 游乐场</h2><p>OpenAI Playground 是一个生成式人工智能沙盒，提供对 OpenAI 开发的各种模型的访问。它通过直观的图形界面允许模型定制。</p>
<p>OpenAI Playground 使理解各种 LLMs 的优缺点变得更加容易。此外，它还支持根据不同输入（如温度）实时测试和调整模型。</p>
<p>然而，OpenAI 对使用该平台收费。费用基于使用的令牌数量，如表 2-2 所示。请注意，价格会定期变动。好消息是截至本文撰写时，所有变动都是价格降低。</p>
<p>表 2-2. OpenAI LLMs的成本</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>输入</th>
<th>输出</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-4&#x2F;8K 上下文</td>
<td>0.03&#x2F;1 千 tokens</td>
<td>0.06&#x2F;1 千 tokens</td>
</tr>
<tr>
<td>GPT-4&#x2F;32K 上下文</td>
<td>0.06&#x2F;1 千 tokens</td>
<td>0.12&#x2F;1K 令牌</td>
</tr>
<tr>
<td>GPT-3.5-Turbo&#x2F;4K 上下文</td>
<td>0.0015&#x2F;1K 令牌</td>
<td>0.002&#x2F;1 千 tokens</td>
</tr>
<tr>
<td>GPT-3.5-Turbo&#x2F;16K 上下文</td>
<td>0.003&#x2F;1 千 tokens</td>
<td>0.004&#x2F;1 千 tokens</td>
</tr>
</tbody></table>
<p>例如，假设您正在使用 GPT-4&#x2F;8K 上下文 LLM。您有一个包含 1,000 个标记的提示，模型对此的响应为 2,000 个标记。那么输入的费用为 3 美分，输出的费用为 12 美分。</p>
<p>当您首次注册OpenAI账户时，您将获得 5 美元的积分，可用于OpenAI Playground。这可以用于调用 API。</p>
<h3 id="令牌"><a href="#令牌" class="headerlink" title="令牌"></a>令牌</h3><p>让我们更详细地看一下令牌。OpenAI 有一个叫做分词器的工具，如图 2-3 所示，我输入了以下内容进行分析：</p>
<blockquote>
<p>聊天生成式人工智能真不可思议！🎉 我喜欢它。</p>
</blockquote>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0203-20240826170149-c9ihr2k.png"></p>
<p> 图 2-3. OpenAI 分词器显示文本片段的标记</p>
<p>在标记化中（用颜色突出显示），词语 ChatGPT 由三个标记组成。拆分为 Chat、G 和 PT。词语不可思议及其后面的感叹号有两个标记，一个是词语，一个是标点符号。至于表情符号，它由三个标记组成。每个标点符号都是一个标记。空格与相邻的词一起计算。</p>
<p>分词器适用于 GPT-3、GPT-3.5 和 GPT-4。请注意，分词在LLMs之间通常是不同的。</p>
<p>  注意</p>
<p>大致上，1000 个令牌大约相当于 750 个单词。</p>
<h3 id="使用平台"><a href="#使用平台" class="headerlink" title="使用平台"></a>使用平台</h3><p>当你进入OpenAI Playground 时，你会看到一个仪表板，如图 2-4 所示。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0204-20240826170149-eqapt0f.png"></p>
<p> 图 2-4. OpenAI 游乐场有一个包含提示、资源和互动区域的仪表板</p>
<p>屏幕中间是与LLM的主要工作流程：</p>
<ul>
<li> 系统：这是您为LLM提供一些上下文的地方，例如，“您是 Python 编程专家。”系统提示是会话中的第一条消息，为交互设置了基础。自定义系统提示可以更好地控制模型在对话中的行为，这在确保其保持在期望的参数或上下文内时特别有用。</li>
<li> 用户：这里是输入提示词的主要指令。例如，这里是您可以要求LLM执行编码任务的地方。</li>
<li> 添加消息：这允许您与LLM进行持续聊天。</li>
</ul>
<p>让我们尝试一个例子。假设您正在进行一个 Python 项目，并且在理解如何实现 Tkinter 库以获取用户输入方面遇到困难。您可以输入以下内容：</p>
<blockquote>
<p>系统消息：您是一名专注于 Tkinter 的 Python 专家。</p>
<p>用户消息：我想使用 Tkinter 创建一个简单的 GUI 来获取用户的姓名和年龄。我该怎么做？</p>
</blockquote>
<p>LLM 将生成代码列表。但假设您想为输入添加验证。您可以按添加按钮并输入“我如何确保输入的年龄是数字而不是文本？”</p>
<p>LLM 将使用 try-except 块响应此代码，将年龄输入转换为整数。</p>
<p>当然，这类似于使用 ChatGPT——但更有结构。此外，真正的强大之处在于定制的能力。您将在屏幕右侧找到这些功能：</p>
<ul>
<li> 模型：您可以从多种模型中选择，甚至可以使用您自己微调的LLMs，以确保模型专注于您编码的独特需求。您可以在OpenAIAPI 文档中找到有关微调模型的更多信息。</li>
<li> 温度：这调整生成内容的随机性或创造性。值的范围是从 0 到 2。值越低，响应越确定和集中。表 2-3 显示了不同类型开发任务的建议温度级别。</li>
</ul>
<p>表 2-3. 某些类型编程任务的建议温度水平</p>
<table>
<thead>
<tr>
<th>任务类别</th>
<th>温度值</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>代码生成</td>
<td>0.2–0.3</td>
<td>确保更确定性、准确的代码遵循通用约定，以实现可靠和易于理解的结果。</td>
</tr>
<tr>
<td>代码审查</td>
<td>0.2 或更少</td>
<td>专注于成熟的最佳实践和标准，以提供准确的反馈。</td>
</tr>
<tr>
<td>修复漏洞</td>
<td>0.2 或更少</td>
<td>生成更准确和直接的解决方案来解决识别的问题。</td>
</tr>
<tr>
<td>创造性问题解决</td>
<td>0.7–1.0</td>
<td>探索更广泛的可能解决方案，适用于头脑风暴或创新问题解决。</td>
</tr>
<tr>
<td>学习和实验</td>
<td>0.7–1.0</td>
<td>提供更多样化的示例和解决方案，以理解不同的问题解决方法。</td>
</tr>
<tr>
<td>数据分析与可视化</td>
<td>0.2 或更少</td>
<td>生成准确且有意义的可视化或分析。</td>
</tr>
<tr>
<td>优化任务</td>
<td>多样化</td>
<td>允许在探索（更高温度）和开发（更低温度）之间取得平衡，以实现高效解决方案。</td>
</tr>
</tbody></table>
<p>然而，如果您使用一个相当高的温度值，结果可能会毫无意义。以下是使用值为 2 时的示例提示：</p>
<blockquote>
<p>在 Python 中，将数据从 CSV 文件迁移到 MySQL 数据库的步骤是什么？</p>
</blockquote>
<p>图 2-5 显示了输出。正如您所看到的，这没有什么意义！</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0205-20240826170150-wm3665w.png"></p>
<p> 图 2-5. 当使用温度为 2 时，LLM 的结果大多是无意义的</p>
<p>现在，让我们看看您可以调整的其他功能：</p>
<ul>
<li> 最大长度：这是生成内容所使用的最大令牌数。该数字&#x3D;&#x3D;包括提示和响应的使用&#x3D;&#x3D;。令牌与内容的比例取决于您使用的模型。</li>
<li> 停止序列：这表明LLM应该停止生成更多文本的一个点。您可以指定一个特定的字符串或字符序列，当在生成的文本中检测到时，将指示模型停止该过程。</li>
<li> Top p：也称为核采样，这种技术根据累积概率阈值选择单词，记作 p，范围从 0 到 1。简单来说，模型不是总是从最可能的几个下一个单词中选择，而是根据指定的 p 值考虑更广泛或更狭窄的可能下一个单词范围。较低的 p 值会导致选择的单词集合更小、更集中，从而生成更可预测和连贯的文本。较高的 p 值则允许更广泛的可能下一个单词集合，从而生成更多样化和创造性的文本。</li>
<li> 频率惩罚：这有助于解决LLMs的一个常见问题，即重复的短语或句子。值范围从 0 到 2。值越高，重复越少。然而，在大于 1 的值时，文本生成可能变得不可预测甚至毫无意义。</li>
<li> 存在惩罚：这也有 0 到 2 的值。更高的值将允许LLM包含更广泛的令牌，这意味着使用更丰富的词汇或更广泛的概念范围。</li>
</ul>
<p>通过频率惩罚、存在惩罚和Top p，OpenAI建议选择一种方法来调整您的任务。但不要害怕实验。优化LLMs的路径并不是由严格的规则铺成的，这要归功于所涉及复杂性的微妙变化。</p>
<h1 id="评估LLMs"><a href="#评估LLMs" class="headerlink" title="评估LLMs"></a>评估LLMs</h1><p>评估LLMs是一项繁重的任务。这些庞然大物往往如此不透明，以至于似乎难以理解。人工智能公司的竞争只会加剧这一点。关于这些模型训练所用的数据集、用于微调其行为的参数数量以及驱动它们的硬件的细节寥寥无几已成为常态。</p>
<p>但有一些好消息，感谢斯坦福大学的一些研究人员。他们创建了一个评分系统，称为基础模型透明度指数，以评估LLMs的开放性。这个标准由一百个标准构成，旨在为LLM透明度的模糊领域带来一些清晰度。</p>
<p>排名基于百分比评分。表 2-4 显示了排名。不幸的是，结果远未令人鼓舞。根据研究人员的说法，没有主要LLM接近实现“足够的透明度”，平均得分仅为 37%。</p>
<p>表 2-4. 模型透明度排名前LLMs</p>
<table>
<thead>
<tr>
<th>公司</th>
<th>Model</th>
<th>排名</th>
</tr>
</thead>
<tbody><tr>
<td>Meta</td>
<td>LLaMA 2</td>
<td>54%</td>
</tr>
<tr>
<td>BigScience</td>
<td>BLOOMZ</td>
<td>53%</td>
</tr>
<tr>
<td>OpenAI</td>
<td>GPT-4</td>
<td>48%</td>
</tr>
<tr>
<td>Stability.ai</td>
<td>Stable Diffusion 2</td>
<td>47%</td>
</tr>
<tr>
<td>谷歌</td>
<td>PaLM 2</td>
<td>40%</td>
</tr>
<tr>
<td>Anthropic</td>
<td>Claude 2</td>
<td>36%</td>
</tr>
<tr>
<td>Cohere</td>
<td>Command</td>
<td>34%</td>
</tr>
<tr>
<td>AI21Lab</td>
<td>Jurassic-2</td>
<td>25%</td>
</tr>
<tr>
<td>Inflection</td>
<td>Inflection-1</td>
<td>21%</td>
</tr>
<tr>
<td>亚马逊</td>
<td>Titan Text</td>
<td>12%</td>
</tr>
</tbody></table>
<p>基础模型研究中心，基础模型透明度指数总分 2023，<a target="_blank" rel="noopener" href="https://crfm.stanford.edu/fmti">https://crfm.stanford.edu/fmti</a></p>
<p>LLMs 处理各种领域和任务的灵活性，例如软件开发，是一个显著的优势。然而，这也使评估过程变得复杂，因为它需要特定领域的评估指标和基准，以确保模型在每个特定应用中的有效性和安全性。</p>
<p>尽管如此，在评估LLMs时仍需考虑一些指标：</p>
<ul>
<li> BERT 评分：该指标旨在通过使用 BERT 嵌入比较生成文本与参考文本来评估文本生成模型。虽然主要用于自然语言文本，但可以扩展或调整用于代码生成任务，特别是在代码用自然语言注释或评论时。</li>
<li>Perplexity 困惑：是评估概率模型的常见指标，如LLMs。它量化了模型预测的概率分布与数据的实际分布之间的契合程度。在代码生成的上下文中，较低的困惑度值表明模型在预测代码序列中的下一个标记方面表现更好。</li>
<li>BLEU（双语评估助手）：最初用于机器翻译，BLEU 也用于代码生成，以比较生成的代码与参考代码。它计算 n-gram 精确度分数，以量化生成文本与参考文本之间的相似性，这有助于评估生成代码的语法正确性。更高的 n-gram 精确度分数表示生成文本与参考文本在特定 n 个单词序列上的更好一致性。</li>
<li>ROUGE（针对摘要评估的召回导向替代方法）：这是另一个借用自自然语言处理的指标，可用于评估代码生成模型。它计算生成文本和参考文本之间的 n-gram 重叠，提供生成代码与预期输出对齐程度的洞察。</li>
<li>MBXP（最基本的 X 编程问题）：该基准专门用于评估跨多种编程语言的代码生成模型。它使用可扩展的转换框架将原始数据集中的提示和测试用例转译为目标语言，从而促进对代码生成模型的全面多语言评估。</li>
<li> 人类评估：这是一个基准测试，用于通过测量从文档字符串合成程序的功能正确性来评估LLMs的代码生成能力。这个基准测试对于代码生成中人工智能模型的持续开发和增强至关重要。虽然不同的模型在 HumanEval 上表现出不同的熟练程度，但一个名为 HUMANEVAL+的扩展版本在识别流行的LLMs生成的先前未检测到的错误代码方面发挥了关键作用。</li>
<li>多语言人类评估（HumanEval-X）：这是原始 HumanEval 基准的扩展。多语言 HumanEval 评估LLMs的代码生成和翻译能力，涵盖超过 10 种编程语言。它采用转换框架将提示和测试用例从 Python 转译为目标语言中的相应数据，从而创建一个更全面的多语言代码生成和翻译基准。</li>
</ul>
<p>另一种评估LLM的方法是查看参数数量——可能达到数千亿。因此，参数越多越好吗？不一定。评估应该采取更细致的方法。首先，扩展参数的成本可能非常庞大，包括计算能力和能源使用。这可能使得LLM在货币化应用方面变得不经济。接下来，随着参数数量的膨胀，模型的复杂性也会增加，这可能导致过拟合。过拟合发生在模型在训练数据上表现得非常好，但在面对未见过的数据时却表现不佳。这削弱了它的泛化能力。</p>
<p>另一个问题是需要大量多样化的训练数据集，以满足这些模型对数据的贪婪需求。然而，获取和整理如此庞大的数据集不仅资源密集，还会带来数据隐私和偏见方面的挑战。此外，随着参数的激增，这些巨型模型的评估变得越来越复杂。评估指标需要更加全面和多样化，以准确衡量模型在众多任务上的表现。</p>
<p>最后，微调可以更好地利用模型，而无需大幅增加基础LLM的参数大小。</p>
<h1 id="LLMs的类型"><a href="#LLMs的类型" class="headerlink" title="LLMs的类型"></a>LLMs的类型</h1><p>有各种类型的LLMs，其中一个显著的类别是开源LLMs。任何人都可以使用、修改或分享它们。它们的透明性意味着你可以看到这些模型是如何工作的。此外，开源LLMs允许开发者合作创新以及开发插件，当然，还可以修复恼人的错误。</p>
<p>最棒的部分？它们没有价格标签。</p>
<p>但开源LLMs并非都是美好和顺利。通常没有专门的团队来解决问题或推出定期更新。因此，如果遇到困难，您可能需要动手去论坛寻求帮助。</p>
<p>开源模型的质量和性能有时像过山车一样波动。此外，还有令人烦恼的安全问题。由于一切都是公开的，黑客更容易找到插入恶意代码的方法。建议谨慎行事。</p>
<p>最后，当涉及用户指南和文档时，开源LLMs可能会让你希望有更多。指南有时感觉像是用象形文字写成的。</p>
<p>表 2-5 显示了一些顶级开源LLMs。</p>
<p>表 2-5. 顶级开源LLMs</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>开发者</th>
<th>参数<br />（B &#x3D; 十亿）<br /></th>
<th>值得注意的特点</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-NeoX-20B</td>
<td>EleutherAI</td>
<td>20B</td>
<td>在“The Pile”数据集上训练；能够执行各种自然语言处理任务，<br />如故事生成、聊天机器人和摘要生成<br /></td>
</tr>
<tr>
<td>LLaMA 2</td>
<td>Meta</td>
<td>7B到 70B</td>
<td>训练于 2 万亿个标记；是 LLaMA 1 上下文长度的两倍</td>
</tr>
<tr>
<td>OPT-175B</td>
<td>Meta</td>
<td>175B</td>
<td>一套模型的一部分；训练时的碳足迹低于 GPT-3</td>
</tr>
<tr>
<td>BLOOM</td>
<td>BigScience</td>
<td>176B</td>
<td>在 ROOTS 语料库上训练；设计用于透明度，公开训练数据细节和评估方法</td>
</tr>
<tr>
<td>Falcon-40B</td>
<td>Technology <br />Innovation <br />Institute (TII)<br /></td>
<td>40B</td>
<td>训练于 1000B 标记</td>
</tr>
<tr>
<td>Dolly 2.0</td>
<td>Databricks</td>
<td>12B</td>
<td>基于 EleutherAI 的 Pythia 模型系列；提供类似 ChatGPT <br />的指令跟随交互性<br /></td>
</tr>
<tr>
<td>Mistral 7B</td>
<td>Mistral AI</td>
<td>7.3B</td>
<td>使用分组查询和滑动窗口注意力；在大规模数据集上训练，<br />擅长处理较长序列<br /></td>
</tr>
<tr>
<td>Mixtral 8X7B</td>
<td>Mistral AI</td>
<td>46.7B</td>
<td>稀疏专家混合模型；像 12.9B 模型一样进行推理，支持多种语言，<br />并在代码生成和推理等各种任务中表现出色<br /></td>
</tr>
</tbody></table>
<p>闭源或专有LLMs则要保密得多。它们通常将代码、训练数据和模型结构严格保密。然而，开发这些复杂系统的公司通常拥有巨额资本。表 2-6 显示了这些公司在 2023 年筹集的资本。</p>
<p>表 2-6. 前LLM名开发者筹集的风险投资</p>
<table>
<thead>
<tr>
<th>公司</th>
<th>资金</th>
</tr>
</thead>
<tbody><tr>
<td>Anthropic</td>
<td>12.5 亿美元</td>
</tr>
<tr>
<td>OpenAI</td>
<td>100 亿美元</td>
</tr>
<tr>
<td>Cohere</td>
<td>2.7 亿美元</td>
</tr>
<tr>
<td>Inflection AI</td>
<td>13 亿美元</td>
</tr>
</tbody></table>
<p>凭借这些资源，这些公司可以聘请世界上最优秀的数据科学家并构建复杂的基础设施。结果是，这些LLMs在性能方面通常是最先进的。它们还为规模和企业的严格需求而构建，例如安全性和隐私。</p>
<p>关于缺点，存在信任问题。这些模型是如何生成响应的？幻觉和偏见怎么办？这些问题的答案可能缺乏细节。</p>
<p>然后这些大型人工智能运营商可能会形成垄断。这可能意味着客户会被锁定在一个生态系统中。最后，闭源LLMs可能比开源项目更容易停滞，因为它们可能无法从开源项目通常享有的多样化输入和审查中受益。</p>
<h1 id="人工智能辅助编程工具评估"><a href="#人工智能辅助编程工具评估" class="headerlink" title="人工智能辅助编程工具评估"></a>人工智能辅助编程工具评估</h1><p>选择哪个人工智能辅助编程工具可能让人困惑。你需要权衡很多因素，比如精确度、聊天功能、安全性、速度和用户友好性。有时候，这归结为使用起来的感觉。但如果你的雇主坚持使用特定系统，你可能就无能为力了。</p>
<p>要了解当前热门的技术，Stack Overflow 2023 开发者调查是一个方便的资源。Stack Overflow 收集了近 90,000 名编码者对最受欢迎工具的见解，您可以在表 2-7 中查看。</p>
<p>表 2-7. 流行的人工智能辅助编程工具排名</p>
<table>
<thead>
<tr>
<th>人工智能辅助开发工具</th>
<th>百分比</th>
</tr>
</thead>
<tbody><tr>
<td>GitHub Copilot</td>
<td>54.77%</td>
</tr>
<tr>
<td>Tabnine</td>
<td>12.88%</td>
</tr>
<tr>
<td>亚马逊CodeWhisperer</td>
<td>5.14%</td>
</tr>
<tr>
<td>Snyk Code</td>
<td>1.33%</td>
</tr>
<tr>
<td>Codeium</td>
<td>1.25%</td>
</tr>
<tr>
<td>Wispr AI</td>
<td>1.13%</td>
</tr>
<tr>
<td>Replit Ghostwriter</td>
<td>0.83%</td>
</tr>
<tr>
<td>Mintlify</td>
<td>0.52%</td>
</tr>
<tr>
<td>Adrenaline</td>
<td>0.43%</td>
</tr>
<tr>
<td>Rubberduck AI</td>
<td>0.37%</td>
</tr>
</tbody></table>
<p>2023 年开发者调查 - Stack Overflow</p>
<p>此图表让您了解可用的众多工具。当您想选择一个时，明智的做法是向其他开发者获取推荐。此外，亲自试用几个也是个好主意。幸运的是，这些工具大多数提供免费试用，因此您可以在不立即承诺的情况下试用它们。</p>
<p>另一个需要考虑的关键方面是公司的财务支持。它有风险投资吗？没有这些，公司可能不仅难以增长，还难以保持其平台的创新性。目前，已经有几家人工智能辅助编程公司不得不停止其服务，这确实会给开发者带来麻烦。以 Kite 为例。它是该领域的早期参与者之一，成立于 2014 年。然而，到 2022 年，公司决定停止该项目。好消息是，它开源了大部分工具的代码库。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>在本章中，我们揭开了生成式人工智能和LLMs的面纱。我们 glimpsed 一些迷人的历史，例如 ELIZA，然后专注于人工智能的一个重大突破：transformer模型。我们还尝试了 OpenAI Playground，并展示了如何自定义 LLM。</p>
<p>本章的一些关键内容包括令牌、利用预训练模型的优势、评估LLMs的注意事项、困惑度和 BLEU 分数等指标，以及开源模型与专有模型。</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/08/30/aiassistedprogramming01/" rel="prev" title="第1章 开发者的新世界">
                  <i class="fa fa-angle-left"></i> 第1章 开发者的新世界
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/09/04/aiassistedprogramming03/" rel="next" title="第3章 提示工程">
                  第3章 提示工程 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Howard Huang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">616k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">18:40</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">
    <!--由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动-->
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.umd.js" integrity="sha256-+2+qOqR8CKoHh/AsVR9k2qaDBKWjYNC2nozhYmv5j9k=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
