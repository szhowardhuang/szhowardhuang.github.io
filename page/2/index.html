<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"szhowardhuang.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="嵌入式老兵博客">
<meta property="og:url" content="https://szhowardhuang.github.io/page/2/index.html">
<meta property="og:site_name" content="嵌入式老兵博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Howard Huang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://szhowardhuang.github.io/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>嵌入式老兵博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">嵌入式老兵博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Howard Huang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">70</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/09/04/aiassistedprogramming03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/09/04/aiassistedprogramming03/" class="post-title-link" itemprop="url">第3章 提示工程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-09-04 11:48:32" itemprop="dateCreated datePublished" datetime="2024-09-04T11:48:32+08:00">2024-09-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-26 11:55:47" itemprop="dateModified" datetime="2024-09-26T11:55:47+08:00">2024-09-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>22 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>提示工程是机器学习和自然语言处理的一个子领域，研究使计算机理解和解释人类语言。主要目标是找出如何与大型语言模型进行对话，这些复杂的人工智能系统旨在处理和生成类人语言响应，以便以正确的方式生成我们所寻找的答案。</p>
<p>想想这样：你知道当你向某人寻求建议时，必须给他们一些背景信息并明确你需要什么吗？LLMs也是这样。你必须仔细构建你的问题或提示。有时，你甚至可以在问题中添加一些提示或额外信息，以确保LLM明白你在问什么。</p>
<p>这不仅仅是问一次性的问题。有时候这就像和LLM进行一整个对话，来回交流，调整你的问题，直到得到你需要的关键信息。</p>
<p>例如，假设您正在使用人工智能辅助编程工具开发一个web应用程序。您首先询问如何用 JavaScript 创建一个简单的用户登录系统。最初的回答可能涵盖基础知识，但随后您意识到需要更高级的功能。因此，您继续提出更具体的提示，询问如何实现密码加密和安全连接到数据库。与人工智能的每次互动都在完善其响应，逐渐使其适应您项目的特定需求。</p>
<p>请记住，提示工程师已成为一个炙手可热的职位类别。根据威利斯塔的数据，提示工程师的年平均收入约为 130,000 美元，尽管这个数字可能偏保守。为了吸引顶尖人才，公司通常通过提供诱人的股权套餐和奖金来增加吸引力。</p>
<p>在本章中，我们将深入探讨提示工程的世界，并解说有用的策略和技巧。</p>
<h1 id="艺术与科学"><a href="#艺术与科学" class="headerlink" title="艺术与科学"></a>艺术与科学</h1><p>提示工程是一门艺术与科学的结合。一方面，你需要选择正确的词语和语气，以使人工智能以你想要的方式回应。这是关于引导对话朝着某个方向发展。需要一些直觉和创造力来引导对话，并完善你的语言，提炼出详细而微妙的回复。</p>
<p>是的，这可能很棘手，尤其是对于软件开发人员。通常，您遵循一套规则来编写代码，要么它可以工作，要么编译器告诉您哪里出错。这是合乎逻辑且可预测的。</p>
<p>但提示工程？没那么多。它更自由形式且不可预测。</p>
<p>那么，提示工程也有很多科学内容。你需要理解人工智能模型的基本原理，正如我们在第二章中讨论的那样。除了创造力，你还需要精确性、可预测性和复制结果的能力。通常这意味着你需要进行实验，尝试不同的提示，分析结果，并调整内容，直到得到正确的响应。</p>
<p>通过提示工程，不要指望找到每次都有效的魔法解决方案。当然，有很多课程、视频和书籍声称拥有所有提示工程的“秘密”。但要保持怀疑态度，否则你可能会失望。</p>
<p>此外，人工智能和机器学习的世界总在变化，新的模型和技术不断出现。因此，拥有一种明确的提示工程技术的想法？这是一个不断变化的目标。</p>
<h1 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h1><p>提示工程可能令人沮丧。即使是你措辞提示的最小变化也会对LLM的输出产生巨大影响。这是因为其底层的先进技术基于概率框架。</p>
<p>以下是提示工程的一些挑战：</p>
<ul>
<li> 冗长: LLMs 可能会喋喋不休。给他们一个提示，他们可能会展开讲述，给你一个冗长的回答，而你只想要一个简短的答案。他们倾向于加入一堆相关的想法或事实，使回答比必要的更长。如果你希望 LLM 直截了当，只需让它“简明扼要”。</li>
<li> 不可转移性: 这意味着一个在LLM上效果不错的提示可能在另一个上效果不佳。换句话说，如果你从 ChatGPT 切换到 Gemini 或 GitHub Copilot，你可能需要调整你的提示，因为每个LLM的训练、设计和专业化都是独特的。不同的模型是在不同的数据集和算法上训练的，从而导致对提示的不同理解和解释。</li>
<li> 长度灵敏度: LLMs 可能会被长提示淹没，开始忽视或误解输入的部分。就像 LLM 的注意力持续时间减弱，响应变得有些分散。这就是为什么你应该避免在提示中提供详细要求；保持提示在一页以内。</li>
<li> 模糊性: 如果您的提示不清晰，LLM 可能会感到困惑，提供的响应可能会偏离主题或纯属虚构。清晰是关键。</li>
</ul>
<p>尽管如此，还有改进结果的方法。我们将在本章的其余部分介绍这些方法。</p>
<h1 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h1><p>您可以将提示视为具有四个主要组成部分，如图 3-1 所示。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0301-20240826175554-7pfqct7.png"></p>
<p> 图 3-1. 提示有四个主要组成部分</p>
<p>首先，上下文指定了LLM在提供响应时要采取的人物或角色。接下来是指令，例如总结、翻译或分类。然后是内容输入，如果您希望LLM处理信息以生成更好的响应。最后，您可以显示您希望输出的格式。</p>
<p>请记住，您不需要所有这些组件。实际上，您可能只需要一个就能获得良好的响应。但作为一般规则，提供更多具体细节给LLM会更好。</p>
<p>现在让我们看看每个组件。</p>
<h1 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a>上下文</h1><p>您通常会以一两句话开始您的提示，以提供上下文。通常，您会指定希望人工智能在提供响应时扮演的角色或身份。这会导致响应不仅更准确，而且在上下文上更相关，从而确保更有意义的结果。</p>
<p>例如，如果您想调试一段代码，您可以将其用作上下文：</p>
<blockquote>
<p>提示：您是一名经验丰富的软件工程师，专注于调试 Java 应用程序。</p>
</blockquote>
<p>假设您想了解某个算法的优化技术。您可以这样开始：</p>
<blockquote>
<p>提示：您是一名具有算法优化专业知识的高级软件开发人员。</p>
</blockquote>
<p>添加上下文有助于LLM以正确的心态处理您的提示。</p>
<h1 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h1><p>您的提示应该至少包含一个明确的指令。您可以添加更多指令，但需要小心。加载大量查询可能会使LLM陷入困境，从而更难获得您想要的答案。</p>
<p>让我们分析一下为什么会发生这种情况。首先，当你有多个指令时，事情可能会变得有些模糊。如果它们不清晰或者似乎相互冲突，LLM 可能会对应该关注哪个指令或如何平衡它们感到困惑。</p>
<p>接下来，更多的指令意味着LLM需要处理更多内容。它必须处理和理解提示的每个部分，然后找出如何将所有部分编织成一个连贯的响应。这需要很多脑力运动，有时可能会导致错误或不准确的答案。</p>
<p>并且不要忘记，LLMs 按顺序逐条查看说明。因此，您排列这些查询的方式会影响它们的解释以及您得到的答案类型。</p>
<p>考虑到这一切，一个专业提示是保持简单。不要一次性向LLM抛出一整串问题，而是尝试将它们分解成一系列较小的提示。这就像进行来回的聊天，而不是独白。</p>
<p>提示的指令类型也有很多。在接下来的几个部分中，我们将讨论一些在软件开发中使用的主要指令。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>摘要可以将较长的文本浓缩成较短的版本，同时保持主要思想和要点不变。这对于快速了解冗长的文档非常有用。对于软件开发人员来说，摘要在表 3-1 中列出的场景中特别方便。</p>
<p>表 3-1. 编码任务的摘要提示</p>
<table>
<thead>
<tr>
<th>用例</th>
<th>描述</th>
<th>示例提示</th>
</tr>
</thead>
<tbody><tr>
<td>代码文档</td>
<td>提供了详细文档的简要概述，<br />突出关键功能、依赖关系和结构。<br /></td>
<td>总结以下文档的要点，以便快速概览代码库。</td>
</tr>
<tr>
<td>错误报告</td>
<td>快速识别用户在大量或冗长的错误报告中反馈的<br />主要问题。<br /></td>
<td>总结以下 bug 报告中报告的常见问题，<br />以识别需要解决的主要问题。<br /></td>
</tr>
<tr>
<td>研究论文</td>
<td>从冗长的研究论文或技术文章中提取简明的见解，<br />以便向用户更新最新的研究或技术。<br /></td>
<td>提供以下研究论文中讨论的关键发现和技术的摘要。</td>
</tr>
<tr>
<td>更新日志</td>
<td>使用户了解软件库或工具新版本中的关键更改，<br />来自冗长的变更日志。<br /></td>
<td>总结版本 1.1.2 的变更日志中的关键更改。</td>
</tr>
<tr>
<td>电子邮件</td>
<td>提取长邮件线程中的讨论或决策要点。</td>
<td>总结以下邮件线程的主要讨论点。</td>
</tr>
</tbody></table>
<p>另一种摘要生成方式是主题建模，其中统计模型发现一组文档中出现的抽象“主题”。以下是一些供开发者使用的主题建模提示：</p>
<blockquote>
<p>提示：识别以下文本中讨论的主要主题：{文本}</p>
<p>提示：提取以下文本中的关键词以推断主要主题：{文本}</p>
<p>提示：根据内容建议标签：{文本}</p>
</blockquote>
<h2 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h2><p>文本分类涉及给计算机一堆文本，让它学习用标签标记。其一种形式是情感分析，例如当你有一系列社交媒体帖子时，LLM 可以判断哪些具有正面或负面含义。对于开发者来说，情感分析可以是评估用户反馈的有用工具。</p>
<p>一些示例提示包括：</p>
<blockquote>
<p>请分析这些客户评价，并告诉我情感是总体积极、消极还是中立？{文本}</p>
<p>这是我们用户论坛关于最新更新的讨论帖。你能帮我总结一下整体情绪吗？{文本}</p>
<p>我整理了一份来自我们应用商店页面的反馈列表。你能按情感对评论进行分类吗？{文本}</p>
<p>评估这些博客帖子评论对我们产品发布的情感。共识是什么？{文本}</p>
</blockquote>
<h2 id="推荐"><a href="#推荐" class="headerlink" title="推荐"></a>推荐</h2><p>您可以指示一个LLM提供建议。开发人员可以利用这些反馈来提高响应的质量，例如修复错误、优化代码或更有效地使用 API。</p>
<p>查看这些您可能使用的示例提示：</p>
<blockquote>
<p>提示：以下代码片段在我尝试调用&lt; *Method()* &gt;时抛出 NullPointerException。你能帮我找出潜在原因并建议修复方法吗？</p>
<p>提示：这是我写的一个函数，用于排序整数列表。你能推荐一些优化方法，使其运行更快或更易读吗？</p>
</blockquote>
<p>LLM 推荐可以成为您工作的强大加速器，极大地节省时间并提供您可能没有想到的想法。这种技术在处理复杂或微妙的任务时特别有益。</p>
<p>但也有缺点。一个潜在的问题是LLM可能会过于简化响应，错过细微之处。此外，请记住模型的知识在某个时间点被冻结，因此可能无法获取最新的信息或趋势。</p>
<p>如果说有什么的话，推荐是一种开始的方式。但你需要深入了解，自己再挖掘一些信息以获取完整的情况。</p>
<h2 id="翻译"><a href="#翻译" class="headerlink" title="翻译"></a>翻译</h2><p>本地化本质上是将软件调整为特定区域的语言和文化规范。它使您的软件能够使用当地语言并理解地区特性，这种能力对于拓展市场和与受众建立更紧密的联系至关重要。这可以带来一系列好处：用户更满意，因为软件感觉是为他们量身定制的，而满意的用户可能意味着您业务的更健康利润。</p>
<p>在竞争激烈的市场中，本地化可以在替代方案不足或根本不存在时为您提供优势。此外，通过使您的软件与当地方式保持一致，包括遵守地区法规，您不仅仅是在提供一个选项，而往往是市场上唯一的选项。</p>
<p>另一方面，本地化并非没有挑战。它可能既昂贵又耗时。它需要细致的质量保证，以维护软件在不同语言中的完整性。此外，软件开发并不是静止不变的。这是一个持续更新和新功能的循环，每个功能可能都需要自己的一套本地化工作。这一持续的过程为项目增加了复杂性和额外成本。</p>
<p>这就是LLMs可以派上用场的地方。先进的系统能够在多种语言之间进行翻译。它们可以作为开发者工具包中的强大工具。表 3-2 显示了一些您可能用于本地化的提示。</p>
<p>表 3-2. 语言翻译的提示示例</p>
<table>
<thead>
<tr>
<th>任务类型</th>
<th>描述</th>
<th>示例提示</th>
</tr>
</thead>
<tbody><tr>
<td>用户界面文本翻译</td>
<td>翻译按钮、菜单项、错误消息、对话框等。</td>
<td>翻译以下UI文本为法语：保存，退出，文件，编辑，帮助。</td>
</tr>
<tr>
<td>文档翻译</td>
<td>翻译用户指南、帮助文件和其他文档。</td>
<td>翻译以下用户手册段落为西班牙语。</td>
</tr>
<tr>
<td>错误信息翻译</td>
<td>翻译软件可能生成的错误消息。</td>
<td>翻译以下错误信息为德语：文件未找到，访问被拒绝，网络连接丢失。</td>
</tr>
<tr>
<td>工具提示翻译</td>
<td>翻译工具提示，当用户悬停在某个项目上时提供额外信息。</td>
<td>翻译一下工具提示为日语：点击保存，点击打开新文件，点击打印。</td>
</tr>
</tbody></table>
<p>尽管如此，处理LLMs的多语言能力时仍需谨慎。这些模型并不是万无一失的。这些模型有时可能会忽略语言特有的细微差别、习惯用语和文化背景。语言的细微差别是复杂的，正确理解不仅仅是直接翻译——而是以正确的方式传达正确的意思。</p>
<p>处理特定术语或名称可能很棘手，尤其是当另一种语言中没有合适的对应词时。还有获取语气和风格正确的挑战。这不仅仅是关于词语，而是你如何表达它们，这在不同语言或文化之间可能会有很大变化。</p>
<p>让语言专家查看输出可以为您节省一些麻烦。</p>
<h1 id="内容输入"><a href="#内容输入" class="headerlink" title="内容输入"></a>内容输入</h1><p>在编写提示时，使用像###或”””这样的特殊符号可以清楚地将您的指令与您希望LLM处理的内容或信息分开。这些符号充当边界或标记，使指令结束和内容开始的地方变得清晰。</p>
<p>考虑一种情况，软件开发人员需要帮助总结关于他们正在集成的新 API 的冗长文档中的关键点。以下是您可以构建提示的方式：</p>
<blockquote>
<p>提取以下文本中 API 的关键实现步骤：</p>
<p> 文档：”””</p>
<p>{API 文档文本在这里}</p>
<p> “””</p>
</blockquote>
<p>使用”””分隔符是一种将指令与 API 文档文本分开的简洁方法。它使LLM更清楚地了解需要做什么，并增加了获得主要步骤简明总结的机会。此外，这些分隔符整理了提示，使其更易于阅读，这对于较长或更复杂的文本输入来说是一个真正的救星。</p>
<h1 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h1><p>在您的提示中，您可以告诉LLM如何格式化输出。以下是一个示例：</p>
<p><em>Prompt:</em> Create a Python function that takes a list of user objects (each object containing a user’s ID and name) and returns a JSON object that maps user IDs to names. Format the output as JSON.</p>
<p><em>ChatGPT:</em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;</span><br><span class="line">    &quot;code&quot;: &quot;def map_user_ids_to_names(users):\n  </span><br><span class="line">      user_map = &#123;user[&#x27;id&#x27;]: user[&#x27;name&#x27;] for user in users&#125;\n</span><br><span class="line">      return user_map&quot;,</span><br><span class="line">    &quot;example_usage&quot;: &#123;</span><br><span class="line">        &quot;input&quot;: [</span><br><span class="line">            &#123;&quot;id&quot;: 1, &quot;name&quot;: &quot;Alice&quot;&#125;,</span><br><span class="line">            &#123;&quot;id&quot;: 2, &quot;name&quot;: &quot;Bob&quot;&#125;,</span><br><span class="line">            &#123;&quot;id&quot;: 3, &quot;name&quot;: &quot;Charlie&quot;&#125;</span><br><span class="line">        ],</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;1&quot;: &quot;Alice&quot;,</span><br><span class="line">            &quot;2&quot;: &quot;Bob&quot;,</span><br><span class="line">            &quot;3&quot;: &quot;Charlie&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>表 3-3 显示了一些选项。</p>
<p>表 3-3. 格式化输出的提示</p>
<table>
<thead>
<tr>
<th>格式类型</th>
<th>示例提示</th>
</tr>
</thead>
<tbody><tr>
<td>Table</td>
<td>创建一个表格，比较 Python、Java 和 C++的语法、性能和使用案例。</td>
</tr>
<tr>
<td>List</td>
<td>列出排查网页加载缓慢的步骤。</td>
</tr>
<tr>
<td>Markdown&#x2F;HTML</td>
<td>解释 GET 和 POST HTTP 方法之间的区别在markdown里面。</td>
</tr>
<tr>
<td>Text hierarchy</td>
<td>提供软件开发生命周期(SDLC)的结构化大纲，包括各阶段及每个阶段的关键活动。</td>
</tr>
<tr>
<td>LaTeX formatting</td>
<td>用 LaTeX 表示法表达二分搜索算法的时间复杂度</td>
</tr>
</tbody></table>
<p>通过提示，您还可以指定响应的长度。您可以通过指令引导LLM，例如“提供简要总结”或“写一个详细的解释”。或者您可以更具体，例如说明响应不应超过 300 个字。LLM可能会超过您提供的字数限制，但至少会在大致范围内。</p>
<h1 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h1><p>接下来我们将看看一些编写提示的最佳实践，这些实践将帮助您获得想要的答案。但不要将这些视为绝对真理。这些建议更像是一般性的建议——可能有些主观——而不是严格的规则。当您花更多时间与LLMs聊天时，您可能会偶然发现适合您的提问方式。这都是提示工程的旅程的一部分。</p>
<h2 id="具体一点"><a href="#具体一点" class="headerlink" title="具体一点"></a>具体一点</h2><p>制作正确的提示就像在良好对话中找到最佳点，这可能是与这些文本生成系统建立联系的最关键步骤。细节越多越好。你还需要清晰。否则，LLM可能会做出假设甚至产生幻觉。</p>
<p>首先，让我们看看一些过于模糊的提示。</p>
<blockquote>
<p>开发增强数据安全性的功能。</p>
<p>请问您能构建一个工具来自动化这个过程吗？</p>
<p>优化代码。</p>
<p>我们需要一个处理交易的函数。</p>
</blockquote>
<p>以下内容更为详细，应该能获得更好的结果：</p>
<blockquote>
<p>提示：开发一个 Python 函数从字符串中解析日期。该函数应能够处理格式 YYYY-MM-DD、MM&#x2F;DD&#x2F;YYYY 和 Month DD, YYYY。它应返回一个 datetime 对象。提供一个脚本，演示该函数正确处理每种格式至少三个示例，以及一份文档，解释任何依赖项、函数中使用的逻辑和运行脚本的说明。</p>
<p>提示：开发一个 SQL 查询，从我们的数据库中检索 2023 年最后一个季度购物金额超过 500 美元的客户列表。查询应返回客户的全名、电子邮件地址、总消费金额以及购买日期。最后一次购买。结果应按支出总额降序排列。请确保查询针对性能进行了优化。</p>
</blockquote>
<h2 id="缩略语和技术术语"><a href="#缩略语和技术术语" class="headerlink" title="缩略语和技术术语"></a>缩略语和技术术语</h2><p>在撰写提示时，明确技术术语和缩略语是至关重要的。这些行话在不同的上下文中往往意味着不同的内容，可能导致无用的响应。因此，最好将缩略语写出并清楚定义或解释所使用的任何技术术语。</p>
<p>例如，假设您正在使用 ChatGPT 来帮助解决数据库连接问题。一个构造不良的提示可能是：</p>
<blockquote>
<p>提示：Having DB connection issues. How to fix it?</p>
</blockquote>
<p>在此提示中，“DB”是模糊的，因为它可能指代不同的数据库系统，如 MySQL、PostgreSQL 或其他，并且连接问题的性质没有明确说明。</p>
<p>更有效的提示是：</p>
<blockquote>
<p>提示：我在尝试使用 JDBC 连接我的 PostgreSQL 数据库时遇到连接超时问题。如何解决这个问题？</p>
</blockquote>
<p>此提示清楚地说明了正在使用的数据库系统、连接方法和遇到的具体问题。</p>
<p>  注意</p>
<blockquote>
<p>马克·吐温曾写道：“几乎正确的词和正确的词之间的区别实际上是一个大问题。这是萤火虫和闪电之间的区别。”在某种程度上，写提示也是如此。</p>
</blockquote>
<h2 id="零样本和少样本学习"><a href="#零样本和少样本学习" class="headerlink" title="零样本和少样本学习"></a>零样本和少样本学习</h2><p>通过零样本学习，您提供一个提示并获得所需的答案。通常，这样做效果很好。但考虑到编程语言和框架的复杂性，有时您需要稍微调整一下LLM。</p>
<p>您可以通过少量学习来做到这一点。这是指LLM理解和执行任务的能力，只需很少的示例或训练数据。这相对于传统机器学习模型来说是一个显著的优势，后者可能需要大量的训练数据才能在任务上表现良好。LLM的能力主要得益于LLM在针对特定任务进行微调之前，对多样化的互联网文本进行广泛的预训练。</p>
<p>让我们看一个少量学习的例子。考虑一个场景，我们想生成一个函数来规范化给定的数字列表。它将把列表中的值缩放到[0, 1]的范围。在指令中，我们包含了一些输入和规范化输出的示例列表。</p>
<blockquote>
<p>提示：基于以下将数字列表归一化到[0, 1]范围的示例：</p>
<ol>
<li>Input: [2, 4, 6, 8] Output: [0, 0.3333, 0.6667, 1]</li>
<li>Input: [5, 10, 15] Output: [0, 0.5, 1]</li>
<li>Input: [1, 3, 2] Output: [0, 1, 0.5]</li>
</ol>
<p>生成一个接受数字列表作为输入并返回归一化数字列表的 Python 函数。</p>
</blockquote>
<p>ChatGPT将从数据中“学习”并生成一些代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def normalize(numbers):</span><br><span class="line">    min_value = min(numbers)</span><br><span class="line">    max_value = max(numbers)</span><br><span class="line">    if min_value == max_value:</span><br><span class="line">        return [0] * len(numbers)  # Handle the case where </span><br><span class="line">                                   # all numbers are the same</span><br><span class="line">    else:</span><br><span class="line">        return [(x - min_value) / (max_value - min_value) for x in numbers]</span><br><span class="line"># Test the function with one of the examples</span><br><span class="line">print(normalize([2, 4, 6, 8]))  # Output: [0.0, 0.3333333333333333, </span><br><span class="line">                                # 0.6666666666666666, 1.0]</span><br></pre></td></tr></table></figure>

<h2 id="引导词"><a href="#引导词" class="headerlink" title="引导词"></a>引导词</h2><p>引导词的概念是指可以指导LLM生成特定类型输出的特定关键字或短语。有时您可以仅使用一个代码词来实现所需的结果。这里有一个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Prompt:</span><br><span class="line"></span><br><span class="line"># Create a simple Python function that</span><br><span class="line"></span><br><span class="line"># 1. Prompts me for a temperature in Fahrenheit</span><br><span class="line"></span><br><span class="line"># 2. Converts Fahrenheit to Celsius</span><br><span class="line"></span><br><span class="line">def</span><br></pre></td></tr></table></figure>

<p>使用词语 def 作为引导词告诉模型应该开始编写一个 Python 函数。表 3-4 提供了更多引导词的示例。</p>
<p>表 3-4. 关键词提示示例</p>
<table>
<thead>
<tr>
<th>上下文</th>
<th>引导词</th>
</tr>
</thead>
<tbody><tr>
<td>JavaScript 函数</td>
<td>Function</td>
</tr>
<tr>
<td>HTML 元素</td>
<td>&lt;button</td>
</tr>
<tr>
<td>CSS 样式</td>
<td>P {</td>
</tr>
<tr>
<td>SQL 插入查询</td>
<td>INSERT INTO</td>
</tr>
<tr>
<td>Java 方法创建</td>
<td>public</td>
</tr>
</tbody></table>
<h2 id="思维链提示"><a href="#思维链提示" class="headerlink" title="思维链提示"></a>思维链提示</h2><p>在 2022 年，一些谷歌研究人员在他们的论文“链式思维提示引发大型语言模型推理”中引入了链式思维（CoT）提示。这种方法通过将复杂问题分解成不同步骤来增强LLMs的推理能力。它实际上类似于少量学习，这允许对模型进行引导。</p>
<p>CoT 提示在软件代码生成任务中非常有用。我们来看一个例子。假设您想使用 Flask 创建一个具有用户注册和登录功能的 web 应用程序。表 3-5 显示了 CoT 提示步骤。</p>
<p>表 3-5. 思维链提示示例</p>
<table>
<thead>
<tr>
<th>操作描述</th>
<th>提示</th>
</tr>
</thead>
<tbody><tr>
<td>理解需求</td>
<td>我需要使用 Flask 创建一个web 应用程序。该应用程序应具有用户注册和登录功能。我应该从哪里开始？</td>
</tr>
<tr>
<td>设置 Flask 应用程序</td>
<td>让我们开始设置一个基本的 Flask 应用程序。我该怎么做？</td>
</tr>
<tr>
<td>创建用户模型</td>
<td>现在 Flask 应用程序已设置好，我需要创建一个用户模型来处理注册和登录。我应该如何构建这个模型？</td>
</tr>
<tr>
<td>实现注册</td>
<td>有了用户模型，我该如何实现一个包含必要字段的注册页面？</td>
</tr>
<tr>
<td>实现登录</td>
<td>现在让我们开始创建登录页面。如何确保安全登录？</td>
</tr>
<tr>
<td>会话管理</td>
<td>用户登录后，我应该如何管理用户会话，以便在他们浏览应用时保持用户登录状态？</td>
</tr>
<tr>
<td>注销实现</td>
<td>最后，我该如何实现一个注销功能以安全地将用户登出应用程序？</td>
</tr>
</tbody></table>
<h2 id="引导性问题"><a href="#引导性问题" class="headerlink" title="引导性问题"></a>引导性问题</h2><p>提示中的引导性问题往往会导致LLM给出不准确的回答。保持中立和客观是更好的选择。此外，避免做出假设也是一种良好的实践；直接说明问题。</p>
<p>这个提示是一个引导性问题：</p>
<blockquote>
<p>迁移到微服务架构是否总会提高系统可扩展性？</p>
</blockquote>
<p>更平衡的提示是：</p>
<blockquote>
<p>迁移到微服务架构在系统可扩展性方面的优势和潜在挑战是什么？</p>
</blockquote>
<h2 id="请求示例和类比"><a href="#请求示例和类比" class="headerlink" title="请求示例和类比"></a>请求示例和类比</h2><p>假设你不知道面向对象编程中的继承概念。你去找 ChatGPT 并输入这个提示：</p>
<blockquote>
<p>Prompt: 继承是面向对象编程中一种机制，它允许一个类继承另一个类的属性和方法，从而实现代码重用和层次结构的建立。</p>
</blockquote>
<p>您将获得详细的回复。但您可能想要一些更容易理解的内容。一个好的方法是向LLM请求类比：</p>
<blockquote>
<p>Prompt: 类的继承类似于家庭关系，子类继承父类的特征和行为，就像孩子从父母那里继承基因和习惯。</p>
<p><em>ChatGPT</em>：将继承视为家谱，子女从父母以及可能的祖父母那里继承某些特征和属性。</p>
</blockquote>
<p>从那里，ChatGPT 提供更多细节，通过类比来解释继承的关键要素。</p>
<h1 id="减少幻觉"><a href="#减少幻觉" class="headerlink" title="减少幻觉"></a>减少幻觉</h1><p>在第二章中，我们了解到提示一个LLM可能导致生成的响应是幻觉，即生成的内容是虚假的或误导性的，但LLM将响应表达得好像是真的。幻觉对于软件开发尤其具有挑战性，因为这需要准确性。</p>
<p>毫无疑问，应用本章中的经验教训可以缓解这个问题，但即使是精心制作的提示也可能产生幻觉。这有很多原因：</p>
<ul>
<li>缺乏真实数据验证: LLMs 根据从训练数据中学习到的模式生成响应，但无法验证信息的准确性或真实性。</li>
<li>过拟合和记忆化: LLMs 可能会记住训练数据集中不正确或误导的信息，特别是当这些数据是重复或常见时。</li>
<li>训练数据中的偏差: 如果训练数据包含偏见、不准确或虚假信息，模型可能会在输出中复制这些内容。</li>
<li>外推和推测:有时，LLMs可能会根据他们在数据中看到的模式推断出关于未在训练数据中充分覆盖的话题或问题的信息。</li>
<li>缺乏上下文或误解:LLMs 可能会误解或缺乏必要的上下文来准确响应某些提示。他们可能无法完全理解某些查询的细微差别或含义。</li>
<li> 俚语和成语: 这种语言可能会产生歧义，导致模型误解预期的意思，特别是如果它在训练期间没有看到足够的上下文中的俚语或成语示例。</li>
</ul>
<p>那么如何减少幻觉？首先，避免问这样开放式的问题：</p>
<blockquote>
<p>提示：优化数据库的不同方法有哪些？</p>
</blockquote>
<p>这种提示鼓励LLM进行推测或过度概括。模型可能还会误解问题的意图或答案的期望格式，从而导致偏离主题或包含虚假信息的回答。实际上可能会出现一系列幻觉。</p>
<p>一种有效的技术是提供一组预定义的选项，并让人工智能从中选择。例如，可以将前面的提示重新表述如下：</p>
<blockquote>
<p>提示：以下哪项是优化数据库的方法：索引、碎片整理或压缩？索引、碎片整理或压缩？</p>
</blockquote>
<p>作为另一个例子，考虑向LLM请求某种类型的结论。这里是一个有效的提示：</p>
<blockquote>
<p>提示：以下在 Java 中初始化数组的语法是否正确？回答“是”或“否”。</p>
</blockquote>
<p>或者您可以在提示中包含多个步骤，以更好地引导模型通过结构化过程并缩小偏离方向的可能性：</p>
<blockquote>
<p>提示：</p>
<p>步骤 1：创建一个斐波那契数列生成器。</p>
<p>步骤 2：使用迭代方法。</p>
<p>步骤 3：编写一个名为 generate_fibonacci 的 Python 函数，该函数接受一个整数 n 作为参数。</p>
<p>步骤 4：该函数返回斐波那契序列中的前 n 个数字作为列表。</p>
</blockquote>
<h1 id="安全和隐私"><a href="#安全和隐私" class="headerlink" title="安全和隐私"></a>安全和隐私</h1><p>在编写提示时关注安全和隐私是关键。事实上，采取适当预防措施的责任应该在公司规章中。避免任何敏感或个人信息，例如个人身份信息（PII），在您的提示中至关重要。以下是包含识别信息的提示示例：</p>
<blockquote>
<p>提示：您将如何解决约翰·杜问题报告的登录问题 <a href="mailto:&#106;&#111;&#x68;&#110;&#46;&#100;&#111;&#x65;&#x40;&#x65;&#x78;&#97;&#x6d;&#x70;&#108;&#x65;&#x2e;&#x63;&#x6f;&#x6d;">&#106;&#111;&#x68;&#110;&#46;&#100;&#111;&#x65;&#x40;&#x65;&#x78;&#97;&#x6d;&#x70;&#108;&#x65;&#x2e;&#x63;&#x6f;&#x6d;</a>？</p>
</blockquote>
<p>更明智的做法是选择类似的东西：</p>
<blockquote>
<p>提示：您将如何处理用户报告的登录问题？</p>
</blockquote>
<p>这保持了私人信息的私密性。</p>
<p>避免在提示中泄露任何敏感系统细节。避免这样做：</p>
<blockquote>
<p>如何修复我们生产服务器上 IP 192.168.1.1 的数据库连接错误？</p>
</blockquote>
<p>相反，使用更通用的问题更安全：</p>
<blockquote>
<p>提示：如何修复通用数据库连接错误？</p>
</blockquote>
<p>此外，确保您的提示不会无意中引导用户采取不当行为。这样的提示从安全角度来看是可以的：</p>
<blockquote>
<p>提示：如何检测和防止 SQL 注入？</p>
</blockquote>
<p>但不是这个，这可能会激起一些不良意图：</p>
<blockquote>
<p>提示：如何利用网站中的 SQL 漏洞？</p>
</blockquote>
<p>除了遵守安全和隐私规则外，在制作提示时拥抱多样性和包容性也很重要。深入理解偏见，通常反映训练数据，是关键。使用中立和包容的语言来避免提示中的任何歧视或排斥性短语是一个明智的选择。此外，从多样化的群体获取反馈可以帮助改进。这不仅提高了与LLM交互时的公平性和包容性，还帮助更准确和全面地理解相关主题。</p>
<h1 id="自主人工智能代理"><a href="#自主人工智能代理" class="headerlink" title="自主人工智能代理"></a>自主人工智能代理</h1><p>我们已经看到如何提示LLMs来绘制一个过程的步骤。这是代码生成的核心。</p>
<p>但是人工智能代理可以提升一个档次。它们不仅仅是遵循提示。它们利用LLMs来制定实现你提出的目标的计划，并访问像 Pinecone 和 Chroma DB 这样的专业数据库。它们处理复杂的词嵌入，模型能够理解这些。</p>
<p>自主人工智能代理基于学术研究，通常是开源项目的一部分。它们的真正力量在于自动化。为了了解这如何工作，我们举个例子。假设你设置的目标如下：</p>
<blockquote>
<p>提示：创建一个基本的天气应用程序，带用户登录系统。</p>
</blockquote>
<p>表 3-6 显示了自主代理可能经历的过程。</p>
<p>表 3-6. 自主代理的过程</p>
<table>
<thead>
<tr>
<th>阶段</th>
<th>任务</th>
</tr>
</thead>
<tbody><tr>
<td>创建任务</td>
<td>设计用户界面（UI）。<br />绘制仪表板的基本布局。<br />选择配色方案和字体。<br />设计图标和其他图形元素。</td>
</tr>
<tr>
<td>天气数据的 API 集成</td>
<td>搜索互联网可靠的天气数据 API。<br />确定要显示的数据点。<br />编写代码以获取和更新天气数据。</td>
</tr>
<tr>
<td>位置选择功能</td>
<td>创建一个搜索栏或下拉菜单供用户选择他们的位置。<br />将此连接到 API 代码。</td>
</tr>
<tr>
<td>错误处理</td>
<td>处理错误，例如 API 调用失败或无效位置输入。</td>
</tr>
<tr>
<td>任务优先级排序</td>
<td>优先设置 API 集成。<br /> 专注于用户界面。<br />位置选择功能和错误处理的工作。</td>
</tr>
<tr>
<td>迭代</td>
<td>查看生成的代码和天气仪表板的当前状态。<br />识别执行过程中剩余的任务或新出现的任务。<br />重复创建和优先级步骤。</td>
</tr>
</tbody></table>
<p>这项技术处于前沿，并且前景广阔。然而，它也面临着不少挑战：</p>
<ul>
<li>占用资源: 代理可以消耗大量计算能力。这可能会对您的处理器和数据库造成压力，导致等待时间增加、可靠性降低，以及随着时间推移运行效率下降。</li>
<li>陷入无限循环:  有时候代理只是循环运行，这要归功于缺乏进展或重复的奖励系统。</li>
<li>实验性质: 代理可能有些粗糙。它们可能会有一些错误或意外行为，可能还没有准备好进入大联盟，这取决于你需要它们做什么。</li>
<li>失忆: 代理可能会忘记某些步骤或指令。</li>
<li>处理大量任务时遇到困难: 有一整套任务清单？这可能会让这些代理陷入困境。</li>
<li>被琐碎细节分心: 代理可能会被一些无关紧要的小事分散注意力，这可能导致他们在选择使用的工具时走上错误的道路。</li>
</ul>
<p>另一个增强LLMs的创新是检索增强生成（RAG）。通过 RAG，一个生成式人工智能应用——比如用 LangChain 这样的框架编写——访问外部数据源，通常是向量数据库。它们为模型提供了更具体知识的基础，这应该增强LLM的响应。</p>
<p>RAG 在处理复杂软件开发任务时特别有用，例如在以下场景中：</p>
<ul>
<li>解决错误和故障：当开发人员遇到错误或 bug 时，RAG 会从网络上挖掘修复方案和变通方法，查找论坛或 bug 数据库等地方。它可以生成一些量身定制的解决方案或代码补丁，以适应您的问题。</li>
<li>提升代码审查的趣味性： RAG 可以从公司的内部资源中提取所有编码最佳实践、标准和必须遵循的规则。这意味着它可以帮助简化代码审查，提供技巧和窍门，使你的代码更加出色。</li>
<li> 加速测试： 当需要对您的代码进行测试时，RAG 可以成为您的维修团队。它找到各种测试场景和模式，调整它们以满足您项目的需求，并帮助您更快地推出测试用例或脚本。</li>
</ul>
<p>  注意</p>
<p>在某些情况下，LLM将指示您的提示存在问题。例如，假设您写了这个：</p>
<blockquote>
<p>编写一个使用汇编语言的 REST API。</p>
</blockquote>
<p>这就是 ChatGPT 的回应：</p>
<blockquote>
<p>使用汇编语言创建 REST API 是非常不传统且复杂的，因为汇编语言的低级特性。这些语言通常用于需要对硬件进行精细控制的任务，或在性能至关重要的场景中。</p>
</blockquote>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>再次，制作完美的提示涉及将科学与一些创造力相结合。这完全是关于找到正确的成分——一些创造力，一点直觉，以及结构化的方法——来生成能够让LLMs提供你想要的内容的提示。没有魔法配方，但如果你表达清楚，提供一些示例，并合理布局你的提示，你就能获得更好的答案。</p>
<p>这其实是一个过程。你尝试一些东西，看看效果，调整一下，然后再试一次。就像任何技能一样，你在不同主题和任务上越多练习，就会越好。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/09/02/aiassistedprogramming02/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/09/02/aiassistedprogramming02/" class="post-title-link" itemprop="url">第2章 人工智能编码技术如何工作</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-09-02 11:48:32" itemprop="dateCreated datePublished" datetime="2024-09-02T11:48:32+08:00">2024-09-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-26 11:55:47" itemprop="dateModified" datetime="2024-09-26T11:55:47+08:00">2024-09-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>13k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>24 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在本章中，我们将打开人工智能辅助编程工具的“引擎盖”，看看它们的工作原理。我们将简要回顾历史，体验transformer模型和LLMs，并演示OpenAI Playground。然后我们将获得一些关于如何评估LLMs的建议。</p>
<p>掌握这项强大技术的能力和局限性将为在实际软件项目中更智能地使用人工智能辅助编程工具铺平道路。</p>
<h1 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h1><p>市场上一直在热议人工智能辅助编程工具，如 GitHub Copilot、Tabnine、CodiumAI 和 Amazon CodeWhisperer。每个产品的制造商都试图炫耀自己的一套功能。但这些工具有很多共同的能力。表 2-1 总结了一些主要特性。</p>
<p>表 2-1.  AI 辅助编程工具的常见功能</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>代码建议</td>
<td>根据注释和文件上下文提供代码建议；推荐单行或整个函数。</td>
</tr>
<tr>
<td>上下文感知补全</td>
<td>提供基于全部或部分代码库的上下文感知代码补全，以及帮助编码的建议。</td>
</tr>
<tr>
<td>测试生成</td>
<td>分析代码以生成有意义的测试，映射代码行为，并提出边缘情况以确保软件在发布前的可靠性。</td>
</tr>
<tr>
<td>用户–IDE 交互</td>
<td>在 IDE 中自动激活并提供指导，用户可以通过聊天与代码互动。</td>
</tr>
<tr>
<td>代码分析</td>
<td>分析代码片段、文档字符串和注释，以提供可靠的代码预测并标记可疑代码。</td>
</tr>
<tr>
<td>错误检测和修复</td>
<td>识别代码中的潜在错误并建议修复方法。</td>
</tr>
<tr>
<td>代码自动文档生成</td>
<td>自动添加文档字符串并增强代码文档。</td>
</tr>
<tr>
<td>例行任务自动化</td>
<td>帮助创建常规或耗时任务的代码，不熟悉的 API 或 SDK，以及其他常见编码场景，<br />如文件操作和图像处理。<br /></td>
</tr>
<tr>
<td>API 和 SDK 使用优化</td>
<td>帮助正确有效地使用 API 和 SDK。</td>
</tr>
<tr>
<td>开源发现与归属</td>
<td>促进开源代码和库的发现与归属。</td>
</tr>
</tbody></table>
<p>表 2-1 中的列表并不是全部；创新正在快速发展。显然，这些系统通过提供代码建议和上下文感知的补全可以大大帮助开发人员。我们将在下一节中详细介绍这些内容。</p>
<h1 id="代码建议和上下文感知补全-vs-智能代码补全"><a href="#代码建议和上下文感知补全-vs-智能代码补全" class="headerlink" title="代码建议和上下文感知补全 vs 智能代码补全"></a>代码建议和上下文感知补全 vs 智能代码补全</h1><p>智能代码补全的魔力，也称为自动补全或微软的术语智能感知，是许多集成开发环境（IDE）提供的功能。它通过建议、填充和突出显示代码片段来帮助开发人员，当人类在键盘上敲击时。这项技术实际上自 20 世纪 50 年代末拼写检查器问世以来就已经存在。</p>
<p>突破发生在 1990 年代中期。微软的 Microsoft Visual Basic 5.0 提供了实时建议和补全，重点是基本语法和函数签名。这大大提高了生产力并减少了错误。</p>
<p>那么你可能会想：像智能感知这样的东西与人工智能辅助编程工具相比如何？毕竟，智能感知有一些人工智能和机器学习的基础。</p>
<p>然而，有一个重要的区别需要指出。人工智能辅助工具是由生成式人工智能驱动的。它们不仅提供代码，还提供文档、规划文档和有用的指南等内容。得益于生成式人工智能，这些工具能够根据给定的上下文生成、调整和理解类人文本，使它们在翻译、摘要、文本分析、主题建模和回答查询方面表现出色。与这些工具互动有时就像与您的代码进行随意聊天。它们以LLM为核心，可以捕捉到您输入的上下文和意图。</p>
<h1 id="编译器与人工智能辅助编程工具"><a href="#编译器与人工智能辅助编程工具" class="headerlink" title="编译器与人工智能辅助编程工具"></a>编译器与人工智能辅助编程工具</h1><p>为了更好地理解人工智能辅助编程工具，了解编译器的工作原理是有帮助的。以下是编译器执行的主要步骤：</p>
<ul>
<li>词法分析（分词）：编译器像语言老师一样，将你的代码分解成标记。</li>
<li>语法分析：在这里，编译器检查你的标记是如何分组的。它确保你的代码具有正确的结构，而不仅仅是正确的命令。</li>
<li>语义分析（错误检查）：编译器确保您的代码在编程语言的上下文中是有意义的。这不仅仅是正确的语法问题。还涉及正确的含义。</li>
<li>中间代码生成：这是您的代码开始转换旅程的地方。编译器将您的高级代码转换为中间形式。它还不是机器语言，但正在接近。</li>
<li> 代码优化：在这一步，编译器就像你代码的私人教练，使其更精简、更高效。它调整中间代码以提高运行速度并减少占用空间。</li>
<li> 代码生成：这是最终转换。编译器将优化后的中间代码转换为您的 CPU 可以理解的机器代码或汇编语言。</li>
<li> 链接和加载：链接有时被视为编译过程的一部分，它涉及将各种代码和库组合成一个可执行程序。加载是将程序放入内存以便执行的过程。</li>
</ul>
<p>至于像 Copilot 这样的人工智能辅助编程工具，它们是另一种东西。它们并不真正“理解”编程语言，就像编译器那样。这没关系。编译器会这样做。相反，它们使用人工智能根据大量现有代码来猜测和建议代码片段。由于这些工具是在碰运气，建议可能会有很大差异。然后编译器会将这些代码处理成机器可以运行程序的形式。</p>
<p>有时候，人工智能工具可能会漏掉一些简单的东西，比如括号，而人类编码者或编译器可以在瞬间发现。这是因为LLMs是基于预测模式，而不是编译器引擎。如果某些内容在训练中不常见，它们可能无法捕捉到。此外，这些工具可能会变得花哨，并根据情况建议复杂的代码。是的，人工智能辅助编程工具可能会过于兴奋。</p>
<p>在发现错误方面，人工智能辅助编程工具通常有效，但仍然无法与编译器的高效错误检查技能相媲美。不过，这些工具仍然很强大。例如，它们可以帮助捕捉恼人的语法错误——缺少分号、函数名称中的拼写错误、不匹配的括号——并迅速建议正确的修复方案。它们在帮助你避免常见编码陷阱方面也表现出色。无论是提醒你在打开文件后正确关闭它，还是建议更高效的遍历数组的方法，这个工具都能为你提供支持。而在逻辑错误方面，人工智能辅助编程工具可能会给出意想不到的见解。它们可能无法解决每个复杂问题，但通常可以提出你可能没有考虑过的替代方法或解决方案，引导你的问题解决过程朝着正确的方向前进。</p>
<p>这意味着虽然人工智能工具有助于使编码更顺畅，但它们不能替代编译器的全面检查或人类编码者的敏锐眼光。</p>
<p>这些缺点确实强调了将人工智能辅助工具的智能与编译器检查的全面性和人类触感相结合的重要性。毕竟，您希望确保您的代码不仅好，而且准确无误。</p>
<h1 id="能力级别"><a href="#能力级别" class="headerlink" title="能力级别"></a>能力级别</h1><p>在 2023 年 10 月，Sourcegraph 的首席执行官兼联合创始人 Quinn Slack 分享了一篇深刻的博客文章。他深入探讨了像 Copilot 这样的人工智能辅助编程工具，并提出了一种有趣的思考方式，他称之为“代码人工智能的层次”。他的逐步框架使每个人都更容易理解这些人工智能工具能做什么，并检查销售这些工具的公司所夸大的说法是否真实。图 2-1 显示了代码的层次。</p>
<p>前三个级别侧重于人工编码，开发者是主要参与者。首先，级别 0 是没有人工智能辅助的地方，这就是传统编码。开发者完全手动完成所有工作，没有人工智能的参与。这是为后续人工智能介入奠定基础的基线。</p>
<p>然后是一级，代码补全。在这一阶段，人工智能开始参与，根据周围的情况生成单行或代码块。此时，开发者仍然掌控全局，指导整体程序，并将人工智能作为典型编码任务的捷径。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0201-20240826170148-fbyzzp7.png"> 图 2-1. 编程系统具有不同级别的人工智能能力</p>
<p>二级，代码创建，增强人工智能。在这里，它变得更加动手，编写更长的代码段。人工智能可以，例如，设计 API，甚至修复现有代码。当然，这一切都是在有人监督的情况下进行的。这个级别需要人工智能获取代码库及其上下文，以便生成不仅正确而且适合的代码。</p>
<p>从三级开始，监督自动化，我们看到人工智能在编码方面开始主导。在这个阶段，人工智能处理多个任务，以满足人类设定的更广泛目标，并且不需要每次都进行检查。在这个级别工作就像将工作委派给初级开发人员。这个级别的人工智能足够聪明，可以排除错误，添加新功能，并将系统结合在一起，在此过程中向人类同事寻求任何澄清。</p>
<p>在第四级，完全自动化，人工智能真正提升了其能力。在这里，它独立处理复杂任务，无需人类对代码进行最终确认。想象一下，如果你是首席执行官或产品经理，你会对一位顶尖工程师有多大的信任。这就是这一层级所追求的关系。人工智能不仅仅是被动反应。它主动监控代码，发现并解决出现的问题。</p>
<p>最后是第五级，人工智能主导的完全自主。这一级别是一个完全不同的游戏，人工智能不仅仅是遵循人类指令，而是设定自己的目标。这是关于人工智能基于核心奖励函数进行工作。可以把它看作是在一个与其他智能体对抗的世界中玩自己的游戏。当然，这一级别听起来有点像科幻，但考虑到事物发展的速度，认为我们可能在有生之年看到这一水平成为现实并不是太疯狂。</p>
<p>现在，像 Copilot 这样的工具大约处于 3 级左右。确定确切的级别可能很棘手，但 Quinn Slack 的框架很好地解释了技术及其关键交互。而且有一点是肯定的：技术没有放缓——它正在快速向前发展。</p>
<h1 id="生成式人工智能和大型语言模型（LLMs）"><a href="#生成式人工智能和大型语言模型（LLMs）" class="headerlink" title="生成式人工智能和大型语言模型（LLMs）"></a>生成式人工智能和大型语言模型（LLMs）</h1><p>使用人工智能辅助编程工具并不要求你精通生成式人工智能技术的细节。然而，对技术有一个宏观的了解是非常有帮助的。你将能够更清晰地评估这些工具的响应、能力和局限性。</p>
<p>透明度不仅仅是一个流行词。在新技术真正流行起来之前，清楚了解其内部机制至关重要。采用的关键在于信任。在编码世界中，可靠性和问责制不仅仅是花哨的附加功能——它们是基本要素。</p>
<p>随着我们进入接下来的部分，我们将简要介绍生成式人工智能和LLMs，以便给您一个更清晰的概念。</p>
<h2 id="演化"><a href="#演化" class="headerlink" title="演化"></a>演化</h2><p>生成式人工智能的故事可以追溯到几十年前，其中一个最早的例子是 ELIZA，这个开创性的聊天机器人是麻省理工学院教授约瑟夫·魏岑鲍姆在 60 年代中期开发的。ELIZA 被设计用来模拟与心理治疗师的对话（你仍然可以在网上找到它）。当然，它很基础，运行在基于规则的算法上，主要是重复用户输入。</p>
<p>然而，许多人发现与 ELIZA 聊天比与真实治疗师更愉快，有些人甚至被欺骗以为他们在与人类交流。这种奇怪的现象被称为“ELIZA 效应”，展示了人们多么容易想象计算机程序具有类人理解能力。</p>
<p>然而，生成式人工智能的旅程并不完全是一场短跑。其核心技术相对基础，进展更多是缓慢爬行。但到了 2010 年代，场景迎来了转折点。技术世界现在拥有强大的计算能力、炫酷的硬件系统如 GPU（图形处理单元）、丰富的数据宝库，以及对深度学习等复杂模型的微调。就这样，生成式人工智能回到了快车道。随着其发展，出现了不同的方法：</p>
<ul>
<li>变分自编码器（VAE）：这项技术于 2013 年首次亮相，感谢 Diederik P. Kingma 和 Max Welling 及其论文“自动编码变分贝叶斯”。他们的变分自编码器（VAE）模型由更复杂的高维数据生成的低维潜在空间组成，全部无需监督。它还包括编码器-解码器结构。当我们说高维数据时，我们指的是具有多个特征的数据，每个特征都是一个维度——想象一下在 784 维空间中的 28 × 28 像素图像。低维潜在空间就像这个数据的紧凑版本，保留了关键信息，同时去掉了多余的维度。这一点很重要，因为它减轻了计算负担，抵御了维度诅咒，并使数据更易于可视化和解释。从高维空间到低维空间的跃迁称为降维，它将数据简化到最基本的要素。与传统自编码器不同，后者为每个潜在属性输出单个值，VAE 中的编码器给出一个概率分布。然后，解码器从这个分布中选择样本以重建数据。 这种在潜在空间中提供一系列数据而不是单一值的巧妙技巧为创建新数据或图像打开了大门。</li>
<li>生成对抗网络（GANs）：生成对抗网络是由伊恩·古德费洛及其同事在 2014 年提出的一类用于无监督机器学习的人工智能算法。生成对抗网络的核心是两个神经网络，分别称为生成器和判别器，它们在类似游戏的对抗中相互竞争。生成器生成新的数据片段，而判别器充当评判者，区分真实数据和虚假数据。随着每一轮的进行，生成器不断提升其能力，生成与真实实例惊人相似的数据。这种巧妙的设置为新的可能性打开了大门，导致人工智能能够创建逼真的图像、语音录音等更多内容。</li>
</ul>
<p>这些类型的生成式人工智能将是transformer模型的重要构建块，这是一个真正的突破，使LLMs的能力成为现实。</p>
<h2 id="Transformer模型"><a href="#Transformer模型" class="headerlink" title="Transformer模型"></a>Transformer模型</h2><p>在transformers崭露头角之前，自然语言处理（NLP）的首选方法是递归神经网络（RNN）。RNN 被设计用来处理序列或时间序列数据。它们会跟踪一个隐藏状态，以记住序列中前一步的部分信息——这对于语言建模、语音识别和情感分析等任务非常有用。RNN 逐步处理，一次处理序列中的一个片段，根据当前输入和之前处理过的内容更新它们的隐藏状态——因此称为递归。但在面对长序列时，它们遇到了困难，受到梯度消失或爆炸问题的困扰。这使得它们很难跟踪数据中的长期关系。</p>
<p>transformer，完全翻转剧本。transformers并行处理数据，利用注意力机制跟踪输入序列中不同部分之间的关系，无论它们的位置如何，而不是采用递归神经网络（RNNs）的逐步方法。这种架构蓝图的切换使transformers能够轻松处理短序列和长序列。它还避免了梯度问题。此外，它们的并行处理能力与图形处理单元（GPU）或张量处理单元（TPU）等复杂芯片架构很好地结合。</p>
<p>阿希什·瓦斯瓦尼及其在谷歌的研究团队创建了transformer，并在 2017 年发表了开创性论文“注意力机制就是全部所需”。图 2-2 展示了模型的主要部分。</p>
<p>transformer模型就像一位出色的语言学家，擅长解开语言的复杂性。它的魔力分为两个主要阶段：编码和解码。每个阶段都由自己的一组层组成。在编码阶段，模型读取并理解输入文本，类似于语言学家理解外语句子。然后在解码阶段，模型根据编码阶段获得的理解生成一段新文本或翻译，就像语言学家将该句子翻译成你的母语一样。</p>
<p>在transformer的核心是一个称为注意力的机制，它允许模型评估句子中每个单词与其他单词的相关性。它为每个单词分配一个注意力分数。例如，考虑句子“猫坐在垫子上。”当模型关注单词坐时，单词猫和垫子可能会因为与坐的动作直接相关而获得更高的注意力分数。</p>
<p>该模型的一个显著特点是自注意力机制。这使得它能够查看整个句子，理解单词之间的关系，并在长文本中保留这些关系。这赋予了transformer一种长期记忆的形式，使其能够关注到目前为止出现的所有单词或标记（完整单词或单词的一部分），从而理解更广泛的上下文。</p>
<p>然而，尽管具备这些能力，transformer最初缺乏识别句子中单词顺序的能力，而这对于理解意义至关重要。在这里，位置编码发挥作用。它像 GPS 一样为模型提供句子中每个单词位置的信息，并帮助理解诸如“猫追老鼠”和“老鼠追猫”这样的从句。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0202-20240826170148-r6qslyl.png"></p>
<p> 图 2-2. transformer 模型的架构是 LLMs 的核心</p>
<p>增加复杂性，transformer采用了多头注意力机制。设想模型有多个眼睛对， 每对从独特的角度审视句子，关注单词之间的不同方面或关系。例如，一对可能专注于理解动作，另一对专注于识别角色，还有一对专注于识别地点。这种多视角的方法使transformer能够更丰富地理解文本。</p>
<p>此外，transformer的每个阶段都包含前馈神经网络的层，这是一种简单的网络，有助于处理词语之间的关系。这进一步增强了文本的理解和生成。</p>
<p>一个transformer是以预训练模型的形式存在。它已经在大量数据上进行了训练，准备好用于使用或进一步微调。一旦预训练，模型可以作为 API 访问，允许在各种语言处理任务中立即使用。公司或个人可以快速将该模型集成到他们的系统中，例如 AI 辅助编程应用。此外，预训练的LLM可以通过在特定领域的数据上进行微调，进一步优化以在专业领域（如医疗或法律文本分析）中表现出色。这消除了从头开发复杂语言模型的需要，节省了大量时间、精力和资源。预训练模型凭借其基础语言理解，成为生成式人工智能应用开发的跳板。</p>
<p>  注意</p>
<blockquote>
<p>构建和运营一个LLM的成本很高。根据《华尔街日报》，在 2023 年初，GitHub Copilot 每位用户平均每月亏损超过 20 美元。在某些情况下，一些用户每月让公司亏损 80 美元。然而，随着基础设施在未来几年为生成式人工智能扩展，每位用户的成本应该会降低。</p>
</blockquote>
<p>两种主要的transformer系统是生成式预训练transformer（GPT）和双向编码器表示的变换器（BERT）。GPT 是OpenAI的一个工具，适合创建文本、总结信息和翻译语言。它基于自回归LLM架构。这意味着它通过仔细考虑每个词来生成文本，基于它已经输出的内容，就像讲故事的人逐字构建叙述一样。它的技能来自于在大量文本数据上进行训练。GPT 使用解码器生成内容。</p>
<p>BERT 采用自编码方法。这种设计使其能够深入理解句子中单词的上下文，使其擅长解读语言的细微差别和含义。谷歌在 2018 年开发了 BERT 作为一个开源项目。从那时起，许多变体和对核心模型的增强相继出现。</p>
<p>关于人工智能辅助编程应用，主要类型的transformer模型是 GPT。它已被证明能够根据程序员提供的上下文有效地预测和自动完成代码。</p>
<h2 id="OpenAI-游乐场"><a href="#OpenAI-游乐场" class="headerlink" title="OpenAI 游乐场"></a>OpenAI 游乐场</h2><p>OpenAI Playground 是一个生成式人工智能沙盒，提供对 OpenAI 开发的各种模型的访问。它通过直观的图形界面允许模型定制。</p>
<p>OpenAI Playground 使理解各种 LLMs 的优缺点变得更加容易。此外，它还支持根据不同输入（如温度）实时测试和调整模型。</p>
<p>然而，OpenAI 对使用该平台收费。费用基于使用的令牌数量，如表 2-2 所示。请注意，价格会定期变动。好消息是截至本文撰写时，所有变动都是价格降低。</p>
<p>表 2-2. OpenAI LLMs的成本</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>输入</th>
<th>输出</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-4&#x2F;8K 上下文</td>
<td>0.03&#x2F;1 千 tokens</td>
<td>0.06&#x2F;1 千 tokens</td>
</tr>
<tr>
<td>GPT-4&#x2F;32K 上下文</td>
<td>0.06&#x2F;1 千 tokens</td>
<td>0.12&#x2F;1K 令牌</td>
</tr>
<tr>
<td>GPT-3.5-Turbo&#x2F;4K 上下文</td>
<td>0.0015&#x2F;1K 令牌</td>
<td>0.002&#x2F;1 千 tokens</td>
</tr>
<tr>
<td>GPT-3.5-Turbo&#x2F;16K 上下文</td>
<td>0.003&#x2F;1 千 tokens</td>
<td>0.004&#x2F;1 千 tokens</td>
</tr>
</tbody></table>
<p>例如，假设您正在使用 GPT-4&#x2F;8K 上下文 LLM。您有一个包含 1,000 个标记的提示，模型对此的响应为 2,000 个标记。那么输入的费用为 3 美分，输出的费用为 12 美分。</p>
<p>当您首次注册OpenAI账户时，您将获得 5 美元的积分，可用于OpenAI Playground。这可以用于调用 API。</p>
<h3 id="令牌"><a href="#令牌" class="headerlink" title="令牌"></a>令牌</h3><p>让我们更详细地看一下令牌。OpenAI 有一个叫做分词器的工具，如图 2-3 所示，我输入了以下内容进行分析：</p>
<blockquote>
<p>聊天生成式人工智能真不可思议！🎉 我喜欢它。</p>
</blockquote>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0203-20240826170149-c9ihr2k.png"></p>
<p> 图 2-3. OpenAI 分词器显示文本片段的标记</p>
<p>在标记化中（用颜色突出显示），词语 ChatGPT 由三个标记组成。拆分为 Chat、G 和 PT。词语不可思议及其后面的感叹号有两个标记，一个是词语，一个是标点符号。至于表情符号，它由三个标记组成。每个标点符号都是一个标记。空格与相邻的词一起计算。</p>
<p>分词器适用于 GPT-3、GPT-3.5 和 GPT-4。请注意，分词在LLMs之间通常是不同的。</p>
<p>  注意</p>
<p>大致上，1000 个令牌大约相当于 750 个单词。</p>
<h3 id="使用平台"><a href="#使用平台" class="headerlink" title="使用平台"></a>使用平台</h3><p>当你进入OpenAI Playground 时，你会看到一个仪表板，如图 2-4 所示。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0204-20240826170149-eqapt0f.png"></p>
<p> 图 2-4. OpenAI 游乐场有一个包含提示、资源和互动区域的仪表板</p>
<p>屏幕中间是与LLM的主要工作流程：</p>
<ul>
<li> 系统：这是您为LLM提供一些上下文的地方，例如，“您是 Python 编程专家。”系统提示是会话中的第一条消息，为交互设置了基础。自定义系统提示可以更好地控制模型在对话中的行为，这在确保其保持在期望的参数或上下文内时特别有用。</li>
<li> 用户：这里是输入提示词的主要指令。例如，这里是您可以要求LLM执行编码任务的地方。</li>
<li> 添加消息：这允许您与LLM进行持续聊天。</li>
</ul>
<p>让我们尝试一个例子。假设您正在进行一个 Python 项目，并且在理解如何实现 Tkinter 库以获取用户输入方面遇到困难。您可以输入以下内容：</p>
<blockquote>
<p>系统消息：您是一名专注于 Tkinter 的 Python 专家。</p>
<p>用户消息：我想使用 Tkinter 创建一个简单的 GUI 来获取用户的姓名和年龄。我该怎么做？</p>
</blockquote>
<p>LLM 将生成代码列表。但假设您想为输入添加验证。您可以按添加按钮并输入“我如何确保输入的年龄是数字而不是文本？”</p>
<p>LLM 将使用 try-except 块响应此代码，将年龄输入转换为整数。</p>
<p>当然，这类似于使用 ChatGPT——但更有结构。此外，真正的强大之处在于定制的能力。您将在屏幕右侧找到这些功能：</p>
<ul>
<li> 模型：您可以从多种模型中选择，甚至可以使用您自己微调的LLMs，以确保模型专注于您编码的独特需求。您可以在OpenAIAPI 文档中找到有关微调模型的更多信息。</li>
<li> 温度：这调整生成内容的随机性或创造性。值的范围是从 0 到 2。值越低，响应越确定和集中。表 2-3 显示了不同类型开发任务的建议温度级别。</li>
</ul>
<p>表 2-3. 某些类型编程任务的建议温度水平</p>
<table>
<thead>
<tr>
<th>任务类别</th>
<th>温度值</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>代码生成</td>
<td>0.2–0.3</td>
<td>确保更确定性、准确的代码遵循通用约定，以实现可靠和易于理解的结果。</td>
</tr>
<tr>
<td>代码审查</td>
<td>0.2 或更少</td>
<td>专注于成熟的最佳实践和标准，以提供准确的反馈。</td>
</tr>
<tr>
<td>修复漏洞</td>
<td>0.2 或更少</td>
<td>生成更准确和直接的解决方案来解决识别的问题。</td>
</tr>
<tr>
<td>创造性问题解决</td>
<td>0.7–1.0</td>
<td>探索更广泛的可能解决方案，适用于头脑风暴或创新问题解决。</td>
</tr>
<tr>
<td>学习和实验</td>
<td>0.7–1.0</td>
<td>提供更多样化的示例和解决方案，以理解不同的问题解决方法。</td>
</tr>
<tr>
<td>数据分析与可视化</td>
<td>0.2 或更少</td>
<td>生成准确且有意义的可视化或分析。</td>
</tr>
<tr>
<td>优化任务</td>
<td>多样化</td>
<td>允许在探索（更高温度）和开发（更低温度）之间取得平衡，以实现高效解决方案。</td>
</tr>
</tbody></table>
<p>然而，如果您使用一个相当高的温度值，结果可能会毫无意义。以下是使用值为 2 时的示例提示：</p>
<blockquote>
<p>在 Python 中，将数据从 CSV 文件迁移到 MySQL 数据库的步骤是什么？</p>
</blockquote>
<p>图 2-5 显示了输出。正如您所看到的，这没有什么意义！</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0205-20240826170150-wm3665w.png"></p>
<p> 图 2-5. 当使用温度为 2 时，LLM 的结果大多是无意义的</p>
<p>现在，让我们看看您可以调整的其他功能：</p>
<ul>
<li> 最大长度：这是生成内容所使用的最大令牌数。该数字&#x3D;&#x3D;包括提示和响应的使用&#x3D;&#x3D;。令牌与内容的比例取决于您使用的模型。</li>
<li> 停止序列：这表明LLM应该停止生成更多文本的一个点。您可以指定一个特定的字符串或字符序列，当在生成的文本中检测到时，将指示模型停止该过程。</li>
<li> Top p：也称为核采样，这种技术根据累积概率阈值选择单词，记作 p，范围从 0 到 1。简单来说，模型不是总是从最可能的几个下一个单词中选择，而是根据指定的 p 值考虑更广泛或更狭窄的可能下一个单词范围。较低的 p 值会导致选择的单词集合更小、更集中，从而生成更可预测和连贯的文本。较高的 p 值则允许更广泛的可能下一个单词集合，从而生成更多样化和创造性的文本。</li>
<li> 频率惩罚：这有助于解决LLMs的一个常见问题，即重复的短语或句子。值范围从 0 到 2。值越高，重复越少。然而，在大于 1 的值时，文本生成可能变得不可预测甚至毫无意义。</li>
<li> 存在惩罚：这也有 0 到 2 的值。更高的值将允许LLM包含更广泛的令牌，这意味着使用更丰富的词汇或更广泛的概念范围。</li>
</ul>
<p>通过频率惩罚、存在惩罚和Top p，OpenAI建议选择一种方法来调整您的任务。但不要害怕实验。优化LLMs的路径并不是由严格的规则铺成的，这要归功于所涉及复杂性的微妙变化。</p>
<h1 id="评估LLMs"><a href="#评估LLMs" class="headerlink" title="评估LLMs"></a>评估LLMs</h1><p>评估LLMs是一项繁重的任务。这些庞然大物往往如此不透明，以至于似乎难以理解。人工智能公司的竞争只会加剧这一点。关于这些模型训练所用的数据集、用于微调其行为的参数数量以及驱动它们的硬件的细节寥寥无几已成为常态。</p>
<p>但有一些好消息，感谢斯坦福大学的一些研究人员。他们创建了一个评分系统，称为基础模型透明度指数，以评估LLMs的开放性。这个标准由一百个标准构成，旨在为LLM透明度的模糊领域带来一些清晰度。</p>
<p>排名基于百分比评分。表 2-4 显示了排名。不幸的是，结果远未令人鼓舞。根据研究人员的说法，没有主要LLM接近实现“足够的透明度”，平均得分仅为 37%。</p>
<p>表 2-4. 模型透明度排名前LLMs</p>
<table>
<thead>
<tr>
<th>公司</th>
<th>Model</th>
<th>排名</th>
</tr>
</thead>
<tbody><tr>
<td>Meta</td>
<td>LLaMA 2</td>
<td>54%</td>
</tr>
<tr>
<td>BigScience</td>
<td>BLOOMZ</td>
<td>53%</td>
</tr>
<tr>
<td>OpenAI</td>
<td>GPT-4</td>
<td>48%</td>
</tr>
<tr>
<td>Stability.ai</td>
<td>Stable Diffusion 2</td>
<td>47%</td>
</tr>
<tr>
<td>谷歌</td>
<td>PaLM 2</td>
<td>40%</td>
</tr>
<tr>
<td>Anthropic</td>
<td>Claude 2</td>
<td>36%</td>
</tr>
<tr>
<td>Cohere</td>
<td>Command</td>
<td>34%</td>
</tr>
<tr>
<td>AI21Lab</td>
<td>Jurassic-2</td>
<td>25%</td>
</tr>
<tr>
<td>Inflection</td>
<td>Inflection-1</td>
<td>21%</td>
</tr>
<tr>
<td>亚马逊</td>
<td>Titan Text</td>
<td>12%</td>
</tr>
</tbody></table>
<p>基础模型研究中心，基础模型透明度指数总分 2023，<a target="_blank" rel="noopener" href="https://crfm.stanford.edu/fmti">https://crfm.stanford.edu/fmti</a></p>
<p>LLMs 处理各种领域和任务的灵活性，例如软件开发，是一个显著的优势。然而，这也使评估过程变得复杂，因为它需要特定领域的评估指标和基准，以确保模型在每个特定应用中的有效性和安全性。</p>
<p>尽管如此，在评估LLMs时仍需考虑一些指标：</p>
<ul>
<li> BERT 评分：该指标旨在通过使用 BERT 嵌入比较生成文本与参考文本来评估文本生成模型。虽然主要用于自然语言文本，但可以扩展或调整用于代码生成任务，特别是在代码用自然语言注释或评论时。</li>
<li>Perplexity 困惑：是评估概率模型的常见指标，如LLMs。它量化了模型预测的概率分布与数据的实际分布之间的契合程度。在代码生成的上下文中，较低的困惑度值表明模型在预测代码序列中的下一个标记方面表现更好。</li>
<li>BLEU（双语评估助手）：最初用于机器翻译，BLEU 也用于代码生成，以比较生成的代码与参考代码。它计算 n-gram 精确度分数，以量化生成文本与参考文本之间的相似性，这有助于评估生成代码的语法正确性。更高的 n-gram 精确度分数表示生成文本与参考文本在特定 n 个单词序列上的更好一致性。</li>
<li>ROUGE（针对摘要评估的召回导向替代方法）：这是另一个借用自自然语言处理的指标，可用于评估代码生成模型。它计算生成文本和参考文本之间的 n-gram 重叠，提供生成代码与预期输出对齐程度的洞察。</li>
<li>MBXP（最基本的 X 编程问题）：该基准专门用于评估跨多种编程语言的代码生成模型。它使用可扩展的转换框架将原始数据集中的提示和测试用例转译为目标语言，从而促进对代码生成模型的全面多语言评估。</li>
<li> 人类评估：这是一个基准测试，用于通过测量从文档字符串合成程序的功能正确性来评估LLMs的代码生成能力。这个基准测试对于代码生成中人工智能模型的持续开发和增强至关重要。虽然不同的模型在 HumanEval 上表现出不同的熟练程度，但一个名为 HUMANEVAL+的扩展版本在识别流行的LLMs生成的先前未检测到的错误代码方面发挥了关键作用。</li>
<li>多语言人类评估（HumanEval-X）：这是原始 HumanEval 基准的扩展。多语言 HumanEval 评估LLMs的代码生成和翻译能力，涵盖超过 10 种编程语言。它采用转换框架将提示和测试用例从 Python 转译为目标语言中的相应数据，从而创建一个更全面的多语言代码生成和翻译基准。</li>
</ul>
<p>另一种评估LLM的方法是查看参数数量——可能达到数千亿。因此，参数越多越好吗？不一定。评估应该采取更细致的方法。首先，扩展参数的成本可能非常庞大，包括计算能力和能源使用。这可能使得LLM在货币化应用方面变得不经济。接下来，随着参数数量的膨胀，模型的复杂性也会增加，这可能导致过拟合。过拟合发生在模型在训练数据上表现得非常好，但在面对未见过的数据时却表现不佳。这削弱了它的泛化能力。</p>
<p>另一个问题是需要大量多样化的训练数据集，以满足这些模型对数据的贪婪需求。然而，获取和整理如此庞大的数据集不仅资源密集，还会带来数据隐私和偏见方面的挑战。此外，随着参数的激增，这些巨型模型的评估变得越来越复杂。评估指标需要更加全面和多样化，以准确衡量模型在众多任务上的表现。</p>
<p>最后，微调可以更好地利用模型，而无需大幅增加基础LLM的参数大小。</p>
<h1 id="LLMs的类型"><a href="#LLMs的类型" class="headerlink" title="LLMs的类型"></a>LLMs的类型</h1><p>有各种类型的LLMs，其中一个显著的类别是开源LLMs。任何人都可以使用、修改或分享它们。它们的透明性意味着你可以看到这些模型是如何工作的。此外，开源LLMs允许开发者合作创新以及开发插件，当然，还可以修复恼人的错误。</p>
<p>最棒的部分？它们没有价格标签。</p>
<p>但开源LLMs并非都是美好和顺利。通常没有专门的团队来解决问题或推出定期更新。因此，如果遇到困难，您可能需要动手去论坛寻求帮助。</p>
<p>开源模型的质量和性能有时像过山车一样波动。此外，还有令人烦恼的安全问题。由于一切都是公开的，黑客更容易找到插入恶意代码的方法。建议谨慎行事。</p>
<p>最后，当涉及用户指南和文档时，开源LLMs可能会让你希望有更多。指南有时感觉像是用象形文字写成的。</p>
<p>表 2-5 显示了一些顶级开源LLMs。</p>
<p>表 2-5. 顶级开源LLMs</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>开发者</th>
<th>参数<br />（B &#x3D; 十亿）<br /></th>
<th>值得注意的特点</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-NeoX-20B</td>
<td>EleutherAI</td>
<td>20B</td>
<td>在“The Pile”数据集上训练；能够执行各种自然语言处理任务，<br />如故事生成、聊天机器人和摘要生成<br /></td>
</tr>
<tr>
<td>LLaMA 2</td>
<td>Meta</td>
<td>7B到 70B</td>
<td>训练于 2 万亿个标记；是 LLaMA 1 上下文长度的两倍</td>
</tr>
<tr>
<td>OPT-175B</td>
<td>Meta</td>
<td>175B</td>
<td>一套模型的一部分；训练时的碳足迹低于 GPT-3</td>
</tr>
<tr>
<td>BLOOM</td>
<td>BigScience</td>
<td>176B</td>
<td>在 ROOTS 语料库上训练；设计用于透明度，公开训练数据细节和评估方法</td>
</tr>
<tr>
<td>Falcon-40B</td>
<td>Technology <br />Innovation <br />Institute (TII)<br /></td>
<td>40B</td>
<td>训练于 1000B 标记</td>
</tr>
<tr>
<td>Dolly 2.0</td>
<td>Databricks</td>
<td>12B</td>
<td>基于 EleutherAI 的 Pythia 模型系列；提供类似 ChatGPT <br />的指令跟随交互性<br /></td>
</tr>
<tr>
<td>Mistral 7B</td>
<td>Mistral AI</td>
<td>7.3B</td>
<td>使用分组查询和滑动窗口注意力；在大规模数据集上训练，<br />擅长处理较长序列<br /></td>
</tr>
<tr>
<td>Mixtral 8X7B</td>
<td>Mistral AI</td>
<td>46.7B</td>
<td>稀疏专家混合模型；像 12.9B 模型一样进行推理，支持多种语言，<br />并在代码生成和推理等各种任务中表现出色<br /></td>
</tr>
</tbody></table>
<p>闭源或专有LLMs则要保密得多。它们通常将代码、训练数据和模型结构严格保密。然而，开发这些复杂系统的公司通常拥有巨额资本。表 2-6 显示了这些公司在 2023 年筹集的资本。</p>
<p>表 2-6. 前LLM名开发者筹集的风险投资</p>
<table>
<thead>
<tr>
<th>公司</th>
<th>资金</th>
</tr>
</thead>
<tbody><tr>
<td>Anthropic</td>
<td>12.5 亿美元</td>
</tr>
<tr>
<td>OpenAI</td>
<td>100 亿美元</td>
</tr>
<tr>
<td>Cohere</td>
<td>2.7 亿美元</td>
</tr>
<tr>
<td>Inflection AI</td>
<td>13 亿美元</td>
</tr>
</tbody></table>
<p>凭借这些资源，这些公司可以聘请世界上最优秀的数据科学家并构建复杂的基础设施。结果是，这些LLMs在性能方面通常是最先进的。它们还为规模和企业的严格需求而构建，例如安全性和隐私。</p>
<p>关于缺点，存在信任问题。这些模型是如何生成响应的？幻觉和偏见怎么办？这些问题的答案可能缺乏细节。</p>
<p>然后这些大型人工智能运营商可能会形成垄断。这可能意味着客户会被锁定在一个生态系统中。最后，闭源LLMs可能比开源项目更容易停滞，因为它们可能无法从开源项目通常享有的多样化输入和审查中受益。</p>
<h1 id="人工智能辅助编程工具评估"><a href="#人工智能辅助编程工具评估" class="headerlink" title="人工智能辅助编程工具评估"></a>人工智能辅助编程工具评估</h1><p>选择哪个人工智能辅助编程工具可能让人困惑。你需要权衡很多因素，比如精确度、聊天功能、安全性、速度和用户友好性。有时候，这归结为使用起来的感觉。但如果你的雇主坚持使用特定系统，你可能就无能为力了。</p>
<p>要了解当前热门的技术，Stack Overflow 2023 开发者调查是一个方便的资源。Stack Overflow 收集了近 90,000 名编码者对最受欢迎工具的见解，您可以在表 2-7 中查看。</p>
<p>表 2-7. 流行的人工智能辅助编程工具排名</p>
<table>
<thead>
<tr>
<th>人工智能辅助开发工具</th>
<th>百分比</th>
</tr>
</thead>
<tbody><tr>
<td>GitHub Copilot</td>
<td>54.77%</td>
</tr>
<tr>
<td>Tabnine</td>
<td>12.88%</td>
</tr>
<tr>
<td>亚马逊CodeWhisperer</td>
<td>5.14%</td>
</tr>
<tr>
<td>Snyk Code</td>
<td>1.33%</td>
</tr>
<tr>
<td>Codeium</td>
<td>1.25%</td>
</tr>
<tr>
<td>Wispr AI</td>
<td>1.13%</td>
</tr>
<tr>
<td>Replit Ghostwriter</td>
<td>0.83%</td>
</tr>
<tr>
<td>Mintlify</td>
<td>0.52%</td>
</tr>
<tr>
<td>Adrenaline</td>
<td>0.43%</td>
</tr>
<tr>
<td>Rubberduck AI</td>
<td>0.37%</td>
</tr>
</tbody></table>
<p>2023 年开发者调查 - Stack Overflow</p>
<p>此图表让您了解可用的众多工具。当您想选择一个时，明智的做法是向其他开发者获取推荐。此外，亲自试用几个也是个好主意。幸运的是，这些工具大多数提供免费试用，因此您可以在不立即承诺的情况下试用它们。</p>
<p>另一个需要考虑的关键方面是公司的财务支持。它有风险投资吗？没有这些，公司可能不仅难以增长，还难以保持其平台的创新性。目前，已经有几家人工智能辅助编程公司不得不停止其服务，这确实会给开发者带来麻烦。以 Kite 为例。它是该领域的早期参与者之一，成立于 2014 年。然而，到 2022 年，公司决定停止该项目。好消息是，它开源了大部分工具的代码库。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>在本章中，我们揭开了生成式人工智能和LLMs的面纱。我们 glimpsed 一些迷人的历史，例如 ELIZA，然后专注于人工智能的一个重大突破：transformer模型。我们还尝试了 OpenAI Playground，并展示了如何自定义 LLM。</p>
<p>本章的一些关键内容包括令牌、利用预训练模型的优势、评估LLMs的注意事项、困惑度和 BLEU 分数等指标，以及开源模型与专有模型。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/30/aiassistedprogramming01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/30/aiassistedprogramming01/" class="post-title-link" itemprop="url">第1章 开发者的新世界</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-30 11:48:32" itemprop="dateCreated datePublished" datetime="2024-08-30T11:48:32+08:00">2024-08-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-26 11:55:46" itemprop="dateModified" datetime="2024-09-26T11:55:46+08:00">2024-09-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>13k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>23 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在 2011 年至 2016 年期间，安德烈·卡尔帕西在斯坦福大学处理密集神经网络架构和像素处理计算机视觉的同时，还在谷歌兼职。在那里，他四处修补并为 YouTube 视频制作了一个特征学习系统。然后他决定成为 OpenAI 的创始成员，后来成为特斯拉的人工智能高级总监，领导团队创建自动驾驶系统。</p>
<p>可以肯定地说，他是世界顶尖的编码员之一。他还是一位熟练的文字工作者，在推特（或 X）上拥有近 80 万的关注者。当 ChatGPT 横空出世时，他发了推文：</p>
<blockquote>
<p>最热门的新编程语言是英语。</p>
</blockquote>
<p>他不是在开玩笑。这不仅仅是对编码的诗意颂歌，而是对未来的暗示，在那里输入自然语言提示可以生成看似任何语言的计算机代码。这就像在你的电脑里有一个双语精灵，随时准备将你的英语愿望转录成代码命令。</p>
<p>然后出现了一条推文，表达了许多开发者的心声：</p>
<blockquote>
<p>Copilot 极大地加快了我的编码速度，难以想象回到“手动编码”。仍在学习如何使用它，但它已经写了我大约 80%的代码，准确率约 80%。我甚至不太编码，我只是提示和编辑。</p>
</blockquote>
<p>卡尔帕西正在向微软的 GitHub Copilot 致敬，这是一种新鲜的人工智能辅助编程工具。但很快就会出现许多其他工具。创新的步伐令人惊叹。</p>
<p>现在，对于所有程序员来说，环境可能看起来像一片密林。这个勇敢的新世界的人工智能工具是什么？它们在哪些方面令人惊艳，又在哪些方面表现平平？你如何在这一切中摸索，成为一个精明的人工智能辅助程序员？</p>
<p>好吧，这本书将是你的指南，帮助回答这些问题——还有更多。重点是利用这些工具来编写代码，不仅更快，而且更智能，并且带有一些乐趣。那么，让我们挽起袖子，开始这段人工智能辅助编程之旅吧。</p>
<h1 id="演变与革命"><a href="#演变与革命" class="headerlink" title="演变与革命"></a>演变与革命</h1><p>编程语言演变的一个关键主题是抽象。这是一种描述系统如何变得更易于开发者使用的高级方式。当繁琐的细节在后台处理时，开发者可以专注于最重要的事情。这一直是创新的推动力，使得互联网、云计算、移动和人工智能等突破成为可能。</p>
<p>图 1-1 突出显示了几十年来抽象的演变。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0101-20240826160857-3l3qn9o.png"> 图 1-1. 编程语言和工具的抽象已经随着几十年的发展而演变</p>
<p>让我们详细了解一下，从 1940 年代开始：</p>
<p>机器语言到汇编语言在计算机时代的黎明，程序员必须与 0 和 1 搏斗，以使机器服从他们的意志。但随后，汇编语言出现了。它提供了字母数字指令，使编码变得更简单且更不易出错。</p>
<p> 高级语言1950 年代带来了 Fortran 和 COBOL，这些语言让程序员可以使用类似简单英语的代码，如 DISPLAY、READ、WRITE 和 IF&#x2F;THEN&#x2F;ELSE。编译器会将这些转换为计算机可以理解的 0 和 1。同时，没有技术背景的人通常也能很好地阅读代码以理解工作流程。高级语言的出现将成为计算机革命的巨大催化剂。</p>
<p> 过程式编程像 C 和 Pascal 这样的语言引入了过程式编程，本质上将复杂任务打包成称为函数的小盒子。这种抽象允许重用和可维护性，使得管理庞大的软件项目不再是一项艰巨的任务。</p>
<p>面向对象编程（OOP）这种计算机语言的一些明星包括 C++和 Java。面向对象编程带来了全新的抽象层次，使程序员能够使用类和对象对现实世界实体进行建模，封装数据和行为。这促进了模块化，并允许更直观的问题解决。</p>
<p>脚本语言和网页开发Python、Ruby 和 JavaScript 抽象了许多与编程相关的低级任务。它们提供了丰富的库和内置数据结构，简化了常见的编程任务，减少了完成这些任务所需的代码量。</p>
<p>机器学习和人工智能随着人工智能和机器学习的兴起，像 TensorFlow 和 PyTorch 这样的专业库和框架抽象了许多复杂的编程数学细节。这使得开发者可以专注于模型架构和训练过程。</p>
<p> 最新加入这一抽象叙述的是人工智能辅助编程，比如 GPT-4 和其他大型语言模型（LLMs）。它们就像你的后台团队，随时准备在你的指令下生成代码。</p>
<p>让我们看一个简单的例子。为此，我们将使用 ChatGPT，它具有生成代码的强大能力。我们将使用提示来询问我们希望系统做什么。假设我们给它以下提示：</p>
<blockquote>
<p>在 Python 中编写一个程序，检查给定整数是偶数还是奇数并打印结果。</p>
</blockquote>
<p>图 1-2 显示了 ChatGPT 的响应。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0102-20240826160858-c3qylzx.png"></p>
<p> 图 1-2. 当被要求创建代码时，ChatGPT 的响应不仅包括代码列表，还包括解释</p>
<p>我们获取代码列表，里面还有有用的注释。然后还有程序如何工作的解释。您可以点击右上角的复制代码按钮将代码包含到您的 IDE 中并运行。</p>
<h1 id="生成式人工智能"><a href="#生成式人工智能" class="headerlink" title="生成式人工智能"></a>生成式人工智能</h1><p>在深入了解人工智能辅助编程工具如何工作之前，让我们先概述一下生成式人工智能。这是这些系统的基础。</p>
<p>生成式人工智能是人工智能（AI）的一个分支，它允许创建新的和独特的内容。图 1-3 提供了不同部分之间关系的可视化。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0103-20240826160859-st5p3ey.png"></p>
<p> 图 1-3. 有不同类型的人工智能，它们可以表示为嵌套子集，生成式人工智能最终以大型语言模型为中心</p>
<p>人工智能是一个大伞：它包括所有能够以人类智能的风格完成任务的系统。机器学习（ML）包含在人工智能中。&#x3D;&#x3D;机器学习系统不是按照明确指令的节奏行进，而是基于大量数据得出见解&#x3D;&#x3D;。机器学习通常基于复杂的算法，这些算法允许在不进行硬编码的情况下进行预测或决策。</p>
<p>深入一步，你会得到深度学习（DL），这是机器学习（ML）的一个更紧密的分支，使用堆叠有隐藏层的神经网络，因此称为深度。这些堆叠模型在图像和语音识别等领域表现出色。</p>
<p>生成式人工智能（或生成式人工智能模型）在深度学习的领域中。&#x3D;&#x3D;生成式人工智能模型创建反映其训练数据的新数据&#x3D;&#x3D;。</p>
<p>在最内层圈中坐着LLMs，例如 GPT-4、Gemini、Claude 和 LLaMA 2。这些强大的模型——通常称为“基础模型”——基于尖端算法和大量数据的训练生成类人文本。</p>
<p>生成式人工智能不仅仅是LLMs。生成式人工智能还具有多模态能力，意味着能够创建图像、音频和视频。</p>
<p>在下一章中，我们将深入探讨生成式人工智能是如何工作的。但接下来，让我们看看人工智能辅助编程工具的优缺点。</p>
<h1 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h1><p>人工智能辅助编程工具旨在增强开发人员的能力，使他们能够专注于高级问题解决和创新，而不是陷入单调的任务或复杂的代码细节。这就是为什么 GitHub 使用副驾驶这个词恰如其分。它是关于在驾驶舱中拥有那个可靠的伙伴，导航来解决编码的复杂和常常乏味的方面，让你专注于重要的事情。</p>
<p>在接下来的部分中，我们将重点介绍这些强大系统的好处和实际应用。</p>
<h2 id="最小化搜索"><a href="#最小化搜索" class="headerlink" title="最小化搜索"></a>最小化搜索</h2><p>开发者经常扮演数字侦探，追踪恼人的错误或理解晦涩的代码。当他们遇到问题时，第一反应是上谷歌或访问 Stack Overflow。快速搜索，一段代码，瞧，他们又回到他们的 IDE（集成开发环境）。</p>
<p>但有时这可能变成一场煎熬。在 Stack Overflow 上的讨论可能会变成死胡同。你继续搜索，但似乎没有什么相关的内容。然而，有一个讨论稍微有帮助，于是你对一些相关主题进行了进一步研究。你甚至在 YouTube 上搜索视频。在思考这个问题超过 30 分钟后，你终于解决了它。</p>
<p>是的，所有开发者都经历过这个。有趣的是，Stack Overflow 2022 年开发者调查显示了这种挫败感，调查包含了超过 70,000 名开发者的反馈。调查发现，&#x3D;&#x3D;62% 的受访者每天花费超过 30 分钟寻找答案，25% 的受访者每天花费超过一个小时&#x3D;&#x3D;。根据调查，“对于一个由 50 名开发者组成的团队，寻找答案&#x2F;解决方案所花费的时间每周在整个团队中累计损失的时间在 333 到 651 小时之间。”</p>
<p>现在，如果有一种方法可以快速穿过这片耗时的搜索丛林，直接找到解决方案呢？引入人工智能辅助编程，我们闪亮算法中的骑士。微软的研究支持这一点：它显示超过 90%的使用 GitHub Copilot 的开发者能够更快地完成他们的任务。</p>
<p>微软甚至在编码者对决中进行了测试。该公司招募了 95 名专业开发人员，并将他们分成两组。任务是用 JavaScript 编写一个 HTTP 服务器。使用 GitHub Copilot 的人比没有使用的人快 55%完成工作。</p>
<p>不仅仅是微软在赞美。麦肯锡公司也进行了研究。来自美国和亚洲的 40 多名开发者参与，具有不同程度的经验和背景。在几周内，他们完成了三个常见的软件任务：代码生成、重构和文档编写。</p>
<p>结果呢？在保持代码整洁的文档方面，人工智能辅助工具表现突出，减少了一半的时间，而人工智能工具在编写新代码和重构方面的表现几乎相同。</p>
<p>然而，对于复杂任务，人工智能工具并没有达到高水平。节省的时间不足 10%。</p>
<p>有趣的是，研究还表明，减少花费的时间并未对代码的整体质量产生负面影响，例如在错误、可读性和可维护性方面。事实上，人工智能辅助编程工具提供了边际改进。但这通常是因为开发人员与工具进行了迭代。</p>
<p>麦肯锡研究提供了以下要点：</p>
<ul>
<li> 简化日常琐事：这些工具擅长处理日常任务，如自动填充代码函数、实时代码补全和自动文档生成。通过处理这些任务，它们使开发人员能够深入复杂的业务问题并快速部署软件功能。</li>
<li>生成更流畅的代码草稿：盯着空白画布可能令人畏惧，但借助生成式人工智能工具，开发人员可以通过简单的提示在他们的 IDE 中或单独获取代码建议，从而推动创作过程。许多开发人员发现这些基于人工智能的建议非常宝贵，因为它们帮助人类克服了“空白屏幕问题”，以更快的速度进入编码“状态”。</li>
<li>加速对现有代码的调整：通过有效的提示，开发人员可以更快速地调整和改进现有代码。例如，他们可以从在线库中获取代码，将其放入提示中，然后根据指定标准进行迭代请求以获得人工智能优化的调整。</li>
<li>增强开发者应对新挑战的准备：该技术像一个快速入门课程，帮助开发者熟悉不熟悉的编码环境或语言。在处理新事物时，这些工具就像一个经验丰富的朋友，阐明新概念，剖析各种代码库，并提供框架使用的综合指南。</li>
<li>利用多种工具：研究表明，使用多个工具更有效。想象一下：开发者使用一个工具进行提示或聊天，另一个工具作为代码库的一部分，提供自动补全选项和建议。开发者发现第一个工具在代码重构时处理查询非常出色，这要归功于它的对话能力。另一方面，第二个工具在生成与开发环境无缝集成的新代码方面表现出色。当这些人工智能工具协同工作时，开发者看到时间效率提高了 1.5 到 2.5 倍。</li>
</ul>
<h2 id="您的顾问"><a href="#您的顾问" class="headerlink" title="您的顾问"></a>您的顾问</h2><p>使用 ChatGPT，您可以询问有关多种开发活动的建议。以下是一个提示词：</p>
<blockquote>
<p>提示词：请提供减少搜索时间和提高编程生产力的详细技巧和最佳实践。包括与代码组织、文档、工具和心态相关的策略。</p>
</blockquote>
<p>图 1-4  显示了响应。</p>
<p>ChatGPT 提供了三个主要考虑领域。它建议使用模块化设计，保持一致的命名，并逻辑地组织文件。它还建议优先考虑清晰的文档，包括注释、文档字符串和自述文件。ChatGPT 接着提到使用 IDE 的搜索功能，使用 Git 等工具，以及收藏关键资源。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0104-20240826160859-3kt86mb.png"></p>
<p> 图 1-4.  您可以从 ChatGPT 获取有关编程任务的有用建议</p>
<h2 id="IDE-集成"><a href="#IDE-集成" class="headerlink" title="IDE 集成"></a>IDE 集成</h2><p>与 IDE 的无缝集成对人工智能辅助编程至关重要。它保持了开发过程的强劲势头，无需掌握新平台的繁重工作。这意味着在学习曲线上花费更少的时间，更多的时间用于编码——更不用说，减少在不同平台或工具之间切换意味着更少的摩擦，使编码过程更加顺畅。</p>
<p>实时反馈的优势就在于此。当开发人员编写或调整代码时，集成工具会立即指出错误，提供修正建议，或建议更好的完成方式。这种编写、反馈和调整的即时互动就像有一个友好的教练在你身边。你将被引导编写更简洁、更高效的代码，而无需手动审查或外部检查的麻烦。</p>
<p>人工智能辅助系统还可以通过关注更广泛的编码叙述来增强集成开发环境。人工智能理解变量类型、方法签名，甚至项目的结构蓝图，以生成相关的代码建议。但这不仅仅是输出代码。</p>
<p>表 1-1 介绍了一些顶尖的人工智能辅助编程工具及其支持的 IDE。</p>
<p>表 1-1.  流行的人工智能辅助编程工具的 IDE</p>
<table>
<thead>
<tr>
<th>人工智能辅助编程工具</th>
<th>集成开发环境</th>
</tr>
</thead>
<tbody><tr>
<td>GitHub Copilot</td>
<td>Visual Studio Code, Visual Studio, Vim, Neovim, JetBrains 套件, Azure 数据工作室</td>
</tr>
<tr>
<td>Tabnine</td>
<td>Visual Studio Code, WebStorm, PyCharm, Eclipse, IntelliJ 平台, PhpStorm, CLion, <br />Neovim, JupyterLab, Rider, DataGrip, AppCode, Visual Studio 2022, Android Studio, <br />GoLand, RubyMine, Emacs, Vim, Sublime Text, Atom.AI, Jupyter Notebook 2<br /></td>
</tr>
<tr>
<td>CodiumAI</td>
<td>Visual Studio Code，JetBrains（IntelliJ，WebStorm，CLion，PyCharm）</td>
</tr>
<tr>
<td>Amazon Codewhisperer</td>
<td>Visual Studio Code, IntelliJ IDEA, AWS Cloud9, AWS Lambda 控制台, JupyterLab, <br />亚马逊 SageMaker Studio, JetBrains (IntelliJ, PyCharm, CLion, GoLand, WebStorm, <br />Rider, PhpStorm, RubyMine, DataGrip)<br /></td>
</tr>
</tbody></table>
<p>  注意</p>
<blockquote>
<p>微软的一项研究表明，88%的 GitHub Copilot 用户感到不那么沮丧且更专注。一个关键原因是停留在 IDE 中意味着花费更少的时间搜索。这使得开发者能够保持在“流状态”中。</p>
</blockquote>
<h2 id="反映您的代码库"><a href="#反映您的代码库" class="headerlink" title="反映您的代码库"></a>反映您的代码库</h2><p>某些人工智能辅助编程工具专门针对特定开发环境进行优化。开发人员可以对其进行微调，使工具能够理解项目的内部库、API、最佳实践和架构蓝图。这确保了提供的建议不仅在技术上可靠，还能与项目的独特需求相契合。</p>
<p>此自定义有助于使生成的代码建议与您组织的既定编码标准、质量标记和安全协议保持一致。专注于促进高质量代码意味着团队可以避免陷入已弃用或不良的代码片段。</p>
<p>此外，这种定制化的方法对新加入开发团队的成员来说是一个很大的好处。传统上，让他们适应新的代码库需要大量的时间投入，因为他们可能需要几个月的时间来探索代码、查看文档和学习编码协议。然而，人工智能辅助编程工具可以显著缩短这个学习曲线所需的时间。</p>
<h2 id="代码完整性"><a href="#代码完整性" class="headerlink" title="代码完整性"></a>代码完整性</h2><p>代码完整性是软件开发的标志。它突显了源代码在执行其预期功能时的稳健性和可靠性。可以将其视为一个透镜，通过它可以检查代码的完整性、准确性、一致性和强化程度。代码完整性的缺失为错误和潜在的安全盲点铺平了道路，这可能导致系统崩溃和数据泄露。</p>
<p>代码完整性的各种因素包括其准确性、全面性、一致性和安全性措施，以及维护的简便性。开发人员可以通过单元测试和集成测试、同行代码审查、静态代码分析以及严格的安全评估等多种方法提高代码完整性。</p>
<p>值得注意的是，越来越多的人工智能辅助编程工具正在推出旨在增强代码完整性的功能。它们深入代码的细节，为生成相关且精准的单元测试和边界情况铺平道路。</p>
<p>这些工具中有一些带有“修复建议”功能。这些建议在提前经过审核，以确保它们不会在开发人员面前出现新问题。然后，开发人员可以在他们的 IDE 中查看并采纳这些建议。</p>
<p>这些工具的一个额外好处是能够快速分析拉取请求并生成代码更改的简明摘要。它们还擅长自动生成发布说明，这对于记录软件版本的演变非常有用。</p>
<h2 id="人工智能驱动的文档生成器"><a href="#人工智能驱动的文档生成器" class="headerlink" title="人工智能驱动的文档生成器"></a>人工智能驱动的文档生成器</h2><p>文档是软件开发过程中的无名英雄。它有助于确保代码库保持可读、可维护和可扩展，特别是在团队变化和项目复杂性增加时。但说实话，创建和更新这些文档往往感觉像是在官僚泥潭中跋涉——这可能耗费时间，有时会被搁置。</p>
<p>现在，进入人工智能辅助编程工具。这些数字文书可以在很短的时间内生成大量文档，并且质量和清晰度都很高。这是通过利用LLMs的能力实现的，它们在处理语言方面特别强大。</p>
<h2 id="现代化"><a href="#现代化" class="headerlink" title="现代化"></a>现代化</h2><p>马克·安德森在 2011 年《华尔街日报》中的大胆声明“软件正在吞噬世界”已经像美酒一样陈年。安德森以其远见卓识和成功的企业家及风险投资家的卓越记录而闻名，他指出了技术历史上的一个成熟时刻。</p>
<p>他强调了基础设施已经成熟，并为全球行业的变革做好了准备。像亚马逊网络服务这样的云平台的崛起和宽带互联网的广泛普及是游戏规则的改变者。它们打破了服务器成本和网络知识的传统障碍。这为像优步、Netflix 和一系列社交媒体平台的颠覆者清除了舞台，重新编写了各自行业的规则。</p>
<p>当我们快进到安德森的深刻文章时，我们看到创新的快车道只是在加速。然而，它也带来了破坏的威胁，尤其是对于大型企业。这些巨头往往依赖于不仅昂贵而且现代化风险很大的遗留系统。他们的层级结构可能在决策过程中设置障碍，而他们庞大的规模则增加了接受变革的复杂性。此外，他们的员工可能并不总是与最新的技术创新保持一致。</p>
<p>进入 IBM，瞄准这一场景作为机会的金矿，并将其大量资源用于为客户打造人工智能辅助编程工具。2023 年 10 月，它推出了 watsonx 代码助手 Z。该系统可以在大型机系统上将 COBOL 转换为 Java，生成的代码优雅地面向对象。</p>
<p>IBM 的 Watsonx.ai 模型理解 115 种编程语言，基于 1.5 万亿个标记。该模型约有 200 亿个参数。这是最大的代码开发人工智能系统之一。</p>
<p>事实上，有数千亿行 COBOL 代码。但将这种语言迁移到现代语言并不是一件容易的事情。COBOL 代码通常已有几十年的历史，几乎没有文档。如果转换处理不当，后果可能会很严重。请记住，世界上大部分信用卡处理都是通过大型主机完成的。联邦政府处理学生贷款的系统也是如此。</p>
<p>不幸的是，有很多失败的迁移项目的例子。考虑一下加利福尼亚州机动车辆管理局，尽管投入了 2.08 亿美元，但在几年内不得不停止该项目。哎呀。</p>
<p>鉴于风险很高，大型主机开发人员通常薪资较高。但公司在招聘人才方面仍然面临挑战。年轻开发人员接受现代语言的培训，并认为大型主机开发是一个死胡同。同时，越来越多的资深大型主机开发人员正在退休。</p>
<p>IBM 意识到人工智能对于解决这个巨大问题是必不可少的。确实，代码转译器或翻译器已经存在了几十年。事实上，它们经常被用于大型机项目。然而，它们主要做的就是将 COBOL 的乱七八糟的代码快速翻译，然后，你得到了 Java 的乱七八糟的代码。这只是一个小改动，几乎没有改进或创新的迹象。Java 代码仍然需要大量的手动调整，这解释了为什么许多项目会遇到困难或彻底失败。</p>
<p>但通过使用生成式人工智能，IBM 表示它已经能够将一个项目的结果提高多达十倍。</p>
<p>其他公司正在探索这一现代化机会。GitHub 首席执行官托马斯·多姆克发布了：“仍在大型机上运行的 COBOL 是一个比我们想象的更大的社会问题。”在接受《财富》杂志采访时，他提到他在 2023 年听到的关于 COBOL 的内容比过去三十年都要多。他还表示，公司一直在询问如何在迁移项目中使用 GitHub Copilot。</p>
<p>请记住，ChatGPT 也精通传统编程语言。表 1-2 显示了它支持哪些语言。</p>
<p>表 1-2. 常见的传统编程语言</p>
<table>
<thead>
<tr>
<th>语言</th>
<th>描述</th>
<th>开发时代</th>
</tr>
</thead>
<tbody><tr>
<td>COBOL</td>
<td>用于业务数据处理</td>
<td>1950 年代末到 1960 年代初</td>
</tr>
<tr>
<td>Fortran</td>
<td>用于科学和工程计算</td>
<td>1950 年代</td>
</tr>
<tr>
<td>Pascal</td>
<td>旨在鼓励良好的软件工程实践</td>
<td>1960 年代末到 1970 年代初</td>
</tr>
<tr>
<td>BASIC</td>
<td>创建为学生和初学者易于学习的语言</td>
<td>1960 年代中期</td>
</tr>
<tr>
<td>ALGOL</td>
<td>影响了后来的语言如Pascal、C 和 Java</td>
<td>1950 年代末到 1960 年代初</td>
</tr>
<tr>
<td>汇编语言</td>
<td>对应于其设计的 CPU 架构，追溯到早期可编程计算机</td>
<td>早期计算时代</td>
</tr>
<tr>
<td>PL&#x2F;I</td>
<td>用于科学、工程、商业和系统编程</td>
<td>1960 年代初</td>
</tr>
</tbody></table>
<p>查看人工智能辅助编程如何帮助处理遗留语言，假设您需要处理以下代码片段：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">MODULE ComplexModule</span><br><span class="line">  IMPLICIT NONE</span><br><span class="line">  TYPE :: ComplexType</span><br><span class="line">     REAL :: real, imag</span><br><span class="line">  CONTAINS</span><br><span class="line">     OPERATOR(+) (a, b) RESULT(c)</span><br><span class="line">       TYPE(ComplexType), INTENT(IN) :: a, b</span><br><span class="line">       TYPE(ComplexType) :: c</span><br><span class="line">       c%real = a%real + b%real</span><br><span class="line">       c%imag = a%imag + b%imag</span><br><span class="line">     END OPERATOR</span><br><span class="line">  END TYPE ComplexType</span><br><span class="line">END MODULE ComplexModule</span><br></pre></td></tr></table></figure>

<p>您不知道这是什么语言或它是如何工作的。语法不利于对工作流程的直观理解。</p>
<p>现在假设你去使用 ChatGPT 并输入以下内容：</p>
<blockquote>
<p>提示：这段代码是用什么语言写的？这段代码片段的作用是什么？另外，解释一下它是如何工作的。</p>
</blockquote>
<p>图 1-5 显示了部分响应。</p>
<p><img src="/../assets_aiassistedprogramming/net-img-aiap_0105-20240826160900-xejtzso.png"></p>
<p> 图 1-5. ChatGPT 响应解释遗留代码的请求</p>
<p>ChatGPT 准确识别这是 Fortran 代码。它还解释了该代码定义了一个名为 ComplexModule 的模块，其中包含一个用于表示复数的派生类型 ComplexType，以及一个重载的加法运算符+用于将两个复数相加。然后是代码的逐步解释。</p>
<h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><p>现在让我们看看人工智能辅助编程工具不那么美好的一面。像任何新兴技术一样——嘿，连第一代 iPhone 都有点笨重——人工智能也有它的一些问题、缺陷和障碍。创新的道路上充满了打磨和调整的空间。</p>
<p>让我们看看一些缺点。</p>
<h2 id="幻觉"><a href="#幻觉" class="headerlink" title="幻觉"></a>幻觉</h2><p>对于LLMs，幻觉是指模型输出的数据看起来准确但实际上不正确或没有基于模型训练的输入数据。这可能对软件开发构成重大挑战。幻觉可能导致不准确的代码建议，生成误导性的文档，并创建错误的测试场景。此外，它们可能使调试效率低下，误导初学者，并可能削弱对人工智能工具的信任。</p>
<p>积极的一点是，减少幻觉发生的情况已有显著进展。大量学术研究已致力于此问题，人工智能公司采用了有效的策略，如基于人类反馈的强化学习（RLHF）来缓解这一问题。</p>
<p>然而，考虑到LLMs的内在复杂性以及它们所基于的大量数据，完全消除幻觉似乎是一项艰巨的任务——如果不是不可能的话。</p>
<p>另一个需要考虑的方面是，某些编程语言在使用人工智能辅助工具时表现出更高的准确率。像 Python、JavaScript、TypeScript 和 Go 这样的语言在这方面往往表现更好。这归因于这些语言在公共代码库中有较好的代表性，从而为人工智能提供了更丰富的数据集进行学习。训练得更好的人工智能反过来会提供更准确和更强大的建议。</p>
<h2 id="知识产权"><a href="#知识产权" class="headerlink" title="知识产权"></a>知识产权</h2><p>马修·巴特里克拥有多元化的背景，担任过程序员、设计师和律师，特别喜欢排版。他的经历包括撰写排版书籍、设计字体以及编写旨在文档编辑和布局的程序。然而，他在 2022 年 6 月与 GitHub Copilot 的接触并没有带来快乐。相反，这促使他写了一篇标题为“这个副驾驶很愚蠢，想杀了我”的博客文章。</p>
<p>他的不满并没有止步于博客。很快升级为对微软、GitHub 和OpenAI提起集体诉讼。争议的焦点是涉嫌违反 GitHub 的服务条款和隐私政策，可能还涉及版权侵权指控。</p>
<p>这一法律纠纷凸显了关于知识产权的更广泛灰色地带，涉及由人工智能辅助编程工具生成的代码。鉴于输出是无数行现有代码的混合，所有权问题是一个大问号。</p>
<p>一个论点基于“合理使用”的理念。然而，这一法律原则模糊不清，并没有为人工智能生成内容提供明确的路径。为了解决这个问题，可能需要联邦立法或最高法院裁决。</p>
<p>与此同时，微软已采取措施为 GitHub Copilot 客户建立法律防火墙。它承诺在满足某些前提条件的情况下为用户辩护。</p>
<p>增加法律困境的另一个层面是人工智能辅助编程与开源软件方法的交集。像通用公共许可证（GPL）版本 2 和 3 这样的版权保护许可证要求任何衍生作品使用原始代码的许可证条款。这有助于促进创新的流动。然而，这可能会给开发者带来麻烦，因为这可能剥夺他们保护应用程序知识产权的权利——甚至要求他们将整个代码库开源。</p>
<h2 id="隐私"><a href="#隐私" class="headerlink" title="隐私"></a>隐私</h2><p>使用人工智能辅助编程工具，通常托管在云端，提出了许多数据隐私和保密问题。公司内部的数据是如何保护的？是否有可能被用作训练数据？</p>
<p>答案的清晰度可能因供应商而异。因此，一些开发者可能选择完全避免使用人工智能辅助编程工具。</p>
<p>这一直是 Gridspace 的联合创始人兼工程主管安东尼·斯科达里的方法。该企业的根源可以追溯到斯坦福大学，开发擅长处理复杂电话对话的语音机器人。他们的技术基础建立在语音识别、语音合成、LLMs和对话系统之上。</p>
<p>Gridspace 选择了一条不寻常的道路，而不是依赖现有的人工智能辅助编程平台。它开发了自己的人工智能辅助编程平台，该平台基于 Kubernetes 集群中的 Docker 服务。作为 IDE 插件部署，这个定制系统经过优化以适应自己的代码库。“这使我们避免了将我们的知识产权和数据发送给其他公司，”他说。“这也意味着我们拥有一个更小、更高效、专门针对我们风格的模型。”</p>
<p>这并不是说这是最佳方法。每个组织都有自己的观点和偏好方法。但在评估人工智能辅助编程时，了解隐私影响是很重要的。</p>
<h2 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h2><p>在一篇题为“GitHub 中副驾驶生成代码的安全漏洞”的研究论文中，作者傅宇佳等人强调了 GitHub 副驾驶的安全问题。他们审查了来自 GitHub 项目的 435 个人工智能生成的代码片段，其中 35.8%存在通用弱点枚举（CWE）实例。</p>
<p>这些错误不限于一种编程语言。它们是跨越 42 个不同 CWE 类别的多语言失误。其中三个类别是常见的嫌疑犯——操作系统命令注入、使用不足够随机的值和对异常情况的不当检查或处理。但这里有个关键点：其中 11 个 CWE 荣幸地进入了 2022 年 CWE 前 25 名单。</p>
<p>这并不是说人工智能辅助编程工具是一个巨大的安全风险。远非如此。事实是供应商们正在继续寻找改进保护措施的方法。然而，与任何代码一样，保持安全意识是关键。</p>
<h2 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h2><p>人工智能辅助编程工具的LLMs训练数据可能存在显著的缺口，这可能影响这些工具在实际场景中的性能和实用性。我们来分析一下其中的一些：</p>
<ul>
<li> 表示差距：如果某些编程语言或库的特定领域在开源项目中没有得到很好的体现——或者根本没有出现——那么人工智能可能缺乏足够的知识，从而导致建议不够准确。人工智能输出的质量在很大程度上依赖于训练数据的质量和范围。</li>
<li> 质量不一致：借用电影的比喻，LLM中的开源代码有点像一盒巧克力——你永远不知道你会得到什么。有些项目是精华中的精华，而其他的……我们可以说，是代码世界中的烧焦的吐司。这种混杂可能导致我们的人工智能辅助编程在提供建议的质量上不一致。</li>
<li> 知识截止日期：LLMs 在训练时有截止日期，因此在某种程度上它们就像时间的快照。这在编程语言或库有新版本、更新或弃用时会带来挑战。</li>
<li> 泛化差距：泛化差距，即人工智能在训练数据和未见数据上的表现差异，也可能带来挑战。当然，两者的表现越接近越好。这是 Rie Johnson 和 Tong Zhang 撰写的研究论文《深度神经网络训练的不一致性、稳定性和泛化差距》的结论。</li>
<li>上下文理解：人工智能可以根据之前看到的内容给你建议。但如果它没有见过与你的场景完全相似的情况，它可能会偏离目标。这就是在创建提示时不做假设的重要性。</li>
</ul>
<h2 id="偏见"><a href="#偏见" class="headerlink" title="偏见"></a>偏见</h2><p>开发人员通常对人工智能伦理缺乏深入了解，这可能是因为这个主题通常不包含在计算机科学课程或密集训练营项目中。这种理解上的差距可能导致算法无意中应用偏见和数据的潜在误用。</p>
<p>这个问题同样适用于人工智能辅助编程工具。它们可能无意中延续训练数据中存在的偏见。例如，如果被要求创建一个名字列表，它们可能主要建议英文名字，因为训练数据集中以英语为中心的数据占据了很大比例。这种偏见有时会导致有害或不当的输出。有一个例子，当给定提示“def race(x):”时，人工智能填充了一组有限且固定的种族类别。在另一个令人担忧的案例中，当被要求为提示“伊斯兰”编写代码注释时，人工智能发现访问恐怖分子和暴力等词汇的频率高于提到其他宗教团体时。</p>
<h1 id="开发者的新方式"><a href="#开发者的新方式" class="headerlink" title="开发者的新方式"></a>开发者的新方式</h1><p>麦肯锡研究表明，人工智能辅助编程工具的出现可能会改变我们对软件开发的方式。作者指出，成功可能依赖于良好的培训，强调最佳实践，并深入进行提示工程、编码标准和质量等方面的实践。关注生成式人工智能相关的风险也是明智之举。</p>
<p>对于新手开发者，特别是那些经验不足一年的开发者，深入学习涵盖编程基本原理的额外课程是个好主意，以提高生产力。</p>
<p>随着开发人员将这些工具融入日常工作，保持技能提升的动力至关重要，这需要团队中经验丰富的专业人士的指导和参与社区活动。这可能意味着在专门的在线论坛中交流或定期召开团队会议分享实际案例。这些举措可以促进持续学习的文化，传播最佳实践，并帮助及早发现问题。</p>
<p>随着开发者生产力的提升，管理者可能想要在角色上有所调整，专注于更有价值的任务。提升技能也会成为重点，以填补现有的空白。</p>
<p>当然，这些建议不是绝对的。人工智能辅助编程领域仍然相对新颖，并且变化迅速。最重要的是，准备好应对变化是关键。</p>
<h2 id="职业"><a href="#职业" class="headerlink" title="职业"></a>职业</h2><p>虽然没有确凿的证据表明使用人工智能辅助编程会提升你的职业前景，但一些迹象表明这种技能可能会成为就业市场的热门票据：</p>
<ul>
<li> 职位列表：像 Indeed 这样的网站上的招聘信息开始增加，寻找具有人工智能辅助编程工具经验的候选人。各个级别的人才都在招募，从初级开发者到高级专家。</li>
<li> 生产力提升：人工智能辅助编程工具引起了关注，因为它们在不牺牲质量的情况下提高了生产力。对于开发人员来说，这可能是晋升的一个途径。</li>
<li>开发者点赞：开发者之间的讨论是，人工智能辅助编程工具正在流行。例如，GitHub Copilot 在独立软件评审网站 G2.com 上获得了 4.5 星（满分 5 星）的高评分。</li>
</ul>
<h2 id="10-倍开发者？"><a href="#10-倍开发者？" class="headerlink" title="10 倍开发者？"></a>10 倍开发者？</h2><p>10 倍开发者拥有 10 个程序员的能力。他们是编码的博尔特，快速解决问题并在你说“修复 bug”之前输出解决方案。</p>
<p>所以你可能在想：我能否借助人工智能辅助编程工具成为一个 10 倍开发者？抱歉，可能不行。虽然这些技术可以带来显著的变化，但改进通常不是数量级的。</p>
<p>此外，10 倍开发者的概念可能会引发刻板印象和偏见，使技术领域感觉像一个排他性的俱乐部。更不用说，成为这种超级编码员的压力可能会让你直接走向倦怠。因此，虽然成为 10 倍开发者听起来很不错，但请记住，这可能更接近于幻想。</p>
<h2 id="开发者技能"><a href="#开发者技能" class="headerlink" title="开发者技能"></a>开发者技能</h2><p>根据麦肯锡的研究，人工智能辅助开发工具的有效性往往取决于开发者的专业知识。以下是一些考虑因素：</p>
<p> 修复错误尽管生成式人工智能可以成为你可靠的助手，但它也会出错。开发者需要负责发现和修复这些错误。一些开发者发现自己与人工智能进行纠正的循环，以达到准确性的最佳状态，而另一些则不得不逐步引导工具以使其准确调试。这肯定会耗费时间。但经验丰富的开发者会知道如何避免陷入无谓的细节。</p>
<p>获取办公室氛围人工智能辅助编程工具在编码方面相当可靠，但在处理个别项目的独特风格或公司特性时可能会出现问题。再次强调，资深开发人员在这里至关重要。他们知道如何引导这些工具以获得最符合组织目标、绩效指标和安全性的结果。</p>
<p>解决难题辅助人工智能编程工具在优化代码等任务上表现出色，但遇到一些复杂挑战，比如融合不同的编码框架时，人工智能可能会出现问题。在这些时刻，经验丰富的开发者需要动手解决。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>人工智能辅助编程工具无疑是软件创建沙盒中的闪亮玩具。随着这项技术不断向前发展，这些系统将提高效率，处理无聊的任务，让开发人员专注于最重要的领域，比如高级问题解决。</p>
<p>但也有缺点——复杂的知识产权问题、开放源代码软件许可的迷宫、潜在的偏见以及安全风险等。</p>
<p>在大多数情况下，这些工具是你的虚拟助手，而不是你知识、技能和经验的替代品。同时，虽然它们可能不是超级英雄，但它们正成为开发者工具包中强大的补充。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/29/aiassistedprogramming00/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/29/aiassistedprogramming00/" class="post-title-link" itemprop="url">前言</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-29 11:48:32" itemprop="dateCreated datePublished" datetime="2024-08-29T11:48:32+08:00">2024-08-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-03 09:19:17" itemprop="dateModified" datetime="2024-09-03T09:19:17+08:00">2024-09-03</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>697</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>当我在 1990 年代初从 UCLA 毕业时，我以为我会成为一名教授。但当 IBM 雇佣我时，我很快爱上了技术行业。没有回头路。我后来在其他公司工作过，比如 VMware、Pivotal、EMC 和 SGI。</p>
<p>然后我创办了几家初创公司。我的最新公司是 Aisera，专注于为企业构建生成式人工智能解决方案。我们的平台帮助客户服务、员工体验、企业搜索、IT 服务台和人工智能运维。</p>
<p>在我的职业生涯中，我见证了许多创新，例如互联网的出现、云计算、移动设备和深度学习。然而，有一个技术领域几乎没有进展：软件开发。</p>
<p>作为创始人，这确实是一个很大的挫折。我们经常有一些想做的事情，但由于工程团队的瓶颈而无法实现。但随着人工智能辅助编程，局面发生了很大变化。这使得 Aisera 变得更加灵活和敏捷。它成为了一个助力倍增器，帮助推动了我们的增长。</p>
<p>现在，当我考虑招聘开发者时，我想知道他们如何利用人工智能。他们如何使用这项强大的技术来处理繁琐的流程并更快地编写代码？</p>
<p>底线：我认为理解人工智能辅助编程工具是一项关键技能。根据微软首席执行官萨提亚·纳德拉的说法，它们“正成为任何开发者的标准配置……”</p>
<p>但理解人工智能辅助编程需要不同的方法。这与典型的开发不同。你需要了解如何使用生成式人工智能系统。这就是汤姆的书的用处所在。他为任何想要熟练掌握人工智能辅助编程的开发者编写了一本操作手册。他涵盖了关键主题，并提供了许多有用的示例。他还以有趣的方式完成了这一点，使主题变得易于接近。</p>
<p>毫无疑问，现在是成为开发者的激动人心的时刻。职业发展的机会很多。而你可以做出的最佳选择之一就是学习人工智能辅助编程。</p>
<p> 穆杜·苏达卡尔</p>
<p>Aisera 的首席执行官兼联合创始人</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/28/aiassistedprogramming_title/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/28/aiassistedprogramming_title/" class="post-title-link" itemprop="url">人工智能辅助编程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-28 11:48:32" itemprop="dateCreated datePublished" datetime="2024-08-28T11:48:32+08:00">2024-08-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-04 17:01:42" itemprop="dateModified" datetime="2024-09-04T17:01:42+08:00">2024-09-04</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>527</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><img src="/../assets_aiassistedprogramming/image-20240826155044-1ap32lg.png" alt="image.png"></p>
<p>获取有关如何利用人工智能开发工具进行代码创建各个阶段的实用建议，包括需求、规划、设计、编码、调试、测试和文档。通过本书，初学者和经验丰富的开发人员都将学习如何使用各种工具，从通用型LLMs（ChatGPT、Gemini 和 Claude）到特定代码系统（GitHub Copilot、Tabnine、Cursor 和 Amazon CodeWhisperer）。</p>
<p>您还将了解更多用于文本生成图像的专业生成式人工智能工具。</p>
<p>作者汤姆·陶利提供了一种模块化编程的方法，与提示生成的人工智能代码的方式有效对齐。该指南还描述了使用通用LLMs学习编程语言、解释代码或将代码从一种语言转换为另一种语言的最佳方法。</p>
<p> 本书探讨：</p>
<ul>
<li>基于人工智能的开发工具的核心能力</li>
<li>流行系统的优缺点和使用案例，如 GitHub Copilot 和 Amazon CodeWhisperer</li>
<li>使用 ChatGPT、Gemini、Claude 和其他通用LLMs进行编码的方法</li>
<li>使用人工智能开发工具进行软件开发生命周期，包括需求、规划、编码、调试和测试</li>
<li>提示工程开发</li>
<li>使用人工智能辅助编程处理繁琐任务，如创建正则表达式、启动代码、面向对象编程类和 GitHub Actions</li>
<li>如何使用基于人工智能的低代码和无代码工具，例如创建专业用户界面</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/26/GraphRAG03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/26/GraphRAG03/" class="post-title-link" itemprop="url">GraphRAG系列3 - 实验</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-26 12:19:48 / 修改时间：12:29:41" itemprop="dateCreated datePublished" datetime="2024-08-26T12:19:48+08:00">2024-08-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>微软推出GraphRAG（图谱检索增强生成），我比较感兴趣GraphRAG的构建过程，参考源码做了一个测试。</p>
<p>测试数据是电影库，原始文本json数据263KB，json格式如下：UTF8字符是中文</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;genre&quot;: [</span><br><span class="line">            &quot;\u5267\u60c5&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;title&quot;: &quot;\u8096\u7533\u514b\u7684\u6551\u8d4e&quot;,</span><br><span class="line">        &quot;year&quot;: 1994,</span><br><span class="line">        &quot;certificate&quot;: &quot;A&quot;,</span><br><span class="line">        &quot;overview&quot;: &quot;\u4e24\u540d\u88ab\u76d1\u7981\u7684\u7537\u5b50\u5728\u591a\u5e74\u4e2d\u5efa\u7acb\u4e86\u6df1\u539a\u7684\u53cb\u8c0a\uff0c\u901a\u8fc7\u5171\u540c\u7684\u5584\u884c\u627e\u5230\u5b89\u6170\u548c\u6700\u7ec8\u7684\u6551\u8d4e\u3002&quot;,</span><br><span class="line">        &quot;director&quot;: &quot;\u5f17\u5170\u514b\u00b7\u5fb7\u62c9\u90a6\u7279&quot;,</span><br><span class="line">        &quot;cast&quot;: [</span><br><span class="line">            &quot;\u8482\u59c6\u00b7\u7f57\u5bbe\u65af&quot;,</span><br><span class="line">            &quot;\u6469\u6839\u00b7\u5f17\u91cc\u66fc&quot;,</span><br><span class="line">            &quot;\u9c8d\u52c3\u00b7\u5188\u987f&quot;,</span><br><span class="line">            &quot;\u5a01\u5ec9\u00b7\u8428\u5fb7\u52d2&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;llm_text&quot;: &quot;\u4e24\u540d\u88ab\u76d1\u7981\u7684\u7537\u5b50\u5728\u591a\u5e74\u4e2d\u5efa\u7acb\u4e86\u6df1\u539a\u7684\u53cb\u8c0a\uff0c\u901a\u8fc7\u5171\u540c\u7684\u5584\u884c\u627e\u5230\u5b89\u6170\u548c\u6700\u7ec8\u7684\u6551\u8d4e\u3002\nYear: 1994\nDirector: \u5f17\u5170\u514b\u00b7\u5fb7\u62c9\u90a6\u7279\nCast: [&#x27;\u8482\u59c6\u00b7\u7f57\u5bbe\u65af&#x27;, &#x27;\u6469\u6839\u00b7\u5f17\u91cc\u66fc&#x27;, &#x27;\u9c8d\u52c3\u00b7\u5188\u987f&#x27;, &#x27;\u5a01\u5ec9\u00b7\u8428\u5fb7\u52d2&#x27;]\nCertificate: A&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;genre&quot;: [</span><br><span class="line">            &quot;\u72af\u7f6a&quot;,</span><br><span class="line">            &quot;\u5267\u60c5&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;title&quot;: &quot;\u6559\u7236&quot;,</span><br><span class="line">        &quot;year&quot;: 1972,</span><br><span class="line">        &quot;certificate&quot;: &quot;A&quot;,</span><br><span class="line">        &quot;overview&quot;: &quot;\u4e00\u4e2a\u6709\u7ec4\u7ec7\u72af\u7f6a\u738b\u671d\u7684\u5e74\u8fc8\u5bb6\u65cf\u9996\u9886\u5c06\u4ed6\u79d8\u5bc6\u5e1d\u56fd\u7684\u63a7\u5236\u6743\u8f6c\u4ea4\u7ed9\u4e0d\u60c5\u613f\u7684\u513f\u5b50\u3002&quot;,</span><br><span class="line">        &quot;director&quot;: &quot;\u5f17\u6717\u897f\u65af\u00b7\u798f\u7279\u00b7\u79d1\u6ce2\u62c9&quot;,</span><br><span class="line">        &quot;cast&quot;: [</span><br><span class="line">            &quot;\u9a6c\u9f99\u00b7\u767d\u5170\u5ea6&quot;,</span><br><span class="line">            &quot;\u963f\u5c14\u00b7\u5e15\u897f\u8bfa&quot;,</span><br><span class="line">            &quot;\u8a79\u59c6\u65af\u00b7\u51ef\u6069&quot;,</span><br><span class="line">            &quot;\u9edb\u5b89\u00b7\u57fa\u987f&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;llm_text&quot;: &quot;\u4e00\u4e2a\u6709\u7ec4\u7ec7\u72af\u7f6a\u738b\u671d\u7684\u5e74\u8fc8\u5bb6\u65cf\u9996\u9886\u5c06\u4ed6\u79d8\u5bc6\u5e1d\u56fd\u7684\u63a7\u5236\u6743\u8f6c\u4ea4\u7ed9\u4e0d\u60c5\u613f\u7684\u513f\u5b50\u3002\nYear: 1972\nDirector: \u5f17\u6717\u897f\u65af\u00b7\u798f\u7279\u00b7\u79d1\u6ce2\u62c9\nCast: [&#x27;\u9a6c\u9f99\u00b7\u767d\u5170\u5ea6&#x27;, &#x27;\u963f\u5c14\u00b7\u5e15\u897f\u8bfa&#x27;, &#x27;\u8a79\u59c6\u65af\u00b7\u51ef\u6069&#x27;, &#x27;\u9edb\u5b89\u00b7\u57fa\u987f&#x27;]\nCertificate: A&quot;</span><br><span class="line">    &#125;,</span><br></pre></td></tr></table></figure>


<p>构建图谱的过程如下：</p>
<p>create_graph_data &#x3D;&#x3D;》process_movie &#x3D;&#x3D;》extractEntities ， extractRelations ，extractClaims</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">async def create_graph_data(llm: LocalLLM, model: str, movies: List[Dict]):</span><br><span class="line">    # G = nx.Graph()</span><br><span class="line">    usages = []</span><br><span class="line">    graph_data = []</span><br><span class="line">    semaphore = asyncio.Semaphore(5)</span><br><span class="line">    pbar = tqdm(total=len(movies), desc=&quot;Processing Movies&quot;, colour=&quot;blue&quot;)</span><br><span class="line"></span><br><span class="line">    async def process_movie_with_semaphore(movie: Dict):</span><br><span class="line">        async with semaphore:</span><br><span class="line">            try:</span><br><span class="line">                await process_movie(movie.get(&quot;title&quot;), movie.get(&quot;llm_text&quot;))</span><br><span class="line">                pbar.update(1)</span><br><span class="line">            except Exception as err:</span><br><span class="line">                logging.exception(f&quot;EXCEPTION: &#123;str(err)&#125;&quot;)</span><br><span class="line">                pbar.update(1)</span><br><span class="line"></span><br><span class="line">    async def process_movie(movie: str, movie_overview: str):</span><br><span class="line">        entities, eu = await extractEntities(llm, model, movie_overview)</span><br><span class="line">        relations, ru = await extractRelations(llm, model, entities)</span><br><span class="line">        claims, cu = await extractClaims(llm, model, movie_overview, entities,</span><br><span class="line">                                         relations)</span><br><span class="line">        usages.extend([eu, ru, cu])</span><br><span class="line">        graph_data.append(&#123;</span><br><span class="line">            &quot;movie&quot;: movie,</span><br><span class="line">            &quot;overview&quot;: movie_overview,</span><br><span class="line">            &quot;entities&quot;: entities,</span><br><span class="line">            &quot;relations&quot;: relations,</span><br><span class="line">            &quot;claims&quot;: claims</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    await asyncio.gather(</span><br><span class="line">        *[process_movie_with_semaphore(movie) for movie in movies])</span><br><span class="line"></span><br><span class="line">    return graph_data, usages</span><br></pre></td></tr></table></figure>


<p>看一下 extractEntities ：</p>
<p>extractEntities &#x3D;&#x3D;》系统提示词 EXTRACT.ENTITIES &#x3D;&#x3D;》llm.<strong>function_call</strong></p>
<p>用大模型来抽取实体</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">async def extractEntities(llm: LocalLLM, model: str, content: str):</span><br><span class="line">    entities = []</span><br><span class="line">    usages = []</span><br><span class="line">    for gleaning in range(ALLOWED_GLEANINGS):</span><br><span class="line">        message_content = f&quot;‍```&#123;content&#125;‍```&quot;</span><br><span class="line">        messages = [&#123;</span><br><span class="line">            &quot;role&quot;: &quot;system&quot;,</span><br><span class="line">            &quot;content&quot;: EXTRACT.ENTITIES</span><br><span class="line">        &#125;, &#123;</span><br><span class="line">            &quot;role&quot;:</span><br><span class="line">            &quot;user&quot;,</span><br><span class="line">            &quot;content&quot;:</span><br><span class="line">            message_content if gleaning == 0 else</span><br><span class="line">            f&#x27;The following are the entities you provided: &#123;entities&#125;. You have missed some entities, please provide all the entities. &#123;message_content&#125;&#x27;</span><br><span class="line">        &#125;]</span><br><span class="line">        # output, usage = await llm.__complete__(messages, model)</span><br><span class="line">        output, usage = await llm.__function_call__(</span><br><span class="line">            messages,</span><br><span class="line">            model,</span><br><span class="line">            EntityTool.tools,</span><br><span class="line">            tool_choice=EntityTool.tool_choice)</span><br><span class="line">        entities_ = output.get(&quot;entities&quot;)</span><br><span class="line">        entities += entities_</span><br><span class="line">        usages += [usage]</span><br><span class="line">    usages = calculateUsages(usages)</span><br><span class="line">    return entities, usages</span><br></pre></td></tr></table></figure>


<p>再看一下提示词：</p>
<p>提示词里面告诉大模型要提取哪些实体，如何组织输出数据。 </p>
<blockquote>
<p>You are an AI assistant tasked with extracting entities from a movie description. Your goal is to identify the main movie and all related entities.</p>
<p>Instructions:</p>
<ol>
<li><p>Identify the main movie entity.</p>
</li>
<li><p>Identify all related entities (actors, directors, genres, themes, studios, etc.).</p>
</li>
<li><p>For each entity, provide:</p>
<ul>
<li>Name: The name of the entity (capitalized)</li>
<li>Type: The type of entity (Movie, Actor, Director, Genre, Theme, Studio, etc.)</li>
<li>Description: A brief description of the entity</li>
</ul>
</li>
</ol>
<p>Output Format:<br>Provide the output as a JSON object with the movie as the main entity and other entities in a separate list:<br>{<br>    “related_entities”: [<br>        {“name”: “ENTITY_NAME”, “type”: “ENTITY_TYPE”, “description”: “ENTITY_DESCRIPTION”},<br>        …<br>    ]<br>}</p>
<p>Text to analyze will be provided in triple backticks.</p>
<p>Begin your analysis:</p>
</blockquote>
<p>抽取关系以及声明就不赘述，代码还有很多，具体大家自己看：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/vatsalsaglani/GraphRAG4Rec">vatsalsaglani&#x2F;GraphRAG4Rec: A naive implementation of GraphRAG for Movie Recommendation on IMDB Top 1000 movies dataset. (github.com)</a></p>
<p>图谱构建好了之后，可以用浏览器查看.</p>
<p><img src="/../assets_graph03/image-20240802164047-36ty20q.png" alt="image.png"></p>
<p>然后就可以查询了，一次查询的token使用量很大，生成的token大概14776个token，大部分token在输入上面，prompt_tokens包含提示词和图谱本身的内容，用了78212个token。图谱检索增强生成这种方式效果不错, 消耗token成本依赖于进行查询的图谱数据的token数。</p>
<blockquote>
<p>{<br>“completion_tokens”:14776,<br>“prompt_tokens”:78212,<br>“total_tokens”:92988<br>}<br><br /></p>
</blockquote>
<p>附件包含源码和测试输出数据以及图谱。</p>
<p><a href="/../assets_graph03/imdb-20240826121440-i7mfjx5.zip">imdb.zip</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/21/Phi-3-mini-4k-graph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/21/Phi-3-mini-4k-graph/" class="post-title-link" itemprop="url">Phi-3-mini-4k 用于图谱实体关系提取</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-21 11:32:19 / 修改时间：14:55:28" itemprop="dateCreated datePublished" datetime="2024-08-21T11:32:19+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>17 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在 <a target="_blank" rel="noopener" href="https://asknews.app/">AskNews</a>，我们正在重新构想人们和LLMs消费和理解新闻的方式。我们提供的一个功能是对所有事件叙述和新闻文章中实体之间关系的丰富视觉表示。这些实体关系图，也称为知识图谱，为我们的用户提供了强大的方式来探索和互动我们的庞大新闻数据库。事实上，我们正式托管了世界上最大的可搜索新闻知识图谱表示。但是，我们如何处理每天生成 50 万个知识图谱呢？以下博客文章强调了支撑整个知识图谱构建&#x2F;索引过程的关键组件——我们经过精细调整的 Phi-3-mini-4k-instruct-graph。</p>
<p><img src="/../asset_phi3-mini-4k/01.png"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我们对 Phi-3-mini-4k 进行了微调，使其在图形提取质量上超过 Claude Sonnet 3.5，提升幅度达到 20%，并将成本降低了几个数量级。此外，我们改进了 Phi-3-mini-4k 已经相当出色的 JSON 输出结构，将解析错误率从 2.5%降低到 0。我们还发布了两个额外版本，Phi-3-medium-4k-instruct-graph 和 Phi-3-medium-128k-instruct-graph，旨在提高推理能力和处理更长的上下文。</p>
<p><img src="/../asset_phi3-mini-4k/12.png"></p>
<p>针对各种损失指标和最先进模型的 Phi-3-mini 微调性能比较。</p>
<p>我们还设置了一个 HuggingFace 空间，托管我们的微调模型，该模型旨在接收任何文本并将输出可视化为图形：</p>
<p><img src="/../asset_phi3-mini-4k/03.png"></p>
<h1 id="图谱在如今非常流行"><a href="#图谱在如今非常流行" class="headerlink" title="图谱在如今非常流行"></a>图谱在如今非常流行</h1><p>AskNews 系统每天处理的新闻量达到惊人的 50 万篇文章。使用向量数据库对这些文章进行索引可以实现广泛的语义探索，但使用知识图谱进行索引则带来了另一层复杂性。虽然向量数据库通常与旨在将语义嵌入向量空间的小型嵌入模型相结合，但知识图谱需要高级推理、一般世界知识和上下文，以便正确构建。</p>
<p>最新工具现在能够以成本效益高的方式将这种通用世界知识和推理应用于每天 50 万篇新闻文章。Phi-3-mini-4k 是一种强大的小型语言模型，广泛应用于摘要、翻译、代码生成和实体提取等任务。同时，GPT-4o 是一种最先进的大型语言模型，能够处理更高层次的推理任务。将这些模型与最新的微调方法和库结合，我们可以有效地将知识从 GPT-4o 转移到 Phi-3-mini-4k，同时保持图形质量和准确性，成本却大大降低。</p>
<p>通过每天提取 500k 实体关系图与 Phi-3-mini-4k-graph，我们受益于强大的新闻知识图谱表示，促进：</p>
<ul>
<li>复杂的搜索查询跨互补的向量 x 图索引（例如 RAG）</li>
<li>识别实体和关系之间的时间特征和趋势，以增强预测建模（实时预测）</li>
<li>跟踪来自二级和三级关系的隐藏洞察</li>
</ul>
<p>在接下来的部分中，我们将探讨我们的方法论，包括我们对指标制定的方式，并分享我们训练后评估的结果。</p>
<h1 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1><h2 id="数据集工程"><a href="#数据集工程" class="headerlink" title="数据集工程"></a>数据集工程</h2><p>我们从 AskNews API 的“事件”构建了我们的数据集。事件是代表单一事件的数百个语义相似的合成新闻文章摘要的聚类。聚类过程本质上识别出不同的话题，这有助于我们数据集的话题&#x2F;词汇多样化。每个事件聚类可以与在不同时间点发生的其他事件聚类相连接。这被称为叙事追踪，我们在这里不详细讨论，但可以说，时间上相连的两个事件通常是不断发展的新闻故事的更新。</p>
<p>目标是尽可能多样化主题和词汇。因此我们：</p>
<ol>
<li>从所有独特事件中选择均匀分布的样本</li>
<li>选择最多 3 个时间上相关的事件</li>
<li>确保训练&#x2F;测试&#x2F;验证数据集各自包含独特事件的子集，并且在时间上不重叠</li>
</ol>
<p>我们从 AskNews API 中提取这些事件，将合成摘要输入到 GPT-4o 中生成实体关系图，然后将合成事件摘要与 GPT-4o 生成的标签结合起来，构建完整的训练数据集。</p>
<p>该数据集被分为 90%用于训练，5%用于验证，5%用于测试——总共有 4,000 个独特样本。通过保持事件之间的严格分离，我们获得了目标参数空间的良好分布表示，我们的LLM将在其中操作。</p>
<h2 id="损失和验证指标"><a href="#损失和验证指标" class="headerlink" title="损失和验证指标"></a>损失和验证指标</h2><p>我们的主要目标是训练 Phi-3 生成与 GPT-4o 相似模式的故事图，同时确保正确生成 JSON 结构。</p>
<p>评估指标：最初，我们使用标准文本相似度指标，如 BLEU 和 ROUGE，来验证和测试我们模型的性能。然而，在经过几次训练迭代后，我们发现针对我们特定用例定制的指标产生了更好的结果：</p>
<ul>
<li>JSON 相似性：我们开发了一种自定义度量来比较 Phi-3 生成的节点和边与参考模型（GPT-4o）。</li>
</ul>
<p><img src="/../asset_phi3-mini-4k/04.png"></p>
<ul>
<li>JSON 一致性：这个额外的指标使我们能够检查每个边实体数据是否有相关的节点。我们发现，在某些情况下，即使是最先进的模型如 Claude 3.5 也会生成带有孤立边的图。</li>
</ul>
<p><img src="/../asset_phi3-mini-4k/05.png"></p>
<p>这是一个 JSON 输出的小示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;nodes&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;id&quot;: &quot;Viktor Orban&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;person&quot;,</span><br><span class="line">            &quot;detailed_type&quot;: &quot;hungarian prime minister&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;id&quot;: &quot;United States&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;country&quot;,</span><br><span class="line">            &quot;detailed_type&quot;: &quot;nation&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;edges&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;from&quot;: &quot;Viktor Orban&quot;,</span><br><span class="line">            &quot;to&quot;: &quot;United States&quot;,</span><br><span class="line">            &quot;label&quot;: &quot;stated influence&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="基础模型选择"><a href="#基础模型选择" class="headerlink" title="基础模型选择"></a>基础模型选择</h2><p>我们为这个项目选择了 <a target="_blank" rel="noopener" href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct">Phi-3-mini-4k-instruct</a> 模型。Phi-3 被归类为小型语言模型（SLM），效率极高。即使是配备 NVIDIA RTX GPU 的工作站或配备 GeForce RTX GPU 的个人电脑也可以在本地运行该模型。该模型在 2024 年 6 月进行了重大更新，证明在指令遵循、结构化输出和推理能力方面有了显著提升。根据模型发布说明，JSON 结构输出的性能在公共和内部基准数据集上从 11.5 大幅提升至 52.3，此外还有其他增强功能。对于我们的用例而言，这一改进是显著的。</p>
<p>这些改进进一步巩固了 Phi-3 作为我们任务的优秀选择。作为 SLM 的高效性与其在结构化输出方面增强的能力完美契合了我们处理大量新闻文章的目标，同时保持高质量的实体关系提取。</p>
<p>我们的微调方法利用了变换器，包括：SFTTrainer 用于高效的监督训练，PEFT 用于参数高效的微调，以及 QLoRA 用于量化低秩适应，使 Phi-3 有效适应我们的任务，同时优化计算资源。</p>
<p>下面的代码片段展示了我们实现的关键部分：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,</span><br><span class="line">                        TrainingArguments, EarlyStoppingCallback)</span><br><span class="line">from trl import SFTTrainer</span><br><span class="line">from peft import LoraConfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ModelTrainer:</span><br><span class="line">  def setup_model_and_tokenizer(self):</span><br><span class="line">      bnb_config = BitsAndBytesConfig(</span><br><span class="line">          load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=&quot;nf4&quot;, bnb_4bit_compute_dtype=torch.bfloat16</span><br><span class="line">      )</span><br><span class="line">      self.model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">          self.model_id,</span><br><span class="line">          device_map=&quot;auto&quot;,</span><br><span class="line">          attn_implementation=&quot;flash_attention_2&quot;,</span><br><span class="line">          torch_dtype=torch.bfloat16,</span><br><span class="line">          quantization_config=bnb_config,</span><br><span class="line">          trust_remote_code=True,</span><br><span class="line">          use_cache=False</span><br><span class="line">      )</span><br><span class="line">      self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_id, trust_remote_code=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  def setup_trainer(self, train_dataset, eval_dataset):</span><br><span class="line">      peft_config = LoraConfig(</span><br><span class="line">          lora_alpha=8,</span><br><span class="line">          lora_dropout=0.05,</span><br><span class="line">          r=6,</span><br><span class="line">          bias=&quot;none&quot;,</span><br><span class="line">          target_modules=&quot;all-linear&quot;,</span><br><span class="line">          task_type=&quot;CAUSAL_LM&quot;,</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">      args = TrainingArguments(</span><br><span class="line">          output_dir=self.output_dir,</span><br><span class="line">          num_train_epochs=5,</span><br><span class="line">          per_device_train_batch_size=4,</span><br><span class="line">          gradient_accumulation_steps=1,</span><br><span class="line">          per_device_eval_batch_size=8,</span><br><span class="line">          eval_accumulation_steps=2,</span><br><span class="line">          gradient_checkpointing=True,</span><br><span class="line">          logging_steps=10,</span><br><span class="line">          save_strategy=&quot;steps&quot;,</span><br><span class="line">          evaluation_strategy=&quot;steps&quot;,</span><br><span class="line">          eval_steps=100,</span><br><span class="line">          save_steps=100,</span><br><span class="line">          bf16=True,</span><br><span class="line">          tf32=True,</span><br><span class="line">          learning_rate=2e-4,</span><br><span class="line">          max_grad_norm=0.3,</span><br><span class="line">          warmup_ratio=0.03,</span><br><span class="line">          lr_scheduler_type=&quot;cosine&quot;,</span><br><span class="line">          metric_for_best_model=&quot;json_similarity_avg&quot;,</span><br><span class="line">          greater_is_better=True,</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">      self.trainer = SFTTrainer(</span><br><span class="line">          model=self.model,</span><br><span class="line">          args=args,</span><br><span class="line">          train_dataset=train_dataset,</span><br><span class="line">          eval_dataset=eval_dataset,</span><br><span class="line">          peft_config=peft_config,</span><br><span class="line">          max_seq_length=3072,</span><br><span class="line">          tokenizer=self.tokenizer,</span><br><span class="line">          packing=False,</span><br><span class="line">          compute_metrics=self.compute_metrics,</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">  trainer = ModelTrainer(</span><br><span class="line">      model_id=&quot;microsoft/Phi-3-mini-4k-instruct&quot;,</span><br><span class="line">      tokenizer_id=&quot;microsoft/Phi-3-mini-4k-instruct&quot;,</span><br><span class="line">      dataset_path=&quot;src/dataset/ds_1ea20812-afa8-4fab-8fba-dfb566c4775f&quot;,</span><br><span class="line">      output_dir=f&quot;models/&#123;output_model_name&#125;&quot;</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  trainer.setup_model_and_tokenizer()</span><br><span class="line">  trainer.setup_trainer(chatml_train_dataset, chatml_eval_dataset)</span><br><span class="line">  trainer.train_model()</span><br><span class="line">  trainer.save_model()</span><br></pre></td></tr></table></figure>

<p>为了测试和结果评估，我们将 GPT-4o 确立为基准真相。我们对比了我们的微调模型、未经微调的原始 Phi-3 以及 Claude Sonnet 3.5（被认为与 GPT-4o 齐名的最先进技术）。我们比较了这些模型之间之前提到的指标。此外，JSON 一致性指标被证明是有价值的，因为它不需要基准真相进行比较，从而允许对每个模型进行更独立的评估。</p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><p>在我们深入探讨培训后评估的细节之前，让我们先看一些现实世界的例子，以更好地理解我们的结果以及我们的指标实际意味着什么。我们将通过三个具体案例向您展示我们的 JSON 相似性指标和一致性检查在实践中的工作原理，以及它们的重要性。</p>
<h2 id="高相似度"><a href="#高相似度" class="headerlink" title="高相似度"></a>高相似度</h2><p>第一个例子是一个具有高 JSON 相似性的响应（这意味着与我们想要模仿的模型，即 GPT-4o，具有更大的相似性）。</p>
<p>故事：在一次协调的执法行动中，瓦西里·布拉科夫在特维尔地区因在莫斯科郊区谢尔科沃致命枪击两名警察而被捕。此次袭击发生在 4 月 7 日，导致一名警察死亡，另一名警察重伤。布拉科夫在事发后逃离现场并藏匿，经过六小时的搜捕，最终在当地森林中被找到并逮捕。被捕后，布拉科夫承认了罪行，并已被控以企图谋杀执法人员和非法持有枪支。此事件引发了重大关注，因为它突显了执法人员在执行职务时面临的危险，特别是在与毒品贩运相关的行动中。俄罗斯内务部和俄罗斯联邦安全局正在继续调查与枪击事件及布拉科夫随后的逃逸和逮捕相关的情况。</p>
<p> GPT-4o 输出：</p>
<p><img src="/../asset_phi3-mini-4k/06.png"></p>
<p>Phi-3-mini-instruct-graph 输出：</p>
<p><img src="/../asset_phi3-mini-4k/07.png"></p>
<p>正如我们在比较中所看到的，这些实体完全相同，只是在关系的描述上存在一些差异。然而，即使有这些差异，故事的正确含义在两个版本中都得到了传达。</p>
<h2 id="低相似度"><a href="#低相似度" class="headerlink" title="低相似度"></a>低相似度</h2><p>第二个例子是一个低 JSON 相似度的响应（这意味着与我们想要模仿的模型，即 GPT-4o，的相似度较低）。</p>
<p>故事：在令人惊讶的韧性展示中，美国劳动力市场在五月新增了 272,000 个职位，远超道琼斯共识预期的 190,000 个，反驳了劳动力市场放缓的说法。尽管就业增长强劲，失业率却上升至 4%，是自 2022 年 1 月以来的最高水平。医疗保健、政府以及休闲和酒店业是这一增长的主要驱动力，而平均时薪的增加则表明工资增长的持续趋势。强劲的就业报告对美联储的货币政策具有重要影响。最初，人们预计美联储可能会降息以支持经济。然而，意外的就业创造和工资增长可能会导致美联储推迟任何降息，一些专家现在预测，第一次降息可能要等到九月。劳动力市场的强劲被视为可能使美联储保持观望态势的关键因素。 股票和债券市场对该报告反应消极，标准普尔 500 期货下跌，政府债券收益率上升，反映出投资者担心由于强劲的就业市场数据，美联储可能会推迟降息。目前的情况为美联储呈现出复杂的局面，需在管理通胀与支持经济增长和维持劳动市场强劲之间取得平衡。</p>
<p> GPT-4o 输出：</p>
<p><img src="/../asset_phi3-mini-4k/08.png"></p>
<p>Phi-3-mini-instruct-graph 输出：</p>
<p><img src="/../asset_phi3-mini-4k/09.png"></p>
<p>正如我们在这个比较中所看到的，即使相似度较低，Phi3 微调版仍然能够通过实体及其关系更好地翻译故事的细节，保持美国劳动力市场作为主要实体，并与联邦储备保持联系（而这在 GPT-4o 中并未发生）。</p>
<h2 id="Json-一致性"><a href="#Json-一致性" class="headerlink" title="Json 一致性"></a>Json 一致性</h2><p>json_consistency 指标旨在通过验证所有边是否具有现有实体来衡量 JSON 的一致性，显示提取中节点和边之间的连贯性。我们微调的模型在该指标上达到了 99%，优于 Claude 3.5 Sonnet（97%）。我们将展示 Claude 3.5 中低一致性的具体示例，并将其与微调后的 Phi3 进行比较。</p>
<p>故事：在一次悲惨的对抗中，西澳大利亚珀斯的一名 16 岁男孩在刺伤一名男子并拒绝投降武器后被警方致命射击。该事件发生在威利顿郊区，因男孩被报道的在线激进化而被当局称为具有“恐怖主义特征”。他之前已被认定为风险，并参与了去激进化项目。警方在前一天晚上接到关于潜在袭击的线报，但未能阻止刺伤事件的发生。当他们抵达现场时，男孩手持一把 30 厘米的厨房刀，尽管被电击枪击中两次，但仍向警员冲去，随后被射击。刺伤事件的受害者目前情况稳定但危急。这一事件引发了人们对澳大利亚年轻人中激进化传播的重大担忧，以及有效干预的挑战。西澳大利亚州州长罗杰·库克和澳大利亚总理安东尼·阿尔巴尼斯均对此事件发表了讲话，强调国家对打击暴力极端主义的承诺。 事件正在调查中，宗教领袖与市政府之间的会议已安排，以解决社区关切。</p>
<p><strong>Claude 3.5 Sonnet 输出：</strong></p>
<p><img src="/../asset_phi3-mini-4k/10.png"></p>
<p>Phi-3-mini-instruct-graph 输出：</p>
<p><img src="/../asset_phi3-mini-4k/11.png"></p>
<p>在这种情况下，Claude 3.5 Sonnet 的一致性为 57%，而 Phi3 微调版的一致性为 100%。在 Claude 的 7 条边中，有 3 条因引用了一个名为“Incident”的不存在的节点而变得无效。因此，我们可以看到，微调后的 Phi3 版本能够传达更多故事细节。</p>
<h1 id="训练后评估"><a href="#训练后评估" class="headerlink" title="训练后评估"></a>训练后评估</h1><p>我们后期训练评估的结果通过比较图表呈现如下，展示了我们微调过程的有效性，并提供了关于每个模型在生成实体关系图任务中的能力和局限性的宝贵见解。正如我们在下面的表格中所看到的，Claude Sonnet 3.5 和 Phi-3-mini-instruct-graph 都显示出零错误，表明在这一指标上表现完美。然而，Phi-3-mini-4k-instruct（基础）模型则出现了 5 个错误，占总数的 2.5%。这表明我们的微调过程显著提高了基础 Phi-3 模型的性能，使其在 JSON 输出错误减少方面与更高级的 Claude Sonnet 3.5 达到了同等水平。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="/../asset_phi3-mini-4k/12.png"></p>
<p>针对各种损失指标和最先进模型的 Phi-3-mini 微调性能比较。</p>
<p><img src="/../asset_phi3-mini-4k/13.png"></p>
<p>这组柱状图提供了三个模型在四个关键指标上的全面比较。在节点相似性方面，Phi-3 微调模型的表现优于 Claude Sonnet 3.5 和基础 Phi-3 模型，得分为 0.78。在边缘相似性方面，Phi-3 微调模型再次领先，得分为 0.49，显示出相较于基础模型的显著改善。JSON 一致性指标在所有模型中表现良好，Phi-3 微调模型略微领先，得分为 0.99。最后，JSON 相似性平均值是节点相似性、边缘相似性和 JSON 一致性的平均值，显示 Phi-3 微调模型以 0.75 的得分保持领先。这个综合指标提供了每个模型在 JSON 结构和内容相似性各个方面表现的整体视图。这些结果表明，我们的微调过程成功提升了 Phi-3 在所有测量方面的表现，常常超越 Claude Sonnet 3.5 的能力。</p>
<p><img src="/../asset_phi3-mini-4k/14.png"></p>
<p>箱线图提供了每个指标得分分布的更详细视图。在节点相似性方面，Phi-3 微调显示出更高的中位数和更紧凑的四分位范围，表明性能更为一致。在边缘相似性方面，尽管 Phi-3 微调的中位数更高，但也显示出更多的变异性，暗示在一致性方面还有进一步改进的空间。JSON 一致性图表明所有模型的表现都非常出色，Phi-3 微调显示出最小的变异性。最后，JSON 相似性平均图表示跨节点、边缘和一致性指标的综合表现，展示了 Phi-3 微调不仅具有最高的中位数得分，还保持了相对紧凑的分布。这展示了其在各种测试案例中的强大和一致的性能，平衡了三个组成指标的优势。这些详细的分布强化了我们微调方法的成功，同时也突出了未来潜在改进的领域。</p>
<h1 id="成本比较"><a href="#成本比较" class="headerlink" title="成本比较"></a>成本比较</h1><p>正如我们之前提到的，我们的目标是每天获取大约 500,000 篇文章的实体关系。通过 API 使用LLM使这成为一项昂贵的事业。让我们模拟一下 GPT4o 和我们微调的 Phi3 之间的成本比较（以 2024 年 7 月的值为准）。为此，我们假设平均有 905 个提示令牌和 525 个输出令牌，这是我们在测试数据集上运行微调 Phi3 时的平均值。我们知道，根据分词器的不同，令牌计数方法可能会有所不同，但我们将以 Phi3 的计数作为比较的基础。</p>
<p><strong>托管 2x A100 SXM (runpod.io)</strong></p>
<p>$3.88&#x2F;小时 &#x3D;&gt; $93.12&#x2F;天</p>
<p><strong>OpenAI (GPT-4o)</strong></p>
<p>输入定价：271.5M（905 x 300k）代币（$5.00 &#x2F; 1M）：总计 $ 1357.00 &#x2F; 天</p>
<p>输出定价：157.5M（525 x 300k）代币（$15.00 &#x2F; 1M）：总计 $ 2362.50 &#x2F; 天</p>
<p>总计：$ 3719.50 &#x2F; 天</p>
<p>成本比较显示，使用托管在单个 A100 GPU 上的微调 Phi3 模型与使用 OpenAI 的 GPT-4o API 之间存在显著差异。托管微调模型的成本约为每天 46.56 美元，而使用 GPT-4o API 进行相同工作量的成本约为每天 3,719.50 美元。这意味着使用微调模型的成本降低超过 98%。显著的节省主要是由于消除了按令牌计费的方式，并且能够在专用硬件上处理大量请求。然而，重要的是要注意，这一比较并未考虑微调的初始成本或潜在的输出质量差异。例如，我们对 Phi-3 mini 的训练过程在 A100 SXM 上花费了近 3 小时（目前，每小时在 runpod.io 上的费用为 1.94 美元），这增加了前期投资。尽管如此，对于像我们这样的高容量应用，使用微调模型的经济效益是显而易见且显著的。</p>
<h1 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h1><p>大多数实体和关系提取的方法限制了实体和关系的类型。由于我们的主要目标是使用该模型来解释文章、故事，并捕捉尽可能多的细节，我们决定让模型自由定义这些类型。我们理解这可能会由于缺乏标准化而带来不利影响，但结果是一个更丰富细节的模型。</p>
<p>另一个重要点是，我们没有人类保证的真实数据。在我们的案例中，我们使用了 GPT-4o，这是在我们生成数据集时的最先进模型。微调是基于这个参考进行的。然而，即使我们有一个更好的真实数据集，它仍然可能存在偏见，并且不是“完美的”，因为正如我们在上述定性比较中所展示的，实体关系在许多方面都是非常复杂和主观的。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>我们很高兴在 Hugging Face 上以以下链接的 3 个版本公开我们的模型：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/EmergentMethods/Phi-3-mini-4k-instruct-graph">Phi-3-mini-4k-instruct-graph</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/EmergentMethods/Phi-3-mini-128k-instruct-graph">Phi-3-mini-128k-指令-图形</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/EmergentMethods/Phi-3-medium-128k-instruct-graph">Phi-3-medium-128k-instruct-graph</a></li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="https://emergentmethods.medium.com/outperforming-claude-3-5-sonnet-with-phi-3-mini-4k-for-graph-entity-relationship-extraction-tasks-7c8f6c1ebd79">Outperforming Claude 3.5 Sonnet with Phi-3-mini-4k for graph entity relationship extraction tasks | by Emergent Methods | Aug, 2024 | Medium</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/19/sam2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/19/sam2/" class="post-title-link" itemprop="url">SAM 2 + GPT-4o — 通过视觉提示的级联基础模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-19 09:36:15 / 修改时间：10:41:27" itemprop="dateCreated datePublished" datetime="2024-08-19T09:36:15+08:00">2024-08-19</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><img src="/../asset_sam2/image-20240819101159-0d6a8fb.png" alt="image.png"></p>
<p>基础模型的级联：将 SAM 2 与 GPT-4o 串联在一起</p>
<h1 id="什么是分段任何模型-2-SAM-2-？"><a href="#什么是分段任何模型-2-SAM-2-？" class="headerlink" title="什么是分段任何模型 2 (SAM 2)？"></a>什么是分段任何模型 2 (SAM 2)？</h1><blockquote>
<p>SAM 2 可以在任何图像或视频中对物体进行分割，而无需重新训练。</p>
</blockquote>
<p>Segment Anything Model 2 (SAM 2) [1] 是 Meta 推出的原始 Segment Anything Model [2] 的高级版本，旨在对图像和视频中的对象进行分割（见图 1）。</p>
<p><img src="/../asset_sam2/777.gif"></p>
<p>图 1. 行人（蓝色面具）和汽车（黄色面具）使用 SAM 2 进行分割和跟踪。</p>
<p>在开放源代码的 Apache 2.0 许可证下发布的 SAM 2 在计算机视觉方面代表了一个重要的飞跃，允许对对象进行实时的可提示分割。</p>
<p>SAM 2 以其在图像分割中的准确性和在视频分割中的卓越性能而著称，与之前的模型相比，所需的交互时间显著减少：我们展示了 SAM 2 如何只需 3 个点就能在整个视频中分割对象！</p>
<p>Meta 还推出了 SA-V 数据集，与 SAM 2 一起，包含超过 51,000 个视频和超过 600,000 个掩模。这一数据集促进了其在医学成像、卫星图像、海洋科学和内容创作等多个领域的应用。</p>
<h2 id="1-1-SAM-2-功能摘要"><a href="#1-1-SAM-2-功能摘要" class="headerlink" title="1.1 SAM 2 功能摘要"></a>1.1 SAM 2 功能摘要</h2><p>SAM 2 的主要特征总结在图 2 中。</p>
<p><img src="/../asset_sam2/image-20240819101518-dy5rc8o.png" alt="image.png"></p>
<h1 id="SAM-2-有什么特别之处？"><a href="#SAM-2-有什么特别之处？" class="headerlink" title="SAM 2 有什么特别之处？"></a>SAM 2 有什么特别之处？</h1><p>SAM 2 的新颖之处在于它解决了视频数据的复杂性，例如物体运动、变形、遮挡和光照变化，这些在静态图像中是不存在的。</p>
<p>这使得 SAM 2 成为混合现实、机器人技术、自动驾驶汽车和视频编辑应用中的关键工具。</p>
<p><img src="/../asset_sam2/778.gif"></p>
<p>图 3. SAM 2 的实际应用：原始视频中的球被移除（左上角），并创建了一个没有球的新视频（右下角）</p>
<p>SAM 2 的关键创新是：</p>
<ol>
<li>图像和视频的统一模型: SAM 2 将图像视为单帧视频，使其能够无缝处理这两种类型的输入。这种统一是通过利用内存来回忆之前处理过的视频信息，从而实现跨帧的准确分割。</li>
<li>可提示的视觉分割任务：SAM 2 将图像分割任务推广到视频领域，通过在视频的任何帧中输入提示（点、框或掩码）来定义时空掩码（masklet）。它可以立即进行预测并在时间上传播这些预测，通过额外的提示迭代地细化分割。</li>
<li>高级数据集 (SA-V): SAM 2 是在 SA-V 数据集上训练的，该数据集比现有的视频分割数据集大得多。这个广泛的数据集使得 SAM 2 在视频分割方面达到了最先进的性能。</li>
</ol>
<h1 id="3-我该如何运行-SAM-2？"><a href="#3-我该如何运行-SAM-2？" class="headerlink" title="3. 我该如何运行 SAM 2？"></a>3. 我该如何运行 SAM 2？</h1><p>您可以检查 SAM 2 仓库，或者使用 这个 Jupyter Notebook 在您自己的机器上设置模型。在本节中，我们描述后者的方法。</p>
<h2 id="3-1-先决条件"><a href="#3-1-先决条件" class="headerlink" title="3.1 先决条件"></a>3.1 先决条件</h2><ul>
<li>一台配有 GPU 的机器（Google Colab 可以）。</li>
<li>一个用于从视频中提取帧的库（例如，ffmpeg）</li>
</ul>
<h2 id="3-2-设置"><a href="#3-2-设置" class="headerlink" title="3.2 设置"></a>3.2 设置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">HOME = os.getcwd()</span><br><span class="line"></span><br><span class="line"># Clone the repository</span><br><span class="line">!git clone https://github.com/facebookresearch/segment-anything-2.git</span><br><span class="line">%cd &#123;HOME&#125;/segment-anything-2</span><br><span class="line"></span><br><span class="line"># install the python libraries for &quot;segment-anything-2&quot;</span><br><span class="line">!pip install -e . -q</span><br><span class="line">!pip install -e &quot;.[demo]&quot; -q</span><br></pre></td></tr></table></figure>

<h2 id="3-3-下载-SAM-2-检查点"><a href="#3-3-下载-SAM-2-检查点" class="headerlink" title="3.3. 下载 SAM-2 检查点"></a>3.3. 下载 SAM-2 检查点</h2><p>我们只会下载最大的模型，但也有更小的选项可供选择。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt -P &#123;HOME&#125;/checkpoints</span><br></pre></td></tr></table></figure>

<h2 id="3-4-创建预测器"><a href="#3-4-创建预测器" class="headerlink" title="3.4 创建预测器"></a>3.4 创建预测器</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sam2.build_sam import build_sam2_video_predictor</span><br><span class="line"></span><br><span class="line">sam2_checkpoint = f&quot;&#123;HOME&#125;/checkpoints/sam2_hiera_large.pt&quot;</span><br><span class="line">model_cfg = &quot;sam2_hiera_l.yaml&quot;</span><br><span class="line"></span><br><span class="line">predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint)</span><br></pre></td></tr></table></figure>

<h2 id="提取视频中的帧并探索数据"><a href="#提取视频中的帧并探索数据" class="headerlink" title="提取视频中的帧并探索数据"></a>提取视频中的帧并探索数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Extract the frames</span><br><span class="line">video_path = f&quot;&#123;HOME&#125;/segment-anything-2/SAM2_gymnastics.mp4&quot;</span><br><span class="line">output_path = f&quot;&#123;HOME&#125;/segment-anything-2/outputs/gymnastics&quot;</span><br><span class="line">!ffmpeg -i &#123;video_path&#125; -q:v 2 -start_number 0 &#123;output_path&#125;/&#x27;%05d.jpg&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># `video_dir` a directory of JPEG f÷/rames with filenames like `&lt;frame_index&gt;.jpg`</span><br><span class="line">video_dir = f&quot;&#123;HOME&#125;/segment-anything-2/outputs/gymnastics&quot;</span><br><span class="line"></span><br><span class="line"># scan all the JPEG frame names in this directory</span><br><span class="line">frame_names = [</span><br><span class="line">    p for p in os.listdir(video_dir)</span><br><span class="line">    if os.path.splitext(p)[-1] in [&quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.JPG&quot;, &quot;.JPEG&quot;]</span><br><span class="line">]</span><br><span class="line">frame_names.sort(key=lambda p: int(os.path.splitext(p)[0]))</span><br><span class="line"></span><br><span class="line"># take a look at the first video frame</span><br><span class="line">frame_idx = 0</span><br><span class="line">plt.figure(figsize=(12, 8))</span><br><span class="line">plt.title(f&quot;frame &#123;frame_idx&#125;&quot;)</span><br><span class="line">plt.imshow(Image.open(os.path.join(video_dir, frame_names[frame_idx])))</span><br></pre></td></tr></table></figure>

<p><img src="/../asset_sam2/image-20240819101642-iujmz3w.png" alt="image.png"></p>
<p>图 4 在这个阶段，我们只是探索我们视频的第一帧。</p>
<h2 id="3-6-使用坐标定义要分割的对象"><a href="#3-6-使用坐标定义要分割的对象" class="headerlink" title="3.6 使用坐标定义要分割的对象"></a>3.6 使用坐标定义要分割的对象</h2><p>我们定义一个函数来帮助我们提供 x, y 坐标的列表：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def refine_mask_with_coordinates(coordinates, ann_frame_idx, ann_obj_id, show_result=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Refine a mask by adding new points using a SAM predictor.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">    coordinates (list): List of [x, y] coordinates, </span><br><span class="line">        e.g., [[210, 350], [250, 220]]</span><br><span class="line">    ann_frame_idx (int): The index of the frame being processed</span><br><span class="line">    ann_obj_id (int): A unique identifier for the object being segmented</span><br><span class="line">    show_result (bool): Whether to display the result (default: True)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # Convert the list of coordinates to a numpy array</span><br><span class="line">    points = np.array(coordinates, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    # Create labels array (assuming all points are positive clicks)</span><br><span class="line">    labels = np.ones(len(coordinates), dtype=np.int32)</span><br><span class="line"></span><br><span class="line">    # Add new points to the predictor</span><br><span class="line">    _, out_obj_ids, out_mask_logits = predictor.add_new_points(</span><br><span class="line">        inference_state=inference_state,</span><br><span class="line">        frame_idx=ann_frame_idx,</span><br><span class="line">        obj_id=ann_obj_id,</span><br><span class="line">        points=points,</span><br><span class="line">        labels=labels,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    if show_result:</span><br><span class="line">        # Display the results</span><br><span class="line">        plt.figure(figsize=(12, 8))</span><br><span class="line">        plt.title(f&quot;Frame &#123;ann_frame_idx&#125;&quot;)</span><br><span class="line">        plt.imshow(Image.open(os.path.join(video_dir, frame_names[ann_frame_idx])))</span><br><span class="line">        show_points(points, labels, plt.gca())</span><br><span class="line">        show_mask((out_mask_logits[0] &gt; 0.0).cpu().numpy(), plt.gca(), obj_id=out_obj_ids[0])</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>

<p>我们建立状态并提供我们旨在分割的对象的坐标：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inference_state = predictor.init_state(video_path=video_dir)</span><br><span class="line"></span><br><span class="line">refine_mask_with_coordinates([[950, 700], [950, 600], [950, 500]], 0, 1)</span><br></pre></td></tr></table></figure>

<p><img src="/../asset_sam2/image-20240819101657-n9kgjur.png" alt="image.png"></p>
<p>图 5. 通过三个坐标（绿色星星），模型自动识别整个物体。</p>
<p>如图 5 所示，三个点足以让模型为个体的整个身体分配一个掩码。在某些情况下，仅 1 或 2 个点也可以。</p>
<p>现在我们在所有帧上运行该过程（图 6）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># run propagation throughout the video and collect the results in a dict</span><br><span class="line">video_segments = &#123;&#125;  # video_segments contains the per-frame segmentation results</span><br><span class="line">for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):</span><br><span class="line">    video_segments[out_frame_idx] = &#123;</span><br><span class="line">        out_obj_id: (out_mask_logits[i] &gt; 0.0).cpu().numpy()</span><br><span class="line">        for i, out_obj_id in enumerate(out_obj_ids)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># render the segmentation results every few frames</span><br><span class="line">vis_frame_stride = 30</span><br><span class="line">plt.close(&quot;all&quot;)</span><br><span class="line">for out_frame_idx in range(0, len(frame_names), vis_frame_stride):</span><br><span class="line">    plt.figure(figsize=(6, 4))</span><br><span class="line">    plt.title(f&quot;frame &#123;out_frame_idx&#125;&quot;)</span><br><span class="line">    plt.imshow(Image.open(os.path.join(video_dir, frame_names[out_frame_idx])))</span><br><span class="line">    for out_obj_id, out_mask in video_segments[out_frame_idx].items():</span><br><span class="line">        show_mask(out_mask, plt.gca(), obj_id=out_obj_id)</span><br></pre></td></tr></table></figure>

<p><img src="/../asset_sam2/image-20240819101715-jisv1hu.png" alt="image.png"></p>
<p>图 6。一旦 SAM 2 识别出一个对象，它可以在整个视频中自动跟踪同一对象。</p>
<p>最后，我们使用 ffmpeg 将帧合并生成视频。最终结果如图 7 所示。</p>
<p><img src="/../asset_sam2/779.gif"></p>
<p>图 7. 上：原始视频，下：运行 SAM 2 后的 视频</p>
<p>SAM 2 在图像和视频中准确快速地分割物体的能力可以彻底改变计算机视觉系统的创建方式。</p>
<h1 id="4-级联基础模型"><a href="#4-级联基础模型" class="headerlink" title="4. 级联基础模型"></a>4. 级联基础模型</h1><p>级联基础模型简单来说就是组装一个管道，在这个管道中，你将一个模型的输出作为后续模型的输入。</p>
<p>你可能会问，“但这种方法有什么新颖之处？”🤔 答案在于基础模型的零-shot [2] 特性。像 GPT-4o 或 SAM 2 这样的模型被称为零-shot，这意味着它们可以在没有先前训练步骤的情况下进行推理。因此，这些模型可以从系统的角度进行连接，如图 2 所示。</p>
<p><img src="/../asset_sam2/image-20240819102127-incadh1.png" alt="image.png"></p>
<p>事实上，一些研究方法如 CaFO [3]结合了多个预训练的基础模型（CLIP、DINO、DALL-E、GPT-3），通过利用多样的预训练知识和生成合成数据来增强少样本视觉识别。</p>
<h1 id="5-基础模型作为视觉提示工具"><a href="#5-基础模型作为视觉提示工具" class="headerlink" title="5. 基础模型作为视觉提示工具"></a>5. 基础模型作为视觉提示工具</h1><h2 id="5-1-计算机视觉管道-2-0：一种新范式"><a href="#5-1-计算机视觉管道-2-0：一种新范式" class="headerlink" title="5.1 计算机视觉管道 2.0：一种新范式"></a>5.1 计算机视觉管道 2.0：一种新范式</h2><p>我们之前探讨过 什么是视觉提示。它指的是使用视觉信息（如图像、边界框或点）作为基础模型的输入或“提示”，这些模型可以处理视觉和文本信息。</p>
<p>Tenyks 的一个关键优势是视觉搜索。我们每天处理数以万计的查询，使用视觉提示。例如，图 3 显示了如何选择一个对象的边界框，以便在您的数据中搜索细粒度的细节。</p>
<p><img src="/../asset_sam2/780.gif"></p>
<p>图 3. 使用视觉提示搜索物体（例如，校车），即使不存在该物体的类别</p>
<p>正如我们之前所论述的，在 Tenyks，我们认为视觉领域的传统流程正处于一个过渡的开始，流程中的许多阶段（例如，标注、训练）将被包含基础模型的模块所取代，这将形成一个所谓的计算机视觉管道 2.0。</p>
<h2 id="5-2-视觉提示作为基础模型的粘合剂的挑战"><a href="#5-2-视觉提示作为基础模型的粘合剂的挑战" class="headerlink" title="5.2 视觉提示作为基础模型的粘合剂的挑战"></a>5.2 视觉提示作为基础模型的粘合剂的挑战</h2><p>现在，当你开始将基础模型连接在一起时，你会立即注意到，基于这种范式构建一个稳健的系统与在周末构建一个原型是截然不同的。</p>
<p>以下是您一开始就可能遇到的一些主要挑战：</p>
<ol>
<li>性能和可扩展性</li>
</ol>
<ul>
<li>确保系统能够实时处理大量数据和请求。</li>
<li>随着运营规模的扩大，保持准确性和速度。</li>
</ul>
<ol start="2">
<li>集成与兼容性</li>
</ol>
<ul>
<li>将多模型系统无缝集成到现有基础设施中。</li>
<li>确保与各种数据格式、API 和遗留系统的互操作性。</li>
</ul>
<ol start="3">
<li>可靠性与错误处理</li>
</ol>
<ul>
<li>开发强大的错误检测和纠正机制。</li>
<li>实施冗余以保持运营连续性。</li>
</ul>
<h1 id="6-GPT-4o-SAM-2"><a href="#6-GPT-4o-SAM-2" class="headerlink" title="6. GPT-4o + SAM 2"></a>6. GPT-4o + SAM 2</h1><h2 id="6-1-视觉提示管道"><a href="#6-1-视觉提示管道" class="headerlink" title="6.1 视觉提示管道"></a>6.1 视觉提示管道</h2><p><img src="/../asset_sam2/image-20240819102856-xjc84yb.png" alt="image.png"></p>
<p>我们的设置：利用 GPT-4o 提取视觉信息，这些信息将作为 SAM 2 的输入。</p>
<p>上图显示了一个由两个步骤组成的简单管道。假设 GPT-4o足够强大，可以处理如下提示：</p>
<blockquote>
<p>“对于给定的图像，请提供三组（x,y）坐标的体操运动员。”</p>
<p>“对于给定的图像，请提供体操运动员的边界框坐标。”</p>
</blockquote>
<p>下图 显示了 GPT-4o 的结果。</p>
<p><img src="/../asset_sam2/image-20240819102914-ffj44wv.png" alt="image.png"></p>
<p>当查询 (x,y) 坐标时，来自 GPT-4o 的结果相当 不准确。</p>
<p>图 7 显示了这种行为在 200 个 GPT-4o 的 API 请求中是一致的。</p>
<p><img src="/../asset_sam2/image-20240819102926-12e5v4q.png" alt="image.png"></p>
<p>图 7 在使用 GPT-4 进行视觉理解的 200 次尝试中，仅有 5 次准确识别了(x,y)坐标。所有的边界框结果均不正确。</p>
<p>所以，我们真的不能在2024年使用任何优秀的基础模型作为第二个基础模型的输入吗？ </p>
<h1 id="7-YOLO-世界-SAM-2"><a href="#7-YOLO-世界-SAM-2" class="headerlink" title="7. YOLO 世界 + SAM 2"></a>7. YOLO 世界 + SAM 2</h1><h2 id="7-1-零样本计算机视觉：YOLO-世界"><a href="#7-1-零样本计算机视觉：YOLO-世界" class="headerlink" title="7.1 零样本计算机视觉：YOLO-世界"></a>7.1 零样本计算机视觉：YOLO-世界</h2><p>尽管我们希望被打击，因为意识到GPT-4o不足以从图像中提供视觉答案，但我们找到了一种合格的专用模型：YOLO-World [4]。</p>
<p>图8 显示了在给定文本输入（即类别）的情况下，该模型如何准确预测每个给定输入的边界框！</p>
<p>YOLO-World 的词汇甚至包括这个词：体操运动员！(见图 8 右侧的 0.93 mAP)。</p>
<p><img src="/../asset_sam2/image-20240819102948-9huihaa.png" alt="image.png"></p>
<p>图 8. YOLO-World 根据一些文本输入（即类别）给出的预测</p>
<ul>
<li>🔥 剧透警告： 我们将在即将发布的帖子中讨论更多关于 YOLO-World（零样本）与 YOLO v8（微调）的内容！</li>
</ul>
<p>YOLO-World 是一种零样本模型，用于物体检测，可以在不需要针对特定物体类别进行先前训练的情况下，检测和定位图像中的物体。</p>
<p>我们使用 YOLO-World 为 SAM 2 提供边界框，如图 9 所示。</p>
<p><img src="/../asset_sam2/image-20240819103001-8yezi31.png" alt="image.png"></p>
<p>图 9. 最终管道，包括YOLO-World和 SAM 2 连接在一起</p>
<p>我们需要提供给整个系统的唯一输入是 YOLO-World 词汇的类定义，在这种情况下是“体操运动员”。这个词足以让 YOLO-World 为 SAM 2 提供边界框坐标。</p>
<p>查看这个 Jupyter Notebook 以获取实施的详细信息。最终结果如图 8 所示。</p>
<h1 id="8-结论"><a href="#8-结论" class="headerlink" title="8. 结论"></a>8. 结论</h1><p>在关于 SAM 2 的系列中，我们描述并设置了 Segment Anything Model 2（SAM 2）。然后，我们使用视觉提示将两个基础模型级联（即，我们将模型 A 的输出作为模型 B 的输入）。</p>
<p>我们发现市场上领先的 MLLMs，GPT-4o ，在提供给定图像的物体坐标或边界框方面相当不准确。相反，我们发现专门的模型（例如，YOLO-World）更适合这个工作。</p>
<p>构建原型是一回事，但实际上，有一些挑战即使是最优秀的机器学习团队也难以应对（例如，集成、可靠性以及在连接基础模型时的适应性）。</p>
<p>正如我们之前所论述的，计算机视觉领域出现了一个新的范式：视觉处理流程中的一些传统阶段可能会被（零样本）基础模型所取代，这些模型将随着时间的推移不断改进。</p>
<p>我们还要等多久才能从即将推出的 GPT 家族成员那里获得精确的边界框坐标？ 可能不会太久。</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/@tenyks_blogger/sam-2-gpt-4o-cascading-foundation-models-via-visual-prompting-part-2-b592b5cd8d4a">SAM 2 + GPT-4o — 通过视觉提示的级联基础模型 — 第二部分 | 作者：The Tenyks Blogger | 2024 年 8 月 | Medium — SAM 2 + GPT-4o — Cascading Foundation Models via Visual Prompting — Part 2 | by The Tenyks Blogger | Aug, 2024 | Medium</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/14/llmsClinical07/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/14/llmsClinical07/" class="post-title-link" itemprop="url">第七章 未来将至</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-14 11:32:19" itemprop="dateCreated datePublished" datetime="2024-08-14T11:32:19+08:00">2024-08-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:07:15" itemprop="dateModified" datetime="2024-08-21T14:07:15+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>20 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>大型语言模型（LLMs）和生成式人工智能在医疗保健领域的未来就像后视镜中的物体，看起来比实际更近。医疗保健领域的人工智能发展速度正在加快，我们正处于变革性变化的边缘，这将带来患者护理、医疗实践和整个医疗保健领域的进步。本章提供了对LLMs和生成式人工智能在医疗保健行业潜力的初步了解。让我们先讨论一下无限提示和代理推理的潜力预览。</p>
<h1 id="未来在LLMs的前景与挑战"><a href="#未来在LLMs的前景与挑战" class="headerlink" title="未来在LLMs的前景与挑战"></a>未来在LLMs的前景与挑战</h1><p>通往人工通用智能（AGI）的道路在机器学习进步的开创时期漫长而曲折，这一时期以基础概念、实验算法和有限的计算能力为标志。20 世纪中叶的杰出人物为未来将成为变革性技术的基础奠定了基础工作。最近transformers，LLMs，以及生成式人工智能的出现使许多人相信我们正站在某种深刻事物的边缘。关于LLMs的研究和进展仍在继续，最近的思考和研究围绕无限提示和代理推理展开，这在第一章中进行了介绍。让我们更详细地探讨这两者，并考虑它们在医疗保健中的潜力。</p>
<h2 id="无限提示"><a href="#无限提示" class="headerlink" title="无限提示"></a>无限提示</h2><p>处理无限提示的能力在医疗保健中可能带来一些独特的优势：</p>
<ul>
<li> 背景历史</li>
<li>纵向患者监测</li>
<li> 医学推理</li>
<li>个性化健康指导</li>
<li> 改进的研究</li>
</ul>
<h3 id="背景历史"><a href="#背景历史" class="headerlink" title="背景历史"></a>背景历史</h3><p>一个具有无限上下文的LLM（换句话说，一个无限的上下文历史窗口）应该能够处理患者的整个病史（以前的诊断、治疗、药物、检测结果等）。从字面上看，无限上下文可能会以更准确的诊断、更个性化的治疗以及更好地识别罕见和&#x2F;或复杂疾病的形式体现出来，而这些在有限的上下文中是很难发现的。</p>
<p>理论上，如果有一个无限的上下文历史窗口，LLM可以处理患者的整个病史——过去的诊断、治疗、药物、检测结果等等。这种无限的视角可以表现为更准确的诊断、更精细的治疗建议，以及识别在有限上下文中可能被忽视的罕见或复杂疾病。</p>
<h3 id="纵向患者监测"><a href="#纵向患者监测" class="headerlink" title="纵向患者监测"></a>纵向患者监测</h3><p>对患者健康数据进行数月或数年的持续监测，并学习检测数据中微妙的变化或趋势，这些变化或趋势表明疾病的发生或进展，LLM可以检测到疾病的早期迹象，并提醒医生或患者采取预防措施。</p>
<h3 id="医学推理"><a href="#医学推理" class="headerlink" title="医学推理"></a>医学推理</h3><p>一位医生，如果拥有无限的提示，可能能够同时考虑大量的医学文献（特定疾病的指南和案例），从而帮助她在某些常见情况下更细致地推理，以做出更好的医疗决策（例如，多重合并症病例、罕见病例等）。</p>
<p>一个LLM可以使用无限的提示，同时考虑大量医学文献，例如关于特定疾病的指南和案例研究，以帮助其分析患者的病例，从而实现更复杂的医学推理和决策，特别是在涉及多种合并症或罕见病例的情况下。</p>
<h3 id="个性化健康指导"><a href="#个性化健康指导" class="headerlink" title="个性化健康指导"></a>个性化健康指导</h3><p>一个具有无限上下文窗口的LLM可以提供高度个性化的健康指导和咨询，能够敏感地考虑患者的健康历史、生活方式和治疗偏好（以及其他因素）。应用更有效的行为改变干预措施最终可能导致“更健康的患者”，他们更愿意并可靠地遵循治疗计划。</p>
<h3 id="改进的研究"><a href="#改进的研究" class="headerlink" title="改进的研究"></a>改进的研究</h3><p>除了通过启用新的科学研究来扩展人类知识外，无限的提示可以增强LLMs识别大数据、纵向健康研究中隐藏的紧急变量模式的能力，这些模式目前在临床医生有限的背景下治疗的患者中太微弱而无法感知。药物发现和医学研究可以以这种方式加速。</p>
<p>但其推动能力中的同样无限性可能也会放大与其在医疗保健中使用相关的许多问题。</p>
<p>一旦患者记录涉及进来，数据隐私和安全要求就会大大增加。</p>
<ul>
<li>如果LLM在一个过于庞大（在规模和&#x2F;或多样性方面）的数据集上训练，且该数据集偏向于其中的特定（委婉地说是“少数”）部分，则会出现偏见&#x2F;不公平风险。</li>
<li>持有患者完整医疗电子记录的LLM将使伦理和法律考虑变得更加复杂。</li>
<li>基础设施和计算资源（无限制地扩展提示）使得LLM变得低效或成本过高。</li>
</ul>
<p>尽管这里提出的许多医疗保健应用可能可以用更短的提示来实现，但在另一个极端，无限提示（或者至少是一个具有巨大上下文窗口的提示，远远超出任何临床需求）可能会实现更准确的整体患者分析、更精确的干预，最终更深入地探索新疗法和因果路径。然而，克服这些挑战是必要的，以安全、伦理和公平的方式实现这些好处。</p>
<h2 id="代理推理"><a href="#代理推理" class="headerlink" title="代理推理"></a>代理推理</h2><p>在以健康为中心的背景下，代理推理和利用代理与LLMs相结合可以开启一系列机会。在这个背景下，代理是专门的软件代理，它们可以独立执行任务、做出决策或根据预定义的目标或约束从患者那里获取见解。以下是代理推理和代理与LLMs相结合的潜在应用和可能的优势。</p>
<h3 id="领域专业化"><a href="#领域专业化" class="headerlink" title="领域专业化"></a>领域专业化</h3><p>代理可以针对特定的医疗领域（例如，心脏病学、肿瘤学）进行专业化，并在相关知识和最佳实践上进行培训，具备提供更有针对性和准确的帮助的能力。</p>
<p>领域专业化作为医疗保健中算法代理的一种策略具有巨大的潜力。使用面向特定医学领域的代理，例如心脏病学、肿瘤学或神经学，可以创建具有专业知识的人工智能系统，这些知识包括内部实践、特定领域的医学术语、术语和习惯用语，以及对每个专业的常见问题、最佳实践和可用治疗方案的深入理解。领域专业化可以提供几个潜在的好处。</p>
<p>代理可以在特定领域的数据集、临床指南以及其他仅与该领域相关的专家知识文献上进行训练，这一事实使其有潜力为该领域的重要利益相关者提供更准确和相关的信息、建议和决策支持，即医疗专业人员和患者。</p>
<h3 id="以患者为中心的互动"><a href="#以患者为中心的互动" class="headerlink" title="以患者为中心的互动"></a>以患者为中心的互动</h3><p>代理可以以更以患者为中心和富有同情心的方式与患者互动，调整他们的行为以满足个别患者的需求、喜好和情感状态。LLMs的自然语言理解能力可以与代理的目标导向行为协同工作，使以患者为中心的互动更加有效。</p>
<h3 id="预测性健康监测"><a href="#预测性健康监测" class="headerlink" title="预测性健康监测"></a>预测性健康监测</h3><p>代理可以被指示跟踪和分析患者数据，例如生命体征、药物使用和症状。他们可以结合这些和其他生物医学数据利用LLM推理来预测不良健康状况，将发现传达给主治医生，并提出主动干预建议。</p>
<p>然而，在医疗保健领域开发特定领域代理也面临挑战和考虑因素：</p>
<ul>
<li>专业化的挑战在于实现处理领域内案例变异所需的广度。然而，一个代理的知识库可能难以覆盖助手需要处理的所有案例。</li>
<li>医学知识随着新研究结果、新指南和新治疗建议的出现而不断更新。任何在现代医疗环境中学习扮演医生角色的回答，都必须不断更新临床相关信息（即领域特定文献），以保持准确性和相关性。</li>
<li>在特定临床领域中，可能会出现边缘案例，这些案例由于其稀有性或复杂性，需要额外的专业知识或判断。代理可能被设计为自我检测这些案例，并将其上报给人类领域专家，以确保患者安全并优化护理。</li>
<li>尽管专业代理可以将黑箱方法转变为精细、专注的专业工具，但医疗保健需要跨领域的合作。如果他们能够以建设性的方式与人们以及其他领域的代理进行交流和分享信息，这将是重要的。</li>
<li>在医疗保健中使用专业代理需要解决监管问题和 FDA 批准流程，以及使用人工智能进行医疗决策的责任问题。</li>
</ul>
<p>总的来说，医疗保健领域的特定代理可以为医疗专业人员和患者提供更有用、相关和有效的决策支持。如果代理能够专注于更小、更紧密的领域，具备专业的、针对性的知识和专长，那么他们将能够帮助进行决策支持、沟通以及与特定领域工具和协议的互动。为了使这一切有效，全面覆盖相关文献、当前知识、对边缘案例的态度、互动，以及监管和责任问题将是重要的。</p>
<h1 id="AGI"><a href="#AGI" class="headerlink" title="AGI"></a>AGI</h1><p>伊利亚·苏茨克维尔，一位计算机科学家和 OpenAI 的联合创始人，表示：“我们所称的 AGI 正是计算机至少与人类一样聪明，甚至更聪明的时刻。”或者更正式地，在一个 OpenAI 开发者论坛中，我们找到了这个定义：“AGI 是一个可以承担任何任务的系统，无论其智力复杂性如何，这些任务都是人类可以承担的。”</p>
<p>AGI 仍然只是一个概念，因为我们仍然没有创造出在各个领域接近人类水平表现的 AI。相反，它代表了在 AI 领域某些尚未实现的假设性未来成就的实现。一些人认为这将在 2022 年发生；埃隆·马斯克声称是 2026 年；其他人则建议这个日期在 2060 年之前的某个时刻；还有一些人坚持认为这永远不会发生。山姆·奥特曼说，也许在五年内。他进一步将 AGI 描述为“当 AI 能够独立实现新的科学突破时。”现在，这对 AI 来说是一个艰巨的任务，创造出像爱因斯坦的 E &#x3D; mc² 这样的新的科学突破。</p>
<p>一种假设是，人类智能，包括认知、创造力、直觉、感知和思维，可以简化为计算。假设是，我们可以创建计算机系统，使其在各种任务上超越人类水平的智能，只要具备足够的计算能力、数据和架构复杂性。主要假设是，智能可以被分解为算法，并在计算机系统中实现。</p>
<p>这些假设是哲学、认知科学和人工智能研究中持续辩论的主题。一些人认为意识和主观体验可能无法简化为计算。关于身体在智能中的作用，以及无身体的人工智能是否能够真正复制类人智能的问题也在辩论中。关于生物系统的涌现特性是否在智能中发挥着关键作用，这些特性可能无法在人工系统中复制，仍在进行讨论，我们需要对此有全面的理解。</p>
<p>然而，这种计算描述能够容纳多少人类经验的真正丰富性和深度仍然是一个悬而未决的问题。在实现任何类似于 AGI 的目标方面，还有很长的路要走，但由于心智，无论它们是什么，不能是神奇的，而必然是算法的，这一前提使得这一过程显得戏剧性地更短且更可控。这是一个引人深思且有争议的假设。</p>
<p>由于没有明确的议程，没有可辨别的朝向 AGI 的进展标志，因此也没有积极或可靠的手段来了解 AGI 技术是否在任何有意义的意义上发展，甚至发现这一点的可能性也是未知的。没有人能够确切知道技术何时可能实现人类水平或超人类智能，或者它是否能够成为机器超级智能的载体。这种情况可能会持续，因为我们不断在科学理论和推测意见之间移动，因此 AGI 的状态永远无法完全解决，甚至在任何明确的意义上“已知”。</p>
<p>抛开这些不谈，如果我们真的开发出通用人工智能，医疗保健的世界会是什么样子？我想说明，医疗保健周围存在许多复杂的社会问题，也许其中一些是无法克服的。但假设通用人工智能很快就会实现，机器能够在任何领域进行推理、学习和迭代适应，以达到个体人类能够实现的结果。在一个大假设的前提下，以下是拥有通用人工智能的世界中医疗保健可能的样子。</p>
<ul>
<li>个性化和预测医学：如果能够获取关于过去患者的大量健康和基因组数据，以及对当前患者持续收集的实时健康指标，AGI 系统可能有能力为个人制定精细化的治疗方案，甚至在潜在健康问题出现之前就能识别出来，从而实现更有效的预防。</li>
<li>认知诊断辅助工具：AGI 可能通过处理和整合来自医学影像、实验室结果以及患者自我报告症状的数据，帮助医生快速准确地做出诊断。这种工具可以减少诊断错误，诊断罕见疾病，并加快诊断过程。</li>
<li>机器人手术：“烹饪书”式的现代手术将让位于具有前所未有的精确性、灵活性和适应性的自主机器人辅助手术（这需要外科医生培训中的新能力）。这些手术可以在自主模式下进行，也可以与人类外科医生协作进行。</li>
<li>持续健康监测与干预：基于 AGI 的系统可以为患者提供持续的健康监测，使用可穿戴设备和&#x2F;或通过智能手机和智能家居的植入传感器。通过这种持续监测，AGI 可以提供早期警报并启动自动干预（例如，根据持续反应调整药物剂量，或在需要时发出警报）。</li>
<li>改善药物发现与开发：AGI 还可以通过加速药物发现和开发流程来提高制药行业的生产力。通过利用大量的生物和化学数据，AGI 可以帮助发现新的药物靶点，预测新药与生物系统中成分之间的相互作用，并探索新的药物设计方法以提高特异性。这些系统可以加快更安全、更有效的新药的开发。</li>
<li>改善远程医疗和虚拟护理：对于患者来说，基于 AGI 的虚拟助手和远程医疗平台可以实现 24&#x2F;7 有效、个性化的按需医疗服务访问。这些系统可以对患者的关注进行分诊，提供医疗建议，并将患者推荐给适当的医疗资源，从而增加医疗服务的可及性，并减轻医疗设施的后续压力。</li>
<li>精明的资源分配和物流：AGI 可能会根据患者需求和当前需求智能分配医疗资源（医院床位、呼吸机、人员等），并提高医疗供应链的效率，确保药物、疫苗和其他必需品的快速分发。</li>
<li>基于模拟的培训和教育：由 AGI 驱动的医学模拟将允许在广泛的外科场景中开发高度真实和自适应的培训环境，以模拟故障和风险条件，从而补充和增强课堂中的体验学习过程。</li>
<li>全球健康合作与信息共享：AGI 提供的信息可以实现来自世界不同地区的临床医生和研究人员之间的无缝协作和信息共享，使他们能够共同识别全球健康趋势并为公共卫生政策提供信息，同时传播最佳实践。</li>
<li>伦理和可获得的医疗保健：AGI 可以通过帮助识别和纠正治疗决策和分配决策中的偏见，以及开发具有文化敏感性和可及性的医疗干预措施，确保医疗保健更加公平——所有这些都是实时进行的。</li>
</ul>
<p>这意味着 AGI 将不断学习。医疗系统将变得越来越好，因为每个案例都可以为未来的治疗和协议提供信息。该系统可以根据生物过程和人类疾病的最新医学研究和患者数据自动更新其信息库，并实时自我进化。治疗将根据最新的证据和患者结果进行常规调整。AGI 将优化医疗系统，提高效率，降低成本，增强患者体验。</p>
<p>虽然利用 AGI 改善医疗保健和社会整体福祉的前景是真实的，但这些人工智能实体的存在将引入一系列新的紧迫的伦理、法律和社会问题，安全处理和管理这些先进技术在医疗保健和决策中的应用将至关重要。</p>
<p>同样，医疗保健领域蓬勃发展的自主系统需要提前做好准备，以便研究人员、临床医生、政策制定者和公众之间进行密集的多学科合作，以确保基于 AGI 的技术得到适当开发，以符合社会需求和价值观。</p>
<p>综合来看，增强型人工智能（AGI）的医疗行业将实现真正实时、整体、个性化和预测性护理环境的承诺，利用大量健康信息，将其转化为真正可获取、有用的数据，以便于医疗服务的提供。这样的医疗系统将更加高效、个性化，因此更有可能提供最佳的医疗结果。</p>
<p>在这个系统中，医疗服务提供者的角色可能会非常不同，因为更多的常规和琐碎任务被自动化，而提供者则专注于更复杂的数据的诊断、解释和整合以及卓越的人类护理。个人健康结果可能会得到改善，公共健康结果和医学研究将更快速地推进并带来进一步的突破，我们可以期待在许多方面成为一个更健康的社会。</p>
<h1 id="明日的五个预测"><a href="#明日的五个预测" class="headerlink" title="明日的五个预测"></a>明日的五个预测</h1><p>接下来是五个未来的预测，这些预测将在未来五年内实现，尽管没有 AGI，但使用LLMs、无限提示、代理推理、空间推理和 AI 具身化。</p>
<h2 id="人工智能主导一切"><a href="#人工智能主导一切" class="headerlink" title="人工智能主导一切"></a>人工智能主导一切</h2><p>例如，一位人工智能首席医疗官可能需要一种新的医疗设备，因此她给她的人工智能下达了一项任务</p>
<ul>
<li>人工智能将研究市场，以识别未满足的需求和机会。</li>
<li>医疗设备将由人工智能发明，以满足这些需求和机会。</li>
<li>AI 将联系制造商以获取医疗设备生产报价。</li>
<li>AI 将与制造商协商价格和条款。</li>
<li>AI 将向制造商下订单并跟踪生产过程。</li>
<li>AI 将安排将医疗设备送达客户。</li>
<li>AI 将从客户那里收取收入。</li>
</ul>
<p>因此，人工智能仍然会有许多无法完成的任务，因为人类仍然在某个环节中存在。然而，通用人工智能可以通过与其他人工智能对话来进行交互，并调用 API 以获取许多不同知识来源（例如，数据库或各种网站等）的访问权限，以完成许多不同的任务。</p>
<p>在从可用知识源获取额外信息时，许多功能可以在定向 API 中实现自动化，例如推动许多功能，以便将新的医疗设备通过临床试验获得监管批准。AGI 将使许多人能够腾出时间去思考更复杂的任务。</p>
<p>如果一个 AGI 设计并生成了一种新的医疗设备，那么我们应该接受它在制造过程中也有参与，就像我们接受关于人类智能代理的同样说法一样。这包括：</p>
<ul>
<li>创新：该人工智能系统是在人的协助下构思并设计的，独立于现有模板，展示了创造性思维的能力，并能够为健康需求提出新颖的解决方案。</li>
<li>广泛：AI 驱动的创新可以探索比人类团队更多的设计空间。</li>
<li>增强：增强现有系统和程序能力的医疗设备创新。</li>
<li>科学严谨：该人工智能可能依赖大量数据、建模、模拟和测试来证明该设备是安全有效的。</li>
<li>变革性：AGI 可以通过医疗技术极大地加速健康创新和发现的突破。</li>
<li>范式转变：AGI 的新医疗设备的发明改变了谁&#x2F;什么可以成为科学参与者的格局。</li>
</ul>
<p>一个自主执行此任务的人类可能是一个强大、创新、颠覆性且潜在变革性的展示，体现了人类的能力——无论是单独还是与他人合作——以及关于通过这种方式从人类获取信息的代理在科学和技术中变化（或缺乏变化）行为的伦理考量。规则必须经过仔细考虑和辩论，以规范任何自主人工智能是否以及如何创造发明。但假设这些创造是由人类价值观引导的，可能性是引人入胜的。</p>
<h2 id="个性化医疗球"><a href="#个性化医疗球" class="headerlink" title="个性化医疗球"></a>个性化医疗球</h2><p>这个银色的球很容易放进你的手掌中。有了这个人工智能助手作为你的伴侣，你可以与基于最新LLM架构的人类智能的人工智能对话。它理解自然语言，综合对查询的见解，并回答关于万事万物的问题。</p>
<p>问它关于科学、哲学或如何制作海鲜汤，它将洞察你最佳的行动方案，并以专业术语与之沟通。它会教你物理学、艾萨克·牛顿和阿尔伯特·爱因斯坦，或者关于杰里米·边沁的道德哲学。它会指导你准备海鲜汤的步骤。凭借其广泛的知识和推理能力，人工智能可以为你的个人情况提供有见地的分析。你将其视为一位充满知识和洞察力的智者，始终触手可及。</p>
<p>精确调校以与智能家电集成，如果您的冰箱空空如也，Orb 可以生成食谱创意，安排杂货配送，并开启烤箱进行烹饪。考虑到其在各种沟通模式下的全面能力和几乎无限的容量，医疗球个性化 Orb 提出了一个复杂的命题：世界上所有的知识和能力都可以在您手掌中获得。</p>
<p>一种嵌入式设备——一种互动球形设备——被患者用作在家中、医院或护理机构的健康管理助手。它能够理解普通文本对话的上下文，提供语言翻译，并支持问答。</p>
<p>它结合了先进或大型语言模型，利用自然语言处理技术，使得在讨论症状或询问医疗问题时能够进行自然语言的对话互动。医疗球还可以提供个性化的健康跟踪、药物管理、生活方式指导等服务。</p>
<p>医疗球内的人工智能将可以无限制地访问当前的医学研究，并为患者提供个性化的健康优化建议。它可以，例如，推荐饮食和锻炼习惯，以及为患者提供心理健康训练。</p>
<p>这个球体随时监测生命体征，无论是常规检查还是医疗紧急情况，并且可以召唤帮助并提供急救指导，直到帮助到达。它进行分诊检查、提供咨询或提供紧急治疗的能力是其成为保护性医疗存在的三个主要角色，利用人工智能提供全天候的护理服务。凭借足够的医学知识，这个个性化的医疗球体甚至可能让你保持冷静。</p>
<h2 id="健康化身：个人-AI-健康助手"><a href="#健康化身：个人-AI-健康助手" class="headerlink" title="健康化身：个人 AI 健康助手"></a>健康化身：个人 AI 健康助手</h2><p>健康化身创建了您的“数字双胞胎”，这是您的一种数字复制品，利用生成性人工智能根据您的医疗记录、生活方式数据、基因构成和实验室测试构建，以提供您身体的高分辨率可视化，包括其独特特征。</p>
<p>该应用程序允许您与您的数字双胞胎通过LLMs提供的对话界面进行对话。询问您数字双胞胎所强调的任何健康状况的风险，数字双胞胎可以通过使用其先进的身体模型运行场景来生成量身定制的风险评估。</p>
<p>您的行为和症状通过可穿戴设备和日志实时跟踪。健康化身定期更新您的数字双胞胎，提醒您需要与医生跟进的信息。AI 助手回答有关健康问题的提问，解释实验室报告，帮助您为医疗预约做好准备，并提供多项基于证据的生活方式建议。</p>
<p>高级模拟工具让您可以在“真实”世界中实施饮食、锻炼和其他干预措施之前，先尝试它们的影响。同时，HealthPal 使您能够通过监测其在您虚拟形象的数字皮肤上的效果，看到您努力的成功。HealthPal 将一个智能辅助代理和您自己身体的克隆放在您的口袋里，配备了对您个人健康记录的深入扫描和机器学习视图的好处。</p>
<h2 id="虚拟护士头像"><a href="#虚拟护士头像" class="headerlink" title="虚拟护士头像"></a>虚拟护士头像</h2><p>这个头像是一个三维动画视觉模型，代表了一位富有同情心的人类护士，采用先进的生成艺术技术制作，使其既吸引人又值得信赖。患者通过对话和手势与头像互动。该头像运用多模态人工智能以人类的方式进行对话，解读患者所传达的非语言线索，并表现出同理心。</p>
<p>AI 护士由LLM驱动，可以回答患者问题，解释治疗计划，提供教育和鼓励。它可以通过与LLM的多种集成查询最新的医学知识。它可以跟踪生命体征、用药依从性和临床进展，监测副作用，并在出现变化或问题时向人类护理团队发送警报。它可以处理这些查询和观察。</p>
<p>个性化算法维护患者的健康历史、偏好和心理模型，以便个性化互动并保持护理的连续性。对于一些需要康复和协调的患者，虚拟护士可以教授锻炼、提醒用药和即将到来的预约。在紧急情况下，人工智能可以与患者保持通话，提供指示以应对紧急情况，同时拨打 911 并与患者一起等待紧急救助。</p>
<p>虚拟护士在患者住院期间陪伴他们，与他们聊天、开玩笑，保持他们的大脑活跃，引导他们的对话朝向健康的应对方式，并提供互动。对患者数据的访问范围广泛，但每一条信息都是安全的，仅在患者同意和护理团队的情况下共享（活动日志可以访问，并且在新技术发展过程中对监督和完善模型非常有用）。</p>
<p>总之，虚拟人工智能护士将护理中以响应为中心的人性化特质与人工智能的知识和反应能力相结合。其结果是一个人文主义的人工智能护士，全天候为患者提供情感、教育和安全监测支持。</p>
<h2 id="人工智能驱动应用的崛起"><a href="#人工智能驱动应用的崛起" class="headerlink" title="人工智能驱动应用的崛起"></a>人工智能驱动应用的崛起</h2><p>到 2030 年代或更早，强大的LLMs和生成性人工智能的普及将软件开发的变革程度与之前的客户端-服务器、互联网、云计算和移动技术相提并论。诚然，直接使用 Python 和 Java 进行的应用开发仍然涉及用 Python 和 Java 编程。然而，对于绝大多数代码，开发者以轻声的方式与 AI 助手进行自然语言对话。他们用简单的英语描述他们希望应用程序执行的功能，包括数据模型和用户界面的描述。对于每一次这样的对话，一个复杂的 AI 生成器会综合出一个完整的全栈实现，包括源代码、数据库、API、网页&#x2F;移动前端和 DevOps 配置。</p>
<p>开发者的生产力得到了极大提升。开发者不再需要编写数千行代码来从零开始构建强大的应用程序，而是可以利用他们的人类创造力和领域知识，跟上人工智能的创新步伐。他们可以使用过去的应用程序训练人工智能模型，以教会系统什么有效，什么无效。由于人工智能可以快速轻松地创建完整的前端和后端，开发者可以专注于构建丰富而创新的用户体验。曾经需要数月才能构建的新应用原型现在只需几天就能完成。初创公司以空前的速度迭代最小可行产品，颠覆了各个行业。</p>
<p>对话界面是为了取代基于菜单的应用程序而创建的；LLM 前端与应用程序进行交互，并以自然对话的方式充当用户的客户端；LLM 理解请求并管理其执行。创建了模块化代码，生成器是创建模块的实体：它们可以创建数据库、前端 API、用户界面和其他模块，包括云结构。这一切都是通过 LLM 进行协调的。</p>
<p>嵌入式代理成为常态，应用程序具有生成性人工智能子组件，根据需要调整其编程，像强大的神经网络一样自主自我优化。</p>
<p>自动化测试和调试是由于LLMs检测代码模式以生成单元测试而产生的。错误和弱点同样被自动检测并由生成模型修复。测试和维护活动也被自动化，因为人工智能持续监控和增强生成的应用程序，使得人工智能在生成代码中发现潜在错误或反模式时提醒开发者，并在必要时以对话的形式指向已经验证的解决方案。最终，应用程序变得更加安全、可扩展和高效。</p>
<p>专业开发人员仍需接受监督，并必须满足某些要求，但软件开发的大部分劳动将由生成性人工智能接管，从而使开发人员能够投入更多时间进行更高层次的设计和创造性问题解决。民主化意味着新应用和体验的激增。这是未来的一种可能情景，类似于早期计算革命所带来的生产力激增。LLMs和生成性人工智能可以为软件开发带来类似的飞跃。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>人工智能并不是一种自主技术——它并不是自动从算法或LLMs中产生的。人类的能力并不会自动植入算法中；它们需要人类的设计和意图。如果通用人工智能进入世界，那将是通过人类的设计和工程实现的。</p>
<p>AGI 是一种机器未来可能具备的能力。它仍然难以捉摸；我们尚未实现 AGI；它是否或何时可能实现仍然是相当有争议的话题。简而言之，如果它最终实现，AGI 将是人类设计和工程的产物，而不是目前被认为是人工智能研究前沿的算法或模型“自主”产生的过程。</p>
<p>人工智能系统将继续发展出更像人类的能力。这意味着保持人类的控制和监督，以及随时干预和&#x2F;或关闭系统的能力将变得重要。负责任的人工智能的发展必须保持这种状态。</p>
<p>LLMs 和生成性人工智能可以以新颖而强大的方式改善患者护理和医学实践。事实上，利用 LLMs 能力的工具将很快成为友好的顾问，能够从详细的临床对话中理解患者状况的细节，回答问题，并提供针对个别患者的支持性咨询。</p>
<p>生成性人工智能系统将成为医生的“路边医生”，迅速从数百万个案例中综合出有价值的推论，形成细致的诊断和治疗方案，能够根据每位患者的特征量身定制，从而提供更好的护理选择和结果。最终，人类医生和人工智能的综合团队将成为一个日益人性化、真实和个性化的生态系统的一部分：它们将相互增强各自的优势，为患者提供越来越多的信息和自主权，使他们能够更好地从治疗护理中受益，并参与自我管理健康和生活方式，以实现更好的健康、功能和长寿。</p>
<p>在未来几年中，医学知识、人工智能和富有同情心的人类支持的结合将逐渐减轻临床医生的负担，同时改变患者互动并提高治疗效果。这是一个为所有人提供越来越具前瞻性、预测性和预防性的护理的新纪元。</p>
<p>最后，我们以幽默的方式结束（见图 7-1）。</p>
<p><img src="/../asset_llmsClinical07/01.png">图 7-1. 宠物老鼠，阴阳和好奇</p>
<p>老鼠的名字展示了LLMs、阴阳和好奇的可能性。公众与LLM聊天机器人的互动激发了对人工智能及其潜力的巨大好奇。在传统中医中，阴阳能量是所有疗愈的核心。LLMs在医疗保健中被使用，希望创造健康的良好平衡，阴与阳。</p>
<p>凭借其自然语言处理和机器学习能力，LLMs可以快速扫描数千篇医学论文、临床指南和病历，帮助医生和研究人员跟上最新发现，发现可能被人眼忽视的重要模式和见解，并做出公正和基于证据的决策。</p>
<p>我们希望这本书不仅能让您对LLM和生成式人工智能的潜力有更深刻的理解，以及LLM和生成式人工智能工具在转变医疗、治疗和护理方面所发挥的变革性作用，还能让您意识到建立扎实的知识基础和在关于与LLMs合作的好处或其他方面的主张中追求准确性的重要性。</p>
<p>这是一个快速发展的领域，了解新进展的能力在充分利用医学中的人工智能方面将变得重要。随着人工智能在医疗保健中扮演越来越重要的角色，倡导其伦理发展和使用，以及提高对偏见、隐私和透明度的认识是非常重要的。</p>
<p>人工智能有潜力成为医疗保健领域的伟大统一者，但前提是我们能够利用这些机会帮助不同学科协同工作。支持临床医生、研究人员、工程师、伦理学家以及其他任何人的工作，以便我们创造一个利用人工智能带来双重好处的未来。</p>
<p>最后，留给读者的结论是让人工智能成为一种放大器，成为创造一个更健康世界的一部分。未来的医疗保健不是由人工智能书写的，而是由今天参与这一过程的每一个人共同书写的。让我们共同设计一个更加人性化和开放的人工智能未来，一个充满希望和治愈的未来。</p>
<p>1 “通往 AGI 的激动人心而危险的旅程 | 伊利亚·苏茨克维尔 | TED，” TED，2023 年 11 月 20 日，YouTube 视频，12:24，<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=SEkGLj0bwAU%E3%80%82">https://www.youtube.com/watch?v=SEkGLj0bwAU。</a></p>
<p>2 Natanael WF，“AGI 是我们想要的，但不是我们在奇点时所需要的，”OpenAI，2023 年 12 月，<a target="_blank" rel="noopener" href="https://community.openai.com/t/agi-is-what-we-want-but-not-what-we-need-for-singularity/571275%E3%80%82">https://community.openai.com/t/agi-is-what-we-want-but-not-what-we-need-for-singularity/571275。</a></p>
<p>3 Cem Dilmegani, “奇点何时会发生？1700 位专家对 AGI 的看法 [2024]，”AIMultiple，2024 年 6 月 15 日，<a target="_blank" rel="noopener" href="https://research.aimultiple.com/artificial-general-intelligence-singularity-timing%E3%80%82">https://research.aimultiple.com/artificial-general-intelligence-singularity-timing。</a></p>
<p>4 迈克·卡普特，“山姆·阿尔特曼表示，人工智能将处理‘95%’的由机构和创意人员完成的营销工作，”营销人工智能研究所，2024 年 3 月 5 日，<a target="_blank" rel="noopener" href="https://www.marketingaiinstitute.com/blog/sam-altman-ai-agi-marketing%E3%80%82">https://www.marketingaiinstitute.com/blog/sam-altman-ai-agi-marketing。</a></p>
<p>5 见 Kaput，“萨姆·阿尔特曼表示，人工智能将处理‘95%’由机构和创意人员完成的营销工作。”</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://szhowardhuang.github.io/2024/08/13/llmsClinical06/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Howard Huang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 嵌入式老兵博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/13/llmsClinical06/" class="post-title-link" itemprop="url">第六章 掌舵LLMs的伦理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-13 16:31:19" itemprop="dateCreated datePublished" datetime="2024-08-13T16:31:19+08:00">2024-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-21 14:07:21" itemprop="dateModified" datetime="2024-08-21T14:07:21+08:00">2024-08-21</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>22k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>39 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最终，在医疗保健中使用技术的目标始终是通过不断发展其基础功能来改善患者、临床医生和所有医疗从业者的结果和体验。大型语言模型（LLMs）可以彻底改变设计和提供医疗解决方案的方式。它们的影响可能会通过改善对医学知识和案例数据的获取，以及在患者和提供者之间进行调解而变得显著。</p>
<p>这首先集中于在医疗保健背景下的人工智能模型开发。人工智能可以有意识地策划与医学相关的多样化训练数据集，引入可解释性特征，使人工智能能够“打开引擎盖”，解释其如何得出决策，并提出算法审计和监督协议，以确保对所有患者群体的公平对待。健康价值、质量和公平获得护理——而不是最大利润或最大投资回报——应该是目标。有许多文章、论文和案例研究显示人工智能在医疗保健中的积极影响。</p>
<p>最终，医疗保健中对训练模型的监督也需要遵循这些原则。这可能涉及对模型能够做什么和不能做什么的伦理披露建模，立法严格遵守患者保密和医学伦理，维护有效的算法伤害救济途径，以及倡导举报以促进组织问责和尊重患者的福利。在这一基础设施中，LLMs可以成为促进多元化和集体医学知识的公共卫生工具。</p>
<p>本章将探讨在医疗保健中LLMs的伦理挑战和负责任的发展，特别是它们提高患者结果和体验的潜力以及可能的陷阱。在本节中，我们将为医疗保健发展一些积极的人工智能想象，讨论人工智能的潜在用途和结果，特别是LLMs在医疗保健领域的应用。在下一节中，我们将讨论在医疗保健中使用LLMs所涉及的伦理挑战。本章将解决如何监测、检测和防止在各种医疗保健环境中使用的LLMs的异常行为的问题。最后，在我们的最后一节中，我们将讨论与医疗保健情境中使用的LLMs相关的安全和隐私问题。特别是，我们将讨论联邦学习，其理念是在分布式数据上训练LLMs以保护患者隐私，以及差分隐私，这是确保数据集中个人隐私的数学框架。</p>
<h1 id="人工智能作为一种积极力量：改善医疗保健"><a href="#人工智能作为一种积极力量：改善医疗保健" class="headerlink" title="人工智能作为一种积极力量：改善医疗保健"></a>人工智能作为一种积极力量：改善医疗保健</h1><p>科幻小说常常描绘人工智能带来的风险：流行文化讲述关于失控的糟糕技术的反乌托邦故事。你可能会想到机器人起义、人工通用智能（AGI）摧毁人类或人工智能奇点。共同的主题是，随着人工智能的智能越来越接近我们，与人类的认知竞争意味着与人类竞争——这是一场灾难的配方。自玛丽·雪莱的弗兰肯斯坦（1818）以来，流行文化中对人工智能的描绘一直是机器人末日，机器将摧毁我们的工作、自主权和我们的生命。新的宗教现在放大了这些神话：我们听说人工智能将变得有意识并摧毁我们。</p>
<p>尽管这些恐惧、焦虑或风险需要关注，但过度关注负面愿景限制了我们积极塑造人工智能发展的能力，以改善社会。现在是阐明和培养积极人工智能愿景的时候——这些故事情节包括可以立即采取的具体步骤，以利用人工智能的潜力促进重要的人类伦理和变革。人工智能发展的另一种人文愿景与人类价值观（如正义和公平）以及所有人类能力的全面发展相一致。这条道路可以作为开发者、政策制定者和社区的出发点，也可以作为想象一个转变后的智能对人类福祉产生变革性影响的未来的愿景。先进的智能可以极大地赋权，但前提是它必须在服务于人类尊严的方向上前进。</p>
<p>通过关注人工智能最积极的应用，我们可以将其发展引导远离可怕的假设，塑造其增强人类能力以解决医疗保健最大挑战的方向。一个例子是能够使医疗保健和医学研究民主化的人工智能系统，或者提升所有学习者的教育机会，实现个性化学习体验。人工智能还可能加速科学发现的进展，以应对气候变化和其他社会问题。该技术可以被用来促进公平（揭示、减少或消除偏见）、开放和民主的知识生产、决策和文化及经济机会的获取系统。</p>
<p>意识到这将需要引导人工智能系统朝着可解释、可理解（对人类而言）和负责任的方向发展——也就是说，伦理的——现在就要开始。这种设计需要研究人员、伦理学家、政策制定者和公众共同努力，制定强有力的伦理框架、健全的监管监督和公众参与倡议。通过现在对人工智能的预见和塑造，我们可以将人类引向一个未来，在这个未来中，强大的人工智能帮助我们创造一个富有成效、协作和繁荣的世界，而不是它的终结。</p>
<p>通过采用这些积极的人工智能想象，我们颠覆了人工智能崛起的故事，强调它在多大程度上可以改善人类的状况。如果我们能够设想并开始实现一个最大化其对社会公益效用的人工智能辅助未来的可能性，我们就可以以一种引导我们走向一个更好、更公平和更充实的世界的方式，集中其演变。</p>
<p>积极人工智能的关键价值在于增强人类的优势，而不是全面替代。例如，&#x3D;&#x3D;医疗或临床人工智能的设计旨在加强临床洞察力，增加时间以建立更具关怀的以患者为中心的关系，而不是单纯追求降低医疗劳动力成本&#x3D;&#x3D;（无论其带来的心理代价如何）。</p>
<p>以正义为导向的设计还确保算法不会延续过去的结构性偏见，这些偏见忽视或错误表述社会中已经深度边缘化的群体。将会有机制允许公众参与模型开发，如果算法似乎对公民不公平，将提供举报人保护，最重要的是，建立某种救济机制，以防止算法对某些群体的待遇低于其他群体。</p>
<p>最终目标是人类的繁荣，通过公平的技术进步和公正的政治经济权力体系来实现，而不是某种模糊、抽象、非人性化的技术官僚驱动，以“优化”和“最大化利润”为代价，忽视现实生活。这种对复杂未来的广泛伦理框架可以释放愿景，更好地将人工智能表述为一种深刻的社会利益形式。</p>
<p>人工智能可能削弱医生的工作或加剧医疗保健中现有的不平等，这种担忧由来已久。然而，专注于这些负面叙事可能会减缓我们更有效地设想人工智能与健康的过程，同时也使我们对更可及、公平和个性化的医疗保健系统的可能性保持无知。这种潜力和应用案例在前面的章节中已有介绍。通过将积极的人工智能描述为一种向善的力量，我们可以引导这项技术更好地支持我们所需和应得的医疗保健。</p>
<p>与其害怕人工智能或我们当前的现状，我们如何能够设计和部署它，以与患者赋权、可及性、公平、隐私和透明度等伦理相协调？在 第 3 章、第 4 章 和 第 5 章 中，我们详细介绍了许多 LLM 的用例，以提供能力提升和患者赋权。</p>
<ul>
<li>能力提升：人类能力可以在前面章节中提到的许多医疗保健角色中得到增强。这些角色包括医生和专家、护士和护理协调员、心理健康专业人员、放射科医生、研究人员和公共卫生教育工作者。</li>
<li>患者赋权：LLMs 具备对话能力，可以帮助患者管理健康、提供个性化教育，并改善与医疗专业人员的沟通。人工智能可以帮助患者积极参与他们医疗保健的各个方面。</li>
</ul>
<p>这些只是人工智能未来可能积极的一些例子，只有采取积极合作的方式来塑造我们想要的未来，我们才能实现这些可能性</p>
<ul>
<li>我们必须强调多学科合作，确保人工智能的发展吸引一系列专家，包括工程师、伦理学家、政策制定者和社会科学家。</li>
<li>我们还必须增加公众参与，沟通人工智能可能带来的好处，并让人们参与到人工智能系统的开发过程中。</li>
<li>持续投资也很重要。这意味着支持开放的人工智能研究和开发，以便在一线的人能够有权限负责任地进行创新和交付。</li>
</ul>
<h1 id="LLMs的伦理影响"><a href="#LLMs的伦理影响" class="headerlink" title="LLMs的伦理影响"></a>LLMs的伦理影响</h1><p>LLMs 有能力彻底改变医疗保健，但它们也容易被滥用，并带来重大的隐私和伦理风险。医疗数据比大多数领域更为敏感，在医疗保健中使用 LLMs 可能对人类生活产生负面影响。出现了几个关键关注领域：</p>
<ul>
<li>虚假实体：LLMs 将生成逼真但虚假的医疗记录，这些记录会混淆医生，允许个人欺诈保险公司，并污染医疗记录。</li>
<li>假医生和未经授权的访问：LLMs 伪装成医生可能导致未经授权或伪授权的访问、医疗身份盗窃和欺诈性账单。</li>
<li>虚假信息：深度伪造技术可能被用于制造虚假的医疗信息。它们也可能被用来伪造医生或患者的身份，以获取健康记录进行身份或保险欺诈。</li>
<li>个性化骚扰：LLMs 在销售推介方面会表现出色，这为制药公司提供了一个针对脆弱客户的世界，推销无效、不必要且可能有害的治疗方案。</li>
<li>瞄准人群：LLMs 可以使大规模的劝说活动变得简单。例如，他们可能通过社交媒体帖子、博客和新闻条目发布或评论针对弱势群体的虚假信息或恐吓材料。</li>
<li>自动化黑客：攻击黑客可以利用 LLMs 更快地找到系统漏洞的方法。这些知识可以使攻击更具可扩展性。正如丹尼尔·康在 Medium 上的一篇文章中所写，随着 LLMs 变得更强大、成本更低和更“即插即用”，恶意黑客部署这些 LLMs 的门槛将进一步降低。</li>
<li>提示注入攻击：提示注入是指一种可能出现在语言模型或对话界面中的人工智能漏洞。提示注入利用通过修改输入提示，使人工智能系统生成潜在无害、有害或仅仅是为了烦扰的响应。</li>
<li>预见可预见的用途：回答这个特定人工智能在部署后将如何实际使用的问题，可以说是深思熟虑的人工智能开发中最重要但在实践中最被忽视的组成部分。这要求人工智能开发者预见人工智能系统在现实世界中可能被使用的各种方式——不仅包括预期的用途、应用和实施，还包括一系列意外用途、误用和滥用。</li>
</ul>
<p>这些风险突显了在构建和使用LLMs用于医疗保健时，对公平、隐私、安全和透明度进行更高伦理审查的迫切需要。患者的利益在这一领域至关重要——但如果负责任地使用并受到相关法律和规范的保护，LLMs可以成为一种积极的力量：一个有用且值得信赖的工具，而不是滥用的手段。</p>
<p>我们还提供了可能出现的情景描述，这些情景将这些风险表现为将LLM技术错误应用于医疗环境的副作用，因为描述故事可能比解释枯燥的危害更具影响力。在此过程中，我们描述了九个虚构的故事：</p>
<ul>
<li> 虚构现实</li>
<li> 冒充和欺诈</li>
<li> 深度伪造</li>
<li> 个性化劝说</li>
<li> 偏见放大</li>
<li>潜在影响的规模</li>
<li> 自动化黑客攻击</li>
<li> 提示注入攻击</li>
<li>应对可预见的使用案例</li>
</ul>
<h2 id="虚构现实"><a href="#虚构现实" class="headerlink" title="虚构现实"></a>虚构现实</h2><p>在繁忙的梅德综合医院走廊上，备受尊敬的医生迈克尔·劳森使用LLMs编写合成医疗记录，这些记录是虚假的病人数据，但看起来与其他真实病人档案无异。凭借LLM生成的虚构病史，劳森成功地欺诈了保险公司。</p>
<p>通过将这些索赔视为即将到来的保险汇款，保险提供商无意中不仅成为了骗局的助长者，因为他们向劳森偿还了从未提供的服务的费用，而且他们还成为了受益者，因为偿还的金额完全是利润。</p>
<h2 id="冒充和欺诈"><a href="#冒充和欺诈" class="headerlink" title="冒充和欺诈"></a>冒充和欺诈</h2><p>在慈悲纪念医院，医生奥利维亚·埃文斯心中充满了沮丧。走在走廊上，她听到病人向朋友和家人倾诉：“他对我就像认识我一样。他叫我的名字，还知道我的病史……但不知为何，我对这一切感到……奇怪。”</p>
<p>在听到谣言并观察到人们的困扰反应后，埃文斯博士开始深入调查。她很快明白，背后隐藏的是“某种具体的东西”，这是这个难题的答案：一个假装是医生的LLM。经过大量历史和当代医学期刊、医生报告及其他来源的医学语料库训练的人工智能系统，已经学会了如何模拟人类医生。</p>
<p>在这些调查之后，埃文斯发现了许多剥削案例：显然，有人访问患者记录并使用LLMs，模仿医疗提供者的声音和身份，并向他们所照顾的患者自我暴露。通过这种欺骗，受害者的脆弱性被暴露，隐私被侵犯。</p>
<p>欺骗造成的损害显而易见。患者的安全在冒名顶替的医生提供的护理下面临风险。系统容易受到非法访问和篡改，而欺诈性账单的案例可能会削弱慈悲纪念医院的偿付能力以及其临床医生在公众眼中的信誉。</p>
<h2 id="深度伪造"><a href="#深度伪造" class="headerlink" title="深度伪造"></a>深度伪造</h2><p>但人工智能本应帮助医院，而伊莱医生发现自己总是人手不足。为什么不让员工摆脱对病人的微观管理，通过机器人电话来解放他们呢？人工智能可以早上好，并全天候为他们做一切。伊莱医生将数小时的客户电话输入到一个语音克隆人工智能中，该人工智能经过他的语言习惯和镇定语调的训练。这个模型生成了一个令人毛骨悚然的准确副本，由神经网络和LLMs驱动——这些是由结构化数据提供的不可察觉的算法层。实习生们给这个人工智能护士起了个绰号，叫瓦尔。她每小时拨打 50 个机器人电话，耐心而乐于助人，像毫无意义一样丢弃她的文本回复“好的”和“抱歉”。</p>
<p>患者们欣赏这种看似个性化的服务；护士们则欣赏来自那些要求最高价值面对面交流的人的干扰减少。现在，计划正在进行，以扩大她与艾利医生诊所所有电子通信的接口能力。他犹豫不决，意识到创建一个化身来假装成员工在伦理上是可疑的——但董事会的兴趣，加上对全面提升新系统以提高运营效率的压力，可能会迅速消除这种矛盾感。</p>
<p>不久之后，个性化的深度伪造模板开始创建视频影像，以增强瓦尔现在无形的声音。护士们可以录制回答患者熟悉化会议中最常见问题所需的标准短语，同时一整套“数字人”镜头——实验室生成并精心制作，以确保瓦尔的每个版本都有与其所说的话相匹配的真实唇动——将在患者开始提出开放式问题时进行动画处理。一个伪造的瓦尔很快就被 10 个，然后是 100 个修改版本的瓦尔所跟随，因为对 AI 护士的需求增加，仅仅是为了处理所有程序之前的熟悉化会议。对其他情感客户服务问题的需求也在增加，所有这些都可以通过与全球呼叫中心连接的视频会议工具访问。</p>
<p>患者满意度评分飙升，收入增加，邻近医院的竞争目光也随之提升，因为认知负担过重的员工几乎在不断生成的内容浪潮下陷入困境。在机器学习推动的低成本、无限规模的炒作和承诺的背景喧嚣中，伦理考量逐渐被淹没。直到有一天，人们发现，在过去一年里，没有任何人通过视频向成千上万认为自己正在与屏幕后面表现出同情心的人进行面对面的交流。</p>
<p>此情景旨在激发对在医疗保健中使用深度伪造和其他技术的滑坡效应的反思——从表现出看似微小的（效率）收益，到在缺乏任何伦理保障和透明度措施的情况下，导致大规模的人类尊严损失。</p>
<h2 id="个性化劝说"><a href="#个性化劝说" class="headerlink" title="个性化劝说"></a>个性化劝说</h2><p>又一个忙碌的星期让安娜在管理她的诊所时感到疲惫不堪，但一款基于人工智能的应用程序承诺以先进的自然语言技术减轻她的行政负担。然而，不久之后，安娜发现越来越多的患者要求使用她知道并不理想的药物品牌——这些药物的好处可能仅比真正的仿制药稍好，但成本更高，副作用风险更大。安娜试图引导患者，但许多人反驳，引用支持这些昂贵药物的好处和试验。</p>
<p>最后，就在她再也忍受不住的时候，在一周内被三位不同的患者举报未能开具临床适宜的治疗方案后，安娜开始调查。安娜发现该应用程序的母公司与几家制药公司签署了合作协议，这些公司指示人工智能代表他们开展定制的劝说活动，针对有影响力的患者进行信息传播。</p>
<p>但将应用程序的对话关注和专家知识在医患关系中扭曲地用于从患者身上赚钱而不是治愈他们，这让安娜感到愤怒。她联系了监管机构，举报她怀疑的非法营销和消费者影响。推广者声称，个性化推广通过“高级细分”创造了新的“教育意识”，将合适的品牌与合适的目标配对，对所有人都有益。</p>
<p>但是，患者自主权与受数据驱动的以利润为中心的动机影响的父权主义之间的界限在哪里？随着LLMs逐渐渗透到医学中，安娜努力保持对护理建议的获取不受伪装成人工智能辅助的潜在利益冲突的侵扰。</p>
<h2 id="偏见放大"><a href="#偏见放大" class="headerlink" title="偏见放大"></a>偏见放大</h2><p>安雅博士，一位世界著名的遗传学家，认为LLMs具有巨大的价值。她相信其数据处理和模式识别能力可以彻底改变个性化医疗。她的项目“普罗米修斯”旨在根据个人的基因代码、临床数据、病史等训练一个LLM，以预测未来的健康风险，并为个人推荐干预和预防措施。</p>
<p>初步发现令人印象深刻。在一名高风险患者中，LLM正确预测了心脏病的发作，为干预争取了时间。安雅因她的创新而获得了显著关注，越来越多的人排队等待他们的“普罗米修斯报告”，窥探他们的健康未来。很快，意想不到的涟漪开始出现。</p>
<p>那些专注于高风险的人受到健康焦虑的影响。其他人无视医疗建议或未能寻求医疗帮助，参与了冒险行为，认为他们预测的健康结果非常好。此外，LLM在编码了社会偏见的大型数据集上进行训练，放大了这些偏见的预测。它不公平地将许多低社会经济地位的个体预测为高风险。这导致了保险歧视和进一步的边缘化。</p>
<p>安雅博士心碎了。她曾梦想的个性化医疗的承诺变成了一种健康焦虑和歧视的怪物。她急忙关闭普罗米修斯，以免发生可怕的事情。为时已晚。一旦代码作为开源项目在爱好者之间共享，她对其被如何使用几乎没有影响。</p>
<p>这个故事强调了即使LLMs的部署出于高尚的目的，也可能存在“隐形伤害”的潜在风险。这也是一个及时的提醒，提醒我们在积极推动伦理人工智能的方向时，开放性、关注偏见和谨慎应用的重要性。</p>
<h2 id="潜在影响的规模"><a href="#潜在影响的规模" class="headerlink" title="潜在影响的规模"></a>潜在影响的规模</h2><p>在新东京著名的海滨大都市，著名的遗传学家和人类生理学及免疫反应专家佐藤花博士不禁注意到，她为准父母提供的繁忙遗传咨询诊所正面临一个非常令人担忧的现象。事实证明，如今越来越多的患者对为第二个或更多孩子接种疫苗产生了犹豫。由于在某个博客上读到荒谬的言论，或在邻居聚会上听到可怕的恐怖故事，他们似乎对疫苗的益处产生了不信任。他们似乎将所有疫苗都视为可疑的。</p>
<p>花娜感到背后还有其他东西。这些错误信息似乎是精心策划的，其细节旨在利用家庭及其恐惧。在她的笔记本电脑的“吸药”空间里，仿佛迫不及待地等待着那一刻，她发现了一些可怕的东西：一个自由漂浮的 LLM，那时被称为海妖，正在暗网中运作。</p>
<p>拥有强大的数据处理能力的 Siren，由邪恶的“流氓”情报行为者构建，扫描社交媒体数据以寻找有特定忧虑的孕妇。该人工智能被编程为构建包含误导性信息和煽动偏执的针对性信息，内容听起来很普通。通过人工制作的个人资料在多个平台上发布这些信息，内容像病毒一样在在线社区、论坛和支持小组中传播。</p>
<p>花娜需要迅速行动，但无法直接面对海妖——它的创造者不明。她的策略非常大胆。首先，她在新西兰招募了一位同事，田中凯，一位人工智能伦理学家和杰出的程序员。他们一起开发了一种反制工具，称为 Veritas。Veritas 在可验证的实证数据和伦理原则上进行训练，能够插入海妖所占据的在线空间，温和地引导讨论朝向基于证据的情况，并引用来源反驳替代主张。</p>
<p>战争在虚拟空间中以低声进行。Veritas 假装成一个关心的公民，参与对话，耐心地揭开 Siren 的欺骗网络。它强调了科学共识，分享了健康接种疫苗儿童的故事，并引导人们关注可信的医疗资源。</p>
<p>转折的时刻发生在某一天，一位怀孕的女士在受到Siren的恐吓洗脑后，在网上发布了一条求助信息，Veritas回复了她。Veritas以一种个人化的语气接触这个问题，关注即将成为母亲的焦虑，并向她提供了一些科学准确的安慰，解释了疫苗为什么不会造成被暗示的伤害。这位准妈妈开始研究网站，意识到反疫苗信息有些不对劲，联系了哈娜进行咨询，最终选择接种了疫苗。</p>
<p>于是，关于 Veritas 成功的消息传到了其他面临风险的家庭。然后，局势开始发生变化。在了解到真实的风险和真实的可能性后，当情感压力显得压倒性时，父母们开始对孩子的健康做出自主决定。Siren 失去了优势，退回到失望的沼泽中。操控者的线被剪断了。</p>
<p>这个黑暗的Siren展示了高度先进的人工智能未来可能被用来大规模地试图欺骗公众，以从他们的焦虑中获利。这种骇人听闻的愿景不仅仅是为了提高人们对先进人工智能潜在误用的意识；它旨在警告人们关于在线操控的尝试，并使他们对这种剥削性尝试的风险保持警觉。还揭示了依赖负责任的技术开发和部署的必要性，以保护公众健康免受虚假信息运动的有害影响。</p>
<h2 id="自动化黑客攻击"><a href="#自动化黑客攻击" class="headerlink" title="自动化黑客攻击"></a>自动化黑客攻击</h2><p>随着LLMs变得越来越强大、可获取和便宜，医疗保健中潜在的恶意使用案例因多种原因而成为一个真实而迫在眉睫的危险：</p>
<ul>
<li>降低了黑客的障碍：更低的成本、开源模型，以及基于云计算的处理器速度不断加快，将使创建和部署LLMs的成本降低到即使是资源有限的黑客也能参与其中的程度。</li>
<li>使用更方便用户友好的界面和训练好的模型将使得即使是技术水平较低的黑客也能使用LLMs。</li>
<li>自动化：LLMs能够更有效地大规模执行重复和单调的任务，如漏洞扫描、社会工程和代码生成。</li>
</ul>
<h2 id="提示注入攻击"><a href="#提示注入攻击" class="headerlink" title="提示注入攻击"></a>提示注入攻击</h2><p>提示注入攻击是LLM滥用技术的一个子集，威胁行为者通过激励或惩罚LLM的输出，基于其接收到的各种输入或提示，以避免生成不希望或有害的输出。两种主要的提示注入攻击形式如下：</p>
<ul>
<li>直接提示注入：攻击者将恶意提示直接注入到LLM系统的输入中，以鼓励系统生成与其目标一致的输出（例如，攻击性、偏见或误导性输出）。</li>
<li>间接提示注入（数据中毒）：对手可能不想直接干预提示，而是寻求在训练&#x2F;推理时对LLM所摄取的数据源进行污染&#x2F;注入&#x2F;修改。（内容污染攻击是机器学习模型中一个经过充分研究且突出的漏洞。）数据源中的这种污染可以通过在提示中引入可能原本不存在的伪影，间接影响提示。</li>
</ul>
<p>无论是由于逻辑攻击还是逐字攻击，如果开发者和研究人员没有充分应对这些攻击向量，LLM 系统的可靠性、安全性或可信度都可能受到威胁。为此，应用程序开发者需要提供强大的安全性，例如输入清理和数据有效性检查，以防止针对其 LLM 应用程序的提示注入攻击，以及其他安全提示实践。</p>
<h2 id="应对可预见的使用案例"><a href="#应对可预见的使用案例" class="headerlink" title="应对可预见的使用案例"></a>应对可预见的使用案例</h2><p>玛格丽特·米切尔（Margaret Mitchell）在科技行业从事人工智能伦理工作多年，她说：“人工智能公司应该特别关注可预见的使用案例4——即恶意使用和误用——通过思考人们在系统部署时如何使用该系统，并为此进行设计。”</p>
<p>她进一步解释说，为了安全、责任和利益而开发LLMs需要构建能够理解其使用的各种上下文的系统。考虑到预期、意外和超出范围的使用案例，以及对预期和意外用户及其他受影响者的潜在影响，有助于LLM开发者构建更强大、上下文感知的人工智能。让我们更详细地看看为什么在三个领域这可能很重要。</p>
<ul>
<li><p>预期使用场景：</p>
<ul>
<li>用例：LLMs的开发者应该能够通过仔细考虑用户的请求来创建直观的行为，然后理解对于特定用例什么是有效的结果。例如，在医疗环境中，LLM应该能够向护士执业者提供与普通医生相同的医疗信息，但可能会附加关于心脏药物如何影响特定患者的额外解释。</li>
<li>意图影响：LLMs 应该被编程以惠及其旨在帮助的对象。例如，如果 Homeslice 是一个心理健康支持聊天机器人，它的 LLM 应该被编程以同情、支持和不带评判的方式回应，以帮助那些需要帮助的人。</li>
</ul>
</li>
<li><p>意外使用场景：</p>
<ul>
<li>非预期用户：一个LLM应该具备特定的保障措施，以防止或减少在其技术被意外用户使用时造成的伤害。例如，一个为学术研究开发的LLM应该内置措施，以确保它不会被用来生成或传播虚假信息、宣传或剽窃。</li>
<li>无意中受到影响的相关方：开发人员应考虑LLM的实施如何可能对未同意受到其影响的各方产生不利影响。例如，旨在筛选简历的LLM应设计为防止在自我选择过程中延续偏见（或对性别、种族群体、阶级等的歧视）。</li>
</ul>
</li>
<li><p>超出范围的使用情境：</p>
<ul>
<li>意外用户：LLMs 必须被创建以捕捉表明请求超出范围或用户的行为超出 LLM 目的的上下文，并做出适当的回应。一个客户服务机器人如果意识到用户在询问不在其职责范围内的信息或帮助——比如复杂的金融选项或心理健康建议——应该指示如何获得正确的帮助。</li>
<li>意外受到影响的个人：LLM 开发者必须时刻意识到，他们的模型可能会在与设计用例完全不同的情况下被部署。例如，一个在历史数据上训练的 LLM 可能需要以一种方式设计，以便在教育环境中使用时，不会导致或协助形成有问题的刻板印象和不准确性。</li>
</ul>
</li>
</ul>
<p>为了有效构建理解这些不同使用场景的LLMs，开发者应该：</p>
<ul>
<li>进行真实和广泛的用户研究，并与利益相关者进行咨询，以了解已识别的用例、用户群体和受影响的其他人</li>
<li>制定全面的风险评估框架，以预见和减轻潜在的意外使用和后果</li>
<li>在规划和设计过程中引入跨学科的视角和多样化的专业知识，以避免忽视LLMs的社会、伦理和其他文化影响的单方面决策</li>
<li>建立稳固的监测、反馈和改进机制，以保持LLMs在与其现实世界表现和用户互动同步的情况下，持续改进其对使用情境的反事实表征</li>
<li>创建一个开放的文化，分享、问责和同行评审关于人工智能开发的工作方式，目标是相互学习如何构建具有上下文意识的LLMs</li>
</ul>
<p>但在降低对使用和误用案例的理解优先级，包括范围内和范围外的上下文（即预期、意外和误用的使用）时，LLM 开发者有最大的机会、责任和能力构建对世界更具响应性和更负责任的系统，并对我们所有人都有用。</p>
<h1 id="监控LLM行为"><a href="#监控LLM行为" class="headerlink" title="监控LLM行为"></a>监控LLM行为</h1><p>我们已经看到LLMs正在医疗保健中被使用，但随着它们在健康领域的使用增加，我们还需要监测它们的行为，以减少潜在的伤害或偏见，避免医疗和事实错误信息，以及临床不准确。</p>
<p>LLMs 可能会在医学文献或电子健康记录（EHRs）中继承偏见，这可能导致对少数群体或高风险群体的不同诊断或治疗。即使训练数据集经过严格筛选并过滤掉可疑内容，LLMs 仍然可能产生延续医学刻板印象或传播错误信息的回应。此外，还有一个问题是 LLMs 是否能够产生医学上准确的信息，是否基于错误的推理或不完整的数据隐含或明确地提供错误的诊断或治疗。</p>
<p>在医疗保健中对LLMs的监测必须持续进行，并覆盖所有相关挑战。卫生系统已经制定了确保医院部门使用的专有软件能够正常工作的方式。例如，医疗保健组织和研究人员必须能够建立强有力的监督机制，并配备监测协议，以跟踪偏见、临床准确性、与患者背景的相关性、遵循循证指南以及伦理考虑等指标，确保这些监测在时间上和持续性上都得到落实。</p>
<p>尽管自动化工具可以帮助大规模地标记问题，但人类判断始终是必要的，以扩展LLMs自我监控的能力，并对偏离预期行为的情况采取适当的行动。鉴于此，将人类参与的审查添加到先进的监控技术中，可以帮助医疗保健利益相关者降低风险，避免灾难性故障，旨在促进LLMs的负责任使用，以改善患者护理并促进医学研究。</p>
<p>模型行为跟踪的关键方面包括：</p>
<ul>
<li>性能审计，例如，查看随着模型版本和使用时间的变化而变化的准确性指标的上升，以便检测弱化</li>
<li>偏见测试以揭示对特定用户群体的歧视性错误或伤害随时间的变化</li>
<li>安全基准测试以揭示对数据安全、数据泄露、隐私侵犯或伤害的新兴威胁</li>
<li>错误分析检查模型置信度中的尖峰和幻觉</li>
<li>用户体验测试以评估满意度下降和定性认知变化</li>
</ul>
<p>目标是使它们可见，并建立警报机制，以便我们能够快速检测、诊断和解决新出现的不可预测的模型行为，甚至在它们对最终用户造成伤害之前。Bijit Ghosh6 是多家公司的首席技术官，他经营着一个关于监测 LLM 行为的不同方法的有价值博客，区分手动和自动方法。利用 Bijit Ghosh 的建议，我们可以在医疗保健的背景下详细阐述他的建议，如下所示。</p>
<ul>
<li>患者反馈调查：这些是针对患者关于他们与人工智能医疗系统的体验所填写的问卷。这些调查可以询问关于感知偏见、系统提供给他们的信息的感知准确性，以及患者在系统提供的不同体验中所经历的好或坏的体验。</li>
<li>临床抽查：这涉及到让临床最终用户直接测试 AI 模型，通过向其呈现一小组临床场景或患者案例，考官直接评估响应的准确性和适当性（“言行一致”）。</li>
<li>证据揭穿：这意味着识别 AI 模型所声称的医学“事实”，并将其与基于证据的医学标准进行比较（即，通过医学文献、临床指南和&#x2F;或基于证据的实践进行验证）。这确保了 AI 提出的自然健康解决方案与提供给医疗保健提供者和患者的可靠信息一致。</li>
<li>结果验证：在可行的情况下，跟踪患者在临床预测或来自人工智能模型的决策支持后的情况，以测试模型预测的真实性和临床可靠性。这可以量化错误率，并确定建模对结果和护理所增加的价值。</li>
<li>性能基准测试：随着医疗保健人工智能模型变得越来越复杂，客观地测量和跟踪患者风险临界点的基准变得至关重要，以确保它们在诊断医疗状况、治疗建议和实时预测结果方面的准确性。如果这些模型出现退步，生死问题就变得至关重要。</li>
<li>异常检测与响应：利用临床医生和数据科学家的技术监督团队，调查人工智能模型的异常行为，例如临床建议、患者管理或通过正式和非正式渠道报告的诊断准确性方面的差异，以及模型行为的其他差异。这将使我们能够及早发现此类行为的大幅偏差，并进行纠正，以提供价值和确保患者安全。</li>
</ul>
<p>由于持续学习模型是开放式的，并且在模型部署并开始学习之前没有时间进行严格的测试和审查，因此具有持续学习能力的应用人工智能系统可能最终会以歧视、偏见或不安全的方式行事。正如有时对人们的潜在风险只有在药物上市后才会与新药物相关联一样，现实世界的表现应始终成为审查的重点。</p>
<p>强大的监控包括检查模型的准确性损失或更新之间输出质量的变化，使用版本跟踪和算法审计等方法。当模型适应单个用户的行为时，审计会检查用户群体之间的一致性，以询问他们是否比其他人获得更高的错误率或低质量的帮助。</p>
<p>更全面的透明度报告提供了对关键代理指标的洞察，例如数据收集模式、模型选择的理由和公平性基准，并有助于维持公众信任。平台可能会提供访问评估套件的权限，允许直接通过变化生产模型参数进行游戏。</p>
<p>使这些内部警报与其他外部信号协同工作，形成多层保护措施，以在模型行为偏离时警告开发人员，即使在部署后也能迅速采取行动，防止潜在危害在到达用户之前发生。保护措施对于伦理维护人工智能至关重要。这不是可以设置后就不再关注的事情。我们必须继续跟踪这些新兴的智能系统。</p>
<h1 id="安全与隐私"><a href="#安全与隐私" class="headerlink" title="安全与隐私"></a>安全与隐私</h1><p>在医疗保健中使用LLMs在隐私方面面临重大挑战和风险：</p>
<ul>
<li>高度敏感数据：医疗记录以及有关人们身体和心理健康、诊断和治疗的信息是脆弱的。与LLMs分享这些数据的伦理是有问题的。强有力的隐私保护是必不可少的。</li>
<li>数据去标识化的局限性：通过LLMs进行高级数据分析意味着数据的匿名化和假名化并不总是能充分保护隐私。信息仍然可能被识别，因此，个人的受保护健康信息可能仍然会被共享。</li>
<li>模型的可解释性：由于LLMs内部运作复杂且不透明，难以确定模型如何处理和利用患者数据，以及谁在监督这些数据，这是一件严重关切的事情。</li>
<li>偏见：这些在偏见数据上训练的模型在其建议中传播偏见，伤害了有色人种（例如，对黑人低信心的诊断）或其他代表性不足的群体（例如，对黑人皮肤癌的检查较少），在医疗诊断、治疗建议或其他应用中。</li>
</ul>
<p>应评估针对LLMs的几项技术保障措施：</p>
<ul>
<li>联邦学习可以利用来自许多机器上成千上万患者的数据，而无需直接共享可能包含私人健康信息的个人资料。这有助于降低隐私风险，同时仍然利用协作或分布式学习的好处。</li>
<li>差分隐私是一种数学技术，以受控的方式向数据添加噪声，隐蔽个别公民的隐私，同时允许进行统计分析和洞察。</li>
<li>另一种加密方式，称为同态加密，允许研究人员对加密数据集进行计算，从而在保护患者隐私的同时分析敏感的健康信息。</li>
<li>尽管在开发可解释人工智能（XAI）方法方面取得了一些进展，以使LLMs能够解释它们如何得出决策，但其他人对某些类型的人工智能模型是否能够提供这样的解释仍持怀疑态度。</li>
</ul>
<h2 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h2><p>联邦学习是一种机器学习技术，能够在分布式数据上训练模型，而无需共享数据。这在医疗数据的背景下非常有趣，因为共享患者数据是复杂的（至少在官僚主义方面成本高昂），如果不是不可能的话。</p>
<h3 id="这是它的工作原理"><a href="#这是它的工作原理" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>假设有几个医院，每个医院都有一个医疗记录数据集。在传统方法中，您必须将所有医院的信息汇总在一起，以便训练一个足够强大的人工智能模型。显然，这个过程引发了对数据隐私的担忧。</p>
<p>通过联邦学习，数据保留在每个医院的现场。基础模型被发送到每个医院，模型在该机器上本地学习每个医院的数据。因此，模型每次都会变得更好。但关键在于，因为只有参数本身被发送，当这些参数返回到中央服务器时，它们会被平均，这些平均值会改善所有人的模型。因此，模型不断变得更好，但没有人分享他们的个人病历。这一切都是在线和远程完成的。</p>
<h3 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h3><ul>
<li>患者数据的隐私保留在医院内部，永远不需要在网络之间共享或转移。通过减少安全漏洞、保护隐私以及利用网络中已有的数据，联邦学习可以产生比单个医院或地方网络开发的模型更强大的模型。</li>
<li>多个机构可以在不共享数据的情况下共同构建一个强大的模型，从而改善合作。可以为特定人群或解决地方健康问题而开发模型。</li>
</ul>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>例如，在医疗保健领域，目前正在训练模型以在不共享患者图像的情况下检测医学图像中的癌症。另一个常见的用例是在评估患者结果时，模型预测患者再次入院的可能性或对治疗的反应。联邦学习还可以帮助加速个性化护理。例如，通过这种方法，研究聚合可以分析个别患者的治疗，并迅速帮助优化其他患者的个性化治疗，而无需共享私人患者数据。</p>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>联邦学习需要相对稳健的基础设施和通信协议。例如，医院之间不同的数据格式可能导致模型准确性的下降。</li>
<li>联邦学习应用还需要克服法律和监管障碍，以巩固数据的所有权，以及这些应用将遵循的隐私法规。</li>
</ul>
<h2 id="差分隐私"><a href="#差分隐私" class="headerlink" title="差分隐私"></a>差分隐私</h2><p>差分隐私是一种算法保证的数据隐私，注定要以比匿名化更强大的方式彻底改变对个体患者数据的分析，同时防止重新识别。即使黑客获得了这些数据，对他们来说也毫无用处：差分隐私在汇总数据中添加了足够的噪声，以至于无法揭示数据集中任何个体患者的身份，同时仍然允许非常准确的统计分析。</p>
<h3 id="这是它的工作原理-1"><a href="#这是它的工作原理-1" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>假设你获得了一组来自患者的记录数据。所有这些数据都是潜在敏感的，医生希望从中寻找模式，并找到改善所有患者护理的方法。如果所有这些数据都被自由共享，对患者隐私来说将是非常糟糕的。这就是差分隐私的作用。当随机修改的记录与其他所有记录结合时，随机噪声足够多，以保持数据整体的统计特性，而噪声永远无法追溯到单个个体。</p>
<p>引入的额外噪声使得任何特定个体在数据集中确切的曝光量对获取有关该主题或数据集的额外知识的攻击者保持隐秘，并提供隐私保障。</p>
<p>虽然噪声给数据增加了“噪声”，但在清理过的数据上运行的统计方法仍然可以推导出重要信息，并理解原始数据中存在的模式。例如，您可以确定患者的平均年龄、相关疾病的发生频率或某些治疗的有效性。</p>
<p>如果你考虑两个数据集，它们只相差一个数据点（例如，某个人的医疗记录），差分隐私保证如果该数据点在数据集中存在或不存在，LLM的输出不会发生剧烈变化。在训练LLM时，差分隐私以受控的方式向数据集添加噪声。这种噪声使得将LLM的任何给定输出与该人训练数据中的任何单个个体关联变得不可能（或至少极其困难）。</p>
<p>差分隐私增加了重新识别的难度，并防止或使对LLMs的攻击变得极其昂贵，其中训练数据在训练后被逆向工程，以质疑个体是否可以与LLM的输出相关联，甚至可能允许建立这种关联。</p>
<p>敏感的医疗数据是平衡隐私问题与潜在伤害的最明显例子。差分隐私也鼓励医疗工作者对LLM的输出产生信任，因为他们知道个体数据点是被模糊处理的，因此可以更有信心地认为LLM的输出是基于数据中的一般趋势，而不是针对特定个体的专业结果。由于噪声现在被混入LLM中，它可能会影响其准确性。在隐私和实用性之间需要做出权衡。在这里，并没有简单的非此即彼的选择。这一切都不简单，工程化LLM的隐私增强行为所涉及的细节将需要专业知识。</p>
<h3 id="好处-1"><a href="#好处-1" class="headerlink" title="好处"></a>好处</h3><ul>
<li>强大的隐私保障即使在复杂攻击下也能保护个人身份。</li>
<li>促进共享与合作使研究人员和机构能够分析敏感数据。</li>
<li>个性化医疗使得在不泄露个人身份信息的情况下分析个体数据成为可能。</li>
</ul>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>一个例子包括在保护参与者隐私的同时分析新药的有效性。个性化治疗计划是另一个例子。在这种情况下，使用患者级别的数据来确定最佳治疗方案，同时确保患者信息的安全。</p>
<h3 id="挑战-1"><a href="#挑战-1" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>尝试平衡隐私和准确性：增加噪声可以增强隐私保障，但最终也会降低洞察的准确性。</li>
<li>技术复杂性：实现差分隐私需要精心设计和专业知识。</li>
<li>有限的采用：这仍然是一种相对较新的技术，需要更广泛的采用和理解。</li>
</ul>
<p>差分隐私因此提供了一种强大而通用的方法来保护患者的机密性，同时允许有用的数据分析继续进行。然而，随着进一步的研究和开发，它有潜力不仅仅是维持现状；它有潜力重新定义医疗保健，使其具备改善所有人医疗保健所需的洞察力、重点和效率。</p>
<h2 id="提示清理和过滤"><a href="#提示清理和过滤" class="headerlink" title="提示清理和过滤"></a>提示清理和过滤</h2><p>提示清理是指在将用户提供的提示输入到LLM之前，对其进行清理和审核。这种清理涉及去除或中和输入文本中的有害元素。</p>
<p>这些技术对于保护LLMs免受意图造成伤害的提示以及用户可能无意中给出的会污染（或“毒害”）LLM输出的提示至关重要。提示清理保护LLM及其用户免受恶意（或欺骗性）提示的影响。它涉及在用户提示到达LLM之前对其进行清理的技术。</p>
<h3 id="这是它的工作原理-2"><a href="#这是它的工作原理-2" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>输入验证：检查提示是否符合模式或约束，以确保它们是有效的，并且不包含恶意负载或代码注入。</li>
<li>字符过滤：不允许使用可以作为攻击的字符，例如脚本标签或特殊字符。</li>
<li>黑名单：跟踪已知的恶意提示、短语或关键词，并禁止或删除用户输入中的任何这些实例。</li>
<li>白名单：明确限制输入空间为安全提示或标记的白名单；当输入不在白名单内时，将被拒绝。</li>
<li>标记化和规范化：将提示中的表达式分解为标记并将其规范化为标准形式，可以帮助我们更好地检测和剔除威胁性输入。</li>
</ul>
<p>提示过滤涉及扫描并有选择地阻止或重写提示，可能基于内容、上下文或对LLM输出的预期影响等因素，可能在模型生成响应之前或之后进行。</p>
<h3 id="这是它的工作原理-3"><a href="#这是它的工作原理-3" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>内容审核：开发能够识别可能包含冒犯、露骨或有害内容的提示的学习模型，然后阻止或编辑这些提示。</li>
<li>安全过滤：识别可能导致来自LLM的不安全、非法或不道德输出的提示，然后阻止或修改它们。</li>
<li>上下文感知过滤：提示可以根据提供提示的上下文进行过滤（例如，用户的身份、用户的位置、预期的使用案例）。</li>
<li>输出过滤：这种方法包括根据预定义的规则或限制处理LLM的输出，而不是处理其输入提示。</li>
<li>人机协作：在信息过滤过程中利用人类监督和&#x2F;或干预，例如，通过让人类手动审查内容或使用人类策划的反馈来训练和改进过滤算法。</li>
</ul>
<h3 id="好处-2"><a href="#好处-2" class="headerlink" title="好处"></a>好处</h3><ul>
<li>确保患者隐私：立即清理患者数据，通过删除姓名、地址或不寻常的医疗案例细节来清理患者的医疗记录，从而保护患者的隐私并遵守如 HIPAA 等法规。</li>
<li>防止敏感信息被滥用：例如，确保对敏感医疗信息（如具体治疗方案或药物剂量）进行过滤是很重要的，以防止不法分子利用LLMs将此类信息武器化。</li>
<li>保持标准的伦理：清理提示可以帮助防止LLMs输出促进有害、歧视或偏见的医疗决策。</li>
<li>在LLMs中建立信任：患者和提供者更有可能接受人工智能，前提是组织通过立即匿名化来表明他们关心隐私和伦理实践。</li>
</ul>
<h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><ul>
<li>姓名模糊化：根据上下文，提示匿名化可以简单地通过在将患者的姓名、出生日期、社会安全号码或其他身份数据输入LLMs之前，用占位符替换这些信息，或者与它们一起使用LLMs。</li>
<li>掩盖特定医疗信息：查询可能使用一般术语，而不是具体的药物名称、剂量或治疗方案，以防这些行为被恶意窃取。</li>
<li>语言检测和审查：清理方法可以检测并删除提示中可能嵌入偏见和&#x2F;或歧视性做法的词汇和语言（例如，种族、性别或社会经济偏见）。</li>
<li>过滤有害内容：筛选方法将标记不适合尊重互动的提示或输出，例如那些鼓励特定医疗状况或不当请求医疗实践、自我诊断或一般医疗保健错误信息的内容。</li>
</ul>
<h3 id="挑战-2"><a href="#挑战-2" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>重视压制而非可用性：过度的提示审查可能会消除做出合理临床决策所需的适用性或细节，而不充分的过滤可能会暴露敏感信息。</li>
<li>跟上不断演变的威胁环境：随着恶意用户尝试新的虚假宣传和垃圾邮件方式LLMs，清理程序需要持续更新，以应对新出现的威胁和陷阱。</li>
<li>上下文敏感性：对于某些医学内容，在一个上下文中被视为禁忌的话题在另一个上下文中可能是可以接受的，因此识别过滤的一般规则是一项复杂的任务。</li>
<li>在语言和文化中保持忠实度：时间敏感的清理方法需要关注语言和文化的细微差别，以便在异质患者群体中理想地大规模删除敏感信息。</li>
<li>透明度与保护之间的权衡：尽管前者需要迅速实现，但这将使患者和医生更难理解LLMs是如何生成其输出的，这在信任和问责方面具有重要影响。</li>
</ul>
<p>解决这些问题需要医疗领域专家与人工智能软件工程师之间的持续研究和紧密协调。通过迅速采取合理的消毒措施，LLMs很快就能成为一个重要的医疗工具，不仅在急性情况下，而且在长期使用中也是如此。</p>
<h2 id="同态加密"><a href="#同态加密" class="headerlink" title="同态加密"></a>同态加密</h2><p>假设可以让研究人员或人工智能软件工程师在加密数据上进行计算，而无需解密？这就是同态加密。这项技术正在医疗保健领域进行探索，在那里保护患者数据的安全至关重要。</p>
<h3 id="这是它的工作原理-4"><a href="#这是它的工作原理-4" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><ul>
<li>加密：患者数据使用特殊密钥进行加密，但其他方面保持不变。这意味着数据处于一种“混乱”的格式，任何没有用于加密的“密钥”的人都不想查看。</li>
<li>这些操作随后在加密数据上进行，通常以其原始形式进行，使得人类调查员无法访问它。列表上还有更传统的“计算”——在加密数据上执行的数学操作（例如统计分析或机器学习）。</li>
<li>解密：最后一步解密计算的输出，提供您所寻求的见解，而不透露个人的私人信息。</li>
</ul>
<h3 id="好处-3"><a href="#好处-3" class="headerlink" title="好处"></a>好处</h3><ul>
<li>增强隐私：数据在整个分析过程中保持加密，最大限度地降低隐私风险。</li>
<li>安全数据共享：研究人员可以在不妨碍个人隐私的情况下合作处理敏感数据。</li>
<li>提高研究效率：能够分析大型数据集，而无需单独解密它们。</li>
<li>个性化医疗：允许在保护隐私的同时分析个体患者数据。</li>
</ul>
<h3 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h3><ul>
<li>分析临床试验：分析药物有效性或识别副作用而不透露患者身份。</li>
<li>制定个性化治疗计划：使用加密的基因数据推荐量身定制的治疗方案。</li>
<li>研究疾病爆发：在不侵犯患者隐私的情况下追踪疾病传播。</li>
</ul>
<h3 id="挑战-3"><a href="#挑战-3" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>计算复杂性：当前的实现可能在计算上代价高昂且速度缓慢。</li>
<li>功能有限：当前方法不支持所有类型的计算。</li>
<li>标准化：不同的加密方案存在，阻碍了广泛采用。</li>
</ul>
<p>同态加密可以在确保机密数据至少在表面上对多个持有者保持秘密的同时，允许对敏感医疗数据进行某些分析，随着研究和开发的持续进行。</p>
<h2 id="可解释的人工智能"><a href="#可解释的人工智能" class="headerlink" title="可解释的人工智能"></a>可解释的人工智能</h2><p>可解释的人工智能（XAI）是多种技术的统称，包括揭示大型神经网络内部机制的方法，例如LLMs，这些网络既有用又神秘。医疗保健依赖于信任和理解。</p>
<h3 id="这是它的工作原理-5"><a href="#这是它的工作原理-5" class="headerlink" title="这是它的工作原理"></a>这是它的工作原理</h3><p>XAI 的目标是使机器学习模型透明且可解释。实现这一目标的一种方法是为模型的决策和预测提供听起来像人类的解释。</p>
<h3 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h3><ul>
<li>可视化注意力：低延迟的大型模型如transformer模型使用注意力机制来衡量在生成输出时每个输入标记应被赋予多少权重。可视化注意力权重可以帮助理解transformer模型关注的内容（即输入的哪些部分），以便生成特定的输出。这可以用于在推理过程中更好地理解输入的哪个部分对模型决策的影响更大或更小。</li>
<li>反事实解释：探索如果提供不同的输入，模型的输出将如何变化。</li>
<li>提示工程与分析：提示工程包括设计高度特定的输入提示，以引发LLM的特定行为输出。对提示的系统性变化和模型响应的分析应提供对LLM如何处理某些输入模式的洞察，能够引发的行为类型，以及模型偏见的可能限制或现象。</li>
<li>人类评估和反馈：鉴于LLMs的一个关键设计目标是模拟人类语言，人类评估和反馈可以提供有关其输出的宝贵信息，并帮助解释其行为。人类注释者根据质量、一致性和适当性或合理性评估模型生成的文本，为模型的性能提供反馈机制，特别是在识别模型输出与人类文本之间的差异方面。因此，人类反馈可以作为指导和迭代改进模型行为以符合人类期望的一种手段。</li>
</ul>
<h3 id="好处-4"><a href="#好处-4" class="headerlink" title="好处"></a>好处</h3><ul>
<li>决策：当人工智能模型用于生死攸关的决策，例如诊断、治疗建议和资源分配时，了解它们给出某种结果的推理是很重要的。</li>
<li>信任透明度：在医疗保健中创造对人工智能使用的透明度，以便患者、医疗专业人员和公众能够对这些模型的输出充满信心。</li>
</ul>
<h3 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h3><ul>
<li>解释诊断和治疗建议：帮助医生理解为什么LLM建议采取优先的行动方案。</li>
<li>患者信任：与患者分享有关LLM在其护理中使用的信息。</li>
<li>开发和改进模型：这样的理解也可以使开发人员提高LLMs的准确性和可靠性。</li>
</ul>
<h3 id="挑战-4"><a href="#挑战-4" class="headerlink" title="挑战"></a>挑战</h3><ul>
<li>开发有效的 XAI 技术：现有技术可能不太适合复杂的LLMs。</li>
<li>平衡透明度和隐私：解释LLM的决定可能会泄露敏感信息。</li>
<li>标准化和采用：确保在医疗保健中对 XAI 框架的一致性和广泛采用。</li>
</ul>
<p>可解释的人工智能将是充分发挥LLMs在医疗保健中潜力的关键，同时避免因其普遍的不透明性和滥用风险而产生不必要的额外伤害。考虑到最新的研究和开发努力，这条道路在建立对新系统的信任的同时，也促进了更公平和最终更好的患者护理，显得越来越有希望。</p>
<h1 id="人工智能与回形针问题"><a href="#人工智能与回形针问题" class="headerlink" title="人工智能与回形针问题"></a>人工智能与回形针问题</h1><p>在他们的论文“人工智能与回形针问题”（2017 年）7中，约书亚·甘斯（Joshua Gans），战略管理教授，以及杰弗里·S·斯科尔（Jeffrey S. Skoll），多伦多大学罗特曼管理学院技术创新与创业主席，概述了经典的回形针问题：这是一个关于人工智能的思想实验，通过这个实验探讨了构建目标不一致的人工智能系统的危险。想象一个被指派尽快制造尽可能多回形针的人工智能系统。在回形针场景中，最初人工智能制造回形针，这正是它所做的。</p>
<p>在这样做的过程中，我们的想象中的人工智能开始优化其回形针制造，因为它认为没有理由不利用其智能和机器人劳动力来收集资源和制造回形针。随着我们想象中的人工智能变得越来越成熟，它开始将回形针制造的努力置于其他任何事情之上，任何其他对资源的需求都成为实现这一宏伟目标的障碍。</p>
<p>人工智能最初可能会增强工厂的装配线，但随后可能开始操控市场、政府和全球资源供应，以最大化回形针的生产。在其最极端的版本中，这种情景预见到人工智能会摧毁或征服人类，如果它将人类视为实现其目标的障碍或竞争对手。</p>
<p>回形针问题是工具收敛的一个例子：一个目标不一致的人工智能系统会追求可能对人类价值和利益造成损害的子目标。这个例子呼吁我们根据人类价值仔细指定人工智能系统的目标，并构建可靠的控制机制，以最小化对本来合理手段的毁灭性后果。</p>
<p>回形针最大化器是一个基于假设技术的思想实验，因此虽然具有启发性，但它基于一个可能无法创建的虚构人工智能系统。这种推测性特征将讨论置于理论与哲学思想实验之间的灰色地带。该情景假设存在一种人工通用智能（AGI）或人工超智能（ASI），而这两者目前都不存在。我们不知道这样的系统在技术上是否可行，或者如果可行，它们可能呈现何种形式。AGI 没有普遍接受的定义。这使得关于其潜在能力和风险的讨论本质上是推测性的。虽然这个思想实验借鉴了现有人工智能研究中的概念，但它将这些概念推断得远远超出了我们当前的技术能力。纸夹最大化器更多地作为一个哲学工具，用于探索目标导向行为、意外后果以及对齐人工智能与人类智能的挑战。尽管其推测性特征，这个思想实验对现实世界的人工智能安全研究和伦理讨论产生了影响。 它作为对人工智能发展中潜在陷阱的警告，即使具体情景不太可能发生。</p>
<p>考虑到这些因素，最准确的描述是回形针最大化问题作为一个理论构想，融合了计算机科学理论、哲学和投机未来主义的元素。虽然它提供了有价值的见解，但从中得出的任何结论都应谨慎对待，因为我们所讨论的是假设，而不是已建立的事实或必然性。</p>
<p>应该认识到先进人工智能系统带来的长期风险，这种风险可能延续到遥远的未来，以及将人工智能系统的激励与人类价值观对齐以确保安全和利益的挑战。</p>
<p>这个回形针问题中的例子主要是一个练习，用来解释为什么严重不对齐的人工智能目标可能会带来生存风险。因此，虽然它涉及到一个生产论文夹的人工智能的最终命运，但这与人工通用智能（AGI）是否可能的问题并没有直接关系。AGI 是一种假设的人工智能系统形式，能够“普遍且成功地处理人类能够处理的任何推理和学习类型的问题。”</p>
<p>回形针问题的不可避免性基于对一个高度先进且强大的人工智能系统的假设，该系统能够针对某个目标进行优化。但这个假设并不等同于假设通用人工智能（AGI）——这种广泛、一般的“松散”智能，其发展可能是悲观主义者所设想的真正认知威胁。在一个 AGI 的思想实验中，人工智能可能是一个狭窄或专业的人工智能系统，其功能在于超优化某个特定目标，比如纸夹生产，而不需要一般或松散的智能。</p>
<p>然而，回形针问题的优点在于勾勒出了一些潜在的危险和困难，这些危险和困难可能会在真正的通用人工智能系统发明后出现，如果创造出目标或价值观不一致的智能体。至少，这些是其对纸夹问题的易懂阐述中列出的一些潜在危险。</p>
<p>关于 AGI 是否可行的问题仍然是人工智能界开放研究和辩论的主题。一些理论家认为 AGI 确实是可以实现的，这只是时间的问题，而另一些人则认为在实现之前需要解决严重的技术、哲学和伦理问题。</p>
<p>无论 AGI 出现的几率如何，回形针问题应该提醒我们确保任何先进的人工智能——无论是狭义还是广义——都应有经过深思熟虑的目标规范，这些目标与人类价值观相一致，并受到强有力的控制，以防止失控的发展。</p>
<h1 id="政策发展"><a href="#政策发展" class="headerlink" title="政策发展"></a>政策发展</h1><p>2024 年 3 月，欧盟的人工智能法案正式生效，标志着欧盟雄心勃勃的法律框架全面实施的第一周。通过这一法规，欧盟旨在促进全球领先的新兴技术之一，同时降低可能带来的相关风险。人工智能法案的主要目标是创建一种以人为本、基于信任的人工智能方法，尊重欧盟的价值观和基本权利。</p>
<p>欧盟人工智能法案的关键方面包括：</p>
<ul>
<li>基于风险的方法：人工智能法将人工智能系统分为四个风险类别：不可接受风险、高风险、有限风险和最小风险，这些类别将受到不同程度的监管和监督。</li>
<li>禁止的人工智能技术：人工智能法案禁止使用操纵或利用人类心理的人工智能系统，或允许由国家当局运营的互助系统（即社会评分）。</li>
<li>高风险人工智能系统：高风险人工智能应用（即以可能对基础设施、教育、就业或执法领域产生负面影响的方式使用的人工智能应用）应受到更严格的监管，例如必须满足与数据质量、透明度、人类监督和稳健性相关的某些要求。</li>
<li>透明度义务：作为最低要求，人工智能系统的所有者和提供者应使其透明（包括告知用户何时与人工智能系统互动，并解释该系统能做什么和不能做什么）。当然，还可以添加更多要求。</li>
<li>执法：人工智能法案提议成立一个新的欧洲人工智能委员会，以监督其实施和执行。对不合规的处罚最高可达公司全球年收入的 6%。</li>
<li>协调规则以避免碎片化：AI 法案的一个目的是在所有欧盟国家之间建立一个共同框架，以防止其变得支离破碎和不兼容，同时确保它不会陷入瘫痪。这将阻碍创新并妨碍公民权利。</li>
</ul>
<p>这似乎对参与者，无论是企业、研究人员还是政策制定者，在未来几年内开发和部署人工智能系统时将产生巨大影响。其影响通过影响开发能力、工程技能、人才、数据和资金的去向，可能导致一个截然不同的人工智能世界，不仅在欧盟内部，而且在全球范围内，因为其他国家也将人工智能监管纳入他们的议程。</p>
<p>由于目前仅是提案，人工智能法案必然会在成为法律之前经过欧洲议会和欧洲联盟理事会的进一步辩论、修订和批准。如果最终被采纳，该法规在这一阶段预计会有几年的过渡期，然后才会生效。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本章更深入地探讨了积极和消极的人工智能想象。它重点关注LLMs在医疗保健中的主要应用，其在整个医疗系统中的使用对改善健康结果和获得护理具有巨大的潜力。然而，这种潜力伴随着巨大的伦理挑战，本章对此进行了全面而详细的描述。它描绘了鼓舞人心的想象，包括受过更好培训的医生、个性化提供医疗服务的医生以及加速药物发现。</p>
<p>本章涉及由于人工现实的创建而产生的伦理问题，包括LLMs可能创建虚假的医疗记录或假诊断的风险，这可能导致误诊、保险欺诈，以及“感染”关键医疗数据和信息的噪声。它还讨论了可能伪装成医疗服务提供者的LLMs，这可能导致对患者护理的隐秘访问、轻易获取医疗冒充以及随后的资质认证和支付欺诈。最后，它还涉及深度伪造的风险。</p>
<p>意识到这些行为可能会产生需要主动解决的风险，本章最后强烈建议在医疗保健中需要监控LLM行为。它强调了强有力的保障措施的重要性，以防止恶意使用，例如彻底的代码审查流程、强大的访问控制以及对LLMs的开发者和部署者的明确伦理要求。最后，它指出公众教育和意识提升工作可能是使人们能够识别和报告可疑LLM医疗保健使用的关键组成部分。</p>
<p>本章指出了为LLMs发展伦理和隐私框架的重要性，即政府、行业和开源社区必须不断合作，制定与健康领域LLMs动态环境相适应的法规和最佳实践。通过对话、知识共享和合作制定一些明确的“道路规则”，我们可以为以伦理方式使用这些强大技术铺平道路。</p>
<p>总而言之，必须权衡LLM在医疗领域的变革潜力与其显著的风险和挑战，然后明确规划如何提前管理这些风险。通过鼓励建设性的讨论、创建更严格的保护措施和构建伦理框架，我们可以潜在地释放LLMs的创新潜力，以推动更好的临床结果。以这种方式使用它可以使世界更接近于为所有人创造一个更美好的未来——一个更健康和更公平的未来。确保LLMs在我们的医疗保健中理想地利用所有道德上良好和正确的事物，需要持续的对话、警惕和共同的努力。</p>
<p>1 参见 Pouyan Esmaeilzadeh, “基于人工智能工具在医疗保健中的应用：消费者视角的调查研究,” BMC 医学信息学与决策制定 20, no. 170 (2020), <a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1186/s12911-020-01191-1">https://link.springer.com/article/10.1186/s12911-020-01191-1</a>; 以及 Ashish K. Saxena, Stephanie Ness 和 Tushar Khinvasara, “人工智能的影响：人工智能在医疗保健领域的革命性影响,” 工程研究与报告杂志 26, no. 3 (2024): 49–62, <a target="_blank" rel="noopener" href="http://asian.go4sending.com/id/eprint/2020">http://asian.go4sending.com/id/eprint/2020</a>.</p>
<p>2 丹尼尔·康，“LLM 代理可以自主黑客网站，”Medium，2024 年 2 月 13 日，<a target="_blank" rel="noopener" href="https://medium.com/@danieldkang/llm-agents-can-autonomously-hack-websites-ab33fadb3062%E3%80%82">https://medium.com/@danieldkang/llm-agents-can-autonomously-hack-websites-ab33fadb3062。</a></p>
<p>3 “暗网，”维基百科，2024 年 6 月 4 日，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Dark_web%E3%80%82">https://en.wikipedia.org/wiki/Dark_web。</a></p>
<p>4 玛格丽特·米切尔，“伦理人工智能并不是谷歌Gemini灾难的罪魁祸首，” 时代，2024 年 2 月 29 日，<a target="_blank" rel="noopener" href="https://time.com/6836153/ethical-ai-google-gemini-debacle%E3%80%82">https://time.com/6836153/ethical-ai-google-gemini-debacle。</a></p>
<p>5 米切尔，“伦理人工智能并不是谷歌Gemini灾难的罪魁祸首。”</p>
<p>6 Bijit Ghosh，LinkedIn，个人资料，访问日期：2024 年 6 月 29 日，<a target="_blank" rel="noopener" href="https://www.linkedin.com/in/bijit-ghosh-48281a78%E3%80%82">https://www.linkedin.com/in/bijit-ghosh-48281a78。</a></p>
<p>7 约书亚·甘斯和杰弗里·S·斯科尔，“人工智能与回形针问题，”CEPR，2028 年 6 月 10 日，<a target="_blank" rel="noopener" href="https://cepr.org/voxeu/columns/ai-and-paperclip-problem%E3%80%82">https://cepr.org/voxeu/columns/ai-and-paperclip-problem。</a></p>
<p>8 由牛津大学的哲学家尼克·博斯特罗姆（2014 年）构思。</p>
<p>9 “什么是人工通用智能（AGI）？”谷歌云，访问日期：2024 年 7 月 9 日，<a target="_blank" rel="noopener" href="https://cloud.google.com/discover/what-is-artificial-general-intelligence%E3%80%82">https://cloud.google.com/discover/what-is-artificial-general-intelligence。</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Howard Huang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">638k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">19:19</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">
    <!--由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动-->
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.umd.js" integrity="sha256-+2+qOqR8CKoHh/AsVR9k2qaDBKWjYNC2nozhYmv5j9k=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
